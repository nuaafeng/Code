{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PINN_train_process: 100%|\u001b[31m██████████\u001b[0m| 30000/30000 [01:46<00:00, 281.85it/s, Loss=592.03595] \n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "def sample(n):\n",
    "    x = torch.rand(n,1).to(device)\n",
    "    y = torch.rand(n,1).to(device)\n",
    "    return x.requires_grad_(True),y.requires_grad_(True)\n",
    "def lx(u):\n",
    "    x,y = sample(100)\n",
    "    cond = (2*x).to(device)\n",
    "    xy =torch.cat([x,y],dim=1)\n",
    "    f = u(xy)\n",
    "    dfdx = torch.autograd.grad(f,x,retain_graph=True,grad_outputs=torch.ones_like(f),create_graph=True,only_inputs=True)[0]\n",
    "    return loss(dfdx,cond)\n",
    "def ly(u):\n",
    "    x,y = sample(100)\n",
    "    cond = (2*y).to(device)\n",
    "    xy =torch.cat([x,y],dim=1)\n",
    "    f = u(xy)\n",
    "    dfdy = torch.autograd.grad(f,y,retain_graph=True,grad_outputs=torch.ones_like(f),create_graph=True,only_inputs=True)[0]\n",
    "    return loss(dfdy,cond)\n",
    "\n",
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,1)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "u = model().to(device)\n",
    "opt = torch.optim.Adam(params=u.parameters())\n",
    "loss = torch.nn.MSELoss()\n",
    "Lmin= math.inf\n",
    "pbar = tqdm(list(range(30000)), desc='PINN_train_process', colour='red')\n",
    "for i in pbar:\n",
    "    opt.zero_grad()\n",
    "    x = 100*torch.rand(1000,1).to(device)\n",
    "    y = 100*torch.rand(1000,1).to(device)\n",
    "    f_r = (x**2 + y**2).to(device)\n",
    "    xy =torch.cat([x,y],dim=1)\n",
    "\n",
    "    l2 = lx(u) + ly(u)\n",
    "    f = u (xy).to(device)\n",
    "    L = loss(f,f_r) + l2\n",
    "    L.backward()\n",
    "    opt.step()\n",
    "    pbar.set_postfix({'Loss':L.cpu().detach().numpy()})\n",
    "    if Lmin>L:\n",
    "        Lmin = L\n",
    "        torch.save(u.state_dict(), './x**2+y**2-models.ckpt')\n",
    "\n",
    "u = model().to(device)\n",
    "u.load_state_dict(torch.load('./x**2+y**2-models.ckpt'))\n",
    "x1 = 100*torch.rand(1000,1).to(device)\n",
    "y1 = 100*torch.rand(1000,1).to(device)\n",
    "x1y1 = torch.cat([x1,y1],dim=1)\n",
    "slove = u(x1y1)\n",
    "losstest = loss(slove,(x1**2+y1**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(1)\n",
    "slove = slove.detach().numpy()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x1,y1,t)\n",
    "ax.scatter(x1,y1,slove)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
