{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchdiffeq import odeint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "config = {\n",
    "    'seed': 102110,      # Your seed number, you can pick your lucky number. :)\n",
    "    'select_all': True,   # Whether to use all features.\n",
    "    'valid_ratio': 0.2,   # validation_size = train_size * valid_ratio\n",
    "    'n_epochs': 5000,     # Number of epochs.            \n",
    "    'batch_size': 20, \n",
    "    'batch_time':10,\n",
    "    'learning_rate': 1e-3,              \n",
    "    'early_stop': 600,    # If model has not improved for this many consecutive epochs, stop training.     \n",
    "    'save_path': './models/model.ckpt',  # Your model will be saved here.\n",
    "    'data_size':1000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_size = config['data_size']\n",
    "batch_time = config['batch_time']\n",
    "t = torch.linspace(0., 25., data_size).to(device)#creat a t tensor  size of data_size then to device   \n",
    "dataset = torch.tensor(pd.read_excel('data1.xlsx').values)\n",
    "dataset = dataset.to(torch.float32)\n",
    "true_y = dataset[0:1000,26].view(1000, 1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class Lamda(nn.Module):\n",
    "#   def forward(self, t, y):\n",
    "#      return torch.mm(y, true_A)\n",
    "\n",
    "def get_batch():\n",
    "    s = torch.from_numpy(np.random.choice(np.arange(data_size - batch_time), config['batch_size'], replace=False))\n",
    "    batch_y0 = true_y[s]\n",
    "    batch_t = t[:batch_time]\n",
    "    batch_y = torch.stack([true_y[s + i] for i in range(batch_time)], dim=0)\n",
    "    return  batch_y0.to(device), batch_t.to(device), batch_y.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 近似状态变量微分的网络\n",
    "- 魔改\n",
    "- 最后的输出是状态变量对时间的导数即可\n",
    "- 网络的输入可以不直接使用状态变量,在求解器的前后可以加入网络结构增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEFunc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ODEFunc, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, t, x):\n",
    "        x = self.net(x)\n",
    "        #x = x.squeeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 求解器训练结构\n",
    "- 最后的输出不能squeeze或者unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Node_trainer():\n",
    "    L_min = math.inf\n",
    "    #i = list(range(config['n_epochs']))\n",
    "    pbar = tqdm(list(range(config['n_epochs'])),desc='trainprocess', colour='red')\n",
    "    for i in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        batch_y0, batch_t, batch_y = get_batch()\n",
    "        pred_y = odeint(func, batch_y0, batch_t).to(device)   #ode求解器（可选伴随灵敏矩阵形式）\n",
    "        loss = torch.mean(torch.abs(pred_y - batch_y))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix({'Loss':loss.cpu().detach().numpy()})\n",
    "        writer.add_scalar('Loss/Node',loss,i)\n",
    "        if loss < L_min:\n",
    "            L_min = loss\n",
    "            torch.save(func.state_dict(), config['save_path'])\n",
    "    writer.close()\n",
    "\n",
    "func  = ODEFunc().to(device)\n",
    "optimizer = optim.RMSprop(func.parameters(),lr=config['learning_rate'])\n",
    "end = time.time()\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\n",
    "Node_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([436, 855, 426,  38, 357,  94,  84,  29, 180, 535, 955, 351, 684, 921,\n",
      "        198,  81, 630, 764, 968, 958])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "batch_y0, batch_t, batch_y = get_batch()\n",
    "s = torch.from_numpy(np.random.choice(np.arange(data_size - batch_time), config['batch_size'], replace=False))\n",
    "print(s)\n",
    "batch_y0 = true_y[s]\n",
    "print(batch_t.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
