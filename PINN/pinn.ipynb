{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x,y需要梯度则加上requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "import torch.nn as nn\n",
    "# 定义区域及其上的采样  \n",
    "def interior(n=1000):  \n",
    "    x = torch.rand((n, 1),requires_grad=True)  \n",
    "    y = torch.rand((n, 1),requires_grad=True)  \n",
    "    cond = (2 - x ** 2) * torch.exp(-y)  \n",
    "    return x.requires_grad_(True), y.requires_grad_(True), cond\n",
    "class My_Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(My_Model,self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.linear = nn.Linear(4,1)\n",
    "    def forward(self,t,x):\n",
    "        x = self.model(t)\n",
    "        t = self.model(t)\n",
    "        x = x.squeeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.MSELoss()\n",
    "net = My_Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.cat(x,y，dim=)拼接在某个维度上拼接\n",
    "torch.autograd.grad(y,x,retain_graph)\n",
    "torch.autograd.grad(y,x,grad_outpus=)\n",
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0114],\n",
      "        [1.7716],\n",
      "        [0.9457],\n",
      "        [1.0429],\n",
      "        [0.4107],\n",
      "        [0.3175],\n",
      "        [0.5872],\n",
      "        [1.9440],\n",
      "        [1.1875],\n",
      "        [1.3997],\n",
      "        [0.5947],\n",
      "        [1.8001],\n",
      "        [0.3485],\n",
      "        [1.1431],\n",
      "        [1.7195],\n",
      "        [1.8550],\n",
      "        [1.7673],\n",
      "        [1.0429],\n",
      "        [1.4071],\n",
      "        [0.1061],\n",
      "        [0.4783],\n",
      "        [1.4740],\n",
      "        [0.6096],\n",
      "        [1.5558],\n",
      "        [1.8467],\n",
      "        [1.5582],\n",
      "        [0.0411],\n",
      "        [1.4726],\n",
      "        [0.9960],\n",
      "        [1.7653],\n",
      "        [1.4992],\n",
      "        [0.8663],\n",
      "        [1.6457],\n",
      "        [1.0960],\n",
      "        [1.4748],\n",
      "        [0.1825],\n",
      "        [0.8266],\n",
      "        [1.4211],\n",
      "        [0.7607],\n",
      "        [0.1250],\n",
      "        [1.6897],\n",
      "        [0.5911],\n",
      "        [0.2998],\n",
      "        [0.4760],\n",
      "        [0.1172],\n",
      "        [0.4716],\n",
      "        [0.7044],\n",
      "        [0.7442],\n",
      "        [1.7329],\n",
      "        [1.8056],\n",
      "        [1.6695],\n",
      "        [1.0702],\n",
      "        [0.9433],\n",
      "        [1.6633],\n",
      "        [0.3016],\n",
      "        [1.5184],\n",
      "        [1.5908],\n",
      "        [0.8191],\n",
      "        [1.1994],\n",
      "        [0.4290],\n",
      "        [1.6723],\n",
      "        [1.6219],\n",
      "        [1.8066],\n",
      "        [0.1206],\n",
      "        [1.7549],\n",
      "        [1.1925],\n",
      "        [0.8947],\n",
      "        [0.8043],\n",
      "        [1.7543],\n",
      "        [1.4812],\n",
      "        [1.3950],\n",
      "        [1.7929],\n",
      "        [0.0499],\n",
      "        [1.1762],\n",
      "        [1.3431],\n",
      "        [1.5911],\n",
      "        [0.2346],\n",
      "        [0.9826],\n",
      "        [1.3485],\n",
      "        [1.9622],\n",
      "        [0.4259],\n",
      "        [1.6933],\n",
      "        [1.9285],\n",
      "        [1.5382],\n",
      "        [1.9388],\n",
      "        [0.9629],\n",
      "        [0.0555],\n",
      "        [1.8718],\n",
      "        [1.9366],\n",
      "        [1.1003],\n",
      "        [0.9426],\n",
      "        [0.5185],\n",
      "        [0.9007],\n",
      "        [1.0998],\n",
      "        [1.2630],\n",
      "        [1.9415],\n",
      "        [0.1750],\n",
      "        [1.9995],\n",
      "        [0.7887],\n",
      "        [0.0847]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "x = torch.rand(100,1).requires_grad_(True)\n",
    "y = x**2\n",
    "z = torch.ones_like(y)\n",
    "dydx = torch.autograd.grad(y,x,grad_outputs=z)\n",
    "print(dydx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lossL: tensor(61618432., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "1 lossL: tensor(61832784., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2 lossL: tensor(63335264., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3 lossL: tensor(64546260., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4 lossL: tensor(63415820., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5 lossL: tensor(63022816., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6 lossL: tensor(62083700., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7 lossL: tensor(61394288., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8 lossL: tensor(64580868., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9 lossL: tensor(60551184., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10 lossL: tensor(60852728., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11 lossL: tensor(60972536., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12 lossL: tensor(58755964., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "13 lossL: tensor(59845608., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14 lossL: tensor(62746992., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15 lossL: tensor(62971624., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16 lossL: tensor(58935056., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17 lossL: tensor(61994704., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18 lossL: tensor(61889436., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19 lossL: tensor(59355756., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20 lossL: tensor(63466692., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21 lossL: tensor(61300088., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22 lossL: tensor(61355276., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23 lossL: tensor(62388200., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24 lossL: tensor(58108664., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "25 lossL: tensor(63705596., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26 lossL: tensor(63967280., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27 lossL: tensor(65133092., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28 lossL: tensor(66151312., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29 lossL: tensor(61186412., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "30 lossL: tensor(61291792., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "31 lossL: tensor(62294216., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "32 lossL: tensor(63962664., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "33 lossL: tensor(63047264., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "34 lossL: tensor(61634880., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "35 lossL: tensor(66356760., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "36 lossL: tensor(63345256., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "37 lossL: tensor(59557576., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "38 lossL: tensor(60999572., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "39 lossL: tensor(63136528., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "40 lossL: tensor(62674628., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "41 lossL: tensor(61804808., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "42 lossL: tensor(60900720., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "43 lossL: tensor(61288668., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "44 lossL: tensor(62182476., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "45 lossL: tensor(59194348., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "46 lossL: tensor(63651012., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "47 lossL: tensor(64990636., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "48 lossL: tensor(62361628., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "49 lossL: tensor(63197652., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "50 lossL: tensor(60426416., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "51 lossL: tensor(56242624., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "52 lossL: tensor(61883308., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "53 lossL: tensor(61901648., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "54 lossL: tensor(61273540., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "55 lossL: tensor(61589476., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "56 lossL: tensor(61323800., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "57 lossL: tensor(61555740., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "58 lossL: tensor(58513968., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "59 lossL: tensor(63145860., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "60 lossL: tensor(58888416., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "61 lossL: tensor(61519596., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "62 lossL: tensor(59018788., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "63 lossL: tensor(62421608., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "64 lossL: tensor(61034188., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "65 lossL: tensor(63732572., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "66 lossL: tensor(62750528., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "67 lossL: tensor(57852684., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "68 lossL: tensor(58213528., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "69 lossL: tensor(62273084., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "70 lossL: tensor(57551556., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "71 lossL: tensor(62433260., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "72 lossL: tensor(61112300., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "73 lossL: tensor(59370960., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "74 lossL: tensor(56959700., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "75 lossL: tensor(60033004., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "76 lossL: tensor(62707780., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "77 lossL: tensor(61487656., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "78 lossL: tensor(61549664., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "79 lossL: tensor(61917404., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "80 lossL: tensor(59949068., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "81 lossL: tensor(61464848., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "82 lossL: tensor(58476920., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "83 lossL: tensor(63223852., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "84 lossL: tensor(59609092., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "85 lossL: tensor(63706036., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "86 lossL: tensor(56980900., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "87 lossL: tensor(63463492., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "88 lossL: tensor(64123416., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "89 lossL: tensor(63305828., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "90 lossL: tensor(59528640., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "91 lossL: tensor(62430932., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "92 lossL: tensor(60589496., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "93 lossL: tensor(67864216., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "94 lossL: tensor(61272092., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "95 lossL: tensor(58695704., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "96 lossL: tensor(56965800., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "97 lossL: tensor(59035700., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "98 lossL: tensor(58750988., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "99 lossL: tensor(60402248., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "100 lossL: tensor(61159092., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "101 lossL: tensor(62780000., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "102 lossL: tensor(64736452., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "103 lossL: tensor(61735472., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "104 lossL: tensor(60391024., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "105 lossL: tensor(60718844., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "106 lossL: tensor(63158056., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "107 lossL: tensor(58336192., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "108 lossL: tensor(60022940., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "109 lossL: tensor(61748744., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "110 lossL: tensor(58892988., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "111 lossL: tensor(62304852., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "112 lossL: tensor(60461736., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "113 lossL: tensor(60699756., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "114 lossL: tensor(60813128., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "115 lossL: tensor(58281920., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "116 lossL: tensor(61922356., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "117 lossL: tensor(61028136., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "118 lossL: tensor(63013904., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "119 lossL: tensor(56980096., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "120 lossL: tensor(60897900., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "121 lossL: tensor(57476764., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "122 lossL: tensor(61438792., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "123 lossL: tensor(60402616., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "124 lossL: tensor(58055044., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "125 lossL: tensor(60095428., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "126 lossL: tensor(60574048., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "127 lossL: tensor(58287476., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "128 lossL: tensor(61285448., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "129 lossL: tensor(63046952., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "130 lossL: tensor(59205388., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "131 lossL: tensor(59691928., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "132 lossL: tensor(59217592., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "133 lossL: tensor(60872148., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "134 lossL: tensor(59846560., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "135 lossL: tensor(60856152., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "136 lossL: tensor(58912220., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "137 lossL: tensor(62067760., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "138 lossL: tensor(63667940., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "139 lossL: tensor(60465992., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "140 lossL: tensor(58877956., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "141 lossL: tensor(53896832., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "142 lossL: tensor(59623008., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "143 lossL: tensor(59629408., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "144 lossL: tensor(60439868., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "145 lossL: tensor(61085856., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "146 lossL: tensor(57468340., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "147 lossL: tensor(61273028., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "148 lossL: tensor(57832896., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "149 lossL: tensor(56699816., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "150 lossL: tensor(59273516., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "151 lossL: tensor(57938312., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "152 lossL: tensor(61699952., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "153 lossL: tensor(56411076., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "154 lossL: tensor(57633148., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "155 lossL: tensor(57401576., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "156 lossL: tensor(58792992., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "157 lossL: tensor(57504900., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "158 lossL: tensor(58345040., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "159 lossL: tensor(61368360., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "160 lossL: tensor(55903984., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "161 lossL: tensor(57526384., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "162 lossL: tensor(59532784., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "163 lossL: tensor(60645604., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "164 lossL: tensor(55884884., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "165 lossL: tensor(54561560., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "166 lossL: tensor(58574672., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "167 lossL: tensor(56049356., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "168 lossL: tensor(56013612., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "169 lossL: tensor(58463816., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "170 lossL: tensor(56309220., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "171 lossL: tensor(54947520., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "172 lossL: tensor(53856396., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "173 lossL: tensor(57283988., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "174 lossL: tensor(55724804., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "175 lossL: tensor(53603224., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "176 lossL: tensor(58390916., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "177 lossL: tensor(56036060., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "178 lossL: tensor(54296608., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "179 lossL: tensor(55761640., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "180 lossL: tensor(55904552., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "181 lossL: tensor(59324800., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "182 lossL: tensor(53970660., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "183 lossL: tensor(55625764., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "184 lossL: tensor(55561784., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "185 lossL: tensor(54887744., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "186 lossL: tensor(55973012., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "187 lossL: tensor(57055940., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "188 lossL: tensor(57978240., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "189 lossL: tensor(57544248., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "190 lossL: tensor(52751520., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "191 lossL: tensor(55896796., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "192 lossL: tensor(52295816., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "193 lossL: tensor(58258524., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "194 lossL: tensor(53961896., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "195 lossL: tensor(53470380., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "196 lossL: tensor(50568956., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "197 lossL: tensor(56799612., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "198 lossL: tensor(53116960., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "199 lossL: tensor(56842704., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "200 lossL: tensor(54190068., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "201 lossL: tensor(53157036., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "202 lossL: tensor(52999884., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "203 lossL: tensor(50773384., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "204 lossL: tensor(55548024., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "205 lossL: tensor(50005264., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "206 lossL: tensor(55135320., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "207 lossL: tensor(52532012., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "208 lossL: tensor(52418736., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "209 lossL: tensor(50825820., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "210 lossL: tensor(53277700., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "211 lossL: tensor(52048424., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "212 lossL: tensor(54523900., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "213 lossL: tensor(52751716., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "214 lossL: tensor(53683276., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "215 lossL: tensor(51993488., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "216 lossL: tensor(47931512., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "217 lossL: tensor(50065000., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "218 lossL: tensor(49061628., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "219 lossL: tensor(53204052., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "220 lossL: tensor(50186372., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "221 lossL: tensor(51902828., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "222 lossL: tensor(49393912., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "223 lossL: tensor(51888536., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "224 lossL: tensor(51418904., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "225 lossL: tensor(49275184., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "226 lossL: tensor(45676468., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "227 lossL: tensor(46999452., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "228 lossL: tensor(52194672., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "229 lossL: tensor(48410176., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "230 lossL: tensor(49278920., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "231 lossL: tensor(51170248., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "232 lossL: tensor(49269484., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "233 lossL: tensor(47532616., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "234 lossL: tensor(49211600., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "235 lossL: tensor(47635308., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "236 lossL: tensor(47112084., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "237 lossL: tensor(48057416., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "238 lossL: tensor(48281612., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "239 lossL: tensor(48157908., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "240 lossL: tensor(47344120., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "241 lossL: tensor(45052084., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "242 lossL: tensor(47174200., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "243 lossL: tensor(46282728., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "244 lossL: tensor(45681984., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "245 lossL: tensor(48041416., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "246 lossL: tensor(42980044., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "247 lossL: tensor(48208784., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "248 lossL: tensor(46831584., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "249 lossL: tensor(45771188., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "250 lossL: tensor(46548512., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "251 lossL: tensor(45551220., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "252 lossL: tensor(44703124., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "253 lossL: tensor(43630840., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "254 lossL: tensor(43905824., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "255 lossL: tensor(43920524., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "256 lossL: tensor(41629488., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "257 lossL: tensor(40296168., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "258 lossL: tensor(43534712., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "259 lossL: tensor(43565524., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "260 lossL: tensor(43948316., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "261 lossL: tensor(41441888., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "262 lossL: tensor(44819996., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "263 lossL: tensor(41913804., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "264 lossL: tensor(42610804., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "265 lossL: tensor(42186628., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "266 lossL: tensor(39902712., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "267 lossL: tensor(40544284., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "268 lossL: tensor(42705728., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "269 lossL: tensor(39181200., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "270 lossL: tensor(41857936., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "271 lossL: tensor(42070632., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "272 lossL: tensor(37360948., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "273 lossL: tensor(37402160., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "274 lossL: tensor(38379076., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "275 lossL: tensor(41658364., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "276 lossL: tensor(38313040., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "277 lossL: tensor(42055964., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "278 lossL: tensor(39766076., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "279 lossL: tensor(38939556., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "280 lossL: tensor(37368912., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "281 lossL: tensor(39374096., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "282 lossL: tensor(39268852., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "283 lossL: tensor(36539248., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "284 lossL: tensor(36227028., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "285 lossL: tensor(37415952., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "286 lossL: tensor(34856444., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "287 lossL: tensor(36973980., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "288 lossL: tensor(37919388., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "289 lossL: tensor(38975064., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "290 lossL: tensor(36447172., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "291 lossL: tensor(37924420., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "292 lossL: tensor(36919460., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "293 lossL: tensor(36521868., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "294 lossL: tensor(33818552., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "295 lossL: tensor(34589900., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "296 lossL: tensor(33862700., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "297 lossL: tensor(37501724., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "298 lossL: tensor(34853816., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "299 lossL: tensor(35067488., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "300 lossL: tensor(35174944., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "301 lossL: tensor(33706916., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "302 lossL: tensor(31894936., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "303 lossL: tensor(33945100., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "304 lossL: tensor(32108568., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "305 lossL: tensor(32823126., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "306 lossL: tensor(33573128., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "307 lossL: tensor(34230268., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "308 lossL: tensor(32910862., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "309 lossL: tensor(32770500., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "310 lossL: tensor(31889230., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "311 lossL: tensor(31267510., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "312 lossL: tensor(33947236., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "313 lossL: tensor(31790902., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "314 lossL: tensor(30925934., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "315 lossL: tensor(30085952., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "316 lossL: tensor(30318216., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "317 lossL: tensor(31280874., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "318 lossL: tensor(31017816., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "319 lossL: tensor(29358352., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "320 lossL: tensor(30218892., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "321 lossL: tensor(30677188., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "322 lossL: tensor(29410064., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "323 lossL: tensor(28783824., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "324 lossL: tensor(29810202., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "325 lossL: tensor(27676518., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "326 lossL: tensor(28413640., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "327 lossL: tensor(25306018., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "328 lossL: tensor(28110966., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "329 lossL: tensor(28419582., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "330 lossL: tensor(26063006., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "331 lossL: tensor(25300972., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "332 lossL: tensor(26119236., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "333 lossL: tensor(25491050., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "334 lossL: tensor(25271132., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "335 lossL: tensor(25288778., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "336 lossL: tensor(25815042., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "337 lossL: tensor(26532102., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "338 lossL: tensor(24497460., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "339 lossL: tensor(23898554., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "340 lossL: tensor(24374326., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "341 lossL: tensor(25130166., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "342 lossL: tensor(23579162., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "343 lossL: tensor(23699148., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "344 lossL: tensor(24418164., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "345 lossL: tensor(24069682., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "346 lossL: tensor(24086444., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "347 lossL: tensor(23236874., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "348 lossL: tensor(22733002., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "349 lossL: tensor(22661770., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "350 lossL: tensor(21167860., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "351 lossL: tensor(20075426., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "352 lossL: tensor(21704302., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "353 lossL: tensor(21080542., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "354 lossL: tensor(20367032., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "355 lossL: tensor(21440398., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "356 lossL: tensor(19435154., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "357 lossL: tensor(19972640., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "358 lossL: tensor(20247020., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "359 lossL: tensor(19454564., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "360 lossL: tensor(19529630., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "361 lossL: tensor(19040988., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "362 lossL: tensor(18796254., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "363 lossL: tensor(18799018., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "364 lossL: tensor(18726494., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "365 lossL: tensor(17832238., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "366 lossL: tensor(19242226., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "367 lossL: tensor(18767102., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "368 lossL: tensor(20447510., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "369 lossL: tensor(19240278., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "370 lossL: tensor(18479004., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "371 lossL: tensor(17829368., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "372 lossL: tensor(17729538., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "373 lossL: tensor(17170264., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "374 lossL: tensor(17522092., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "375 lossL: tensor(16964822., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "376 lossL: tensor(16721888., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "377 lossL: tensor(17531038., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "378 lossL: tensor(16265255., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "379 lossL: tensor(15974970., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "380 lossL: tensor(14184595., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "381 lossL: tensor(17272290., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "382 lossL: tensor(14949211., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "383 lossL: tensor(15412874., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "384 lossL: tensor(15504578., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "385 lossL: tensor(15355940., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "386 lossL: tensor(14616018., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "387 lossL: tensor(13680287., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "388 lossL: tensor(12943940., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "389 lossL: tensor(13981986., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "390 lossL: tensor(13349676., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "391 lossL: tensor(13379571., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "392 lossL: tensor(13459564., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "393 lossL: tensor(13626088., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "394 lossL: tensor(13719567., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "395 lossL: tensor(13016639., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "396 lossL: tensor(12453290., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "397 lossL: tensor(11850154., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "398 lossL: tensor(13211734., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "399 lossL: tensor(12180894., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "400 lossL: tensor(13856818., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "401 lossL: tensor(11889142., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "402 lossL: tensor(11153902., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "403 lossL: tensor(11688901., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "404 lossL: tensor(12294649., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "405 lossL: tensor(11386516., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "406 lossL: tensor(11218191., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "407 lossL: tensor(11618929., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "408 lossL: tensor(10572650., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "409 lossL: tensor(10579533., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "410 lossL: tensor(10931341., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "411 lossL: tensor(10202151., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "412 lossL: tensor(11366805., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "413 lossL: tensor(9807674., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "414 lossL: tensor(9245907., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "415 lossL: tensor(10308578., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "416 lossL: tensor(10006727., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "417 lossL: tensor(9951815., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "418 lossL: tensor(10129031., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "419 lossL: tensor(9687245., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "420 lossL: tensor(9257828., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "421 lossL: tensor(9041063., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "422 lossL: tensor(9054773., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "423 lossL: tensor(8279843., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "424 lossL: tensor(9262451., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "425 lossL: tensor(8499746., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "426 lossL: tensor(8980733., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "427 lossL: tensor(8782505., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "428 lossL: tensor(8526705., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "429 lossL: tensor(7817577., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "430 lossL: tensor(8643763., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "431 lossL: tensor(7942370., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "432 lossL: tensor(7884764.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "433 lossL: tensor(7604030.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "434 lossL: tensor(8837476., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "435 lossL: tensor(7145972., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "436 lossL: tensor(7451888.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "437 lossL: tensor(7344859.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "438 lossL: tensor(6859775., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "439 lossL: tensor(6911847.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "440 lossL: tensor(6930092., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "441 lossL: tensor(7567537.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "442 lossL: tensor(7178179.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "443 lossL: tensor(7717668., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "444 lossL: tensor(6561485., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "445 lossL: tensor(7206768., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "446 lossL: tensor(6955711., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "447 lossL: tensor(6679953.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "448 lossL: tensor(7017380., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "449 lossL: tensor(6680043.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "450 lossL: tensor(6176911., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "451 lossL: tensor(6088289., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "452 lossL: tensor(6366141.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "453 lossL: tensor(6017691.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "454 lossL: tensor(5896681.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "455 lossL: tensor(5307151., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "456 lossL: tensor(5786659., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "457 lossL: tensor(5368248.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "458 lossL: tensor(5927265.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "459 lossL: tensor(5532672.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "460 lossL: tensor(5299439.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "461 lossL: tensor(5157983.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "462 lossL: tensor(5430279.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "463 lossL: tensor(5173861.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "464 lossL: tensor(5040094., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "465 lossL: tensor(5522776.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "466 lossL: tensor(5230507.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "467 lossL: tensor(5490666., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "468 lossL: tensor(5459918., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "469 lossL: tensor(4723552., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "470 lossL: tensor(5155622.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "471 lossL: tensor(4878638., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "472 lossL: tensor(5361740., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "473 lossL: tensor(4771703.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "474 lossL: tensor(4949881., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "475 lossL: tensor(4611381.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "476 lossL: tensor(4545196., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "477 lossL: tensor(4498095.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "478 lossL: tensor(4463141., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "479 lossL: tensor(4357024.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "480 lossL: tensor(4220940.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "481 lossL: tensor(4428464., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "482 lossL: tensor(4600530.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "483 lossL: tensor(4207645.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "484 lossL: tensor(4740642., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "485 lossL: tensor(3968288.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "486 lossL: tensor(4073560.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "487 lossL: tensor(3617030.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "488 lossL: tensor(3952048.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "489 lossL: tensor(4616465.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "490 lossL: tensor(3850915., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "491 lossL: tensor(4293548.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "492 lossL: tensor(3396864., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "493 lossL: tensor(4106668.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "494 lossL: tensor(3793628.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "495 lossL: tensor(4123174.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "496 lossL: tensor(3778128.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "497 lossL: tensor(3951682., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "498 lossL: tensor(3631444., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "499 lossL: tensor(3751115.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "500 lossL: tensor(3700905.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "501 lossL: tensor(3455434.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "502 lossL: tensor(3846362.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "503 lossL: tensor(3688883.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "504 lossL: tensor(3531485., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "505 lossL: tensor(3599153.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "506 lossL: tensor(3678401., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "507 lossL: tensor(3528610.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "508 lossL: tensor(3423406.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "509 lossL: tensor(3459255., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "510 lossL: tensor(3401107.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "511 lossL: tensor(3557105.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "512 lossL: tensor(3026716.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "513 lossL: tensor(3577128.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "514 lossL: tensor(3389714., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "515 lossL: tensor(3241397.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "516 lossL: tensor(3244738.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "517 lossL: tensor(3957926.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "518 lossL: tensor(3272781., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "519 lossL: tensor(3325510.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "520 lossL: tensor(3392930.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "521 lossL: tensor(3075028.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "522 lossL: tensor(3224276.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "523 lossL: tensor(3061366.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "524 lossL: tensor(3036338.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "525 lossL: tensor(3387735.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "526 lossL: tensor(2973940.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "527 lossL: tensor(2833461.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "528 lossL: tensor(3213347.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "529 lossL: tensor(3192384.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "530 lossL: tensor(3056163., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "531 lossL: tensor(3149293.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "532 lossL: tensor(3053077.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "533 lossL: tensor(2995542.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "534 lossL: tensor(3089212.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "535 lossL: tensor(2895147.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "536 lossL: tensor(3049822.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "537 lossL: tensor(2924655.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "538 lossL: tensor(3011687.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "539 lossL: tensor(2840575.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "540 lossL: tensor(3239729., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "541 lossL: tensor(3114968.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "542 lossL: tensor(3102932., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "543 lossL: tensor(3197796., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "544 lossL: tensor(3053780.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "545 lossL: tensor(2999779.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "546 lossL: tensor(3065782.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "547 lossL: tensor(3011567.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "548 lossL: tensor(2985233.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "549 lossL: tensor(2925268., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "550 lossL: tensor(3156241.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "551 lossL: tensor(3037858.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "552 lossL: tensor(3097946.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "553 lossL: tensor(2857620.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "554 lossL: tensor(2770116.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "555 lossL: tensor(2957190.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "556 lossL: tensor(2827045.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "557 lossL: tensor(2932781.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "558 lossL: tensor(3037774.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "559 lossL: tensor(2863924.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "560 lossL: tensor(2859601.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "561 lossL: tensor(2952482.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "562 lossL: tensor(2890958.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "563 lossL: tensor(2882099.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "564 lossL: tensor(2976486.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "565 lossL: tensor(2875045.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "566 lossL: tensor(2818774.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "567 lossL: tensor(2754869.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "568 lossL: tensor(2998628.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "569 lossL: tensor(2846503.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "570 lossL: tensor(2942053., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "571 lossL: tensor(2862972.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "572 lossL: tensor(2824840.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "573 lossL: tensor(2847955.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "574 lossL: tensor(2749902.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "575 lossL: tensor(2941841.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "576 lossL: tensor(2954476.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "577 lossL: tensor(2821093.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "578 lossL: tensor(2821746., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "579 lossL: tensor(2833762., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "580 lossL: tensor(2782237.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "581 lossL: tensor(2877211.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "582 lossL: tensor(2974068.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "583 lossL: tensor(2799174., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "584 lossL: tensor(2873844.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "585 lossL: tensor(2938629.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "586 lossL: tensor(2759934., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "587 lossL: tensor(2772480., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "588 lossL: tensor(2827915.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "589 lossL: tensor(2892166.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "590 lossL: tensor(2714300.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "591 lossL: tensor(2709523.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "592 lossL: tensor(2793463., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "593 lossL: tensor(2881923.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "594 lossL: tensor(2715824.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "595 lossL: tensor(2848149.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "596 lossL: tensor(2756401.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "597 lossL: tensor(2823659.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "598 lossL: tensor(2818140.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "599 lossL: tensor(3042309.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "600 lossL: tensor(2707040., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "601 lossL: tensor(2725271.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "602 lossL: tensor(2725692.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "603 lossL: tensor(2899791., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "604 lossL: tensor(2844710.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "605 lossL: tensor(2691005.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "606 lossL: tensor(2753915.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "607 lossL: tensor(2539769., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "608 lossL: tensor(2803980.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "609 lossL: tensor(2808862.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "610 lossL: tensor(3081396.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "611 lossL: tensor(2877701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "612 lossL: tensor(2651299.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "613 lossL: tensor(2798917.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "614 lossL: tensor(2863442., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "615 lossL: tensor(2744213.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "616 lossL: tensor(2761611.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "617 lossL: tensor(2749462.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "618 lossL: tensor(2853648., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "619 lossL: tensor(2968306.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "620 lossL: tensor(2823902.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "621 lossL: tensor(2738187.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "622 lossL: tensor(2622215.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "623 lossL: tensor(2844001.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "624 lossL: tensor(2650543.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "625 lossL: tensor(2848793.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "626 lossL: tensor(2940842.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "627 lossL: tensor(2671768.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "628 lossL: tensor(2746668.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "629 lossL: tensor(2843168., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "630 lossL: tensor(2814155.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "631 lossL: tensor(2761598.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "632 lossL: tensor(2844541.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "633 lossL: tensor(2762951.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "634 lossL: tensor(2707916.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "635 lossL: tensor(2902062., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "636 lossL: tensor(2704917.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "637 lossL: tensor(2796457.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "638 lossL: tensor(2628556.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "639 lossL: tensor(2697861.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "640 lossL: tensor(2762159.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "641 lossL: tensor(2749009.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "642 lossL: tensor(2918221., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "643 lossL: tensor(2713260.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "644 lossL: tensor(2923637., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "645 lossL: tensor(2887987., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "646 lossL: tensor(2618236.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "647 lossL: tensor(2535352.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "648 lossL: tensor(2769432.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "649 lossL: tensor(2646946.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "650 lossL: tensor(2764978.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "651 lossL: tensor(2833234.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "652 lossL: tensor(2827451.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "653 lossL: tensor(2699200., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "654 lossL: tensor(2849094.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "655 lossL: tensor(2708568., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "656 lossL: tensor(2667891.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "657 lossL: tensor(2716767.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "658 lossL: tensor(2973973.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "659 lossL: tensor(2745651.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "660 lossL: tensor(2609142.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "661 lossL: tensor(2719359., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "662 lossL: tensor(2888535.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "663 lossL: tensor(2738714.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "664 lossL: tensor(2800162.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "665 lossL: tensor(2629088.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "666 lossL: tensor(2829673., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "667 lossL: tensor(3049397.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "668 lossL: tensor(2927784.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "669 lossL: tensor(2858054.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "670 lossL: tensor(2806096.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "671 lossL: tensor(2822708.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "672 lossL: tensor(3130673., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "673 lossL: tensor(2616106.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "674 lossL: tensor(2783362.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "675 lossL: tensor(2773986.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "676 lossL: tensor(2714461.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "677 lossL: tensor(2829645.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "678 lossL: tensor(2827741.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "679 lossL: tensor(2652439.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "680 lossL: tensor(2756633., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "681 lossL: tensor(2698905.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "682 lossL: tensor(2718392.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "683 lossL: tensor(2857039.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "684 lossL: tensor(2704211., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "685 lossL: tensor(2698251.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "686 lossL: tensor(2700469.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "687 lossL: tensor(2817503., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "688 lossL: tensor(2845775.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "689 lossL: tensor(2768920.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "690 lossL: tensor(2775767.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "691 lossL: tensor(2744667.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "692 lossL: tensor(3002120., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "693 lossL: tensor(2655584.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "694 lossL: tensor(2986172.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "695 lossL: tensor(2835349.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "696 lossL: tensor(2735738.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "697 lossL: tensor(2911022.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "698 lossL: tensor(2814527.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "699 lossL: tensor(2686158.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "700 lossL: tensor(2664341.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "701 lossL: tensor(2543442.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "702 lossL: tensor(2738611., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "703 lossL: tensor(2823170.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "704 lossL: tensor(2524396., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "705 lossL: tensor(2736845.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "706 lossL: tensor(2838159., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "707 lossL: tensor(2765672.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "708 lossL: tensor(2924030.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "709 lossL: tensor(2687730.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "710 lossL: tensor(2840632., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "711 lossL: tensor(2709237., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "712 lossL: tensor(2767584.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "713 lossL: tensor(2836725.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "714 lossL: tensor(3020416., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "715 lossL: tensor(2730884.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "716 lossL: tensor(2898061., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "717 lossL: tensor(2821020.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "718 lossL: tensor(2619034., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "719 lossL: tensor(2704587., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "720 lossL: tensor(2803984.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "721 lossL: tensor(2819747.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "722 lossL: tensor(2884426.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "723 lossL: tensor(2970748.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "724 lossL: tensor(2992644.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "725 lossL: tensor(2821670.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "726 lossL: tensor(2828285.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "727 lossL: tensor(2701389.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "728 lossL: tensor(2568906.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "729 lossL: tensor(2834155.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "730 lossL: tensor(2934866., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "731 lossL: tensor(2781850.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "732 lossL: tensor(2673914., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "733 lossL: tensor(2755791., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "734 lossL: tensor(2687916.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "735 lossL: tensor(2763428.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "736 lossL: tensor(2750053.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "737 lossL: tensor(2829748., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "738 lossL: tensor(2772601.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "739 lossL: tensor(2833434.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "740 lossL: tensor(2687988.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "741 lossL: tensor(2813972.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "742 lossL: tensor(2750634., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "743 lossL: tensor(2674941.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "744 lossL: tensor(2722765.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "745 lossL: tensor(2813743., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "746 lossL: tensor(2811402., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "747 lossL: tensor(3019509., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "748 lossL: tensor(2804062.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "749 lossL: tensor(2659756.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "750 lossL: tensor(2913572.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "751 lossL: tensor(2988366.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "752 lossL: tensor(2768558.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "753 lossL: tensor(2682092., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "754 lossL: tensor(2847071.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "755 lossL: tensor(2824348., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "756 lossL: tensor(2769470., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "757 lossL: tensor(2738521.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "758 lossL: tensor(2915130.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "759 lossL: tensor(2801449.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "760 lossL: tensor(2715214.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "761 lossL: tensor(2985732.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "762 lossL: tensor(2776670., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "763 lossL: tensor(2989601., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "764 lossL: tensor(2659746., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "765 lossL: tensor(2727657., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "766 lossL: tensor(2691939.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "767 lossL: tensor(2747535.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "768 lossL: tensor(2817942.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "769 lossL: tensor(2715493., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "770 lossL: tensor(2584292.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "771 lossL: tensor(2787254.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "772 lossL: tensor(2781680.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "773 lossL: tensor(2730780.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "774 lossL: tensor(2791106.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "775 lossL: tensor(2798678.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "776 lossL: tensor(2782500.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "777 lossL: tensor(2970676.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "778 lossL: tensor(2731825., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "779 lossL: tensor(2749010.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "780 lossL: tensor(2749702., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "781 lossL: tensor(2864081., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "782 lossL: tensor(2621731., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "783 lossL: tensor(2771806.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "784 lossL: tensor(2784561.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "785 lossL: tensor(2633280., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "786 lossL: tensor(2848382.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "787 lossL: tensor(2683971.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "788 lossL: tensor(2846733., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "789 lossL: tensor(3051781., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "790 lossL: tensor(2672048.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "791 lossL: tensor(2679743., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "792 lossL: tensor(2741638., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "793 lossL: tensor(2741503.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "794 lossL: tensor(2685042.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "795 lossL: tensor(2707727.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "796 lossL: tensor(2799286.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "797 lossL: tensor(2649595.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "798 lossL: tensor(2764161.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "799 lossL: tensor(2844139., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "800 lossL: tensor(2780310.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "801 lossL: tensor(2747791.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "802 lossL: tensor(2979380.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "803 lossL: tensor(2819163., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "804 lossL: tensor(2929500.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "805 lossL: tensor(2831399.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "806 lossL: tensor(2755377.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "807 lossL: tensor(2748850.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "808 lossL: tensor(2585277.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "809 lossL: tensor(2721683.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "810 lossL: tensor(2724895., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "811 lossL: tensor(2658939.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "812 lossL: tensor(2670096.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "813 lossL: tensor(2683884., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "814 lossL: tensor(2753682., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "815 lossL: tensor(2759735.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "816 lossL: tensor(2740147.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "817 lossL: tensor(2721974., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "818 lossL: tensor(2678090.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "819 lossL: tensor(2865563.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "820 lossL: tensor(3167673.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "821 lossL: tensor(2758207.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "822 lossL: tensor(2887952.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "823 lossL: tensor(2761281.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "824 lossL: tensor(2924365.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "825 lossL: tensor(2732265., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "826 lossL: tensor(2869734.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "827 lossL: tensor(2696927., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "828 lossL: tensor(2688759.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "829 lossL: tensor(2626153.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "830 lossL: tensor(2835073., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "831 lossL: tensor(2844826., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "832 lossL: tensor(2840792., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "833 lossL: tensor(2803369.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "834 lossL: tensor(2647127.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "835 lossL: tensor(2789586.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "836 lossL: tensor(2789815., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "837 lossL: tensor(2824560., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "838 lossL: tensor(2748201.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "839 lossL: tensor(2926686.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "840 lossL: tensor(2672389.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "841 lossL: tensor(2919881.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "842 lossL: tensor(2909995.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "843 lossL: tensor(2740591.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "844 lossL: tensor(2789859.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "845 lossL: tensor(2749199.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "846 lossL: tensor(2677370.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "847 lossL: tensor(2803625.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "848 lossL: tensor(2716339.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "849 lossL: tensor(2785525.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "850 lossL: tensor(2748930.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "851 lossL: tensor(2807991., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "852 lossL: tensor(2722477.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "853 lossL: tensor(2723691.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "854 lossL: tensor(2817820.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "855 lossL: tensor(2707421.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "856 lossL: tensor(2391982.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "857 lossL: tensor(2663939.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "858 lossL: tensor(2791812.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "859 lossL: tensor(2852558.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "860 lossL: tensor(2815899., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "861 lossL: tensor(2698995.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "862 lossL: tensor(2774929.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "863 lossL: tensor(2680281.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "864 lossL: tensor(2777683.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "865 lossL: tensor(2523091.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "866 lossL: tensor(2845299.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "867 lossL: tensor(2730868.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "868 lossL: tensor(2788410.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "869 lossL: tensor(2877845.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "870 lossL: tensor(2711577.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "871 lossL: tensor(2707604.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "872 lossL: tensor(2960043.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "873 lossL: tensor(2882092., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "874 lossL: tensor(2721778.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "875 lossL: tensor(2663257., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "876 lossL: tensor(2721061., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "877 lossL: tensor(2813514.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "878 lossL: tensor(2718498.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "879 lossL: tensor(2878703.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "880 lossL: tensor(2501187., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "881 lossL: tensor(2933372.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "882 lossL: tensor(2811342.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "883 lossL: tensor(2785849.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "884 lossL: tensor(2748907.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "885 lossL: tensor(2912719.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "886 lossL: tensor(2601657.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "887 lossL: tensor(2726665., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "888 lossL: tensor(2665231.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "889 lossL: tensor(2667766., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "890 lossL: tensor(2670464.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "891 lossL: tensor(2766577.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "892 lossL: tensor(2707494., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "893 lossL: tensor(2815552.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "894 lossL: tensor(2651284., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "895 lossL: tensor(2744114.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "896 lossL: tensor(2763128.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "897 lossL: tensor(2824719.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "898 lossL: tensor(2574165.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "899 lossL: tensor(2757677.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "900 lossL: tensor(2768362., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "901 lossL: tensor(2763572.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "902 lossL: tensor(2722287.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "903 lossL: tensor(2864078., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "904 lossL: tensor(2589007., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "905 lossL: tensor(2849322.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "906 lossL: tensor(2853552.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "907 lossL: tensor(2802664.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "908 lossL: tensor(2863961.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "909 lossL: tensor(2708472.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "910 lossL: tensor(2893564.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "911 lossL: tensor(2769764.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "912 lossL: tensor(2777910.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "913 lossL: tensor(2804863.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "914 lossL: tensor(2705933.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "915 lossL: tensor(2781014., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "916 lossL: tensor(2723244.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "917 lossL: tensor(2877695., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "918 lossL: tensor(2830197.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "919 lossL: tensor(2766656., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "920 lossL: tensor(2745523.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "921 lossL: tensor(2873012.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "922 lossL: tensor(2722623., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "923 lossL: tensor(2894275.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "924 lossL: tensor(2780219.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "925 lossL: tensor(2762776.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "926 lossL: tensor(2828381.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "927 lossL: tensor(2773397.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "928 lossL: tensor(2865116., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "929 lossL: tensor(2737473.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "930 lossL: tensor(2708014.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "931 lossL: tensor(2880896.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "932 lossL: tensor(2839196.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "933 lossL: tensor(2776813.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "934 lossL: tensor(2668135., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "935 lossL: tensor(2802325.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "936 lossL: tensor(2650439.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "937 lossL: tensor(2754831.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "938 lossL: tensor(2839843., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "939 lossL: tensor(2717736.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "940 lossL: tensor(2864697.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "941 lossL: tensor(2616871.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "942 lossL: tensor(2930809., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "943 lossL: tensor(2793925.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "944 lossL: tensor(2702527., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "945 lossL: tensor(2899623.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "946 lossL: tensor(2748770., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "947 lossL: tensor(2845744.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "948 lossL: tensor(2688804.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "949 lossL: tensor(2830850.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "950 lossL: tensor(2951779.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "951 lossL: tensor(2885155., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "952 lossL: tensor(2609283.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "953 lossL: tensor(2704749.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "954 lossL: tensor(2724893.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "955 lossL: tensor(2864078.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "956 lossL: tensor(2699468., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "957 lossL: tensor(2668944.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "958 lossL: tensor(2670643., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "959 lossL: tensor(2692004., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "960 lossL: tensor(2686251.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "961 lossL: tensor(2828085.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "962 lossL: tensor(2710689.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "963 lossL: tensor(2792833.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "964 lossL: tensor(2742993.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "965 lossL: tensor(2959305.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "966 lossL: tensor(2676564.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "967 lossL: tensor(2662609.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "968 lossL: tensor(2690175.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "969 lossL: tensor(2814257.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "970 lossL: tensor(2851755.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "971 lossL: tensor(2710390.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "972 lossL: tensor(2799879.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "973 lossL: tensor(2801128.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "974 lossL: tensor(2585559.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "975 lossL: tensor(2754778.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "976 lossL: tensor(2728158.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "977 lossL: tensor(2579863.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "978 lossL: tensor(2758156., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "979 lossL: tensor(2734243.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "980 lossL: tensor(2785757.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "981 lossL: tensor(2727654.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "982 lossL: tensor(2726120., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "983 lossL: tensor(2741799.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "984 lossL: tensor(2731735.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "985 lossL: tensor(2770975.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "986 lossL: tensor(2872668.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "987 lossL: tensor(2849975.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "988 lossL: tensor(2859813., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "989 lossL: tensor(2797380.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "990 lossL: tensor(2636682., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "991 lossL: tensor(2938738.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "992 lossL: tensor(2732169.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "993 lossL: tensor(2647211.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "994 lossL: tensor(2688836.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "995 lossL: tensor(2722935., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "996 lossL: tensor(2915997.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "997 lossL: tensor(2757251.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "998 lossL: tensor(2854590.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "999 lossL: tensor(2789689.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1000 lossL: tensor(2771560., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1001 lossL: tensor(2578203.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1002 lossL: tensor(2484366.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1003 lossL: tensor(2643485.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1004 lossL: tensor(2767327.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1005 lossL: tensor(2736120.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1006 lossL: tensor(2874249., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1007 lossL: tensor(2865637.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1008 lossL: tensor(2622069.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1009 lossL: tensor(2890290.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1010 lossL: tensor(2901881., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1011 lossL: tensor(2681382.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1012 lossL: tensor(2899186.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1013 lossL: tensor(2881305., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1014 lossL: tensor(2993264.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1015 lossL: tensor(2918407., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1016 lossL: tensor(2722150., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1017 lossL: tensor(2768317.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1018 lossL: tensor(2811483.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1019 lossL: tensor(2811611.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1020 lossL: tensor(2798711.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1021 lossL: tensor(2882379.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1022 lossL: tensor(2789011.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1023 lossL: tensor(2819439.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1024 lossL: tensor(2803946.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1025 lossL: tensor(2634945.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1026 lossL: tensor(2885661.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1027 lossL: tensor(2605185.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1028 lossL: tensor(2745846.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1029 lossL: tensor(2577616.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1030 lossL: tensor(2571844.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1031 lossL: tensor(2903607., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1032 lossL: tensor(2716680.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1033 lossL: tensor(2795310., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1034 lossL: tensor(2674633., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1035 lossL: tensor(2691308.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1036 lossL: tensor(3004339., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1037 lossL: tensor(2628745.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1038 lossL: tensor(2603558.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1039 lossL: tensor(2777603., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1040 lossL: tensor(2817497.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1041 lossL: tensor(2816201., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1042 lossL: tensor(2766339., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1043 lossL: tensor(2692472.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1044 lossL: tensor(2766420.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1045 lossL: tensor(2807666., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1046 lossL: tensor(2775347.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1047 lossL: tensor(2874149.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1048 lossL: tensor(2799250.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1049 lossL: tensor(2809310.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1050 lossL: tensor(2831720.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1051 lossL: tensor(2661547.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1052 lossL: tensor(2947519.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1053 lossL: tensor(2769320.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1054 lossL: tensor(2873023.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1055 lossL: tensor(2830819.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1056 lossL: tensor(2707193., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1057 lossL: tensor(2942705.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1058 lossL: tensor(2732364., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1059 lossL: tensor(2630712., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1060 lossL: tensor(2908453., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1061 lossL: tensor(2805558.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1062 lossL: tensor(2884456.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1063 lossL: tensor(2742399., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1064 lossL: tensor(2662044.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1065 lossL: tensor(2957215., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1066 lossL: tensor(2799778.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1067 lossL: tensor(2916567.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1068 lossL: tensor(2952926., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1069 lossL: tensor(2746776.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1070 lossL: tensor(2717795.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1071 lossL: tensor(2744600., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1072 lossL: tensor(2744519.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1073 lossL: tensor(2741168.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1074 lossL: tensor(2624552.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1075 lossL: tensor(2711938.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1076 lossL: tensor(2649022.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1077 lossL: tensor(2646133.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1078 lossL: tensor(2809235.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1079 lossL: tensor(2719213., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1080 lossL: tensor(2685847., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1081 lossL: tensor(2765107.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1082 lossL: tensor(2721904.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1083 lossL: tensor(2741229.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1084 lossL: tensor(2974337.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1085 lossL: tensor(2684950.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1086 lossL: tensor(2869084.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1087 lossL: tensor(2893583.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1088 lossL: tensor(2813977., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1089 lossL: tensor(2715941.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1090 lossL: tensor(2796940.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1091 lossL: tensor(2800483., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1092 lossL: tensor(2682553., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1093 lossL: tensor(2859971., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1094 lossL: tensor(2789145.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1095 lossL: tensor(2598696.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1096 lossL: tensor(2913500., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1097 lossL: tensor(2809894.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1098 lossL: tensor(2697782.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1099 lossL: tensor(2614523.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1100 lossL: tensor(2686047., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1101 lossL: tensor(2846267.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1102 lossL: tensor(2732246.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1103 lossL: tensor(2655088.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1104 lossL: tensor(2747689.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1105 lossL: tensor(2855760.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1106 lossL: tensor(2708247., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1107 lossL: tensor(2753187.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1108 lossL: tensor(2752349.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1109 lossL: tensor(2904219.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1110 lossL: tensor(2660304.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1111 lossL: tensor(2904391.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1112 lossL: tensor(2606981.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1113 lossL: tensor(2616871.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1114 lossL: tensor(2691387.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1115 lossL: tensor(2643070., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1116 lossL: tensor(2753314.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1117 lossL: tensor(2671603., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1118 lossL: tensor(2769730.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1119 lossL: tensor(2662715., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1120 lossL: tensor(2902913., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1121 lossL: tensor(2818052.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1122 lossL: tensor(2849420.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1123 lossL: tensor(2858953., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1124 lossL: tensor(2675315.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1125 lossL: tensor(2713323.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1126 lossL: tensor(2699436.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1127 lossL: tensor(2745341.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1128 lossL: tensor(2704960.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1129 lossL: tensor(2733120.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1130 lossL: tensor(2745571., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1131 lossL: tensor(2777917.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1132 lossL: tensor(2734681., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1133 lossL: tensor(2875784., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1134 lossL: tensor(2725288.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1135 lossL: tensor(2875252.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1136 lossL: tensor(2665317.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1137 lossL: tensor(2724478., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1138 lossL: tensor(2727164., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1139 lossL: tensor(2869717.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1140 lossL: tensor(2756032.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1141 lossL: tensor(2712382.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1142 lossL: tensor(2862091.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1143 lossL: tensor(2866873.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1144 lossL: tensor(2777202.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1145 lossL: tensor(2833416.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1146 lossL: tensor(2645598., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1147 lossL: tensor(2849868.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1148 lossL: tensor(2811759., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1149 lossL: tensor(2830974., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1150 lossL: tensor(2822260.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1151 lossL: tensor(2667225.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1152 lossL: tensor(2675932.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1153 lossL: tensor(2658838.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1154 lossL: tensor(2806112., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1155 lossL: tensor(2958688.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1156 lossL: tensor(2779437.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1157 lossL: tensor(2703136.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1158 lossL: tensor(2768161.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1159 lossL: tensor(2822618.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1160 lossL: tensor(2696133.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1161 lossL: tensor(2711660.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1162 lossL: tensor(2641500., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1163 lossL: tensor(2753352.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1164 lossL: tensor(2799422., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1165 lossL: tensor(2688238.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1166 lossL: tensor(2908480.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1167 lossL: tensor(2769878., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1168 lossL: tensor(2773288.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1169 lossL: tensor(2808393., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1170 lossL: tensor(2707704.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1171 lossL: tensor(2724949.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1172 lossL: tensor(2594372.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1173 lossL: tensor(2577827.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1174 lossL: tensor(2490105., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1175 lossL: tensor(2656794.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1176 lossL: tensor(2677291.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1177 lossL: tensor(2758855., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1178 lossL: tensor(2569838.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1179 lossL: tensor(2820391., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1180 lossL: tensor(2751082.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1181 lossL: tensor(2816439.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1182 lossL: tensor(2616843.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1183 lossL: tensor(2702342.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1184 lossL: tensor(2738569., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1185 lossL: tensor(2598531.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1186 lossL: tensor(2724482., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1187 lossL: tensor(2783685.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1188 lossL: tensor(2878841.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1189 lossL: tensor(2818027.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1190 lossL: tensor(2662071.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1191 lossL: tensor(2890383.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1192 lossL: tensor(2831768.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1193 lossL: tensor(2652218., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1194 lossL: tensor(2816754., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1195 lossL: tensor(2640908.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1196 lossL: tensor(2804040.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1197 lossL: tensor(2747312., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1198 lossL: tensor(2652499.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1199 lossL: tensor(2766575.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1200 lossL: tensor(2727653.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1201 lossL: tensor(2827328., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1202 lossL: tensor(2570699.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1203 lossL: tensor(2723831.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1204 lossL: tensor(2685225.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1205 lossL: tensor(2922375., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1206 lossL: tensor(2762747., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1207 lossL: tensor(2552797.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1208 lossL: tensor(2797434.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1209 lossL: tensor(2695001.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1210 lossL: tensor(2772630.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1211 lossL: tensor(2775619.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1212 lossL: tensor(2825300.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1213 lossL: tensor(2706118.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1214 lossL: tensor(2764788.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1215 lossL: tensor(2776015., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1216 lossL: tensor(2633393.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1217 lossL: tensor(2776085.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1218 lossL: tensor(2735371.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1219 lossL: tensor(2768486., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1220 lossL: tensor(2747846.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1221 lossL: tensor(2610233.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1222 lossL: tensor(2754100., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1223 lossL: tensor(2749044.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1224 lossL: tensor(2783553.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1225 lossL: tensor(2993642.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1226 lossL: tensor(2794496.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1227 lossL: tensor(2683800.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1228 lossL: tensor(2651182.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1229 lossL: tensor(2682863.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1230 lossL: tensor(2726567., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1231 lossL: tensor(2761291.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1232 lossL: tensor(2711407.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1233 lossL: tensor(2644701.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1234 lossL: tensor(2573549.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1235 lossL: tensor(2857253.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1236 lossL: tensor(2793787.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1237 lossL: tensor(2752166., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1238 lossL: tensor(2624342.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1239 lossL: tensor(2523167.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1240 lossL: tensor(2839374., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1241 lossL: tensor(2678871.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1242 lossL: tensor(2734816.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1243 lossL: tensor(2867319.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1244 lossL: tensor(2726116.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1245 lossL: tensor(2715136.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1246 lossL: tensor(2701670.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1247 lossL: tensor(2737987.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1248 lossL: tensor(2798868.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1249 lossL: tensor(2720373., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1250 lossL: tensor(2708278.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1251 lossL: tensor(2629169., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1252 lossL: tensor(2763868.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1253 lossL: tensor(2766477.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1254 lossL: tensor(2788004.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1255 lossL: tensor(2601860.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1256 lossL: tensor(2651565.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1257 lossL: tensor(2663292., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1258 lossL: tensor(2688840.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1259 lossL: tensor(2780508., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1260 lossL: tensor(2919335., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1261 lossL: tensor(2610246., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1262 lossL: tensor(2818780.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1263 lossL: tensor(2816881.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1264 lossL: tensor(2724415.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1265 lossL: tensor(2668499.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1266 lossL: tensor(2708905., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1267 lossL: tensor(2784146.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1268 lossL: tensor(2850584., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1269 lossL: tensor(2703054.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1270 lossL: tensor(2825188.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1271 lossL: tensor(2683347.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1272 lossL: tensor(2771325., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1273 lossL: tensor(2828804.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1274 lossL: tensor(2835942.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1275 lossL: tensor(2666667.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1276 lossL: tensor(2703161.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1277 lossL: tensor(2848667.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1278 lossL: tensor(2835617.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1279 lossL: tensor(2732552., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1280 lossL: tensor(2622645., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1281 lossL: tensor(2760411.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1282 lossL: tensor(2733477., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1283 lossL: tensor(2795991.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1284 lossL: tensor(2628764.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1285 lossL: tensor(2719629., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1286 lossL: tensor(2867907.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1287 lossL: tensor(2535029.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1288 lossL: tensor(2636134.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1289 lossL: tensor(2874111.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1290 lossL: tensor(2799711., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1291 lossL: tensor(2814469.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1292 lossL: tensor(2864599., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1293 lossL: tensor(2768118.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1294 lossL: tensor(2627427.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1295 lossL: tensor(2894834.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1296 lossL: tensor(2804460.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1297 lossL: tensor(2886993.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1298 lossL: tensor(2836685., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1299 lossL: tensor(2706321.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1300 lossL: tensor(2849795., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1301 lossL: tensor(2702529.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1302 lossL: tensor(2908180., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1303 lossL: tensor(2554698.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1304 lossL: tensor(2898701.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1305 lossL: tensor(2799277.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1306 lossL: tensor(2694629.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1307 lossL: tensor(2494025.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1308 lossL: tensor(2608752., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1309 lossL: tensor(2676725.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1310 lossL: tensor(2783474.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1311 lossL: tensor(2708248.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1312 lossL: tensor(2777698.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1313 lossL: tensor(2849637.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1314 lossL: tensor(2839700.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1315 lossL: tensor(2618093.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1316 lossL: tensor(2786143.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1317 lossL: tensor(2921572.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1318 lossL: tensor(2628261.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1319 lossL: tensor(2612606.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1320 lossL: tensor(2781267.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1321 lossL: tensor(2773333., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1322 lossL: tensor(2799090.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1323 lossL: tensor(2631700.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1324 lossL: tensor(2817083., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1325 lossL: tensor(2805351., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1326 lossL: tensor(2821009., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1327 lossL: tensor(2858687.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1328 lossL: tensor(2811983.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1329 lossL: tensor(2945679.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1330 lossL: tensor(2675998.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1331 lossL: tensor(2712086.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1332 lossL: tensor(2846787.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1333 lossL: tensor(2861077.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1334 lossL: tensor(2652380.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1335 lossL: tensor(2701745., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1336 lossL: tensor(2635976.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1337 lossL: tensor(2736821.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1338 lossL: tensor(2648536.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1339 lossL: tensor(2622124.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1340 lossL: tensor(2882531.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1341 lossL: tensor(2689688.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1342 lossL: tensor(2735751.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1343 lossL: tensor(2744805., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1344 lossL: tensor(2829231., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1345 lossL: tensor(2901163.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1346 lossL: tensor(2748651.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1347 lossL: tensor(2840326.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1348 lossL: tensor(2661408., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1349 lossL: tensor(2690947.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1350 lossL: tensor(2742377.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1351 lossL: tensor(2930216.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1352 lossL: tensor(2738646.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1353 lossL: tensor(2783026., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1354 lossL: tensor(2787132., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1355 lossL: tensor(2579977.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1356 lossL: tensor(2778618.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1357 lossL: tensor(2788031.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1358 lossL: tensor(2737360.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1359 lossL: tensor(2779828.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1360 lossL: tensor(2890711.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1361 lossL: tensor(2670608.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1362 lossL: tensor(2815088.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1363 lossL: tensor(2804954., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1364 lossL: tensor(2655097., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1365 lossL: tensor(2808013.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1366 lossL: tensor(2658933.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1367 lossL: tensor(2836402.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1368 lossL: tensor(2627523., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1369 lossL: tensor(2603055.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1370 lossL: tensor(2725856., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1371 lossL: tensor(2671903.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1372 lossL: tensor(2744934.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1373 lossL: tensor(2730005.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1374 lossL: tensor(2686336., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1375 lossL: tensor(2693353.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1376 lossL: tensor(2591501.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1377 lossL: tensor(2806736.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1378 lossL: tensor(2654295.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1379 lossL: tensor(2768578.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1380 lossL: tensor(2651580.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1381 lossL: tensor(2705961.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1382 lossL: tensor(2649959.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1383 lossL: tensor(2771026.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1384 lossL: tensor(2765451.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1385 lossL: tensor(2706330.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1386 lossL: tensor(2538949.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1387 lossL: tensor(2637764.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1388 lossL: tensor(2860768.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1389 lossL: tensor(2714543.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1390 lossL: tensor(2889233., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1391 lossL: tensor(2762320.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1392 lossL: tensor(2686675.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1393 lossL: tensor(2619604.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1394 lossL: tensor(2619240.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1395 lossL: tensor(2718757.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1396 lossL: tensor(2752848.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1397 lossL: tensor(2586548.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1398 lossL: tensor(2753187.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1399 lossL: tensor(2790805.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1400 lossL: tensor(2798753.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1401 lossL: tensor(2585455.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1402 lossL: tensor(2654807.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1403 lossL: tensor(2732498., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1404 lossL: tensor(2677139., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1405 lossL: tensor(2631549.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1406 lossL: tensor(2604928., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1407 lossL: tensor(2563870., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1408 lossL: tensor(2664843.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1409 lossL: tensor(2756205.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1410 lossL: tensor(2739090.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1411 lossL: tensor(2871634.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1412 lossL: tensor(2755397., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1413 lossL: tensor(2850310.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1414 lossL: tensor(2557398.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1415 lossL: tensor(2740526., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1416 lossL: tensor(2613197., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1417 lossL: tensor(2780093., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1418 lossL: tensor(2644688.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1419 lossL: tensor(2523469.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1420 lossL: tensor(2813347., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1421 lossL: tensor(2666219.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1422 lossL: tensor(2890253.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1423 lossL: tensor(2806958.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1424 lossL: tensor(2629503.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1425 lossL: tensor(2719823.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1426 lossL: tensor(2852052.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1427 lossL: tensor(2703142.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1428 lossL: tensor(2826784.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1429 lossL: tensor(2779366.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1430 lossL: tensor(2563901.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1431 lossL: tensor(2634819.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1432 lossL: tensor(2773649.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1433 lossL: tensor(2822701.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1434 lossL: tensor(2629934.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1435 lossL: tensor(2715855., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1436 lossL: tensor(2733024.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1437 lossL: tensor(2671526.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1438 lossL: tensor(2820353.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1439 lossL: tensor(2677879.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1440 lossL: tensor(2709613.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1441 lossL: tensor(2688550.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1442 lossL: tensor(2855661., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1443 lossL: tensor(2630859.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1444 lossL: tensor(2612701.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1445 lossL: tensor(2660846.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1446 lossL: tensor(2766615.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1447 lossL: tensor(2588075.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1448 lossL: tensor(2784185., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1449 lossL: tensor(2877494., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1450 lossL: tensor(2919095.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1451 lossL: tensor(2812348.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1452 lossL: tensor(2804257.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1453 lossL: tensor(2784941.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1454 lossL: tensor(2728014.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1455 lossL: tensor(2902296.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1456 lossL: tensor(2686978., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1457 lossL: tensor(2615360.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1458 lossL: tensor(2768538.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1459 lossL: tensor(2661444.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1460 lossL: tensor(2720679.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1461 lossL: tensor(2669899.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1462 lossL: tensor(2736220.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1463 lossL: tensor(2670027.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1464 lossL: tensor(2631929., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1465 lossL: tensor(2602476., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1466 lossL: tensor(2684743.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1467 lossL: tensor(2702994.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1468 lossL: tensor(2820555.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1469 lossL: tensor(2856684.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1470 lossL: tensor(2676163.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1471 lossL: tensor(2717844.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1472 lossL: tensor(2663059.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1473 lossL: tensor(2715163.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1474 lossL: tensor(2837807.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1475 lossL: tensor(2688075.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1476 lossL: tensor(2710503.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1477 lossL: tensor(2756108.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1478 lossL: tensor(2556254., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1479 lossL: tensor(2761539.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1480 lossL: tensor(2705666., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1481 lossL: tensor(2704361.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1482 lossL: tensor(2882048.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1483 lossL: tensor(2921842., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1484 lossL: tensor(2620756.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1485 lossL: tensor(2554029.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1486 lossL: tensor(2600068.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1487 lossL: tensor(2865084.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1488 lossL: tensor(2701926., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1489 lossL: tensor(2822341.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1490 lossL: tensor(2661553.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1491 lossL: tensor(2715045., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1492 lossL: tensor(2715746.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1493 lossL: tensor(2710468.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1494 lossL: tensor(2838950.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1495 lossL: tensor(2547130., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1496 lossL: tensor(2678981.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1497 lossL: tensor(2676057.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1498 lossL: tensor(2855627., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1499 lossL: tensor(2772450.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1500 lossL: tensor(2783387.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1501 lossL: tensor(2782654.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1502 lossL: tensor(2890508.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1503 lossL: tensor(2766224.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1504 lossL: tensor(2805366., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1505 lossL: tensor(2631299.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1506 lossL: tensor(2769318.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1507 lossL: tensor(2733412.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1508 lossL: tensor(2679004.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1509 lossL: tensor(2694338.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1510 lossL: tensor(2770875.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1511 lossL: tensor(2793744.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1512 lossL: tensor(2918597.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1513 lossL: tensor(2716512.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1514 lossL: tensor(2785707.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1515 lossL: tensor(2717508., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1516 lossL: tensor(2769377., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1517 lossL: tensor(2834663.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1518 lossL: tensor(2737376., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1519 lossL: tensor(2664051.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1520 lossL: tensor(2703284.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1521 lossL: tensor(2660433.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1522 lossL: tensor(2685800., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1523 lossL: tensor(2629967.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1524 lossL: tensor(2805835.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1525 lossL: tensor(2731809.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1526 lossL: tensor(2795439., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1527 lossL: tensor(2578887.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1528 lossL: tensor(2742879.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1529 lossL: tensor(2769541.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1530 lossL: tensor(2893917.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1531 lossL: tensor(2844106.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1532 lossL: tensor(2736111.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1533 lossL: tensor(2557969.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1534 lossL: tensor(2683299.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1535 lossL: tensor(2698581.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1536 lossL: tensor(2649391.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1537 lossL: tensor(2708416.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1538 lossL: tensor(2683760.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1539 lossL: tensor(2600976.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1540 lossL: tensor(2749805., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1541 lossL: tensor(2705791.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1542 lossL: tensor(2717790., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1543 lossL: tensor(2653406.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1544 lossL: tensor(2629520.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1545 lossL: tensor(2739750.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1546 lossL: tensor(2648837.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1547 lossL: tensor(2847043.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1548 lossL: tensor(2494180.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1549 lossL: tensor(2659362., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1550 lossL: tensor(2604114.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1551 lossL: tensor(2841258.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1552 lossL: tensor(2725578.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1553 lossL: tensor(2951176.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1554 lossL: tensor(2875959.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1555 lossL: tensor(2482678.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1556 lossL: tensor(2716852.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1557 lossL: tensor(2853417.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1558 lossL: tensor(2599955., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1559 lossL: tensor(2834153.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1560 lossL: tensor(2685868.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1561 lossL: tensor(2815884.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1562 lossL: tensor(2698998.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1563 lossL: tensor(2718338.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1564 lossL: tensor(2565268.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1565 lossL: tensor(2726033.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1566 lossL: tensor(2874317.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1567 lossL: tensor(2767213., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1568 lossL: tensor(2743209.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1569 lossL: tensor(2880020., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1570 lossL: tensor(2787075.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1571 lossL: tensor(2589865., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1572 lossL: tensor(2858183.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1573 lossL: tensor(2800453.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1574 lossL: tensor(2956485.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1575 lossL: tensor(2729110., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1576 lossL: tensor(2697570., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1577 lossL: tensor(2678692.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1578 lossL: tensor(2878968., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1579 lossL: tensor(2620049.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1580 lossL: tensor(2775231., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1581 lossL: tensor(2809685.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1582 lossL: tensor(2708118.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1583 lossL: tensor(2638499.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1584 lossL: tensor(2630482.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1585 lossL: tensor(2793476.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1586 lossL: tensor(2530455.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1587 lossL: tensor(2807154.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1588 lossL: tensor(2858985.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1589 lossL: tensor(2685283.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1590 lossL: tensor(2623286.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1591 lossL: tensor(2533524.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1592 lossL: tensor(2605155.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1593 lossL: tensor(2709106., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1594 lossL: tensor(2589129., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1595 lossL: tensor(2737058.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1596 lossL: tensor(2626432., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1597 lossL: tensor(2641133.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1598 lossL: tensor(2714916.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1599 lossL: tensor(2822223.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1600 lossL: tensor(2698443.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1601 lossL: tensor(2671802.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1602 lossL: tensor(2711249.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1603 lossL: tensor(2802239.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1604 lossL: tensor(2802732.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1605 lossL: tensor(2772665.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1606 lossL: tensor(2679787., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1607 lossL: tensor(2778921., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1608 lossL: tensor(2753187., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1609 lossL: tensor(2778136.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1610 lossL: tensor(2841131., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1611 lossL: tensor(2724274.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1612 lossL: tensor(2715909.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1613 lossL: tensor(2734323.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1614 lossL: tensor(2532900.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1615 lossL: tensor(2906518.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1616 lossL: tensor(2777966.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1617 lossL: tensor(2796132.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1618 lossL: tensor(2842344.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1619 lossL: tensor(2774394.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1620 lossL: tensor(2677592., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1621 lossL: tensor(2630255.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1622 lossL: tensor(2882867., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1623 lossL: tensor(2774587.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1624 lossL: tensor(2750499., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1625 lossL: tensor(2702856.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1626 lossL: tensor(2513355., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1627 lossL: tensor(2688239.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1628 lossL: tensor(2602428., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1629 lossL: tensor(2851993., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1630 lossL: tensor(2691273.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1631 lossL: tensor(2852807.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1632 lossL: tensor(2757384.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1633 lossL: tensor(2881082.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1634 lossL: tensor(2734596.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1635 lossL: tensor(2887195., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1636 lossL: tensor(2693966.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1637 lossL: tensor(2796084.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1638 lossL: tensor(2677539., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1639 lossL: tensor(2807947.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1640 lossL: tensor(2593770.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1641 lossL: tensor(2949905.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1642 lossL: tensor(2788719.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1643 lossL: tensor(2831584.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1644 lossL: tensor(2806385.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1645 lossL: tensor(2528014., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1646 lossL: tensor(2571715.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1647 lossL: tensor(2849088.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1648 lossL: tensor(2802444.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1649 lossL: tensor(2715835.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1650 lossL: tensor(2756500., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1651 lossL: tensor(2837005., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1652 lossL: tensor(2573762.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1653 lossL: tensor(2730475.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1654 lossL: tensor(2476522.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1655 lossL: tensor(2750897., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1656 lossL: tensor(2877027.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1657 lossL: tensor(2645591.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1658 lossL: tensor(2778528.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1659 lossL: tensor(2676734., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1660 lossL: tensor(2848377.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1661 lossL: tensor(2707252.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1662 lossL: tensor(2836028.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1663 lossL: tensor(2641707.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1664 lossL: tensor(2769635., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1665 lossL: tensor(2558927.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1666 lossL: tensor(2833290., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1667 lossL: tensor(2796689.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1668 lossL: tensor(2815041.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1669 lossL: tensor(2701292.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1670 lossL: tensor(2799551.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1671 lossL: tensor(2664875.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1672 lossL: tensor(2738523.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1673 lossL: tensor(2758304.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1674 lossL: tensor(2852553.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1675 lossL: tensor(2753352.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1676 lossL: tensor(2786191.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1677 lossL: tensor(2674683.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1678 lossL: tensor(2707635., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1679 lossL: tensor(2666637.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1680 lossL: tensor(2788791.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1681 lossL: tensor(2853089., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1682 lossL: tensor(2673275.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1683 lossL: tensor(2624495.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1684 lossL: tensor(2608371., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1685 lossL: tensor(2690136.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1686 lossL: tensor(2886212.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1687 lossL: tensor(2779119.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1688 lossL: tensor(2789872.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1689 lossL: tensor(2590604.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1690 lossL: tensor(2778313., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1691 lossL: tensor(2687012.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1692 lossL: tensor(2837162.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1693 lossL: tensor(2716908.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1694 lossL: tensor(2786552.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1695 lossL: tensor(2678810.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1696 lossL: tensor(2720967.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1697 lossL: tensor(2574156., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1698 lossL: tensor(2590515.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1699 lossL: tensor(2639349., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1700 lossL: tensor(2575366.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1701 lossL: tensor(2799878.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1702 lossL: tensor(2708515.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1703 lossL: tensor(2723655.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1704 lossL: tensor(2865599., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1705 lossL: tensor(2833691.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1706 lossL: tensor(2668106., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1707 lossL: tensor(2739118.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1708 lossL: tensor(2686170.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1709 lossL: tensor(2798808.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1710 lossL: tensor(2576794.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1711 lossL: tensor(2684995.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1712 lossL: tensor(2742296., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1713 lossL: tensor(2831399.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1714 lossL: tensor(2725182.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1715 lossL: tensor(2819953., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1716 lossL: tensor(2671178.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1717 lossL: tensor(2689015.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1718 lossL: tensor(2732157.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1719 lossL: tensor(2548969.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1720 lossL: tensor(2720882.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1721 lossL: tensor(2689595., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1722 lossL: tensor(2736781.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1723 lossL: tensor(2749664., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1724 lossL: tensor(2609440.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1725 lossL: tensor(2513533.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1726 lossL: tensor(2732481.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1727 lossL: tensor(2699957.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1728 lossL: tensor(2820185.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1729 lossL: tensor(2844746.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1730 lossL: tensor(2659990.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1731 lossL: tensor(2500099., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1732 lossL: tensor(2744637.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1733 lossL: tensor(2697967.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1734 lossL: tensor(2704915.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1735 lossL: tensor(2716686.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1736 lossL: tensor(2719422.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1737 lossL: tensor(2774442.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1738 lossL: tensor(2725235.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1739 lossL: tensor(2674150.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1740 lossL: tensor(2601503., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1741 lossL: tensor(2726110.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1742 lossL: tensor(2692472., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1743 lossL: tensor(2654466.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1744 lossL: tensor(2704981., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1745 lossL: tensor(2708714.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1746 lossL: tensor(2819506., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1747 lossL: tensor(2685223., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1748 lossL: tensor(2851920.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1749 lossL: tensor(2647682.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1750 lossL: tensor(2620533.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1751 lossL: tensor(2683549.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1752 lossL: tensor(2753550.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1753 lossL: tensor(2827575.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1754 lossL: tensor(2728069.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1755 lossL: tensor(2772268.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1756 lossL: tensor(2815576.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1757 lossL: tensor(2793420.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1758 lossL: tensor(2523783.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1759 lossL: tensor(2755440.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1760 lossL: tensor(2724067.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1761 lossL: tensor(2698656.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1762 lossL: tensor(2794695.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1763 lossL: tensor(2712315.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1764 lossL: tensor(2646354.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1765 lossL: tensor(2759624., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1766 lossL: tensor(2748219.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1767 lossL: tensor(2754774.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1768 lossL: tensor(2759642.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1769 lossL: tensor(2707906.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1770 lossL: tensor(2896591.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1771 lossL: tensor(2467162.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1772 lossL: tensor(2739425.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1773 lossL: tensor(2731654.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1774 lossL: tensor(2742286.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1775 lossL: tensor(2725111.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1776 lossL: tensor(2655757.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1777 lossL: tensor(2779285., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1778 lossL: tensor(2676729.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1779 lossL: tensor(2520664.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1780 lossL: tensor(2611759.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1781 lossL: tensor(2800260., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1782 lossL: tensor(2728333.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1783 lossL: tensor(2692221.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1784 lossL: tensor(2716128., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1785 lossL: tensor(2808690.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1786 lossL: tensor(2660305., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1787 lossL: tensor(2826065., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1788 lossL: tensor(2631339.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1789 lossL: tensor(2827731.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1790 lossL: tensor(2713705.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1791 lossL: tensor(2643698.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1792 lossL: tensor(2848371., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1793 lossL: tensor(2732271.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1794 lossL: tensor(2697295.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1795 lossL: tensor(2693889.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1796 lossL: tensor(2805669.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1797 lossL: tensor(2859735., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1798 lossL: tensor(2790113., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1799 lossL: tensor(2590586., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1800 lossL: tensor(2627439., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1801 lossL: tensor(2783362.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1802 lossL: tensor(2858728.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1803 lossL: tensor(2628995., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1804 lossL: tensor(2713419.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1805 lossL: tensor(2953743.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1806 lossL: tensor(2656564.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1807 lossL: tensor(2746954.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1808 lossL: tensor(2577358.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1809 lossL: tensor(2847986.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1810 lossL: tensor(2775931., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1811 lossL: tensor(2773098., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1812 lossL: tensor(2791121.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1813 lossL: tensor(2677429.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1814 lossL: tensor(2891281.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1815 lossL: tensor(2782383., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1816 lossL: tensor(2485279.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1817 lossL: tensor(2847352., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1818 lossL: tensor(2822734.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1819 lossL: tensor(2667790., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1820 lossL: tensor(2777945., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1821 lossL: tensor(2685880.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1822 lossL: tensor(2794459., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1823 lossL: tensor(2767184.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1824 lossL: tensor(2867503.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1825 lossL: tensor(2768000., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1826 lossL: tensor(2770836., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1827 lossL: tensor(2701007.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1828 lossL: tensor(2763625.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1829 lossL: tensor(2764877., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1830 lossL: tensor(2717217., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1831 lossL: tensor(2606055., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1832 lossL: tensor(2771221., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1833 lossL: tensor(2913030.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1834 lossL: tensor(2585030.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1835 lossL: tensor(2791989., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1836 lossL: tensor(2449490.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1837 lossL: tensor(2794084.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1838 lossL: tensor(2499087.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1839 lossL: tensor(2913211.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1840 lossL: tensor(2806784.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1841 lossL: tensor(2559415.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1842 lossL: tensor(2711499.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1843 lossL: tensor(2746998., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1844 lossL: tensor(2723840.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1845 lossL: tensor(2729839.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1846 lossL: tensor(2746333., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1847 lossL: tensor(2805379.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1848 lossL: tensor(2742224.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1849 lossL: tensor(2726524., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1850 lossL: tensor(2875410.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1851 lossL: tensor(2677316.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1852 lossL: tensor(2846152., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1853 lossL: tensor(2654354.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1854 lossL: tensor(2690615.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1855 lossL: tensor(2672994.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1856 lossL: tensor(2679070.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1857 lossL: tensor(2668188.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1858 lossL: tensor(2644945., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1859 lossL: tensor(2805245.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1860 lossL: tensor(2749730.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1861 lossL: tensor(2720882., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1862 lossL: tensor(2687581.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1863 lossL: tensor(2641671., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1864 lossL: tensor(2773353., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1865 lossL: tensor(2836295.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1866 lossL: tensor(2508656., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1867 lossL: tensor(2768599.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1868 lossL: tensor(2771093.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1869 lossL: tensor(2750554., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1870 lossL: tensor(2664340.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1871 lossL: tensor(2548014., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1872 lossL: tensor(2733364.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1873 lossL: tensor(2579801.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1874 lossL: tensor(2763661.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1875 lossL: tensor(2803762.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1876 lossL: tensor(2544591.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1877 lossL: tensor(2751684.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1878 lossL: tensor(2793812., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1879 lossL: tensor(2680722.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1880 lossL: tensor(3004845., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1881 lossL: tensor(2622942.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1882 lossL: tensor(2871793.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1883 lossL: tensor(2668002., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1884 lossL: tensor(2660704.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1885 lossL: tensor(2888731.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1886 lossL: tensor(2837161., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1887 lossL: tensor(2798322., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1888 lossL: tensor(2663522.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1889 lossL: tensor(2746173.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1890 lossL: tensor(2651692.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1891 lossL: tensor(2705900.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1892 lossL: tensor(2543887., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1893 lossL: tensor(2660529., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1894 lossL: tensor(2716065., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1895 lossL: tensor(2811276.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1896 lossL: tensor(2809800., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1897 lossL: tensor(2721177.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1898 lossL: tensor(2682753.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1899 lossL: tensor(2660539., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1900 lossL: tensor(2754430.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1901 lossL: tensor(2698952.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1902 lossL: tensor(2587339., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1903 lossL: tensor(2603960., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1904 lossL: tensor(2696128.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1905 lossL: tensor(2774492.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1906 lossL: tensor(2702348.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1907 lossL: tensor(2592740.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1908 lossL: tensor(2875301.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1909 lossL: tensor(2758273.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1910 lossL: tensor(2677013.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1911 lossL: tensor(2670587.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1912 lossL: tensor(2877256.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1913 lossL: tensor(2904306.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1914 lossL: tensor(2591649.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1915 lossL: tensor(2980169., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1916 lossL: tensor(2869264.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1917 lossL: tensor(2747725., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1918 lossL: tensor(2714014.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1919 lossL: tensor(2557318.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1920 lossL: tensor(2683162.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1921 lossL: tensor(2725808.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1922 lossL: tensor(2607511.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1923 lossL: tensor(2722329.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1924 lossL: tensor(2579904.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1925 lossL: tensor(2919471., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1926 lossL: tensor(2599006.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1927 lossL: tensor(2776016.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1928 lossL: tensor(2641484.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1929 lossL: tensor(2856968.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1930 lossL: tensor(2761608.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1931 lossL: tensor(2618443., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1932 lossL: tensor(2748851., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1933 lossL: tensor(2645765.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1934 lossL: tensor(2831113.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1935 lossL: tensor(2649591.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1936 lossL: tensor(2737232., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1937 lossL: tensor(2745308.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1938 lossL: tensor(2779106.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1939 lossL: tensor(2653620.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1940 lossL: tensor(2507327.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1941 lossL: tensor(2597936., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1942 lossL: tensor(2657570., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1943 lossL: tensor(2803178.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1944 lossL: tensor(2756042., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1945 lossL: tensor(2595124.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1946 lossL: tensor(2619939., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1947 lossL: tensor(2876163.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1948 lossL: tensor(2790818.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1949 lossL: tensor(2660727., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1950 lossL: tensor(2619338.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1951 lossL: tensor(2744368.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1952 lossL: tensor(2781728., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1953 lossL: tensor(2697295.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1954 lossL: tensor(2694381.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1955 lossL: tensor(2714708.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1956 lossL: tensor(2512739.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1957 lossL: tensor(2769554., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1958 lossL: tensor(2715460.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1959 lossL: tensor(2939575.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1960 lossL: tensor(2726494.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1961 lossL: tensor(2685952.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1962 lossL: tensor(2779130.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1963 lossL: tensor(2653540., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1964 lossL: tensor(2721034., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1965 lossL: tensor(2728693.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1966 lossL: tensor(2617097., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1967 lossL: tensor(2717286.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1968 lossL: tensor(2876088., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1969 lossL: tensor(2630060.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1970 lossL: tensor(2655053., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1971 lossL: tensor(2665831.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1972 lossL: tensor(2666414., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1973 lossL: tensor(2655537., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1974 lossL: tensor(2693640.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1975 lossL: tensor(2768157.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1976 lossL: tensor(2727280., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1977 lossL: tensor(2697227.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1978 lossL: tensor(2638327.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1979 lossL: tensor(2689081.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1980 lossL: tensor(2504655., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1981 lossL: tensor(2551931.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1982 lossL: tensor(2704571.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1983 lossL: tensor(2690807.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1984 lossL: tensor(2664255.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1985 lossL: tensor(2691901., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1986 lossL: tensor(2769133.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1987 lossL: tensor(2629449.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1988 lossL: tensor(2556108.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1989 lossL: tensor(2608241.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1990 lossL: tensor(2734205.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1991 lossL: tensor(2765853.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1992 lossL: tensor(2829486.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1993 lossL: tensor(2900145.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1994 lossL: tensor(2620787.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1995 lossL: tensor(2829054., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1996 lossL: tensor(2725274.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1997 lossL: tensor(2874447.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1998 lossL: tensor(2622674., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "1999 lossL: tensor(2725020.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2000 lossL: tensor(2755918.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2001 lossL: tensor(2783529.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2002 lossL: tensor(2848931., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2003 lossL: tensor(2711822.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2004 lossL: tensor(2702599.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2005 lossL: tensor(2579091.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2006 lossL: tensor(2632605.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2007 lossL: tensor(2632340.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2008 lossL: tensor(2632484.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2009 lossL: tensor(2838798.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2010 lossL: tensor(2639482.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2011 lossL: tensor(2626368.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2012 lossL: tensor(2737232.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2013 lossL: tensor(2667393.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2014 lossL: tensor(2551415., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2015 lossL: tensor(2664849.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2016 lossL: tensor(2676624.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2017 lossL: tensor(2792345.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2018 lossL: tensor(2728251.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2019 lossL: tensor(2832342.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2020 lossL: tensor(2765935.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2021 lossL: tensor(2884502.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2022 lossL: tensor(2790556.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2023 lossL: tensor(2718382.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2024 lossL: tensor(2775213.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2025 lossL: tensor(2989968.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2026 lossL: tensor(2543921.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2027 lossL: tensor(2699040.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2028 lossL: tensor(2625267.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2029 lossL: tensor(2550776.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2030 lossL: tensor(2626080.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2031 lossL: tensor(2704044., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2032 lossL: tensor(2723255., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2033 lossL: tensor(2732305.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2034 lossL: tensor(2663252.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2035 lossL: tensor(2649047.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2036 lossL: tensor(2579485.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2037 lossL: tensor(2709079.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2038 lossL: tensor(2665854.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2039 lossL: tensor(2801486.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2040 lossL: tensor(2544213.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2041 lossL: tensor(2746734.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2042 lossL: tensor(2723275.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2043 lossL: tensor(2585163.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2044 lossL: tensor(2812860.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2045 lossL: tensor(2661000.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2046 lossL: tensor(2870691.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2047 lossL: tensor(2546864.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2048 lossL: tensor(2598128.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2049 lossL: tensor(2641626.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2050 lossL: tensor(2726308.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2051 lossL: tensor(2620791.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2052 lossL: tensor(2657135.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2053 lossL: tensor(2777051.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2054 lossL: tensor(2850404., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2055 lossL: tensor(2638143.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2056 lossL: tensor(2847597., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2057 lossL: tensor(2719484.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2058 lossL: tensor(2833719., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2059 lossL: tensor(2926037.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2060 lossL: tensor(2591321.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2061 lossL: tensor(2644929., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2062 lossL: tensor(2586908.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2063 lossL: tensor(2603363.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2064 lossL: tensor(2719734.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2065 lossL: tensor(2728029.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2066 lossL: tensor(2654348.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2067 lossL: tensor(2696963., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2068 lossL: tensor(2608141.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2069 lossL: tensor(2699469., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2070 lossL: tensor(2816685.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2071 lossL: tensor(2786059.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2072 lossL: tensor(2647972.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2073 lossL: tensor(2807156.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2074 lossL: tensor(2759293.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2075 lossL: tensor(2743227.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2076 lossL: tensor(2795248.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2077 lossL: tensor(2737151., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2078 lossL: tensor(2689144., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2079 lossL: tensor(2672772., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2080 lossL: tensor(2580579.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2081 lossL: tensor(2517673., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2082 lossL: tensor(2517857.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2083 lossL: tensor(2727032., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2084 lossL: tensor(2648846.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2085 lossL: tensor(2692041.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2086 lossL: tensor(2729491., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2087 lossL: tensor(2711623.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2088 lossL: tensor(2698500., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2089 lossL: tensor(2717221.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2090 lossL: tensor(2521244.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2091 lossL: tensor(2749370.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2092 lossL: tensor(2624443., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2093 lossL: tensor(2661523.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2094 lossL: tensor(2816639.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2095 lossL: tensor(2756883., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2096 lossL: tensor(2717791.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2097 lossL: tensor(2672150.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2098 lossL: tensor(2582118.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2099 lossL: tensor(2664716.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2100 lossL: tensor(2624145.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2101 lossL: tensor(2600423., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2102 lossL: tensor(2592573., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2103 lossL: tensor(2647127.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2104 lossL: tensor(2719327.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2105 lossL: tensor(2583020.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2106 lossL: tensor(2519638.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2107 lossL: tensor(2823560.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2108 lossL: tensor(2745014.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2109 lossL: tensor(2668361., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2110 lossL: tensor(2642905.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2111 lossL: tensor(2520336.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2112 lossL: tensor(2695254.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2113 lossL: tensor(2654712., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2114 lossL: tensor(2691344., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2115 lossL: tensor(2730642.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2116 lossL: tensor(2760834., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2117 lossL: tensor(2748214.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2118 lossL: tensor(2638436.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2119 lossL: tensor(2777141.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2120 lossL: tensor(2655562., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2121 lossL: tensor(2683253.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2122 lossL: tensor(2724071., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2123 lossL: tensor(2576299.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2124 lossL: tensor(2803814.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2125 lossL: tensor(2705462.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2126 lossL: tensor(2669135.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2127 lossL: tensor(2804797., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2128 lossL: tensor(2954818.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2129 lossL: tensor(2727099., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2130 lossL: tensor(2643036.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2131 lossL: tensor(2654535.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2132 lossL: tensor(2670338.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2133 lossL: tensor(2806974., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2134 lossL: tensor(2756013.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2135 lossL: tensor(2560107.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2136 lossL: tensor(2574518., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2137 lossL: tensor(2674203.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2138 lossL: tensor(2884451.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2139 lossL: tensor(2576737., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2140 lossL: tensor(2712072.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2141 lossL: tensor(2760607., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2142 lossL: tensor(2868443., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2143 lossL: tensor(2644410.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2144 lossL: tensor(2616144.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2145 lossL: tensor(2890760., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2146 lossL: tensor(2563553.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2147 lossL: tensor(2686086.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2148 lossL: tensor(2623384.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2149 lossL: tensor(2572537.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2150 lossL: tensor(2746186.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2151 lossL: tensor(2759279.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2152 lossL: tensor(2598487.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2153 lossL: tensor(2656153.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2154 lossL: tensor(2878224.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2155 lossL: tensor(2679851.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2156 lossL: tensor(2744830., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2157 lossL: tensor(2801368.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2158 lossL: tensor(2833800.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2159 lossL: tensor(2785219.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2160 lossL: tensor(2767800.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2161 lossL: tensor(2478955., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2162 lossL: tensor(2798436.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2163 lossL: tensor(2705079.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2164 lossL: tensor(2775332.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2165 lossL: tensor(2719781.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2166 lossL: tensor(2752397.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2167 lossL: tensor(2671301., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2168 lossL: tensor(2788957.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2169 lossL: tensor(2585640., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2170 lossL: tensor(2561121.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2171 lossL: tensor(2767080., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2172 lossL: tensor(2637971.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2173 lossL: tensor(2592727.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2174 lossL: tensor(2819748.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2175 lossL: tensor(2794918.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2176 lossL: tensor(2711315.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2177 lossL: tensor(2549659.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2178 lossL: tensor(2651380.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2179 lossL: tensor(2536254.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2180 lossL: tensor(2687761.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2181 lossL: tensor(2779902.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2182 lossL: tensor(2772316.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2183 lossL: tensor(2618814.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2184 lossL: tensor(2697980.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2185 lossL: tensor(2580901.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2186 lossL: tensor(2711369., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2187 lossL: tensor(2689805.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2188 lossL: tensor(2636104.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2189 lossL: tensor(2755906.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2190 lossL: tensor(2749634.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2191 lossL: tensor(2544143.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2192 lossL: tensor(2651380.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2193 lossL: tensor(2764819., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2194 lossL: tensor(2548183.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2195 lossL: tensor(2549442.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2196 lossL: tensor(2765359., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2197 lossL: tensor(2705159., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2198 lossL: tensor(2631954.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2199 lossL: tensor(2771423.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2200 lossL: tensor(2613749., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2201 lossL: tensor(2584900.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2202 lossL: tensor(2737411.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2203 lossL: tensor(2730566., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2204 lossL: tensor(2588793.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2205 lossL: tensor(2639910.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2206 lossL: tensor(2681006.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2207 lossL: tensor(2631148.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2208 lossL: tensor(2754288.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2209 lossL: tensor(2596712., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2210 lossL: tensor(2523530.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2211 lossL: tensor(2720693.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2212 lossL: tensor(2579629.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2213 lossL: tensor(2804767.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2214 lossL: tensor(2777497., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2215 lossL: tensor(2627121.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2216 lossL: tensor(2670640.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2217 lossL: tensor(2857105.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2218 lossL: tensor(2592818.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2219 lossL: tensor(2673309., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2220 lossL: tensor(2609630., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2221 lossL: tensor(2694888.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2222 lossL: tensor(2724477., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2223 lossL: tensor(2529794.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2224 lossL: tensor(2670103.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2225 lossL: tensor(2840078.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2226 lossL: tensor(2836790.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2227 lossL: tensor(2627372., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2228 lossL: tensor(2893069., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2229 lossL: tensor(2647251.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2230 lossL: tensor(2691290.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2231 lossL: tensor(2669951.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2232 lossL: tensor(2674936.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2233 lossL: tensor(2701554.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2234 lossL: tensor(2617434., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2235 lossL: tensor(2660719.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2236 lossL: tensor(2751753.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2237 lossL: tensor(2566134.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2238 lossL: tensor(2670375.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2239 lossL: tensor(2691554.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2240 lossL: tensor(2933871., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2241 lossL: tensor(2558754.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2242 lossL: tensor(2725939.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2243 lossL: tensor(2600963.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2244 lossL: tensor(2692598.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2245 lossL: tensor(2582344.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2246 lossL: tensor(2614199., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2247 lossL: tensor(2692824.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2248 lossL: tensor(2507325.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2249 lossL: tensor(2558207.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2250 lossL: tensor(2571963.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2251 lossL: tensor(2653234., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2252 lossL: tensor(2612886.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2253 lossL: tensor(2581954.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2254 lossL: tensor(2611662., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2255 lossL: tensor(2798622., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2256 lossL: tensor(2688107.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2257 lossL: tensor(2762276.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2258 lossL: tensor(2608385.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2259 lossL: tensor(2615121.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2260 lossL: tensor(2626692.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2261 lossL: tensor(2698183.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2262 lossL: tensor(2838799.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2263 lossL: tensor(2704160.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2264 lossL: tensor(2570043.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2265 lossL: tensor(2683515.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2266 lossL: tensor(2678050.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2267 lossL: tensor(2550988.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2268 lossL: tensor(2707556.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2269 lossL: tensor(2841962.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2270 lossL: tensor(2455586., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2271 lossL: tensor(2806903.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2272 lossL: tensor(2607300.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2273 lossL: tensor(2808560.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2274 lossL: tensor(2613720., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2275 lossL: tensor(2764744.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2276 lossL: tensor(2690372.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2277 lossL: tensor(2651217., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2278 lossL: tensor(2760725.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2279 lossL: tensor(2795360., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2280 lossL: tensor(2619828.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2281 lossL: tensor(2802504.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2282 lossL: tensor(2839688.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2283 lossL: tensor(2613220., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2284 lossL: tensor(2729420.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2285 lossL: tensor(2608551.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2286 lossL: tensor(2615709., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2287 lossL: tensor(2655634.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2288 lossL: tensor(2606148.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2289 lossL: tensor(2673700.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2290 lossL: tensor(2647633., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2291 lossL: tensor(2723285.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2292 lossL: tensor(2868239.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2293 lossL: tensor(2647661., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2294 lossL: tensor(2547610., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2295 lossL: tensor(2823446.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2296 lossL: tensor(2687773., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2297 lossL: tensor(2630028.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2298 lossL: tensor(2678403.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2299 lossL: tensor(2796979.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2300 lossL: tensor(2724724., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2301 lossL: tensor(2908236., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2302 lossL: tensor(2788117., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2303 lossL: tensor(2773381.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2304 lossL: tensor(2586415., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2305 lossL: tensor(2616686., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2306 lossL: tensor(2645562.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2307 lossL: tensor(2693957.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2308 lossL: tensor(2578506., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2309 lossL: tensor(2790403.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2310 lossL: tensor(2701856.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2311 lossL: tensor(2689255.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2312 lossL: tensor(2659309.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2313 lossL: tensor(2698347.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2314 lossL: tensor(2569779.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2315 lossL: tensor(2706369., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2316 lossL: tensor(2697173.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2317 lossL: tensor(2702765., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2318 lossL: tensor(2799014.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2319 lossL: tensor(2604679., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2320 lossL: tensor(2634369.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2321 lossL: tensor(2816603.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2322 lossL: tensor(2589875., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2323 lossL: tensor(2468197.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2324 lossL: tensor(2684230.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2325 lossL: tensor(2662332., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2326 lossL: tensor(2769541.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2327 lossL: tensor(2781057., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2328 lossL: tensor(2545350.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2329 lossL: tensor(2736863.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2330 lossL: tensor(2754202.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2331 lossL: tensor(2537075.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2332 lossL: tensor(2531250.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2333 lossL: tensor(2568767.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2334 lossL: tensor(2651049., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2335 lossL: tensor(2752093.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2336 lossL: tensor(2549710.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2337 lossL: tensor(2685452.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2338 lossL: tensor(2638234.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2339 lossL: tensor(2558233.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2340 lossL: tensor(2754535.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2341 lossL: tensor(2661705.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2342 lossL: tensor(2624492.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2343 lossL: tensor(2657858., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2344 lossL: tensor(2830094.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2345 lossL: tensor(2653098., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2346 lossL: tensor(2527584.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2347 lossL: tensor(2658352.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2348 lossL: tensor(2675485.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2349 lossL: tensor(2803502., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2350 lossL: tensor(2890469.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2351 lossL: tensor(2519068.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2352 lossL: tensor(2601254.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2353 lossL: tensor(2624419.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2354 lossL: tensor(2556340.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2355 lossL: tensor(2818682.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2356 lossL: tensor(2647905.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2357 lossL: tensor(2705530.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2358 lossL: tensor(2672100.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2359 lossL: tensor(2573261.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2360 lossL: tensor(2875351.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2361 lossL: tensor(2568045.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2362 lossL: tensor(2668239.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2363 lossL: tensor(2473869.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2364 lossL: tensor(2551508.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2365 lossL: tensor(2857213.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2366 lossL: tensor(2801946., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2367 lossL: tensor(2716722.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2368 lossL: tensor(2581577., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2369 lossL: tensor(2595361., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2370 lossL: tensor(2681810.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2371 lossL: tensor(2711286.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2372 lossL: tensor(2671830., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2373 lossL: tensor(2640687.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2374 lossL: tensor(2754655.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2375 lossL: tensor(2545876.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2376 lossL: tensor(2827581., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2377 lossL: tensor(2658602., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2378 lossL: tensor(2770387.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2379 lossL: tensor(2648479.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2380 lossL: tensor(2739770.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2381 lossL: tensor(2626323.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2382 lossL: tensor(2703369.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2383 lossL: tensor(2679066.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2384 lossL: tensor(2660977.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2385 lossL: tensor(2521184.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2386 lossL: tensor(2525048.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2387 lossL: tensor(2598684.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2388 lossL: tensor(2490195., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2389 lossL: tensor(2660747.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2390 lossL: tensor(2687213., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2391 lossL: tensor(2724957.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2392 lossL: tensor(2585553.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2393 lossL: tensor(2723161., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2394 lossL: tensor(2658226.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2395 lossL: tensor(2449865.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2396 lossL: tensor(2544724.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2397 lossL: tensor(2485376.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2398 lossL: tensor(2698237.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2399 lossL: tensor(2585740.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2400 lossL: tensor(2689572.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2401 lossL: tensor(2762122.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2402 lossL: tensor(2658758.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2403 lossL: tensor(2660836., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2404 lossL: tensor(2523762.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2405 lossL: tensor(2914067.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2406 lossL: tensor(2788679., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2407 lossL: tensor(2574223.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2408 lossL: tensor(2713090.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2409 lossL: tensor(2569991., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2410 lossL: tensor(2549808.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2411 lossL: tensor(2597443.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2412 lossL: tensor(2627809., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2413 lossL: tensor(2800792., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2414 lossL: tensor(2810362.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2415 lossL: tensor(2655003.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2416 lossL: tensor(2625621.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2417 lossL: tensor(2614528., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2418 lossL: tensor(2588374.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2419 lossL: tensor(2697277.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2420 lossL: tensor(2699170.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2421 lossL: tensor(2681268.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2422 lossL: tensor(2605661., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2423 lossL: tensor(2771190., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2424 lossL: tensor(2548470.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2425 lossL: tensor(2713346.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2426 lossL: tensor(2669979.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2427 lossL: tensor(2685340.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2428 lossL: tensor(2761228., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2429 lossL: tensor(2455770.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2430 lossL: tensor(2635407., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2431 lossL: tensor(2668348., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2432 lossL: tensor(2870665.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2433 lossL: tensor(2591986.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2434 lossL: tensor(2585321., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2435 lossL: tensor(2671933.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2436 lossL: tensor(2589308.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2437 lossL: tensor(2542998.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2438 lossL: tensor(2513248.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2439 lossL: tensor(2449365.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2440 lossL: tensor(2728503.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2441 lossL: tensor(2777679.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2442 lossL: tensor(2894783., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2443 lossL: tensor(2802194.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2444 lossL: tensor(2617165.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2445 lossL: tensor(2665491.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2446 lossL: tensor(2527139.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2447 lossL: tensor(2536237., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2448 lossL: tensor(2775090.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2449 lossL: tensor(2654510.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2450 lossL: tensor(2606978.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2451 lossL: tensor(2730340.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2452 lossL: tensor(2570783., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2453 lossL: tensor(2468898., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2454 lossL: tensor(2600113.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2455 lossL: tensor(2695510.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2456 lossL: tensor(2651898.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2457 lossL: tensor(2591897.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2458 lossL: tensor(2659133.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2459 lossL: tensor(2668000.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2460 lossL: tensor(2760167., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2461 lossL: tensor(2817909.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2462 lossL: tensor(2589561.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2463 lossL: tensor(2596303.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2464 lossL: tensor(2736935., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2465 lossL: tensor(2669210.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2466 lossL: tensor(2591220., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2467 lossL: tensor(2525065.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2468 lossL: tensor(2606292., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2469 lossL: tensor(2560142.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2470 lossL: tensor(2705748.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2471 lossL: tensor(2542624.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2472 lossL: tensor(2662818., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2473 lossL: tensor(2736889.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2474 lossL: tensor(2544976.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2475 lossL: tensor(2609189.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2476 lossL: tensor(2754835.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2477 lossL: tensor(2638217.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2478 lossL: tensor(2624832.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2479 lossL: tensor(2491512.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2480 lossL: tensor(2438540.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2481 lossL: tensor(2742023.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2482 lossL: tensor(2821078.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2483 lossL: tensor(2670765.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2484 lossL: tensor(2720207.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2485 lossL: tensor(2703711.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2486 lossL: tensor(2596288.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2487 lossL: tensor(2676925.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2488 lossL: tensor(2617119.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2489 lossL: tensor(2516198.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2490 lossL: tensor(2753309.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2491 lossL: tensor(2810061.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2492 lossL: tensor(2611294.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2493 lossL: tensor(2674764., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2494 lossL: tensor(2698235.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2495 lossL: tensor(2811077.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2496 lossL: tensor(2703009., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2497 lossL: tensor(2654250., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2498 lossL: tensor(2522254.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2499 lossL: tensor(2711358.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2500 lossL: tensor(2448321.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2501 lossL: tensor(2721270.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2502 lossL: tensor(2627240., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2503 lossL: tensor(2585894., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2504 lossL: tensor(2784777., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2505 lossL: tensor(2522416.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2506 lossL: tensor(2801965.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2507 lossL: tensor(2713079., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2508 lossL: tensor(2655729.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2509 lossL: tensor(2667207., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2510 lossL: tensor(2589437.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2511 lossL: tensor(2600234.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2512 lossL: tensor(2917985.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2513 lossL: tensor(2570018., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2514 lossL: tensor(2663862.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2515 lossL: tensor(2635324.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2516 lossL: tensor(2778079.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2517 lossL: tensor(2761403.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2518 lossL: tensor(2849819.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2519 lossL: tensor(2663923.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2520 lossL: tensor(2711890., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2521 lossL: tensor(2570085., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2522 lossL: tensor(2541624.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2523 lossL: tensor(2725777.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2524 lossL: tensor(2627739.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2525 lossL: tensor(2697129.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2526 lossL: tensor(2698231.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2527 lossL: tensor(2353335., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "2528 lossL: tensor(2638739.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2529 lossL: tensor(2673987.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2530 lossL: tensor(2822421.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2531 lossL: tensor(2744720., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2532 lossL: tensor(2619072.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2533 lossL: tensor(2833852.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2534 lossL: tensor(2530636.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2535 lossL: tensor(2858558.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2536 lossL: tensor(2683476.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2537 lossL: tensor(2582253., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2538 lossL: tensor(2498309.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2539 lossL: tensor(2590674.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2540 lossL: tensor(2739871., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2541 lossL: tensor(2661360.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2542 lossL: tensor(2516310., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2543 lossL: tensor(2618450.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2544 lossL: tensor(2738547.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2545 lossL: tensor(2645670.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2546 lossL: tensor(2762739.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2547 lossL: tensor(2641054.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2548 lossL: tensor(2663949.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2549 lossL: tensor(2600054.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2550 lossL: tensor(2760992.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2551 lossL: tensor(2624583.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2552 lossL: tensor(2869610., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2553 lossL: tensor(2753476., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2554 lossL: tensor(2742283.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2555 lossL: tensor(2761723.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2556 lossL: tensor(2570191.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2557 lossL: tensor(2622948.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2558 lossL: tensor(2551970., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2559 lossL: tensor(2678499.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2560 lossL: tensor(2517201.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2561 lossL: tensor(2739480.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2562 lossL: tensor(2814813.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2563 lossL: tensor(2748054.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2564 lossL: tensor(2574519.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2565 lossL: tensor(2763500.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2566 lossL: tensor(2532545., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2567 lossL: tensor(2649428., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2568 lossL: tensor(2691661.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2569 lossL: tensor(2696316.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2570 lossL: tensor(2612649.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2571 lossL: tensor(2670933.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2572 lossL: tensor(2588536., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2573 lossL: tensor(2575767., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2574 lossL: tensor(2615261.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2575 lossL: tensor(2568129.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2576 lossL: tensor(2701536., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2577 lossL: tensor(2528847., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2578 lossL: tensor(2564521.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2579 lossL: tensor(2611124., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2580 lossL: tensor(2664390.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2581 lossL: tensor(2682857.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2582 lossL: tensor(2531963.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2583 lossL: tensor(2577851., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2584 lossL: tensor(2614201.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2585 lossL: tensor(2571147.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2586 lossL: tensor(2800894., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2587 lossL: tensor(2720985.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2588 lossL: tensor(2656824.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2589 lossL: tensor(2635800.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2590 lossL: tensor(2665202.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2591 lossL: tensor(2664764.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2592 lossL: tensor(2692794.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2593 lossL: tensor(2680207., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2594 lossL: tensor(2753168.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2595 lossL: tensor(2665752.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2596 lossL: tensor(2741683.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2597 lossL: tensor(2689148., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2598 lossL: tensor(2555659.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2599 lossL: tensor(2621797., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2600 lossL: tensor(2826886., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2601 lossL: tensor(2623993., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2602 lossL: tensor(2573028.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2603 lossL: tensor(2570986.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2604 lossL: tensor(2658650.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2605 lossL: tensor(2739321.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2606 lossL: tensor(2783505.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2607 lossL: tensor(2728803.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2608 lossL: tensor(2464726., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2609 lossL: tensor(2507033.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2610 lossL: tensor(2785009.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2611 lossL: tensor(2591080.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2612 lossL: tensor(2542484.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2613 lossL: tensor(2605028.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2614 lossL: tensor(2636067.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2615 lossL: tensor(2834795.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2616 lossL: tensor(2542169.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2617 lossL: tensor(2691646.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2618 lossL: tensor(2762926.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2619 lossL: tensor(2625349.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2620 lossL: tensor(2575460.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2621 lossL: tensor(2695539.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2622 lossL: tensor(2662159.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2623 lossL: tensor(2867799., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2624 lossL: tensor(2867271., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2625 lossL: tensor(2674861., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2626 lossL: tensor(2613052.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2627 lossL: tensor(2631725., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2628 lossL: tensor(2614724.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2629 lossL: tensor(2672016., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2630 lossL: tensor(2815671., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2631 lossL: tensor(2777777., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2632 lossL: tensor(2764493., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2633 lossL: tensor(2712761.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2634 lossL: tensor(2737622., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2635 lossL: tensor(2697980., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2636 lossL: tensor(2680753.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2637 lossL: tensor(2809184., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2638 lossL: tensor(2694082., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2639 lossL: tensor(2605051.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2640 lossL: tensor(2560797.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2641 lossL: tensor(2667422.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2642 lossL: tensor(2745787.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2643 lossL: tensor(2715327.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2644 lossL: tensor(2681808.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2645 lossL: tensor(2607082.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2646 lossL: tensor(2589763.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2647 lossL: tensor(2603738.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2648 lossL: tensor(2658054.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2649 lossL: tensor(2674291., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2650 lossL: tensor(2677913.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2651 lossL: tensor(2654885., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2652 lossL: tensor(2495141.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2653 lossL: tensor(2737855., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2654 lossL: tensor(2594434.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2655 lossL: tensor(2697091.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2656 lossL: tensor(2624490.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2657 lossL: tensor(2612565.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2658 lossL: tensor(2639851.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2659 lossL: tensor(2668851., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2660 lossL: tensor(2608485.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2661 lossL: tensor(2842590., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2662 lossL: tensor(2592150.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2663 lossL: tensor(2577819., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2664 lossL: tensor(2758167., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2665 lossL: tensor(2778647.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2666 lossL: tensor(2584505.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2667 lossL: tensor(2793822.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2668 lossL: tensor(2725082.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2669 lossL: tensor(2676275.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2670 lossL: tensor(2558668., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2671 lossL: tensor(2845660.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2672 lossL: tensor(2699897.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2673 lossL: tensor(2584120.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2674 lossL: tensor(2745549.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2675 lossL: tensor(2576884.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2676 lossL: tensor(2500835.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2677 lossL: tensor(2755586.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2678 lossL: tensor(2685177., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2679 lossL: tensor(2527854.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2680 lossL: tensor(2855697.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2681 lossL: tensor(2638332.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2682 lossL: tensor(2737964.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2683 lossL: tensor(2738113.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2684 lossL: tensor(2603621.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2685 lossL: tensor(2478283.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2686 lossL: tensor(2678375.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2687 lossL: tensor(2628829.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2688 lossL: tensor(2944032.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2689 lossL: tensor(2689266.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2690 lossL: tensor(2620761.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2691 lossL: tensor(2618377., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2692 lossL: tensor(2427648.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2693 lossL: tensor(2709360.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2694 lossL: tensor(2796584.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2695 lossL: tensor(2513305., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2696 lossL: tensor(2686592.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2697 lossL: tensor(2733492.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2698 lossL: tensor(2690224.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2699 lossL: tensor(2659793.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2700 lossL: tensor(2461210.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2701 lossL: tensor(2743155., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2702 lossL: tensor(2729600.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2703 lossL: tensor(2679224.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2704 lossL: tensor(2741588.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2705 lossL: tensor(2791926.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2706 lossL: tensor(2732812., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2707 lossL: tensor(2676275.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2708 lossL: tensor(2706829.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2709 lossL: tensor(2694307.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2710 lossL: tensor(2776262.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2711 lossL: tensor(2878243.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2712 lossL: tensor(2669608.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2713 lossL: tensor(2618852.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2714 lossL: tensor(2521994., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2715 lossL: tensor(2592567.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2716 lossL: tensor(2713423.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2717 lossL: tensor(2807964.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2718 lossL: tensor(2806506.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2719 lossL: tensor(2434708.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2720 lossL: tensor(2674919., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2721 lossL: tensor(2721973.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2722 lossL: tensor(2633687.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2723 lossL: tensor(2672156.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2724 lossL: tensor(2511673.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2725 lossL: tensor(2726616.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2726 lossL: tensor(2781985.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2727 lossL: tensor(2565704.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2728 lossL: tensor(2572097.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2729 lossL: tensor(2607311.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2730 lossL: tensor(2586639.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2731 lossL: tensor(2733643.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2732 lossL: tensor(2594722., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2733 lossL: tensor(2678514.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2734 lossL: tensor(2617305.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2735 lossL: tensor(2753150.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2736 lossL: tensor(2584979.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2737 lossL: tensor(2712403., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2738 lossL: tensor(2570374.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2739 lossL: tensor(2793696.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2740 lossL: tensor(2591346., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2741 lossL: tensor(2569766.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2742 lossL: tensor(2657605.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2743 lossL: tensor(2704871.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2744 lossL: tensor(2584561., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2745 lossL: tensor(2601764., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2746 lossL: tensor(2655795.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2747 lossL: tensor(2574624.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2748 lossL: tensor(2767350.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2749 lossL: tensor(2575631.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2750 lossL: tensor(2611501.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2751 lossL: tensor(2677923.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2752 lossL: tensor(2521237., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2753 lossL: tensor(2678856.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2754 lossL: tensor(2783358., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2755 lossL: tensor(2430358.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2756 lossL: tensor(2726207., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2757 lossL: tensor(2528724.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2758 lossL: tensor(2587172.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2759 lossL: tensor(2685993.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2760 lossL: tensor(2560603.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2761 lossL: tensor(2514613.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2762 lossL: tensor(2682237., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2763 lossL: tensor(2673602.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2764 lossL: tensor(2634554.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2765 lossL: tensor(2762303.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2766 lossL: tensor(2483053.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2767 lossL: tensor(2607489., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2768 lossL: tensor(2701959.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2769 lossL: tensor(2654665.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2770 lossL: tensor(2588801.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2771 lossL: tensor(2665091.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2772 lossL: tensor(2836102.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2773 lossL: tensor(2722154.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2774 lossL: tensor(2563130.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2775 lossL: tensor(2774968.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2776 lossL: tensor(2654770., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2777 lossL: tensor(2584678.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2778 lossL: tensor(2612620., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2779 lossL: tensor(2648716.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2780 lossL: tensor(2603433., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2781 lossL: tensor(2589130.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2782 lossL: tensor(2725908.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2783 lossL: tensor(2687387., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2784 lossL: tensor(2622129., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2785 lossL: tensor(2786951.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2786 lossL: tensor(2724433.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2787 lossL: tensor(2833075.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2788 lossL: tensor(2385301.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2789 lossL: tensor(2616137., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2790 lossL: tensor(2559787.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2791 lossL: tensor(2497352.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2792 lossL: tensor(2659971.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2793 lossL: tensor(2659398.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2794 lossL: tensor(2576358., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2795 lossL: tensor(2676678.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2796 lossL: tensor(2625422., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2797 lossL: tensor(2790845.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2798 lossL: tensor(2529788.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2799 lossL: tensor(2849644., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2800 lossL: tensor(2601893.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2801 lossL: tensor(2804885.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2802 lossL: tensor(2684838.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2803 lossL: tensor(2641317.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2804 lossL: tensor(2680949., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2805 lossL: tensor(2608067.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2806 lossL: tensor(2644013.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2807 lossL: tensor(2546714., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2808 lossL: tensor(2845448.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2809 lossL: tensor(2738501.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2810 lossL: tensor(2752474., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2811 lossL: tensor(2621397., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2812 lossL: tensor(2518315.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2813 lossL: tensor(2677641.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2814 lossL: tensor(2575642.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2815 lossL: tensor(2726992.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2816 lossL: tensor(2758500.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2817 lossL: tensor(2758454.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2818 lossL: tensor(2581340., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2819 lossL: tensor(2679535.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2820 lossL: tensor(2616768.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2821 lossL: tensor(2604585.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2822 lossL: tensor(2423742., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2823 lossL: tensor(2591059.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2824 lossL: tensor(2607396., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2825 lossL: tensor(2676889.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2826 lossL: tensor(2697312., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2827 lossL: tensor(2603097., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2828 lossL: tensor(2663160.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2829 lossL: tensor(2639326.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2830 lossL: tensor(2537981., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2831 lossL: tensor(2706368.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2832 lossL: tensor(2827145.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2833 lossL: tensor(2621171.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2834 lossL: tensor(2548664.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2835 lossL: tensor(2618565.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2836 lossL: tensor(2813545., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2837 lossL: tensor(2571653.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2838 lossL: tensor(2629634.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2839 lossL: tensor(2664437.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2840 lossL: tensor(2551632.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2841 lossL: tensor(2707465., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2842 lossL: tensor(2661672.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2843 lossL: tensor(2688150.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2844 lossL: tensor(2673740.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2845 lossL: tensor(2755077.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2846 lossL: tensor(2657502.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2847 lossL: tensor(2766212.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2848 lossL: tensor(2746850.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2849 lossL: tensor(2478360.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2850 lossL: tensor(2510235.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2851 lossL: tensor(2767896.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2852 lossL: tensor(2504485., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2853 lossL: tensor(2437405.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2854 lossL: tensor(2570000.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2855 lossL: tensor(2661816.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2856 lossL: tensor(2586585.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2857 lossL: tensor(2639713.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2858 lossL: tensor(2558359., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2859 lossL: tensor(2733142.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2860 lossL: tensor(2611701.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2861 lossL: tensor(2593253.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2862 lossL: tensor(2643656., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2863 lossL: tensor(2582083.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2864 lossL: tensor(2638570., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2865 lossL: tensor(2562020.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2866 lossL: tensor(2699585., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2867 lossL: tensor(2649643.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2868 lossL: tensor(2691979.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2869 lossL: tensor(2653852.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2870 lossL: tensor(2711999.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2871 lossL: tensor(2873105., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2872 lossL: tensor(2643724.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2873 lossL: tensor(2651327.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2874 lossL: tensor(2728245., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2875 lossL: tensor(2516758.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2876 lossL: tensor(2691201.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2877 lossL: tensor(2686253., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2878 lossL: tensor(2665717., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2879 lossL: tensor(2817789.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2880 lossL: tensor(2484916.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2881 lossL: tensor(2623874., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2882 lossL: tensor(2671458.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2883 lossL: tensor(2671422.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2884 lossL: tensor(2555618.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2885 lossL: tensor(2650520., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2886 lossL: tensor(2661174.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2887 lossL: tensor(2524670.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2888 lossL: tensor(2682830., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2889 lossL: tensor(2614585.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2890 lossL: tensor(2447825.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2891 lossL: tensor(2629445.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2892 lossL: tensor(2486562.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2893 lossL: tensor(2559767., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2894 lossL: tensor(2643166.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2895 lossL: tensor(2698200.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2896 lossL: tensor(2641486.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2897 lossL: tensor(2538163.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2898 lossL: tensor(2688147., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2899 lossL: tensor(2464978.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2900 lossL: tensor(2660318.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2901 lossL: tensor(2720600.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2902 lossL: tensor(2546411., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2903 lossL: tensor(2446367.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2904 lossL: tensor(2695291.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2905 lossL: tensor(2620162.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2906 lossL: tensor(2615732., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2907 lossL: tensor(2547354., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2908 lossL: tensor(2552441.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2909 lossL: tensor(2472694.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2910 lossL: tensor(2622536., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2911 lossL: tensor(2637983.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2912 lossL: tensor(2435363.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2913 lossL: tensor(2946299.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2914 lossL: tensor(2555836.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2915 lossL: tensor(2575841.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2916 lossL: tensor(2552423.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2917 lossL: tensor(2772772., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2918 lossL: tensor(2711499.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2919 lossL: tensor(2489182.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2920 lossL: tensor(2613076., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2921 lossL: tensor(2736008., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2922 lossL: tensor(2826556.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2923 lossL: tensor(2674509., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2924 lossL: tensor(2492285.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2925 lossL: tensor(2616861.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2926 lossL: tensor(2554967.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2927 lossL: tensor(2638859.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2928 lossL: tensor(2512379.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2929 lossL: tensor(2772238.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2930 lossL: tensor(2743358., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2931 lossL: tensor(2512625.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2932 lossL: tensor(2591996.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2933 lossL: tensor(2697151.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2934 lossL: tensor(2688785.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2935 lossL: tensor(2584740.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2936 lossL: tensor(2531713.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2937 lossL: tensor(2776919.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2938 lossL: tensor(2581718.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2939 lossL: tensor(2758234.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2940 lossL: tensor(2618871.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2941 lossL: tensor(2503654.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2942 lossL: tensor(2513704., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2943 lossL: tensor(2681570.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2944 lossL: tensor(2706020., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2945 lossL: tensor(2761024., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2946 lossL: tensor(2600744., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2947 lossL: tensor(2601728., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2948 lossL: tensor(2576662.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2949 lossL: tensor(2613896.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2950 lossL: tensor(2516909.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2951 lossL: tensor(2674988.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2952 lossL: tensor(2599684.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2953 lossL: tensor(2606162.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2954 lossL: tensor(2704458.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2955 lossL: tensor(2494462.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2956 lossL: tensor(2683465., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2957 lossL: tensor(2539705.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2958 lossL: tensor(2462605.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2959 lossL: tensor(2770799.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2960 lossL: tensor(2545598., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2961 lossL: tensor(2616960.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2962 lossL: tensor(2770635.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2963 lossL: tensor(2650667., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2964 lossL: tensor(2636065.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2965 lossL: tensor(2634300.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2966 lossL: tensor(2644589.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2967 lossL: tensor(2586724.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2968 lossL: tensor(2747850.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2969 lossL: tensor(2817039.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2970 lossL: tensor(2856757., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2971 lossL: tensor(2485406.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2972 lossL: tensor(2662791.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2973 lossL: tensor(2637192.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2974 lossL: tensor(2691976.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2975 lossL: tensor(2723760.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2976 lossL: tensor(2644107.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2977 lossL: tensor(2831676.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2978 lossL: tensor(2654673.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2979 lossL: tensor(2348501.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "2980 lossL: tensor(2588628., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2981 lossL: tensor(2668254.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2982 lossL: tensor(2660510.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2983 lossL: tensor(2817087.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2984 lossL: tensor(2571945., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2985 lossL: tensor(2642947.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2986 lossL: tensor(2583522.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2987 lossL: tensor(2680944.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2988 lossL: tensor(2519964., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2989 lossL: tensor(2477345.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2990 lossL: tensor(2531197.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2991 lossL: tensor(2558886.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2992 lossL: tensor(2392659.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2993 lossL: tensor(2693503., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2994 lossL: tensor(2507960.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2995 lossL: tensor(2722670.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2996 lossL: tensor(2549452., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2997 lossL: tensor(2700968.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2998 lossL: tensor(2682380.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "2999 lossL: tensor(2609266.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3000 lossL: tensor(2522203.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3001 lossL: tensor(2545041.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3002 lossL: tensor(2662701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3003 lossL: tensor(2559654.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3004 lossL: tensor(2800368.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3005 lossL: tensor(2649102.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3006 lossL: tensor(2605785.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3007 lossL: tensor(2727107.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3008 lossL: tensor(2458375.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3009 lossL: tensor(2550831.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3010 lossL: tensor(2558593.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3011 lossL: tensor(2674608.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3012 lossL: tensor(2617891.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3013 lossL: tensor(2608560., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3014 lossL: tensor(2654100.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3015 lossL: tensor(2615898.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3016 lossL: tensor(2773987.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3017 lossL: tensor(2709760.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3018 lossL: tensor(2679568.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3019 lossL: tensor(2633017.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3020 lossL: tensor(2801982.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3021 lossL: tensor(2674064., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3022 lossL: tensor(2456261.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3023 lossL: tensor(2688566.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3024 lossL: tensor(2671161., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3025 lossL: tensor(2863536.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3026 lossL: tensor(2677982.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3027 lossL: tensor(2690641.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3028 lossL: tensor(2644727., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3029 lossL: tensor(2651519.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3030 lossL: tensor(2668786.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3031 lossL: tensor(2750659.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3032 lossL: tensor(2532127.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3033 lossL: tensor(2539628.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3034 lossL: tensor(2549818.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3035 lossL: tensor(2576871.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3036 lossL: tensor(2553137.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3037 lossL: tensor(2760425.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3038 lossL: tensor(2713021.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3039 lossL: tensor(2574341.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3040 lossL: tensor(2613604.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3041 lossL: tensor(2644559.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3042 lossL: tensor(2591269., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3043 lossL: tensor(2833320., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3044 lossL: tensor(2658070.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3045 lossL: tensor(2472374., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3046 lossL: tensor(2605696.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3047 lossL: tensor(2585899.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3048 lossL: tensor(2669446.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3049 lossL: tensor(2596117., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3050 lossL: tensor(2658374.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3051 lossL: tensor(2662752.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3052 lossL: tensor(2452749.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3053 lossL: tensor(2686235.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3054 lossL: tensor(2508136.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3055 lossL: tensor(2697938.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3056 lossL: tensor(2474254.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3057 lossL: tensor(2501495., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3058 lossL: tensor(2568241.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3059 lossL: tensor(2685803., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3060 lossL: tensor(2601481.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3061 lossL: tensor(2653623., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3062 lossL: tensor(2660029., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3063 lossL: tensor(2597317., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3064 lossL: tensor(2583889.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3065 lossL: tensor(2574726.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3066 lossL: tensor(2648007.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3067 lossL: tensor(2588582.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3068 lossL: tensor(2599675., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3069 lossL: tensor(2619648.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3070 lossL: tensor(2760508., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3071 lossL: tensor(2543514.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3072 lossL: tensor(2576283.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3073 lossL: tensor(2636499.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3074 lossL: tensor(2570735.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3075 lossL: tensor(2586182.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3076 lossL: tensor(2767563.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3077 lossL: tensor(2632277.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3078 lossL: tensor(2674582.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3079 lossL: tensor(2603471.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3080 lossL: tensor(2563457., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3081 lossL: tensor(2756445., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3082 lossL: tensor(2738642.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3083 lossL: tensor(2506205., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3084 lossL: tensor(2510137.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3085 lossL: tensor(2484936.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3086 lossL: tensor(2609089.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3087 lossL: tensor(2550227.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3088 lossL: tensor(2553370.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3089 lossL: tensor(2639234., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3090 lossL: tensor(2610095., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3091 lossL: tensor(2458460., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3092 lossL: tensor(2595315.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3093 lossL: tensor(2512355.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3094 lossL: tensor(2536465.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3095 lossL: tensor(2762948.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3096 lossL: tensor(2702236., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3097 lossL: tensor(2707165., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3098 lossL: tensor(2515546.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3099 lossL: tensor(2524534., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3100 lossL: tensor(2577060., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3101 lossL: tensor(2642406.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3102 lossL: tensor(2814177.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3103 lossL: tensor(2791576.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3104 lossL: tensor(2476604., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3105 lossL: tensor(2517204.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3106 lossL: tensor(2549908., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3107 lossL: tensor(2877188.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3108 lossL: tensor(2673769.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3109 lossL: tensor(2539087.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3110 lossL: tensor(2549573.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3111 lossL: tensor(2576658.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3112 lossL: tensor(2559464.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3113 lossL: tensor(2725459.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3114 lossL: tensor(2802843., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3115 lossL: tensor(2701040.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3116 lossL: tensor(2565314.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3117 lossL: tensor(2676281., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3118 lossL: tensor(2539018.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3119 lossL: tensor(2665477.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3120 lossL: tensor(2568901.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3121 lossL: tensor(2455216., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3122 lossL: tensor(2572241.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3123 lossL: tensor(2684022., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3124 lossL: tensor(2544528., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3125 lossL: tensor(2647836., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3126 lossL: tensor(2481216.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3127 lossL: tensor(2573744., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3128 lossL: tensor(2545045.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3129 lossL: tensor(2693586.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3130 lossL: tensor(2736107.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3131 lossL: tensor(2812051., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3132 lossL: tensor(2575748.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3133 lossL: tensor(2510561., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3134 lossL: tensor(2515131.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3135 lossL: tensor(2592038.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3136 lossL: tensor(2683039.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3137 lossL: tensor(2585630.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3138 lossL: tensor(2626102.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3139 lossL: tensor(2669093., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3140 lossL: tensor(2552284.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3141 lossL: tensor(2733541.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3142 lossL: tensor(2558090.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3143 lossL: tensor(2664215.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3144 lossL: tensor(2609283.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3145 lossL: tensor(2573974.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3146 lossL: tensor(2593558.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3147 lossL: tensor(2389637.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3148 lossL: tensor(2747975.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3149 lossL: tensor(2436895.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3150 lossL: tensor(2631393.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3151 lossL: tensor(2596924.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3152 lossL: tensor(2731366.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3153 lossL: tensor(2660263., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3154 lossL: tensor(2594300.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3155 lossL: tensor(2835841.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3156 lossL: tensor(2613126.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3157 lossL: tensor(2701249.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3158 lossL: tensor(2598394., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3159 lossL: tensor(2567076.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3160 lossL: tensor(2590841., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3161 lossL: tensor(2616667.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3162 lossL: tensor(2612862.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3163 lossL: tensor(2582393.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3164 lossL: tensor(2608699.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3165 lossL: tensor(2389484., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3166 lossL: tensor(2707271.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3167 lossL: tensor(2551270.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3168 lossL: tensor(2499244., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3169 lossL: tensor(2653785.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3170 lossL: tensor(2635363., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3171 lossL: tensor(2564233.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3172 lossL: tensor(2657037.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3173 lossL: tensor(2727318.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3174 lossL: tensor(2783289.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3175 lossL: tensor(2588823.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3176 lossL: tensor(2526358., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3177 lossL: tensor(2733842.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3178 lossL: tensor(2451066.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3179 lossL: tensor(2707591., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3180 lossL: tensor(2699421.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3181 lossL: tensor(2705396., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3182 lossL: tensor(2601701.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3183 lossL: tensor(2561935.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3184 lossL: tensor(2596084., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3185 lossL: tensor(2474886.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3186 lossL: tensor(2605637.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3187 lossL: tensor(2610515., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3188 lossL: tensor(2799347.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3189 lossL: tensor(2697585.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3190 lossL: tensor(2462327.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3191 lossL: tensor(2600950.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3192 lossL: tensor(2577511., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3193 lossL: tensor(2636408.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3194 lossL: tensor(2585534.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3195 lossL: tensor(2594112.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3196 lossL: tensor(2457387.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3197 lossL: tensor(2672992.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3198 lossL: tensor(2622690.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3199 lossL: tensor(2809617., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3200 lossL: tensor(2656550.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3201 lossL: tensor(2522916.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3202 lossL: tensor(2908884.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3203 lossL: tensor(2764738.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3204 lossL: tensor(2664803., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3205 lossL: tensor(2598748.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3206 lossL: tensor(2626397.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3207 lossL: tensor(2404641.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3208 lossL: tensor(2574631.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3209 lossL: tensor(2712599.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3210 lossL: tensor(2745485.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3211 lossL: tensor(2511651.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3212 lossL: tensor(2413407., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3213 lossL: tensor(2606978.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3214 lossL: tensor(2569739.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3215 lossL: tensor(2784826.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3216 lossL: tensor(2706096.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3217 lossL: tensor(2497131.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3218 lossL: tensor(2505301.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3219 lossL: tensor(2565302.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3220 lossL: tensor(2384190.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3221 lossL: tensor(2734945.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3222 lossL: tensor(2703373.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3223 lossL: tensor(2508899.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3224 lossL: tensor(2564429.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3225 lossL: tensor(2612618.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3226 lossL: tensor(2667447.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3227 lossL: tensor(2410197.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3228 lossL: tensor(2532558.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3229 lossL: tensor(2448209.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3230 lossL: tensor(2685158.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3231 lossL: tensor(2718427., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3232 lossL: tensor(2657210.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3233 lossL: tensor(2606182.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3234 lossL: tensor(2783769.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3235 lossL: tensor(2627969.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3236 lossL: tensor(2769307.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3237 lossL: tensor(2605395.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3238 lossL: tensor(2704468.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3239 lossL: tensor(2644400.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3240 lossL: tensor(2560710.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3241 lossL: tensor(2531921.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3242 lossL: tensor(2620886.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3243 lossL: tensor(2555370.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3244 lossL: tensor(2735669., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3245 lossL: tensor(2662014.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3246 lossL: tensor(2796759.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3247 lossL: tensor(2800260.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3248 lossL: tensor(2620386., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3249 lossL: tensor(2607089.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3250 lossL: tensor(2442815., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3251 lossL: tensor(2542067.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3252 lossL: tensor(2742965.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3253 lossL: tensor(2340873.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "3254 lossL: tensor(2600327., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3255 lossL: tensor(2503122.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3256 lossL: tensor(2668544.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3257 lossL: tensor(2498380.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3258 lossL: tensor(2628725.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3259 lossL: tensor(2604052., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3260 lossL: tensor(2600005.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3261 lossL: tensor(2594456.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3262 lossL: tensor(2557087.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3263 lossL: tensor(2510474.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3264 lossL: tensor(2747981.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3265 lossL: tensor(2526529.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3266 lossL: tensor(2621995., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3267 lossL: tensor(2607399.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3268 lossL: tensor(2751946.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3269 lossL: tensor(2609514.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3270 lossL: tensor(2686712., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3271 lossL: tensor(2597329.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3272 lossL: tensor(2489787., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3273 lossL: tensor(2530194., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3274 lossL: tensor(2504505., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3275 lossL: tensor(2368476., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3276 lossL: tensor(2626900., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3277 lossL: tensor(2674438.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3278 lossL: tensor(2602105., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3279 lossL: tensor(2582597.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3280 lossL: tensor(2724489., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3281 lossL: tensor(2727792., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3282 lossL: tensor(2609457.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3283 lossL: tensor(2563300., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3284 lossL: tensor(2589042.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3285 lossL: tensor(2565087.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3286 lossL: tensor(2785798., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3287 lossL: tensor(2612443.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3288 lossL: tensor(2521087.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3289 lossL: tensor(2610021.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3290 lossL: tensor(2723301.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3291 lossL: tensor(2521553.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3292 lossL: tensor(2683272., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3293 lossL: tensor(2659588., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3294 lossL: tensor(2622398., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3295 lossL: tensor(2456302.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3296 lossL: tensor(2527833., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3297 lossL: tensor(2609773.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3298 lossL: tensor(2621934., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3299 lossL: tensor(2593491., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3300 lossL: tensor(2596102., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3301 lossL: tensor(2451393.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3302 lossL: tensor(2542229., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3303 lossL: tensor(2620715.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3304 lossL: tensor(2634368.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3305 lossL: tensor(2639056.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3306 lossL: tensor(2626662.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3307 lossL: tensor(2621512.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3308 lossL: tensor(2509210.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3309 lossL: tensor(2484405., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3310 lossL: tensor(2669696.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3311 lossL: tensor(2556569., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3312 lossL: tensor(2597955.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3313 lossL: tensor(2531264.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3314 lossL: tensor(2605135.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3315 lossL: tensor(2656492.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3316 lossL: tensor(2603141.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3317 lossL: tensor(2648880., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3318 lossL: tensor(2605406.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3319 lossL: tensor(2471822., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3320 lossL: tensor(2681960.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3321 lossL: tensor(2726378.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3322 lossL: tensor(2403980.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3323 lossL: tensor(2566762., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3324 lossL: tensor(2632485.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3325 lossL: tensor(2433170.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3326 lossL: tensor(2561160., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3327 lossL: tensor(2558785.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3328 lossL: tensor(2628626.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3329 lossL: tensor(2504299.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3330 lossL: tensor(2483737.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3331 lossL: tensor(2536861., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3332 lossL: tensor(2416223., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3333 lossL: tensor(2516324.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3334 lossL: tensor(2646962.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3335 lossL: tensor(2618753., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3336 lossL: tensor(2689554.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3337 lossL: tensor(2598919.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3338 lossL: tensor(2518084.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3339 lossL: tensor(2685914.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3340 lossL: tensor(2504264.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3341 lossL: tensor(2619672.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3342 lossL: tensor(2447048., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3343 lossL: tensor(2633747., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3344 lossL: tensor(2630496.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3345 lossL: tensor(2555323.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3346 lossL: tensor(2666941., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3347 lossL: tensor(2873390.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3348 lossL: tensor(2451640., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3349 lossL: tensor(2758287.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3350 lossL: tensor(2629609.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3351 lossL: tensor(2651895.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3352 lossL: tensor(2609980.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3353 lossL: tensor(2495535.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3354 lossL: tensor(2554223., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3355 lossL: tensor(2537364.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3356 lossL: tensor(2598900.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3357 lossL: tensor(2548823., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3358 lossL: tensor(2492309.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3359 lossL: tensor(2490841., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3360 lossL: tensor(2450379., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3361 lossL: tensor(2761145.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3362 lossL: tensor(2598863.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3363 lossL: tensor(2450052.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3364 lossL: tensor(2678021.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3365 lossL: tensor(2610180.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3366 lossL: tensor(2466499.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3367 lossL: tensor(2478149., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3368 lossL: tensor(2793022.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3369 lossL: tensor(2489656.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3370 lossL: tensor(2422640., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3371 lossL: tensor(2680961.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3372 lossL: tensor(2615400., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3373 lossL: tensor(2489885.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3374 lossL: tensor(2708564., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3375 lossL: tensor(2576966.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3376 lossL: tensor(2546980.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3377 lossL: tensor(2519734.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3378 lossL: tensor(2613603.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3379 lossL: tensor(2571055., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3380 lossL: tensor(2552117.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3381 lossL: tensor(2699002.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3382 lossL: tensor(2663807.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3383 lossL: tensor(2471168.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3384 lossL: tensor(2518309.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3385 lossL: tensor(2588215.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3386 lossL: tensor(2737286.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3387 lossL: tensor(2483548.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3388 lossL: tensor(2766858.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3389 lossL: tensor(2481574.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3390 lossL: tensor(2541157.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3391 lossL: tensor(2572998., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3392 lossL: tensor(2756356., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3393 lossL: tensor(2647690., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3394 lossL: tensor(2501584., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3395 lossL: tensor(2750277.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3396 lossL: tensor(2563001.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3397 lossL: tensor(2615462.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3398 lossL: tensor(2583681., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3399 lossL: tensor(2532584.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3400 lossL: tensor(2416800., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3401 lossL: tensor(2607645., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3402 lossL: tensor(2796930.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3403 lossL: tensor(2697154.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3404 lossL: tensor(2524662., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3405 lossL: tensor(2580870.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3406 lossL: tensor(2634014.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3407 lossL: tensor(2607106.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3408 lossL: tensor(2516353., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3409 lossL: tensor(2512376.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3410 lossL: tensor(2535945., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3411 lossL: tensor(2495815.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3412 lossL: tensor(2500947.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3413 lossL: tensor(2730840.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3414 lossL: tensor(2666523.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3415 lossL: tensor(2692057., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3416 lossL: tensor(2627567.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3417 lossL: tensor(2651644.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3418 lossL: tensor(2479322., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3419 lossL: tensor(2603717., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3420 lossL: tensor(2533558., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3421 lossL: tensor(2530830., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3422 lossL: tensor(2703290.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3423 lossL: tensor(2504117.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3424 lossL: tensor(2545553., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3425 lossL: tensor(2603009.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3426 lossL: tensor(2504567.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3427 lossL: tensor(2582687.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3428 lossL: tensor(2491854.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3429 lossL: tensor(2582093.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3430 lossL: tensor(2600194.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3431 lossL: tensor(2717859.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3432 lossL: tensor(2510438.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3433 lossL: tensor(2450493., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3434 lossL: tensor(2687296.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3435 lossL: tensor(2597105., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3436 lossL: tensor(2582652.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3437 lossL: tensor(2666166.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3438 lossL: tensor(2487886., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3439 lossL: tensor(2538873.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3440 lossL: tensor(2599093.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3441 lossL: tensor(2460600.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3442 lossL: tensor(2727529., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3443 lossL: tensor(2417950.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3444 lossL: tensor(2783005., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3445 lossL: tensor(2528023.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3446 lossL: tensor(2580087., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3447 lossL: tensor(2561220.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3448 lossL: tensor(2609008.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3449 lossL: tensor(2644324.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3450 lossL: tensor(2662419.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3451 lossL: tensor(2687646., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3452 lossL: tensor(2585299.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3453 lossL: tensor(2646901.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3454 lossL: tensor(2668791., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3455 lossL: tensor(2765517.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3456 lossL: tensor(2582990.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3457 lossL: tensor(2311852., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "3458 lossL: tensor(2496670.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3459 lossL: tensor(2784599.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3460 lossL: tensor(2568038.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3461 lossL: tensor(2534572.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3462 lossL: tensor(2690882., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3463 lossL: tensor(2657232.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3464 lossL: tensor(2763686.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3465 lossL: tensor(2546372.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3466 lossL: tensor(2810683.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3467 lossL: tensor(2435572.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3468 lossL: tensor(2529317.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3469 lossL: tensor(2587617.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3470 lossL: tensor(2674256.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3471 lossL: tensor(2705422., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3472 lossL: tensor(2769771.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3473 lossL: tensor(2642056.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3474 lossL: tensor(2662174.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3475 lossL: tensor(2536005., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3476 lossL: tensor(2657830.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3477 lossL: tensor(2694250.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3478 lossL: tensor(2689737.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3479 lossL: tensor(2512542., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3480 lossL: tensor(2733574.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3481 lossL: tensor(2586955., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3482 lossL: tensor(2564311.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3483 lossL: tensor(2534823.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3484 lossL: tensor(2490002., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3485 lossL: tensor(2491352., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3486 lossL: tensor(2619299.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3487 lossL: tensor(2433839.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3488 lossL: tensor(2465544.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3489 lossL: tensor(2482960.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3490 lossL: tensor(2534968.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3491 lossL: tensor(2561378.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3492 lossL: tensor(2665622.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3493 lossL: tensor(2495356.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3494 lossL: tensor(2432094.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3495 lossL: tensor(2454100.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3496 lossL: tensor(2521764.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3497 lossL: tensor(2509090.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3498 lossL: tensor(2549529.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3499 lossL: tensor(2577598., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3500 lossL: tensor(2577921.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3501 lossL: tensor(2678840.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3502 lossL: tensor(2528695.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3503 lossL: tensor(2652411.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3504 lossL: tensor(2645648.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3505 lossL: tensor(2490877.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3506 lossL: tensor(2577808.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3507 lossL: tensor(2571095.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3508 lossL: tensor(2625351., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3509 lossL: tensor(2660851.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3510 lossL: tensor(2587960.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3511 lossL: tensor(2540516.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3512 lossL: tensor(2660161.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3513 lossL: tensor(2507251.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3514 lossL: tensor(2626317., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3515 lossL: tensor(2441011.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3516 lossL: tensor(2618877., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3517 lossL: tensor(2495320.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3518 lossL: tensor(2517066.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3519 lossL: tensor(2638934., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3520 lossL: tensor(2533916.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3521 lossL: tensor(2576476.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3522 lossL: tensor(2477426.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3523 lossL: tensor(2462254., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3524 lossL: tensor(2667098.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3525 lossL: tensor(2695553., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3526 lossL: tensor(2512199.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3527 lossL: tensor(2658954., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3528 lossL: tensor(2625667.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3529 lossL: tensor(2663087.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3530 lossL: tensor(2458331.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3531 lossL: tensor(2554236.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3532 lossL: tensor(2585789.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3533 lossL: tensor(2492458., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3534 lossL: tensor(2664953., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3535 lossL: tensor(2633601.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3536 lossL: tensor(2607100.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3537 lossL: tensor(2739252.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3538 lossL: tensor(2697417.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3539 lossL: tensor(2357292.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3540 lossL: tensor(2617599.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3541 lossL: tensor(2514006.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3542 lossL: tensor(2699792.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3543 lossL: tensor(2556418., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3544 lossL: tensor(2621162.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3545 lossL: tensor(2603720., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3546 lossL: tensor(2497873., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3547 lossL: tensor(2702480., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3548 lossL: tensor(2475723., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3549 lossL: tensor(2577881.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3550 lossL: tensor(2728090.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3551 lossL: tensor(2512951.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3552 lossL: tensor(2724118.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3553 lossL: tensor(2502966.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3554 lossL: tensor(2533925., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3555 lossL: tensor(2557441.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3556 lossL: tensor(2617820.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3557 lossL: tensor(2588412.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3558 lossL: tensor(2501498.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3559 lossL: tensor(2442460.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3560 lossL: tensor(2624373., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3561 lossL: tensor(2569550.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3562 lossL: tensor(2599134.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3563 lossL: tensor(2609942., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3564 lossL: tensor(2605102.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3565 lossL: tensor(2590122.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3566 lossL: tensor(2537813.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3567 lossL: tensor(2709876.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3568 lossL: tensor(2440218.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3569 lossL: tensor(2545870., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3570 lossL: tensor(2714353.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3571 lossL: tensor(2685765.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3572 lossL: tensor(2425785.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3573 lossL: tensor(2661731.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3574 lossL: tensor(2587312.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3575 lossL: tensor(2486073.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3576 lossL: tensor(2439023.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3577 lossL: tensor(2545103.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3578 lossL: tensor(2529944.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3579 lossL: tensor(2647485., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3580 lossL: tensor(2503374., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3581 lossL: tensor(2474981.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3582 lossL: tensor(2687809.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3583 lossL: tensor(2470632.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3584 lossL: tensor(2653242.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3585 lossL: tensor(2560348.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3586 lossL: tensor(2550037.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3587 lossL: tensor(2597975., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3588 lossL: tensor(2605677., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3589 lossL: tensor(2554366.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3590 lossL: tensor(2559330.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3591 lossL: tensor(2486945.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3592 lossL: tensor(2614331.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3593 lossL: tensor(2513845.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3594 lossL: tensor(2635636.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3595 lossL: tensor(2580112.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3596 lossL: tensor(2497728.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3597 lossL: tensor(2561087.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3598 lossL: tensor(2672764.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3599 lossL: tensor(2578180.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3600 lossL: tensor(2504103.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3601 lossL: tensor(2433065.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3602 lossL: tensor(2603365., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3603 lossL: tensor(2578682.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3604 lossL: tensor(2590555., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3605 lossL: tensor(2435686.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3606 lossL: tensor(2479984., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3607 lossL: tensor(2542195.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3608 lossL: tensor(2637385.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3609 lossL: tensor(2529173.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3610 lossL: tensor(2690764., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3611 lossL: tensor(2452868.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3612 lossL: tensor(2561222.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3613 lossL: tensor(2627999.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3614 lossL: tensor(2511161.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3615 lossL: tensor(2607778.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3616 lossL: tensor(2722809.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3617 lossL: tensor(2634440.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3618 lossL: tensor(2664103.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3619 lossL: tensor(2522668.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3620 lossL: tensor(2659226.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3621 lossL: tensor(2522530.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3622 lossL: tensor(2613470., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3623 lossL: tensor(2475940.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3624 lossL: tensor(2600068.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3625 lossL: tensor(2590752., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3626 lossL: tensor(2697521.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3627 lossL: tensor(2653965.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3628 lossL: tensor(2462022., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3629 lossL: tensor(2619102.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3630 lossL: tensor(2527765., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3631 lossL: tensor(2576810.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3632 lossL: tensor(2506613., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3633 lossL: tensor(2724907.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3634 lossL: tensor(2621973., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3635 lossL: tensor(2611952.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3636 lossL: tensor(2566116.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3637 lossL: tensor(2512821.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3638 lossL: tensor(2752033.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3639 lossL: tensor(2635534.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3640 lossL: tensor(2627009.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3641 lossL: tensor(2548799., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3642 lossL: tensor(2576768.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3643 lossL: tensor(2469157.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3644 lossL: tensor(2625864., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3645 lossL: tensor(2505504., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3646 lossL: tensor(2595457.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3647 lossL: tensor(2428023.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3648 lossL: tensor(2350324.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3649 lossL: tensor(2553638., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3650 lossL: tensor(2526284.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3651 lossL: tensor(2702551.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3652 lossL: tensor(2497091.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3653 lossL: tensor(2716461.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3654 lossL: tensor(2591201.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3655 lossL: tensor(2666357.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3656 lossL: tensor(2505492.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3657 lossL: tensor(2489379.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3658 lossL: tensor(2532197.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3659 lossL: tensor(2562102.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3660 lossL: tensor(2512056.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3661 lossL: tensor(2633029.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3662 lossL: tensor(2444287.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3663 lossL: tensor(2788069., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3664 lossL: tensor(2542003.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3665 lossL: tensor(2499660.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3666 lossL: tensor(2556953.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3667 lossL: tensor(2551879., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3668 lossL: tensor(2442806.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3669 lossL: tensor(2422824.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3670 lossL: tensor(2641924.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3671 lossL: tensor(2445315.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3672 lossL: tensor(2539367.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3673 lossL: tensor(2410134., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3674 lossL: tensor(2637743.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3675 lossL: tensor(2616747., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3676 lossL: tensor(2525294.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3677 lossL: tensor(2590574., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3678 lossL: tensor(2643477., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3679 lossL: tensor(2570732.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3680 lossL: tensor(2666037.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3681 lossL: tensor(2396335., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3682 lossL: tensor(2590025.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3683 lossL: tensor(2670406.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3684 lossL: tensor(2538799., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3685 lossL: tensor(2559575.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3686 lossL: tensor(2415373.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3687 lossL: tensor(2492715., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3688 lossL: tensor(2491417., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3689 lossL: tensor(2636140.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3690 lossL: tensor(2498589.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3691 lossL: tensor(2525687.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3692 lossL: tensor(2549715.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3693 lossL: tensor(2431952.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3694 lossL: tensor(2553544.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3695 lossL: tensor(2668104.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3696 lossL: tensor(2582007., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3697 lossL: tensor(2579789.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3698 lossL: tensor(2368192.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3699 lossL: tensor(2777960., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3700 lossL: tensor(2839624., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3701 lossL: tensor(2436172., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3702 lossL: tensor(2619238.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3703 lossL: tensor(2427115.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3704 lossL: tensor(2724892.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3705 lossL: tensor(2638431., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3706 lossL: tensor(2520324.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3707 lossL: tensor(2534421.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3708 lossL: tensor(2609708., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3709 lossL: tensor(2675157.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3710 lossL: tensor(2449868., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3711 lossL: tensor(2372530., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3712 lossL: tensor(2618438.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3713 lossL: tensor(2629711.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3714 lossL: tensor(2620503., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3715 lossL: tensor(2596658.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3716 lossL: tensor(2540430.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3717 lossL: tensor(2499989., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3718 lossL: tensor(2525420.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3719 lossL: tensor(2560199., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3720 lossL: tensor(2630837.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3721 lossL: tensor(2509861.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3722 lossL: tensor(2708164.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3723 lossL: tensor(2520625.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3724 lossL: tensor(2734202., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3725 lossL: tensor(2535663., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3726 lossL: tensor(2609168.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3727 lossL: tensor(2431531., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3728 lossL: tensor(2421694.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3729 lossL: tensor(2600148., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3730 lossL: tensor(2555333.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3731 lossL: tensor(2476105., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3732 lossL: tensor(2730285.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3733 lossL: tensor(2423404.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3734 lossL: tensor(2561285.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3735 lossL: tensor(2570651.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3736 lossL: tensor(2466656., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3737 lossL: tensor(2553963.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3738 lossL: tensor(2683406., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3739 lossL: tensor(2416077.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3740 lossL: tensor(2749666.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3741 lossL: tensor(2583015.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3742 lossL: tensor(2467225.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3743 lossL: tensor(2640272.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3744 lossL: tensor(2553653.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3745 lossL: tensor(2441966.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3746 lossL: tensor(2466541., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3747 lossL: tensor(2665884.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3748 lossL: tensor(2607218., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3749 lossL: tensor(2538966.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3750 lossL: tensor(2554850.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3751 lossL: tensor(2477197., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3752 lossL: tensor(2370734.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3753 lossL: tensor(2593589.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3754 lossL: tensor(2563502.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3755 lossL: tensor(2540932.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3756 lossL: tensor(2553984.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3757 lossL: tensor(2487582.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3758 lossL: tensor(2620599.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3759 lossL: tensor(2714513., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3760 lossL: tensor(2526596.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3761 lossL: tensor(2645482.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3762 lossL: tensor(2604502.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3763 lossL: tensor(2521227.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3764 lossL: tensor(2518722.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3765 lossL: tensor(2698982.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3766 lossL: tensor(2582261., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3767 lossL: tensor(2714662.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3768 lossL: tensor(2583415., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3769 lossL: tensor(2550609.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3770 lossL: tensor(2517286.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3771 lossL: tensor(2714056.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3772 lossL: tensor(2587043.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3773 lossL: tensor(2637668.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3774 lossL: tensor(2543944.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3775 lossL: tensor(2579000.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3776 lossL: tensor(2642747.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3777 lossL: tensor(2570014.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3778 lossL: tensor(2528649.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3779 lossL: tensor(2626956.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3780 lossL: tensor(2555882.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3781 lossL: tensor(2588316.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3782 lossL: tensor(2670127.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3783 lossL: tensor(2502660.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3784 lossL: tensor(2393273.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3785 lossL: tensor(2678218.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3786 lossL: tensor(2519267.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3787 lossL: tensor(2643570.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3788 lossL: tensor(2475131.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3789 lossL: tensor(2594817., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3790 lossL: tensor(2512390.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3791 lossL: tensor(2637590.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3792 lossL: tensor(2395273., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3793 lossL: tensor(2526045.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3794 lossL: tensor(2804508., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3795 lossL: tensor(2587231.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3796 lossL: tensor(2581399.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3797 lossL: tensor(2491604.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3798 lossL: tensor(2596184.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3799 lossL: tensor(2618744., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3800 lossL: tensor(2514190.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3801 lossL: tensor(2475217.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3802 lossL: tensor(2629937.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3803 lossL: tensor(2644025., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3804 lossL: tensor(2438801., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3805 lossL: tensor(2722533., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3806 lossL: tensor(2534971.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3807 lossL: tensor(2530458.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3808 lossL: tensor(2435632.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3809 lossL: tensor(2467372.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3810 lossL: tensor(2554199.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3811 lossL: tensor(2660682., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3812 lossL: tensor(2511953.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3813 lossL: tensor(2360556., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3814 lossL: tensor(2547784.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3815 lossL: tensor(2559552.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3816 lossL: tensor(2619409.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3817 lossL: tensor(2515150.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3818 lossL: tensor(2536927.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3819 lossL: tensor(2497559., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3820 lossL: tensor(2489553.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3821 lossL: tensor(2539248.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3822 lossL: tensor(2729750.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3823 lossL: tensor(2577736.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3824 lossL: tensor(2424434.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3825 lossL: tensor(2565330.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3826 lossL: tensor(2315835., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3827 lossL: tensor(2599697.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3828 lossL: tensor(2591529.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3829 lossL: tensor(2565709.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3830 lossL: tensor(2546331.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3831 lossL: tensor(2455218.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3832 lossL: tensor(2678025.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3833 lossL: tensor(2415871.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3834 lossL: tensor(2559111.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3835 lossL: tensor(2579070.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3836 lossL: tensor(2783408.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3837 lossL: tensor(2669077.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3838 lossL: tensor(2676540., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3839 lossL: tensor(2506973., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3840 lossL: tensor(2634132.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3841 lossL: tensor(2438591.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3842 lossL: tensor(2687287., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3843 lossL: tensor(2556257.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3844 lossL: tensor(2611614.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3845 lossL: tensor(2671610.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3846 lossL: tensor(2383900.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3847 lossL: tensor(2501114., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3848 lossL: tensor(2500759.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3849 lossL: tensor(2749879.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3850 lossL: tensor(2557809.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3851 lossL: tensor(2525542.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3852 lossL: tensor(2649328.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3853 lossL: tensor(2585355.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3854 lossL: tensor(2816173.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3855 lossL: tensor(2530418.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3856 lossL: tensor(2472719.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3857 lossL: tensor(2683614.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3858 lossL: tensor(2607278., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3859 lossL: tensor(2480928.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3860 lossL: tensor(2571911.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3861 lossL: tensor(2480860.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3862 lossL: tensor(2441338.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3863 lossL: tensor(2695453.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3864 lossL: tensor(2610095.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3865 lossL: tensor(2583500.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3866 lossL: tensor(2512322.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3867 lossL: tensor(2459123.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3868 lossL: tensor(2385738.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3869 lossL: tensor(2671158.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3870 lossL: tensor(2621071.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3871 lossL: tensor(2657828.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3872 lossL: tensor(2479500.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3873 lossL: tensor(2636193., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3874 lossL: tensor(2502245.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3875 lossL: tensor(2580715.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3876 lossL: tensor(2495168.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3877 lossL: tensor(2639177.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3878 lossL: tensor(2492887.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3879 lossL: tensor(2670975.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3880 lossL: tensor(2504283.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3881 lossL: tensor(2655603., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3882 lossL: tensor(2532090.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3883 lossL: tensor(2485951.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3884 lossL: tensor(2507911.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3885 lossL: tensor(2483024., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3886 lossL: tensor(2588494.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3887 lossL: tensor(2503457.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3888 lossL: tensor(2543012.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3889 lossL: tensor(2431507., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3890 lossL: tensor(2715792.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3891 lossL: tensor(2428539.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3892 lossL: tensor(2609256.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3893 lossL: tensor(2339328.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3894 lossL: tensor(2605736.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3895 lossL: tensor(2594823., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3896 lossL: tensor(2517687., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3897 lossL: tensor(2486785., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3898 lossL: tensor(2616569., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3899 lossL: tensor(2309986., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "3900 lossL: tensor(2537872., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3901 lossL: tensor(2394705.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3902 lossL: tensor(2575066.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3903 lossL: tensor(2453227.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3904 lossL: tensor(2478284., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3905 lossL: tensor(2508359.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3906 lossL: tensor(2640510.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3907 lossL: tensor(2566096.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3908 lossL: tensor(2566863.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3909 lossL: tensor(2723558.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3910 lossL: tensor(2481323.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3911 lossL: tensor(2426228.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3912 lossL: tensor(2553094.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3913 lossL: tensor(2433961.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3914 lossL: tensor(2550555.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3915 lossL: tensor(2542479.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3916 lossL: tensor(2541843.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3917 lossL: tensor(2503989.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3918 lossL: tensor(2590840.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3919 lossL: tensor(2541102.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3920 lossL: tensor(2389387.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3921 lossL: tensor(2473510.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3922 lossL: tensor(2387866.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3923 lossL: tensor(2563904.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3924 lossL: tensor(2553417.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3925 lossL: tensor(2534297.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3926 lossL: tensor(2524403., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3927 lossL: tensor(2652656.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3928 lossL: tensor(2620111.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3929 lossL: tensor(2358039.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3930 lossL: tensor(2691634.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3931 lossL: tensor(2544758.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3932 lossL: tensor(2531148., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3933 lossL: tensor(2518601., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3934 lossL: tensor(2568564.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3935 lossL: tensor(2648920.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3936 lossL: tensor(2700744.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3937 lossL: tensor(2608240., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3938 lossL: tensor(2524693.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3939 lossL: tensor(2413555.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3940 lossL: tensor(2535099.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3941 lossL: tensor(2541588.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3942 lossL: tensor(2559285.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3943 lossL: tensor(2517203.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3944 lossL: tensor(2509373.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3945 lossL: tensor(2458936.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3946 lossL: tensor(2614297.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3947 lossL: tensor(2517026.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3948 lossL: tensor(2375684., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3949 lossL: tensor(2465995., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3950 lossL: tensor(2469241., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3951 lossL: tensor(2570275.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3952 lossL: tensor(2664707.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3953 lossL: tensor(2470144., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3954 lossL: tensor(2551427.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3955 lossL: tensor(2705009.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3956 lossL: tensor(2505714.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3957 lossL: tensor(2482668.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3958 lossL: tensor(2565106., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3959 lossL: tensor(2723889., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3960 lossL: tensor(2566414.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3961 lossL: tensor(2590219., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3962 lossL: tensor(2522531.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3963 lossL: tensor(2401065.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3964 lossL: tensor(2517874.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3965 lossL: tensor(2595971.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3966 lossL: tensor(2471937.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3967 lossL: tensor(2509240.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3968 lossL: tensor(2562221., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3969 lossL: tensor(2612519., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3970 lossL: tensor(2618257.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3971 lossL: tensor(2530630.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3972 lossL: tensor(2630954.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3973 lossL: tensor(2428453.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3974 lossL: tensor(2640035.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3975 lossL: tensor(2432018.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3976 lossL: tensor(2609052.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3977 lossL: tensor(2557076., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3978 lossL: tensor(2500509.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3979 lossL: tensor(2542089., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3980 lossL: tensor(2362477.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3981 lossL: tensor(2636525.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3982 lossL: tensor(2427550.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3983 lossL: tensor(2494569.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3984 lossL: tensor(2327439.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3985 lossL: tensor(2645163.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3986 lossL: tensor(2641344.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3987 lossL: tensor(2523903.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3988 lossL: tensor(2517916., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3989 lossL: tensor(2470435., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3990 lossL: tensor(2539233., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3991 lossL: tensor(2505041.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3992 lossL: tensor(2578435.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3993 lossL: tensor(2502272., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3994 lossL: tensor(2620501.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3995 lossL: tensor(2418868.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3996 lossL: tensor(2641227.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3997 lossL: tensor(2573551.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3998 lossL: tensor(2426175.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "3999 lossL: tensor(2601259.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4000 lossL: tensor(2421491.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4001 lossL: tensor(2556837.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4002 lossL: tensor(2578256., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4003 lossL: tensor(2647718.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4004 lossL: tensor(2483025.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4005 lossL: tensor(2658129.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4006 lossL: tensor(2573899.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4007 lossL: tensor(2453414., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4008 lossL: tensor(2615354.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4009 lossL: tensor(2584718., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4010 lossL: tensor(2548454., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4011 lossL: tensor(2375023.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4012 lossL: tensor(2508837.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4013 lossL: tensor(2479957.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4014 lossL: tensor(2660891.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4015 lossL: tensor(2665432., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4016 lossL: tensor(2484398.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4017 lossL: tensor(2571204.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4018 lossL: tensor(2456854.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4019 lossL: tensor(2515322.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4020 lossL: tensor(2623713.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4021 lossL: tensor(2499460.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4022 lossL: tensor(2505913.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4023 lossL: tensor(2562599., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4024 lossL: tensor(2473273.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4025 lossL: tensor(2478131.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4026 lossL: tensor(2418603.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4027 lossL: tensor(2530295., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4028 lossL: tensor(2424832.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4029 lossL: tensor(2500615.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4030 lossL: tensor(2455580.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4031 lossL: tensor(2639593.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4032 lossL: tensor(2615666.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4033 lossL: tensor(2605537.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4034 lossL: tensor(2426962.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4035 lossL: tensor(2427444., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4036 lossL: tensor(2517239., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4037 lossL: tensor(2431949., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4038 lossL: tensor(2627278.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4039 lossL: tensor(2509156.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4040 lossL: tensor(2706601.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4041 lossL: tensor(2619944.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4042 lossL: tensor(2458769.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4043 lossL: tensor(2566471.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4044 lossL: tensor(2514459.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4045 lossL: tensor(2610125.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4046 lossL: tensor(2631450.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4047 lossL: tensor(2591471.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4048 lossL: tensor(2640062.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4049 lossL: tensor(2468504., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4050 lossL: tensor(2508046.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4051 lossL: tensor(2452025.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4052 lossL: tensor(2593702.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4053 lossL: tensor(2519204.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4054 lossL: tensor(2475711.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4055 lossL: tensor(2392872.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4056 lossL: tensor(2615805.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4057 lossL: tensor(2522266., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4058 lossL: tensor(2542068.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4059 lossL: tensor(2580352.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4060 lossL: tensor(2536479., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4061 lossL: tensor(2598610.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4062 lossL: tensor(2620547., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4063 lossL: tensor(2501495.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4064 lossL: tensor(2437718.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4065 lossL: tensor(2485011., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4066 lossL: tensor(2401870.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4067 lossL: tensor(2499033., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4068 lossL: tensor(2445190.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4069 lossL: tensor(2516724., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4070 lossL: tensor(2525227.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4071 lossL: tensor(2630944.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4072 lossL: tensor(2393385., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4073 lossL: tensor(2625264.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4074 lossL: tensor(2501100.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4075 lossL: tensor(2603404.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4076 lossL: tensor(2387035.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4077 lossL: tensor(2566852.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4078 lossL: tensor(2553794., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4079 lossL: tensor(2448244.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4080 lossL: tensor(2464452.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4081 lossL: tensor(2439126.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4082 lossL: tensor(2557282.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4083 lossL: tensor(2444466.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4084 lossL: tensor(2517500.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4085 lossL: tensor(2532231., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4086 lossL: tensor(2544489.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4087 lossL: tensor(2541477.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4088 lossL: tensor(2582646., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4089 lossL: tensor(2595104., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4090 lossL: tensor(2579353.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4091 lossL: tensor(2451726.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4092 lossL: tensor(2557234.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4093 lossL: tensor(2593819.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4094 lossL: tensor(2450902., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4095 lossL: tensor(2558832.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4096 lossL: tensor(2521093., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4097 lossL: tensor(2547535.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4098 lossL: tensor(2468403.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4099 lossL: tensor(2613727., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4100 lossL: tensor(2376645., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4101 lossL: tensor(2534088.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4102 lossL: tensor(2379200., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4103 lossL: tensor(2276326.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "4104 lossL: tensor(2560598., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4105 lossL: tensor(2498756.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4106 lossL: tensor(2590775.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4107 lossL: tensor(2559299., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4108 lossL: tensor(2494777.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4109 lossL: tensor(2500058.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4110 lossL: tensor(2431637.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4111 lossL: tensor(2498900.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4112 lossL: tensor(2434792., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4113 lossL: tensor(2403999.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4114 lossL: tensor(2335329.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4115 lossL: tensor(2429753.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4116 lossL: tensor(2280901.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4117 lossL: tensor(2518944.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4118 lossL: tensor(2712888.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4119 lossL: tensor(2542624.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4120 lossL: tensor(2632302.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4121 lossL: tensor(2530755.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4122 lossL: tensor(2493454., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4123 lossL: tensor(2574514.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4124 lossL: tensor(2511843.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4125 lossL: tensor(2460671.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4126 lossL: tensor(2722235.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4127 lossL: tensor(2508303.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4128 lossL: tensor(2634498.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4129 lossL: tensor(2546629., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4130 lossL: tensor(2499656.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4131 lossL: tensor(2530999., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4132 lossL: tensor(2513469.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4133 lossL: tensor(2544322.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4134 lossL: tensor(2638375.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4135 lossL: tensor(2577437., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4136 lossL: tensor(2689751., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4137 lossL: tensor(2472607.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4138 lossL: tensor(2441359.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4139 lossL: tensor(2447419., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4140 lossL: tensor(2513560.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4141 lossL: tensor(2559362.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4142 lossL: tensor(2418277.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4143 lossL: tensor(2659238.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4144 lossL: tensor(2403230.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4145 lossL: tensor(2633933.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4146 lossL: tensor(2606554.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4147 lossL: tensor(2524055.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4148 lossL: tensor(2509179.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4149 lossL: tensor(2424980.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4150 lossL: tensor(2407375.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4151 lossL: tensor(2574116.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4152 lossL: tensor(2476071.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4153 lossL: tensor(2536464.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4154 lossL: tensor(2746240.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4155 lossL: tensor(2564718.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4156 lossL: tensor(2418638.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4157 lossL: tensor(2593212., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4158 lossL: tensor(2425512.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4159 lossL: tensor(2426244.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4160 lossL: tensor(2425911.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4161 lossL: tensor(2525129.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4162 lossL: tensor(2627394.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4163 lossL: tensor(2377767.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4164 lossL: tensor(2471850.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4165 lossL: tensor(2471333.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4166 lossL: tensor(2549413.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4167 lossL: tensor(2534769.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4168 lossL: tensor(2434204.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4169 lossL: tensor(2613678.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4170 lossL: tensor(2606684.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4171 lossL: tensor(2449200.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4172 lossL: tensor(2551967.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4173 lossL: tensor(2605176.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4174 lossL: tensor(2577477.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4175 lossL: tensor(2449792., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4176 lossL: tensor(2562521., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4177 lossL: tensor(2525712., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4178 lossL: tensor(2508032., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4179 lossL: tensor(2522316., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4180 lossL: tensor(2533690.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4181 lossL: tensor(2474954., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4182 lossL: tensor(2533483.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4183 lossL: tensor(2405632., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4184 lossL: tensor(2618487.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4185 lossL: tensor(2474101., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4186 lossL: tensor(2590652., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4187 lossL: tensor(2288374., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4188 lossL: tensor(2479125.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4189 lossL: tensor(2568615.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4190 lossL: tensor(2578957.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4191 lossL: tensor(2359409., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4192 lossL: tensor(2599931.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4193 lossL: tensor(2458963.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4194 lossL: tensor(2439818.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4195 lossL: tensor(2484259.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4196 lossL: tensor(2642421., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4197 lossL: tensor(2482963.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4198 lossL: tensor(2482171.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4199 lossL: tensor(2526253.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4200 lossL: tensor(2511446.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4201 lossL: tensor(2481681.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4202 lossL: tensor(2460202., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4203 lossL: tensor(2386912.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4204 lossL: tensor(2553259.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4205 lossL: tensor(2391859.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4206 lossL: tensor(2605239.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4207 lossL: tensor(2443073.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4208 lossL: tensor(2481253., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4209 lossL: tensor(2387272.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4210 lossL: tensor(2505929.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4211 lossL: tensor(2496349.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4212 lossL: tensor(2472518.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4213 lossL: tensor(2410559.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4214 lossL: tensor(2526948., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4215 lossL: tensor(2440153.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4216 lossL: tensor(2549844.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4217 lossL: tensor(2476555.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4218 lossL: tensor(2768577., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4219 lossL: tensor(2498999.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4220 lossL: tensor(2475810., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4221 lossL: tensor(2480046., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4222 lossL: tensor(2603286.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4223 lossL: tensor(2538581., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4224 lossL: tensor(2623948.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4225 lossL: tensor(2532222.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4226 lossL: tensor(2546268.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4227 lossL: tensor(2393143.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4228 lossL: tensor(2444044.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4229 lossL: tensor(2596764.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4230 lossL: tensor(2553439.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4231 lossL: tensor(2514310.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4232 lossL: tensor(2600193.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4233 lossL: tensor(2502153.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4234 lossL: tensor(2503193.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4235 lossL: tensor(2596433., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4236 lossL: tensor(2460833., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4237 lossL: tensor(2580994.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4238 lossL: tensor(2610771.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4239 lossL: tensor(2597507., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4240 lossL: tensor(2442595.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4241 lossL: tensor(2665631.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4242 lossL: tensor(2415315.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4243 lossL: tensor(2590653., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4244 lossL: tensor(2463129.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4245 lossL: tensor(2355898.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4246 lossL: tensor(2472218.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4247 lossL: tensor(2583173.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4248 lossL: tensor(2491796.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4249 lossL: tensor(2608315., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4250 lossL: tensor(2554997.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4251 lossL: tensor(2647113.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4252 lossL: tensor(2466575.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4253 lossL: tensor(2366006.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4254 lossL: tensor(2393630.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4255 lossL: tensor(2478564.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4256 lossL: tensor(2657617.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4257 lossL: tensor(2545819.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4258 lossL: tensor(2590087., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4259 lossL: tensor(2376081.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4260 lossL: tensor(2615460.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4261 lossL: tensor(2615693., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4262 lossL: tensor(2449539.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4263 lossL: tensor(2611251.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4264 lossL: tensor(2588719.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4265 lossL: tensor(2417926.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4266 lossL: tensor(2397964.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4267 lossL: tensor(2481717., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4268 lossL: tensor(2698763.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4269 lossL: tensor(2370569.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4270 lossL: tensor(2356780., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4271 lossL: tensor(2551085.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4272 lossL: tensor(2467387.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4273 lossL: tensor(2598566.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4274 lossL: tensor(2466990.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4275 lossL: tensor(2548121.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4276 lossL: tensor(2556310.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4277 lossL: tensor(2568402.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4278 lossL: tensor(2445464.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4279 lossL: tensor(2541644.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4280 lossL: tensor(2345845.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4281 lossL: tensor(2473921.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4282 lossL: tensor(2516035.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4283 lossL: tensor(2669063.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4284 lossL: tensor(2625529., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4285 lossL: tensor(2486319.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4286 lossL: tensor(2524044.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4287 lossL: tensor(2552582.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4288 lossL: tensor(2518106., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4289 lossL: tensor(2572346.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4290 lossL: tensor(2578551., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4291 lossL: tensor(2447703.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4292 lossL: tensor(2593871.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4293 lossL: tensor(2584091.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4294 lossL: tensor(2370035.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4295 lossL: tensor(2595322.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4296 lossL: tensor(2455618.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4297 lossL: tensor(2545102., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4298 lossL: tensor(2563244.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4299 lossL: tensor(2468639.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4300 lossL: tensor(2478181.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4301 lossL: tensor(2486209.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4302 lossL: tensor(2502890.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4303 lossL: tensor(2572295.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4304 lossL: tensor(2443710.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4305 lossL: tensor(2629790., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4306 lossL: tensor(2456306., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4307 lossL: tensor(2601021.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4308 lossL: tensor(2671219.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4309 lossL: tensor(2620534.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4310 lossL: tensor(2618270.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4311 lossL: tensor(2606709., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4312 lossL: tensor(2456667.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4313 lossL: tensor(2494864.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4314 lossL: tensor(2511059.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4315 lossL: tensor(2521956., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4316 lossL: tensor(2601220., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4317 lossL: tensor(2577160.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4318 lossL: tensor(2554655.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4319 lossL: tensor(2614491.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4320 lossL: tensor(2401024.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4321 lossL: tensor(2489931.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4322 lossL: tensor(2542003.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4323 lossL: tensor(2382635.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4324 lossL: tensor(2424335., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4325 lossL: tensor(2551074.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4326 lossL: tensor(2506764.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4327 lossL: tensor(2540393., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4328 lossL: tensor(2324694.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4329 lossL: tensor(2508228.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4330 lossL: tensor(2554878., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4331 lossL: tensor(2440465., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4332 lossL: tensor(2366661.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4333 lossL: tensor(2495223.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4334 lossL: tensor(2582899.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4335 lossL: tensor(2566756.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4336 lossL: tensor(2566804.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4337 lossL: tensor(2454701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4338 lossL: tensor(2577151.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4339 lossL: tensor(2501785.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4340 lossL: tensor(2522610.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4341 lossL: tensor(2518398.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4342 lossL: tensor(2451673.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4343 lossL: tensor(2637103., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4344 lossL: tensor(2669797., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4345 lossL: tensor(2390824.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4346 lossL: tensor(2480345.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4347 lossL: tensor(2499770.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4348 lossL: tensor(2439611.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4349 lossL: tensor(2621742.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4350 lossL: tensor(2477853.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4351 lossL: tensor(2426411.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4352 lossL: tensor(2603765.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4353 lossL: tensor(2448300., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4354 lossL: tensor(2646742.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4355 lossL: tensor(2604216., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4356 lossL: tensor(2559668.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4357 lossL: tensor(2500582.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4358 lossL: tensor(2391334.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4359 lossL: tensor(2552300.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4360 lossL: tensor(2565403.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4361 lossL: tensor(2596764.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4362 lossL: tensor(2491992.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4363 lossL: tensor(2506672.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4364 lossL: tensor(2509700.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4365 lossL: tensor(2633388.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4366 lossL: tensor(2507150.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4367 lossL: tensor(2609144., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4368 lossL: tensor(2505624.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4369 lossL: tensor(2500959.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4370 lossL: tensor(2530689.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4371 lossL: tensor(2477156.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4372 lossL: tensor(2404361.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4373 lossL: tensor(2595257.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4374 lossL: tensor(2471332.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4375 lossL: tensor(2381933.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4376 lossL: tensor(2443448., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4377 lossL: tensor(2442092.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4378 lossL: tensor(2428485., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4379 lossL: tensor(2548691., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4380 lossL: tensor(2468761.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4381 lossL: tensor(2486465., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4382 lossL: tensor(2560055.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4383 lossL: tensor(2419687., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4384 lossL: tensor(2403564.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4385 lossL: tensor(2343015., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4386 lossL: tensor(2464721.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4387 lossL: tensor(2732608.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4388 lossL: tensor(2690350.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4389 lossL: tensor(2406573.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4390 lossL: tensor(2483055.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4391 lossL: tensor(2676416.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4392 lossL: tensor(2516913.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4393 lossL: tensor(2478615., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4394 lossL: tensor(2421474.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4395 lossL: tensor(2508598.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4396 lossL: tensor(2437625.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4397 lossL: tensor(2463218.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4398 lossL: tensor(2512556.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4399 lossL: tensor(2478894.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4400 lossL: tensor(2658677.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4401 lossL: tensor(2606017., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4402 lossL: tensor(2574102.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4403 lossL: tensor(2504376., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4404 lossL: tensor(2507888.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4405 lossL: tensor(2446915.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4406 lossL: tensor(2383236.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4407 lossL: tensor(2449038.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4408 lossL: tensor(2530617.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4409 lossL: tensor(2438315.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4410 lossL: tensor(2503499.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4411 lossL: tensor(2530572.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4412 lossL: tensor(2392199.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4413 lossL: tensor(2500465.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4414 lossL: tensor(2453250.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4415 lossL: tensor(2518293., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4416 lossL: tensor(2368154.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4417 lossL: tensor(2586667.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4418 lossL: tensor(2508363., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4419 lossL: tensor(2582201.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4420 lossL: tensor(2440861.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4421 lossL: tensor(2472836.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4422 lossL: tensor(2442586.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4423 lossL: tensor(2466954.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4424 lossL: tensor(2564428.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4425 lossL: tensor(2466175.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4426 lossL: tensor(2488548.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4427 lossL: tensor(2418938., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4428 lossL: tensor(2518805.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4429 lossL: tensor(2428839.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4430 lossL: tensor(2390886., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4431 lossL: tensor(2600893.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4432 lossL: tensor(2472250., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4433 lossL: tensor(2462067.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4434 lossL: tensor(2397198.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4435 lossL: tensor(2603279.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4436 lossL: tensor(2521213., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4437 lossL: tensor(2567208.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4438 lossL: tensor(2600672.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4439 lossL: tensor(2431511.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4440 lossL: tensor(2431060.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4441 lossL: tensor(2522935., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4442 lossL: tensor(2595109.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4443 lossL: tensor(2527756.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4444 lossL: tensor(2375723.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4445 lossL: tensor(2591987.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4446 lossL: tensor(2497116.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4447 lossL: tensor(2612744.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4448 lossL: tensor(2422432.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4449 lossL: tensor(2408140., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4450 lossL: tensor(2578920., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4451 lossL: tensor(2403872.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4452 lossL: tensor(2447222., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4453 lossL: tensor(2525777.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4454 lossL: tensor(2423952., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4455 lossL: tensor(2535086.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4456 lossL: tensor(2506623.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4457 lossL: tensor(2470432.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4458 lossL: tensor(2520874.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4459 lossL: tensor(2495071.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4460 lossL: tensor(2327747.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4461 lossL: tensor(2431185.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4462 lossL: tensor(2634769., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4463 lossL: tensor(2539398.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4464 lossL: tensor(2390860.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4465 lossL: tensor(2375511., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4466 lossL: tensor(2530903.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4467 lossL: tensor(2342557.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4468 lossL: tensor(2684605.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4469 lossL: tensor(2623687.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4470 lossL: tensor(2377942., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4471 lossL: tensor(2426645.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4472 lossL: tensor(2484620.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4473 lossL: tensor(2575287.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4474 lossL: tensor(2506992.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4475 lossL: tensor(2450327.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4476 lossL: tensor(2485952.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4477 lossL: tensor(2540621.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4478 lossL: tensor(2402826.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4479 lossL: tensor(2588147., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4480 lossL: tensor(2617737.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4481 lossL: tensor(2489168., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4482 lossL: tensor(2448973., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4483 lossL: tensor(2477635.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4484 lossL: tensor(2614388.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4485 lossL: tensor(2497786.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4486 lossL: tensor(2564429.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4487 lossL: tensor(2437397., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4488 lossL: tensor(2395433.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4489 lossL: tensor(2557586.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4490 lossL: tensor(2645828.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4491 lossL: tensor(2437081.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4492 lossL: tensor(2478549.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4493 lossL: tensor(2553615.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4494 lossL: tensor(2554743., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4495 lossL: tensor(2670852., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4496 lossL: tensor(2451494., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4497 lossL: tensor(2651304.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4498 lossL: tensor(2461547.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4499 lossL: tensor(2483353.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4500 lossL: tensor(2394456.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4501 lossL: tensor(2464073., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4502 lossL: tensor(2531977.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4503 lossL: tensor(2611340.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4504 lossL: tensor(2472750.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4505 lossL: tensor(2406102., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4506 lossL: tensor(2453924.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4507 lossL: tensor(2538544.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4508 lossL: tensor(2444933.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4509 lossL: tensor(2479181.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4510 lossL: tensor(2506455., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4511 lossL: tensor(2538704.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4512 lossL: tensor(2450081.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4513 lossL: tensor(2566135.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4514 lossL: tensor(2407870.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4515 lossL: tensor(2685839.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4516 lossL: tensor(2494668., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4517 lossL: tensor(2442009.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4518 lossL: tensor(2578665., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4519 lossL: tensor(2650098.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4520 lossL: tensor(2542604.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4521 lossL: tensor(2420126.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4522 lossL: tensor(2665595., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4523 lossL: tensor(2506378., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4524 lossL: tensor(2391551.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4525 lossL: tensor(2508122.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4526 lossL: tensor(2513320., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4527 lossL: tensor(2434510., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4528 lossL: tensor(2515257., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4529 lossL: tensor(2457485.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4530 lossL: tensor(2472914.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4531 lossL: tensor(2434109.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4532 lossL: tensor(2350167.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4533 lossL: tensor(2542251.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4534 lossL: tensor(2375672.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4535 lossL: tensor(2458138.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4536 lossL: tensor(2589070.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4537 lossL: tensor(2646737.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4538 lossL: tensor(2505114.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4539 lossL: tensor(2417508.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4540 lossL: tensor(2402702., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4541 lossL: tensor(2360549.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4542 lossL: tensor(2532273.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4543 lossL: tensor(2458792.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4544 lossL: tensor(2520492.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4545 lossL: tensor(2486759.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4546 lossL: tensor(2348805.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4547 lossL: tensor(2428229.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4548 lossL: tensor(2538899.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4549 lossL: tensor(2517551.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4550 lossL: tensor(2580668., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4551 lossL: tensor(2445862.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4552 lossL: tensor(2522798.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4553 lossL: tensor(2419921.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4554 lossL: tensor(2442240.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4555 lossL: tensor(2507671.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4556 lossL: tensor(2557908., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4557 lossL: tensor(2387520.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4558 lossL: tensor(2458535.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4559 lossL: tensor(2458358., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4560 lossL: tensor(2411949., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4561 lossL: tensor(2466171., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4562 lossL: tensor(2431783.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4563 lossL: tensor(2604830.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4564 lossL: tensor(2574628.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4565 lossL: tensor(2569757.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4566 lossL: tensor(2403143.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4567 lossL: tensor(2577887.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4568 lossL: tensor(2590169.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4569 lossL: tensor(2390747.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4570 lossL: tensor(2654224.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4571 lossL: tensor(2581339.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4572 lossL: tensor(2485885.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4573 lossL: tensor(2541005.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4574 lossL: tensor(2384945.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4575 lossL: tensor(2526851.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4576 lossL: tensor(2593896., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4577 lossL: tensor(2605930.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4578 lossL: tensor(2382804.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4579 lossL: tensor(2524634.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4580 lossL: tensor(2524239.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4581 lossL: tensor(2476357.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4582 lossL: tensor(2351517.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4583 lossL: tensor(2747885.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4584 lossL: tensor(2527888.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4585 lossL: tensor(2337140.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4586 lossL: tensor(2399013., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4587 lossL: tensor(2638995.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4588 lossL: tensor(2546151.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4589 lossL: tensor(2260398.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "4590 lossL: tensor(2641829., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4591 lossL: tensor(2449272.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4592 lossL: tensor(2719302., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4593 lossL: tensor(2511973.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4594 lossL: tensor(2585820.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4595 lossL: tensor(2463262.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4596 lossL: tensor(2582304.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4597 lossL: tensor(2428320.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4598 lossL: tensor(2615028., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4599 lossL: tensor(2485276., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4600 lossL: tensor(2472261.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4601 lossL: tensor(2650436.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4602 lossL: tensor(2314919.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4603 lossL: tensor(2563327.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4604 lossL: tensor(2605842.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4605 lossL: tensor(2637297.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4606 lossL: tensor(2539139.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4607 lossL: tensor(2523621.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4608 lossL: tensor(2356602.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4609 lossL: tensor(2446994.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4610 lossL: tensor(2372993.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4611 lossL: tensor(2584622.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4612 lossL: tensor(2482924., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4613 lossL: tensor(2414546.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4614 lossL: tensor(2450166., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4615 lossL: tensor(2428000.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4616 lossL: tensor(2464105.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4617 lossL: tensor(2401695.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4618 lossL: tensor(2448610.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4619 lossL: tensor(2467926., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4620 lossL: tensor(2614755.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4621 lossL: tensor(2415750.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4622 lossL: tensor(2477894.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4623 lossL: tensor(2342707.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4624 lossL: tensor(2476769.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4625 lossL: tensor(2381967.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4626 lossL: tensor(2347224.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4627 lossL: tensor(2436198.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4628 lossL: tensor(2562228.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4629 lossL: tensor(2385876., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4630 lossL: tensor(2455177.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4631 lossL: tensor(2489648., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4632 lossL: tensor(2469433.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4633 lossL: tensor(2519783.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4634 lossL: tensor(2360094.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4635 lossL: tensor(2507929., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4636 lossL: tensor(2401975.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4637 lossL: tensor(2532850.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4638 lossL: tensor(2353789.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4639 lossL: tensor(2567898.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4640 lossL: tensor(2399767.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4641 lossL: tensor(2372668.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4642 lossL: tensor(2415019., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4643 lossL: tensor(2354950., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4644 lossL: tensor(2722397.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4645 lossL: tensor(2410233.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4646 lossL: tensor(2406637.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4647 lossL: tensor(2561944., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4648 lossL: tensor(2443224.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4649 lossL: tensor(2345504., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4650 lossL: tensor(2582750.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4651 lossL: tensor(2458000.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4652 lossL: tensor(2662300., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4653 lossL: tensor(2597541.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4654 lossL: tensor(2585410., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4655 lossL: tensor(2456772., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4656 lossL: tensor(2388976.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4657 lossL: tensor(2470150.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4658 lossL: tensor(2496846.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4659 lossL: tensor(2317526.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4660 lossL: tensor(2478082.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4661 lossL: tensor(2305940.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4662 lossL: tensor(2405435.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4663 lossL: tensor(2375418., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4664 lossL: tensor(2179771.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "4665 lossL: tensor(2539723., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4666 lossL: tensor(2345848.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4667 lossL: tensor(2412080.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4668 lossL: tensor(2426567.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4669 lossL: tensor(2563835., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4670 lossL: tensor(2395818.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4671 lossL: tensor(2550590.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4672 lossL: tensor(2438845.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4673 lossL: tensor(2457034., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4674 lossL: tensor(2315478.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4675 lossL: tensor(2508760.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4676 lossL: tensor(2499047.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4677 lossL: tensor(2469157.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4678 lossL: tensor(2357394., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4679 lossL: tensor(2571812.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4680 lossL: tensor(2290446.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4681 lossL: tensor(2384093., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4682 lossL: tensor(2514456.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4683 lossL: tensor(2576646.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4684 lossL: tensor(2422720.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4685 lossL: tensor(2551851.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4686 lossL: tensor(2342369.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4687 lossL: tensor(2429871.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4688 lossL: tensor(2453747.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4689 lossL: tensor(2377499.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4690 lossL: tensor(2506121.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4691 lossL: tensor(2356584.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4692 lossL: tensor(2604006., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4693 lossL: tensor(2541054.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4694 lossL: tensor(2446399.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4695 lossL: tensor(2566299.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4696 lossL: tensor(2505418.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4697 lossL: tensor(2440869.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4698 lossL: tensor(2490277.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4699 lossL: tensor(2377953.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4700 lossL: tensor(2558819.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4701 lossL: tensor(2638180.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4702 lossL: tensor(2522825.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4703 lossL: tensor(2480451.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4704 lossL: tensor(2323845., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4705 lossL: tensor(2406420.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4706 lossL: tensor(2625016., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4707 lossL: tensor(2590247.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4708 lossL: tensor(2424371.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4709 lossL: tensor(2543183., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4710 lossL: tensor(2298089., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4711 lossL: tensor(2437984.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4712 lossL: tensor(2401344.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4713 lossL: tensor(2416738.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4714 lossL: tensor(2546129., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4715 lossL: tensor(2486086.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4716 lossL: tensor(2481883.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4717 lossL: tensor(2413530., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4718 lossL: tensor(2571307.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4719 lossL: tensor(2319764.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4720 lossL: tensor(2544196.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4721 lossL: tensor(2532055.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4722 lossL: tensor(2369510.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4723 lossL: tensor(2429620.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4724 lossL: tensor(2456427.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4725 lossL: tensor(2240051.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4726 lossL: tensor(2358828., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4727 lossL: tensor(2324622., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4728 lossL: tensor(2371454.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4729 lossL: tensor(2422557., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4730 lossL: tensor(2381833.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4731 lossL: tensor(2415186.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4732 lossL: tensor(2532492.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4733 lossL: tensor(2404496.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4734 lossL: tensor(2592179.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4735 lossL: tensor(2370853.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4736 lossL: tensor(2477474., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4737 lossL: tensor(2376049.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4738 lossL: tensor(2507119., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4739 lossL: tensor(2354452.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4740 lossL: tensor(2307910.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4741 lossL: tensor(2398445.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4742 lossL: tensor(2476840.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4743 lossL: tensor(2362497.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4744 lossL: tensor(2449281.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4745 lossL: tensor(2315453.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4746 lossL: tensor(2410938.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4747 lossL: tensor(2461936.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4748 lossL: tensor(2330434., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4749 lossL: tensor(2578787.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4750 lossL: tensor(2424250., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4751 lossL: tensor(2342507., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4752 lossL: tensor(2476857., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4753 lossL: tensor(2388628.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4754 lossL: tensor(2317525.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4755 lossL: tensor(2486934.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4756 lossL: tensor(2390734.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4757 lossL: tensor(2423446.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4758 lossL: tensor(2364519.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4759 lossL: tensor(2551902., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4760 lossL: tensor(2570291.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4761 lossL: tensor(2461769.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4762 lossL: tensor(2386698.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4763 lossL: tensor(2469305.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4764 lossL: tensor(2384461.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4765 lossL: tensor(2303382.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4766 lossL: tensor(2428847.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4767 lossL: tensor(2428808.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4768 lossL: tensor(2452306.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4769 lossL: tensor(2333017., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4770 lossL: tensor(2619740.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4771 lossL: tensor(2428885.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4772 lossL: tensor(2482650.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4773 lossL: tensor(2551688., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4774 lossL: tensor(2429804., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4775 lossL: tensor(2364207., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4776 lossL: tensor(2515111.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4777 lossL: tensor(2377518., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4778 lossL: tensor(2446858.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4779 lossL: tensor(2529167.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4780 lossL: tensor(2540605.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4781 lossL: tensor(2378927.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4782 lossL: tensor(2606981., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4783 lossL: tensor(2372502.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4784 lossL: tensor(2414540.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4785 lossL: tensor(2384934.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4786 lossL: tensor(2402786., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4787 lossL: tensor(2424584.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4788 lossL: tensor(2232011.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4789 lossL: tensor(2435697.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4790 lossL: tensor(2549140.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4791 lossL: tensor(2459199., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4792 lossL: tensor(2306705., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4793 lossL: tensor(2612487.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4794 lossL: tensor(2636566.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4795 lossL: tensor(2521315., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4796 lossL: tensor(2403943.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4797 lossL: tensor(2425247.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4798 lossL: tensor(2526415.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4799 lossL: tensor(2617490.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4800 lossL: tensor(2376312.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4801 lossL: tensor(2418993.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4802 lossL: tensor(2430145.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4803 lossL: tensor(2384724.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4804 lossL: tensor(2404687.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4805 lossL: tensor(2367535.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4806 lossL: tensor(2546651.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4807 lossL: tensor(2392134.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4808 lossL: tensor(2638415.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4809 lossL: tensor(2360223., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4810 lossL: tensor(2406986.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4811 lossL: tensor(2403707.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4812 lossL: tensor(2411982.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4813 lossL: tensor(2520160., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4814 lossL: tensor(2427144.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4815 lossL: tensor(2279141.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4816 lossL: tensor(2498509.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4817 lossL: tensor(2474313.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4818 lossL: tensor(2396665., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4819 lossL: tensor(2396922.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4820 lossL: tensor(2532392.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4821 lossL: tensor(2331788.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4822 lossL: tensor(2499799.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4823 lossL: tensor(2501156.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4824 lossL: tensor(2345210.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4825 lossL: tensor(2251626., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4826 lossL: tensor(2515214.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4827 lossL: tensor(2398481., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4828 lossL: tensor(2403475.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4829 lossL: tensor(2529643., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4830 lossL: tensor(2636472.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4831 lossL: tensor(2382650.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4832 lossL: tensor(2629803.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4833 lossL: tensor(2438082.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4834 lossL: tensor(2511900.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4835 lossL: tensor(2399146.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4836 lossL: tensor(2642101.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4837 lossL: tensor(2366226.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4838 lossL: tensor(2570013.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4839 lossL: tensor(2319694.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4840 lossL: tensor(2441596.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4841 lossL: tensor(2547066., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4842 lossL: tensor(2395290.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4843 lossL: tensor(2478915.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4844 lossL: tensor(2373397., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4845 lossL: tensor(2532618.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4846 lossL: tensor(2476034.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4847 lossL: tensor(2266163.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4848 lossL: tensor(2509691.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4849 lossL: tensor(2292687.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4850 lossL: tensor(2430503.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4851 lossL: tensor(2282262.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4852 lossL: tensor(2398980., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4853 lossL: tensor(2506450., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4854 lossL: tensor(2591196.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4855 lossL: tensor(2410377.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4856 lossL: tensor(2515450.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4857 lossL: tensor(2349051.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4858 lossL: tensor(2421572.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4859 lossL: tensor(2439475.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4860 lossL: tensor(2326628.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4861 lossL: tensor(2492105., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4862 lossL: tensor(2453491.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4863 lossL: tensor(2548121.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4864 lossL: tensor(2460606., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4865 lossL: tensor(2494397.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4866 lossL: tensor(2462194., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4867 lossL: tensor(2419977.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4868 lossL: tensor(2489365.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4869 lossL: tensor(2427486.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4870 lossL: tensor(2426974.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4871 lossL: tensor(2465615.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4872 lossL: tensor(2383814., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4873 lossL: tensor(2426285., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4874 lossL: tensor(2380914.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4875 lossL: tensor(2436192., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4876 lossL: tensor(2583463.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4877 lossL: tensor(2452505.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4878 lossL: tensor(2461089.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4879 lossL: tensor(2228154.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4880 lossL: tensor(2346695.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4881 lossL: tensor(2399470.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4882 lossL: tensor(2576786., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4883 lossL: tensor(2429247.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4884 lossL: tensor(2453239.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4885 lossL: tensor(2386183.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4886 lossL: tensor(2630416.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4887 lossL: tensor(2439689.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4888 lossL: tensor(2413692., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4889 lossL: tensor(2324835., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4890 lossL: tensor(2486353.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4891 lossL: tensor(2338140.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4892 lossL: tensor(2524531., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4893 lossL: tensor(2362471.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4894 lossL: tensor(2567128.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4895 lossL: tensor(2505483.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4896 lossL: tensor(2502026.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4897 lossL: tensor(2450184.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4898 lossL: tensor(2501440.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4899 lossL: tensor(2344097., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4900 lossL: tensor(2399011.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4901 lossL: tensor(2485171.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4902 lossL: tensor(2358043.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4903 lossL: tensor(2384279.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4904 lossL: tensor(2398920.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4905 lossL: tensor(2441617.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4906 lossL: tensor(2422330.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4907 lossL: tensor(2540978., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4908 lossL: tensor(2512415.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4909 lossL: tensor(2514237.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4910 lossL: tensor(2401667.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4911 lossL: tensor(2339298.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4912 lossL: tensor(2349016., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4913 lossL: tensor(2243593.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4914 lossL: tensor(2471376.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4915 lossL: tensor(2410618.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4916 lossL: tensor(2456350.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4917 lossL: tensor(2363078.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4918 lossL: tensor(2536379., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4919 lossL: tensor(2399037.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4920 lossL: tensor(2489165., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4921 lossL: tensor(2374394.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4922 lossL: tensor(2372403.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4923 lossL: tensor(2330047., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4924 lossL: tensor(2489569.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4925 lossL: tensor(2457415., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4926 lossL: tensor(2496027.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4927 lossL: tensor(2465178.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4928 lossL: tensor(2369192.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4929 lossL: tensor(2378724.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4930 lossL: tensor(2510158.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4931 lossL: tensor(2496783., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4932 lossL: tensor(2438821.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4933 lossL: tensor(2291661., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4934 lossL: tensor(2418853.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4935 lossL: tensor(2372429., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4936 lossL: tensor(2250046.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4937 lossL: tensor(2424746.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4938 lossL: tensor(2470644.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4939 lossL: tensor(2493750.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4940 lossL: tensor(2373383.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4941 lossL: tensor(2293128.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4942 lossL: tensor(2599022.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4943 lossL: tensor(2426961.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4944 lossL: tensor(2279610.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4945 lossL: tensor(2269217.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4946 lossL: tensor(2543989.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4947 lossL: tensor(2554280.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4948 lossL: tensor(2382586.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4949 lossL: tensor(2419370.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4950 lossL: tensor(2451416.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4951 lossL: tensor(2341329.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4952 lossL: tensor(2532280.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4953 lossL: tensor(2412997.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4954 lossL: tensor(2550282.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4955 lossL: tensor(2459014.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4956 lossL: tensor(2386067.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4957 lossL: tensor(2475987., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4958 lossL: tensor(2559290.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4959 lossL: tensor(2362869.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4960 lossL: tensor(2497748.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4961 lossL: tensor(2485734.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4962 lossL: tensor(2352294.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4963 lossL: tensor(2586529.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4964 lossL: tensor(2348682.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4965 lossL: tensor(2370085.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4966 lossL: tensor(2368410.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4967 lossL: tensor(2366568.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4968 lossL: tensor(2457503.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4969 lossL: tensor(2468743., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4970 lossL: tensor(2257042., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4971 lossL: tensor(2282314.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4972 lossL: tensor(2375159., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4973 lossL: tensor(2314267.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4974 lossL: tensor(2477962.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4975 lossL: tensor(2367107., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4976 lossL: tensor(2508853.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4977 lossL: tensor(2404182.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4978 lossL: tensor(2602205.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4979 lossL: tensor(2465980.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4980 lossL: tensor(2290540.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4981 lossL: tensor(2515918.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4982 lossL: tensor(2449458.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4983 lossL: tensor(2259732.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4984 lossL: tensor(2396208.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4985 lossL: tensor(2501445.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4986 lossL: tensor(2494428., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4987 lossL: tensor(2396514.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4988 lossL: tensor(2395897.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4989 lossL: tensor(2444749.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4990 lossL: tensor(2274644., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4991 lossL: tensor(2363866.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4992 lossL: tensor(2299077.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4993 lossL: tensor(2416744.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4994 lossL: tensor(2331693.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4995 lossL: tensor(2389601.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4996 lossL: tensor(2437295.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4997 lossL: tensor(2643173.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4998 lossL: tensor(2306994.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "4999 lossL: tensor(2372228.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5000 lossL: tensor(2334681.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5001 lossL: tensor(2275474.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5002 lossL: tensor(2378290.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5003 lossL: tensor(2390345.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5004 lossL: tensor(2372722.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5005 lossL: tensor(2384336.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5006 lossL: tensor(2427546.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5007 lossL: tensor(2465232., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5008 lossL: tensor(2617408., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5009 lossL: tensor(2366183.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5010 lossL: tensor(2383923.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5011 lossL: tensor(2271791.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5012 lossL: tensor(2405742.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5013 lossL: tensor(2348397., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5014 lossL: tensor(2422278., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5015 lossL: tensor(2480692.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5016 lossL: tensor(2556573.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5017 lossL: tensor(2540351.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5018 lossL: tensor(2587663.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5019 lossL: tensor(2410837.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5020 lossL: tensor(2392447., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5021 lossL: tensor(2350401.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5022 lossL: tensor(2420139.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5023 lossL: tensor(2331089.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5024 lossL: tensor(2492629.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5025 lossL: tensor(2560308.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5026 lossL: tensor(2431830.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5027 lossL: tensor(2530394.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5028 lossL: tensor(2301954., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5029 lossL: tensor(2296116.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5030 lossL: tensor(2385146.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5031 lossL: tensor(2414389.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5032 lossL: tensor(2378874.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5033 lossL: tensor(2499575., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5034 lossL: tensor(2452266., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5035 lossL: tensor(2425484.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5036 lossL: tensor(2344204.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5037 lossL: tensor(2373540., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5038 lossL: tensor(2528857., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5039 lossL: tensor(2537979.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5040 lossL: tensor(2351499., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5041 lossL: tensor(2338679.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5042 lossL: tensor(2462898.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5043 lossL: tensor(2341106., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5044 lossL: tensor(2396689.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5045 lossL: tensor(2302244., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5046 lossL: tensor(2515697.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5047 lossL: tensor(2436659.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5048 lossL: tensor(2432196.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5049 lossL: tensor(2391055.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5050 lossL: tensor(2490702.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5051 lossL: tensor(2371138.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5052 lossL: tensor(2428756., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5053 lossL: tensor(2412682.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5054 lossL: tensor(2576896.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5055 lossL: tensor(2457788.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5056 lossL: tensor(2521724.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5057 lossL: tensor(2380073.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5058 lossL: tensor(2467986., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5059 lossL: tensor(2540465., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5060 lossL: tensor(2459312.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5061 lossL: tensor(2485946.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5062 lossL: tensor(2439890.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5063 lossL: tensor(2325099.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5064 lossL: tensor(2385312., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5065 lossL: tensor(2505575.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5066 lossL: tensor(2487456., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5067 lossL: tensor(2469460.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5068 lossL: tensor(2379379.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5069 lossL: tensor(2431790., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5070 lossL: tensor(2436766.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5071 lossL: tensor(2353973., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5072 lossL: tensor(2501916.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5073 lossL: tensor(2380876.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5074 lossL: tensor(2531179.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5075 lossL: tensor(2443597.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5076 lossL: tensor(2441869.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5077 lossL: tensor(2419537.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5078 lossL: tensor(2362679.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5079 lossL: tensor(2474002., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5080 lossL: tensor(2494389., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5081 lossL: tensor(2443847.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5082 lossL: tensor(2391725.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5083 lossL: tensor(2440081.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5084 lossL: tensor(2376166., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5085 lossL: tensor(2578552., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5086 lossL: tensor(2427575., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5087 lossL: tensor(2625113., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5088 lossL: tensor(2463096.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5089 lossL: tensor(2483919.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5090 lossL: tensor(2438267.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5091 lossL: tensor(2480254.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5092 lossL: tensor(2494371., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5093 lossL: tensor(2416921.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5094 lossL: tensor(2416194.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5095 lossL: tensor(2386371.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5096 lossL: tensor(2274037.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5097 lossL: tensor(2525769.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5098 lossL: tensor(2299656., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5099 lossL: tensor(2508006.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5100 lossL: tensor(2302199.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5101 lossL: tensor(2371738., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5102 lossL: tensor(2459296., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5103 lossL: tensor(2359700.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5104 lossL: tensor(2463424.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5105 lossL: tensor(2425914.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5106 lossL: tensor(2378956.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5107 lossL: tensor(2408265.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5108 lossL: tensor(2573732.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5109 lossL: tensor(2346347., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5110 lossL: tensor(2398511.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5111 lossL: tensor(2524478., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5112 lossL: tensor(2292260.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5113 lossL: tensor(2373535.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5114 lossL: tensor(2335375.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5115 lossL: tensor(2262528., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5116 lossL: tensor(2393681.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5117 lossL: tensor(2287270.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5118 lossL: tensor(2466753.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5119 lossL: tensor(2515953., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5120 lossL: tensor(2336230., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5121 lossL: tensor(2276999.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5122 lossL: tensor(2372696.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5123 lossL: tensor(2519307.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5124 lossL: tensor(2288001.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5125 lossL: tensor(2472935.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5126 lossL: tensor(2547551., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5127 lossL: tensor(2454975.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5128 lossL: tensor(2258572.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5129 lossL: tensor(2339216.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5130 lossL: tensor(2547352.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5131 lossL: tensor(2272837.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5132 lossL: tensor(2428627.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5133 lossL: tensor(2275042., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5134 lossL: tensor(2345530.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5135 lossL: tensor(2314379.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5136 lossL: tensor(2393579.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5137 lossL: tensor(2293629.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5138 lossL: tensor(2372849.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5139 lossL: tensor(2496814.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5140 lossL: tensor(2391005.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5141 lossL: tensor(2423331.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5142 lossL: tensor(2584818., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5143 lossL: tensor(2359264.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5144 lossL: tensor(2279546.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5145 lossL: tensor(2355971.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5146 lossL: tensor(2436409.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5147 lossL: tensor(2443957.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5148 lossL: tensor(2522484.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5149 lossL: tensor(2517677., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5150 lossL: tensor(2505166.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5151 lossL: tensor(2443790.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5152 lossL: tensor(2517286.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5153 lossL: tensor(2405453., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5154 lossL: tensor(2312940.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5155 lossL: tensor(2321742., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5156 lossL: tensor(2363442.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5157 lossL: tensor(2377251.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5158 lossL: tensor(2396388.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5159 lossL: tensor(2386381.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5160 lossL: tensor(2434232.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5161 lossL: tensor(2285717.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5162 lossL: tensor(2322556.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5163 lossL: tensor(2382329.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5164 lossL: tensor(2460929.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5165 lossL: tensor(2396855.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5166 lossL: tensor(2352580.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5167 lossL: tensor(2551727.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5168 lossL: tensor(2240413., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5169 lossL: tensor(2380827., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5170 lossL: tensor(2398586.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5171 lossL: tensor(2539994., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5172 lossL: tensor(2469178.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5173 lossL: tensor(2415899., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5174 lossL: tensor(2295353.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5175 lossL: tensor(2379234.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5176 lossL: tensor(2416866., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5177 lossL: tensor(2496819., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5178 lossL: tensor(2474899.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5179 lossL: tensor(2398985., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5180 lossL: tensor(2501333.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5181 lossL: tensor(2359146.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5182 lossL: tensor(2235787.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5183 lossL: tensor(2596083.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5184 lossL: tensor(2432072.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5185 lossL: tensor(2307053.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5186 lossL: tensor(2331980., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5187 lossL: tensor(2678768.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5188 lossL: tensor(2361455.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5189 lossL: tensor(2432477., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5190 lossL: tensor(2430062.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5191 lossL: tensor(2412939., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5192 lossL: tensor(2333697.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5193 lossL: tensor(2410836.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5194 lossL: tensor(2524332., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5195 lossL: tensor(2404646.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5196 lossL: tensor(2534163., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5197 lossL: tensor(2502004.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5198 lossL: tensor(2417207., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5199 lossL: tensor(2524974.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5200 lossL: tensor(2368591.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5201 lossL: tensor(2533024.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5202 lossL: tensor(2518248.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5203 lossL: tensor(2366010.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5204 lossL: tensor(2298236., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5205 lossL: tensor(2503033., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5206 lossL: tensor(2457087.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5207 lossL: tensor(2383672.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5208 lossL: tensor(2501626., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5209 lossL: tensor(2318273.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5210 lossL: tensor(2258814.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5211 lossL: tensor(2412993., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5212 lossL: tensor(2370268., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5213 lossL: tensor(2300254.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5214 lossL: tensor(2278150.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5215 lossL: tensor(2390205.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5216 lossL: tensor(2231884., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5217 lossL: tensor(2514444., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5218 lossL: tensor(2239636., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5219 lossL: tensor(2443575.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5220 lossL: tensor(2429022.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5221 lossL: tensor(2329616., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5222 lossL: tensor(2311306.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5223 lossL: tensor(2368125.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5224 lossL: tensor(2420087.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5225 lossL: tensor(2297085.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5226 lossL: tensor(2391386., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5227 lossL: tensor(2307449.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5228 lossL: tensor(2338312., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5229 lossL: tensor(2438529.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5230 lossL: tensor(2311599.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5231 lossL: tensor(2435079., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5232 lossL: tensor(2399368.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5233 lossL: tensor(2404953.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5234 lossL: tensor(2195625., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5235 lossL: tensor(2445533.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5236 lossL: tensor(2324008.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5237 lossL: tensor(2365193.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5238 lossL: tensor(2371272.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5239 lossL: tensor(2368063., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5240 lossL: tensor(2362269.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5241 lossL: tensor(2353799.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5242 lossL: tensor(2355480., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5243 lossL: tensor(2386723.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5244 lossL: tensor(2322894.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5245 lossL: tensor(2484732.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5246 lossL: tensor(2476818.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5247 lossL: tensor(2335240., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5248 lossL: tensor(2303924.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5249 lossL: tensor(2220923.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5250 lossL: tensor(2283228., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5251 lossL: tensor(2370461.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5252 lossL: tensor(2268140.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5253 lossL: tensor(2305860.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5254 lossL: tensor(2244630., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5255 lossL: tensor(2312099.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5256 lossL: tensor(2422793., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5257 lossL: tensor(2383764., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5258 lossL: tensor(2505912.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5259 lossL: tensor(2323197.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5260 lossL: tensor(2486941.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5261 lossL: tensor(2478482., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5262 lossL: tensor(2620371.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5263 lossL: tensor(2273198.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5264 lossL: tensor(2264978.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5265 lossL: tensor(2470515.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5266 lossL: tensor(2354636., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5267 lossL: tensor(2414826.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5268 lossL: tensor(2417182.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5269 lossL: tensor(2291896.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5270 lossL: tensor(2515155.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5271 lossL: tensor(2453986., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5272 lossL: tensor(2414293.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5273 lossL: tensor(2358198., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5274 lossL: tensor(2554223., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5275 lossL: tensor(2385125.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5276 lossL: tensor(2334717.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5277 lossL: tensor(2291535., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5278 lossL: tensor(2471407., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5279 lossL: tensor(2379216.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5280 lossL: tensor(2319167.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5281 lossL: tensor(2496738., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5282 lossL: tensor(2380284.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5283 lossL: tensor(2283348.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5284 lossL: tensor(2490902.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5285 lossL: tensor(2446651., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5286 lossL: tensor(2561376.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5287 lossL: tensor(2579852., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5288 lossL: tensor(2370536.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5289 lossL: tensor(2407508.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5290 lossL: tensor(2471963.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5291 lossL: tensor(2297394.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5292 lossL: tensor(2218447., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5293 lossL: tensor(2335414.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5294 lossL: tensor(2370531.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5295 lossL: tensor(2292745.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5296 lossL: tensor(2398844., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5297 lossL: tensor(2356605., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5298 lossL: tensor(2325000., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5299 lossL: tensor(2310532.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5300 lossL: tensor(2367219.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5301 lossL: tensor(2277435., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5302 lossL: tensor(2333081.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5303 lossL: tensor(2344548.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5304 lossL: tensor(2432870.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5305 lossL: tensor(2441894.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5306 lossL: tensor(2495549.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5307 lossL: tensor(2376803.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5308 lossL: tensor(2219596.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5309 lossL: tensor(2350431.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5310 lossL: tensor(2468284.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5311 lossL: tensor(2322529., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5312 lossL: tensor(2345666.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5313 lossL: tensor(2339120., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5314 lossL: tensor(2414523.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5315 lossL: tensor(2280933.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5316 lossL: tensor(2326756.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5317 lossL: tensor(2336256.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5318 lossL: tensor(2350446.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5319 lossL: tensor(2551856.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5320 lossL: tensor(2323188.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5321 lossL: tensor(2231477., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5322 lossL: tensor(2412441.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5323 lossL: tensor(2409775.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5324 lossL: tensor(2335542.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5325 lossL: tensor(2282758.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5326 lossL: tensor(2394136.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5327 lossL: tensor(2370535.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5328 lossL: tensor(2457232.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5329 lossL: tensor(2276148.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5330 lossL: tensor(2314390.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5331 lossL: tensor(2319676., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5332 lossL: tensor(2380254.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5333 lossL: tensor(2392881.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5334 lossL: tensor(2065029., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "5335 lossL: tensor(2234381.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5336 lossL: tensor(2446273.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5337 lossL: tensor(2491784.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5338 lossL: tensor(2318112.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5339 lossL: tensor(2203900.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5340 lossL: tensor(2329293.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5341 lossL: tensor(2440784.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5342 lossL: tensor(2306902.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5343 lossL: tensor(2517056.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5344 lossL: tensor(2469969.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5345 lossL: tensor(2217038.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5346 lossL: tensor(2334853.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5347 lossL: tensor(2298491.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5348 lossL: tensor(2281992.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5349 lossL: tensor(2449088.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5350 lossL: tensor(2347302.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5351 lossL: tensor(2419769.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5352 lossL: tensor(2283892.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5353 lossL: tensor(2388878.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5354 lossL: tensor(2285470.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5355 lossL: tensor(2252197.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5356 lossL: tensor(2378487.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5357 lossL: tensor(2328380.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5358 lossL: tensor(2352801.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5359 lossL: tensor(2344574.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5360 lossL: tensor(2457856., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5361 lossL: tensor(2427244.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5362 lossL: tensor(2437903.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5363 lossL: tensor(2446736.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5364 lossL: tensor(2545343.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5365 lossL: tensor(2304389.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5366 lossL: tensor(2318367.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5367 lossL: tensor(2314564.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5368 lossL: tensor(2288590., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5369 lossL: tensor(2358308.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5370 lossL: tensor(2201687.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5371 lossL: tensor(2453749., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5372 lossL: tensor(2398016.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5373 lossL: tensor(2455250., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5374 lossL: tensor(2456969., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5375 lossL: tensor(2319713.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5376 lossL: tensor(2307121.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5377 lossL: tensor(2302632.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5378 lossL: tensor(2360739., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5379 lossL: tensor(2520331.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5380 lossL: tensor(2290997.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5381 lossL: tensor(2398144.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5382 lossL: tensor(2402573.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5383 lossL: tensor(2306451.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5384 lossL: tensor(2351076.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5385 lossL: tensor(2409976., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5386 lossL: tensor(2304990.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5387 lossL: tensor(2314655.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5388 lossL: tensor(2462640.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5389 lossL: tensor(2191319.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5390 lossL: tensor(2367191.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5391 lossL: tensor(2505591.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5392 lossL: tensor(2435324.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5393 lossL: tensor(2313898.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5394 lossL: tensor(2467784.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5395 lossL: tensor(2315066.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5396 lossL: tensor(2324276.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5397 lossL: tensor(2466234.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5398 lossL: tensor(2278513.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5399 lossL: tensor(2355562.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5400 lossL: tensor(2290238.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5401 lossL: tensor(2158980.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5402 lossL: tensor(2363458., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5403 lossL: tensor(2319230.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5404 lossL: tensor(2330286.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5405 lossL: tensor(2312275., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5406 lossL: tensor(2407852.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5407 lossL: tensor(2368818.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5408 lossL: tensor(2372784., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5409 lossL: tensor(2539813.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5410 lossL: tensor(2431899.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5411 lossL: tensor(2440872.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5412 lossL: tensor(2294479., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5413 lossL: tensor(2488026., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5414 lossL: tensor(2401243.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5415 lossL: tensor(2347639.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5416 lossL: tensor(2406743.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5417 lossL: tensor(2450265., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5418 lossL: tensor(2257759., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5419 lossL: tensor(2366812.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5420 lossL: tensor(2355228.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5421 lossL: tensor(2245949.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5422 lossL: tensor(2435271., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5423 lossL: tensor(2327241.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5424 lossL: tensor(2459990., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5425 lossL: tensor(2405203., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5426 lossL: tensor(2320154.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5427 lossL: tensor(2372196.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5428 lossL: tensor(2375272.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5429 lossL: tensor(2303648.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5430 lossL: tensor(2446938., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5431 lossL: tensor(2461431.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5432 lossL: tensor(2419129., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5433 lossL: tensor(2616904., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5434 lossL: tensor(2277707.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5435 lossL: tensor(2438365.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5436 lossL: tensor(2310719.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5437 lossL: tensor(2376077.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5438 lossL: tensor(2377076.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5439 lossL: tensor(2374430.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5440 lossL: tensor(2279322., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5441 lossL: tensor(2339270., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5442 lossL: tensor(2179257.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5443 lossL: tensor(2429593., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5444 lossL: tensor(2437254.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5445 lossL: tensor(2480960., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5446 lossL: tensor(2513067., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5447 lossL: tensor(2255603.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5448 lossL: tensor(2257995.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5449 lossL: tensor(2447504.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5450 lossL: tensor(2367251.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5451 lossL: tensor(2378358., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5452 lossL: tensor(2316977.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5453 lossL: tensor(2383970.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5454 lossL: tensor(2317836., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5455 lossL: tensor(2485961.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5456 lossL: tensor(2065356.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5457 lossL: tensor(2320327.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5458 lossL: tensor(2266678., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5459 lossL: tensor(2298662.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5460 lossL: tensor(2417717.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5461 lossL: tensor(2445494.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5462 lossL: tensor(2363377.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5463 lossL: tensor(2298487.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5464 lossL: tensor(2325638.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5465 lossL: tensor(2449808.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5466 lossL: tensor(2521357., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5467 lossL: tensor(2297534.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5468 lossL: tensor(2308254.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5469 lossL: tensor(2423224.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5470 lossL: tensor(2317264.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5471 lossL: tensor(2268729.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5472 lossL: tensor(2274217.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5473 lossL: tensor(2396744.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5474 lossL: tensor(2344716.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5475 lossL: tensor(2418133.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5476 lossL: tensor(2354962., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5477 lossL: tensor(2296514.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5478 lossL: tensor(2262337., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5479 lossL: tensor(2457969., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5480 lossL: tensor(2367191.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5481 lossL: tensor(2358341.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5482 lossL: tensor(2300583.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5483 lossL: tensor(2227819.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5484 lossL: tensor(2262834.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5485 lossL: tensor(2380649.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5486 lossL: tensor(2520782.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5487 lossL: tensor(2309900.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5488 lossL: tensor(2273829.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5489 lossL: tensor(2308805.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5490 lossL: tensor(2324490.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5491 lossL: tensor(2331613.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5492 lossL: tensor(2292334., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5493 lossL: tensor(2406767., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5494 lossL: tensor(2431490.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5495 lossL: tensor(2490866., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5496 lossL: tensor(2318423.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5497 lossL: tensor(2554774.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5498 lossL: tensor(2452055., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5499 lossL: tensor(2506146.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5500 lossL: tensor(2490965.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5501 lossL: tensor(2424592.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5502 lossL: tensor(2393014.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5503 lossL: tensor(2226668.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5504 lossL: tensor(2283560., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5505 lossL: tensor(2405198.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5506 lossL: tensor(2301192.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5507 lossL: tensor(2347038.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5508 lossL: tensor(2349284., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5509 lossL: tensor(2437138., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5510 lossL: tensor(2205423.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5511 lossL: tensor(2297672., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5512 lossL: tensor(2528090.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5513 lossL: tensor(2346482.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5514 lossL: tensor(2389014.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5515 lossL: tensor(2466239.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5516 lossL: tensor(2243500.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5517 lossL: tensor(2213312.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5518 lossL: tensor(2315373.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5519 lossL: tensor(2444494., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5520 lossL: tensor(2339921.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5521 lossL: tensor(2486420.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5522 lossL: tensor(2437909., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5523 lossL: tensor(2311498., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5524 lossL: tensor(2307563.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5525 lossL: tensor(2337486.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5526 lossL: tensor(2284951., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5527 lossL: tensor(2401731., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5528 lossL: tensor(2331175., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5529 lossL: tensor(2309421.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5530 lossL: tensor(2385148.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5531 lossL: tensor(2365014.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5532 lossL: tensor(2294405.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5533 lossL: tensor(2260066., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5534 lossL: tensor(2337451.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5535 lossL: tensor(2446725., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5536 lossL: tensor(2242353.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5537 lossL: tensor(2135677., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5538 lossL: tensor(2262486.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5539 lossL: tensor(2491913.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5540 lossL: tensor(2328176.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5541 lossL: tensor(2452384.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5542 lossL: tensor(2291582.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5543 lossL: tensor(2304553.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5544 lossL: tensor(2271814.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5545 lossL: tensor(2307611., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5546 lossL: tensor(2178290.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5547 lossL: tensor(2273224., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5548 lossL: tensor(2254779.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5549 lossL: tensor(2435344.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5550 lossL: tensor(2277353.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5551 lossL: tensor(2289212., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5552 lossL: tensor(2459002., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5553 lossL: tensor(2306028., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5554 lossL: tensor(2225837.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5555 lossL: tensor(2323468.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5556 lossL: tensor(2268251.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5557 lossL: tensor(2280685., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5558 lossL: tensor(2414591.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5559 lossL: tensor(2213241.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5560 lossL: tensor(2408305., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5561 lossL: tensor(2398284.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5562 lossL: tensor(2252073.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5563 lossL: tensor(2411839.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5564 lossL: tensor(2422677., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5565 lossL: tensor(2410521.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5566 lossL: tensor(2298570.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5567 lossL: tensor(2453027.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5568 lossL: tensor(2475735., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5569 lossL: tensor(2218699.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5570 lossL: tensor(2205752., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5571 lossL: tensor(2357491., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5572 lossL: tensor(2319515.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5573 lossL: tensor(2293265.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5574 lossL: tensor(2285400., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5575 lossL: tensor(2347042.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5576 lossL: tensor(2448954.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5577 lossL: tensor(2423509., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5578 lossL: tensor(2369598.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5579 lossL: tensor(2256622.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5580 lossL: tensor(2300085.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5581 lossL: tensor(2420487., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5582 lossL: tensor(2207220., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5583 lossL: tensor(2264199.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5584 lossL: tensor(2405225.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5585 lossL: tensor(2286992., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5586 lossL: tensor(2282762.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5587 lossL: tensor(2352972.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5588 lossL: tensor(2345632.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5589 lossL: tensor(2555976., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5590 lossL: tensor(2285695., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5591 lossL: tensor(2336129., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5592 lossL: tensor(2339166.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5593 lossL: tensor(2360703.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5594 lossL: tensor(2426953.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5595 lossL: tensor(2294184.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5596 lossL: tensor(2580235.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5597 lossL: tensor(2319645., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5598 lossL: tensor(2336416.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5599 lossL: tensor(2209054.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5600 lossL: tensor(2135863.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5601 lossL: tensor(2283890.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5602 lossL: tensor(2250405., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5603 lossL: tensor(2329380.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5604 lossL: tensor(2466368., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5605 lossL: tensor(2385801., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5606 lossL: tensor(2368235.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5607 lossL: tensor(2114250.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5608 lossL: tensor(2403868.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5609 lossL: tensor(2431180., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5610 lossL: tensor(2325679.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5611 lossL: tensor(2273110., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5612 lossL: tensor(2335776., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5613 lossL: tensor(2372279., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5614 lossL: tensor(2255414., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5615 lossL: tensor(2315229.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5616 lossL: tensor(2258224.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5617 lossL: tensor(2378309.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5618 lossL: tensor(2256669., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5619 lossL: tensor(2418142.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5620 lossL: tensor(2194058.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5621 lossL: tensor(2280762.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5622 lossL: tensor(2260338.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5623 lossL: tensor(2516630., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5624 lossL: tensor(2299369.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5625 lossL: tensor(2412560.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5626 lossL: tensor(2238415.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5627 lossL: tensor(2279763., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5628 lossL: tensor(2297038.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5629 lossL: tensor(2350719.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5630 lossL: tensor(2438711., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5631 lossL: tensor(2378909.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5632 lossL: tensor(2370402.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5633 lossL: tensor(2245876.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5634 lossL: tensor(2258506.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5635 lossL: tensor(2299046.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5636 lossL: tensor(2448428.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5637 lossL: tensor(2325665.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5638 lossL: tensor(2392497.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5639 lossL: tensor(2212988.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5640 lossL: tensor(2273532., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5641 lossL: tensor(2287565.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5642 lossL: tensor(2339957.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5643 lossL: tensor(2283456.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5644 lossL: tensor(2346302.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5645 lossL: tensor(2326529., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5646 lossL: tensor(2332285., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5647 lossL: tensor(2288639.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5648 lossL: tensor(2167726.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5649 lossL: tensor(2139469.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5650 lossL: tensor(2279294.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5651 lossL: tensor(2297949., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5652 lossL: tensor(2360906.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5653 lossL: tensor(2302640.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5654 lossL: tensor(2285154., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5655 lossL: tensor(2130451.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5656 lossL: tensor(2430228.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5657 lossL: tensor(2223192., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5658 lossL: tensor(2411092., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5659 lossL: tensor(2375261.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5660 lossL: tensor(2373470.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5661 lossL: tensor(2172437., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5662 lossL: tensor(2220278.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5663 lossL: tensor(2160571.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5664 lossL: tensor(2385884., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5665 lossL: tensor(2317785.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5666 lossL: tensor(2290167., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5667 lossL: tensor(2304129.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5668 lossL: tensor(2323756., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5669 lossL: tensor(2366002.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5670 lossL: tensor(2274106.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5671 lossL: tensor(2428534.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5672 lossL: tensor(2259194.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5673 lossL: tensor(2255854., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5674 lossL: tensor(2305277.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5675 lossL: tensor(2355598.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5676 lossL: tensor(2359052., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5677 lossL: tensor(2243536.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5678 lossL: tensor(2412090.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5679 lossL: tensor(2469549.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5680 lossL: tensor(2363989.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5681 lossL: tensor(2342587.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5682 lossL: tensor(2315272.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5683 lossL: tensor(2212980.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5684 lossL: tensor(2201122.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5685 lossL: tensor(2300362.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5686 lossL: tensor(2302400.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5687 lossL: tensor(2272354.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5688 lossL: tensor(2313204.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5689 lossL: tensor(2481147.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5690 lossL: tensor(2282588.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5691 lossL: tensor(2327821.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5692 lossL: tensor(2201591., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5693 lossL: tensor(2394302.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5694 lossL: tensor(2287866.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5695 lossL: tensor(2342152.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5696 lossL: tensor(2555008., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5697 lossL: tensor(2469174.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5698 lossL: tensor(2352017.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5699 lossL: tensor(2273646.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5700 lossL: tensor(2263361.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5701 lossL: tensor(2504880., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5702 lossL: tensor(2449297.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5703 lossL: tensor(2146336.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5704 lossL: tensor(2359208.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5705 lossL: tensor(2361313., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5706 lossL: tensor(2252867., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5707 lossL: tensor(2312733., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5708 lossL: tensor(2268294.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5709 lossL: tensor(2164660., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5710 lossL: tensor(2354076., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5711 lossL: tensor(2131639., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5712 lossL: tensor(2447933.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5713 lossL: tensor(2392989.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5714 lossL: tensor(2248547., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5715 lossL: tensor(2377771., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5716 lossL: tensor(2350054., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5717 lossL: tensor(2249842.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5718 lossL: tensor(2424402.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5719 lossL: tensor(2343993.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5720 lossL: tensor(2246427.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5721 lossL: tensor(2248866., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5722 lossL: tensor(2338226., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5723 lossL: tensor(2421245.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5724 lossL: tensor(2359879.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5725 lossL: tensor(2410346., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5726 lossL: tensor(2446573.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5727 lossL: tensor(2270985., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5728 lossL: tensor(2407882., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5729 lossL: tensor(2351731.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5730 lossL: tensor(2396178., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5731 lossL: tensor(2456716.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5732 lossL: tensor(2333416.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5733 lossL: tensor(2318218.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5734 lossL: tensor(2437770.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5735 lossL: tensor(2119551.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5736 lossL: tensor(2349293.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5737 lossL: tensor(2464918.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5738 lossL: tensor(2450471.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5739 lossL: tensor(2337153., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5740 lossL: tensor(2469275.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5741 lossL: tensor(2405460.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5742 lossL: tensor(2380815., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5743 lossL: tensor(2252677.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5744 lossL: tensor(2109466.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5745 lossL: tensor(2223048.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5746 lossL: tensor(2430452., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5747 lossL: tensor(2431602.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5748 lossL: tensor(2269665.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5749 lossL: tensor(2358508.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5750 lossL: tensor(2267802., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5751 lossL: tensor(2370382.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5752 lossL: tensor(2204635.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5753 lossL: tensor(2309278., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5754 lossL: tensor(2450105.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5755 lossL: tensor(2238926.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5756 lossL: tensor(2381939.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5757 lossL: tensor(2203932.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5758 lossL: tensor(2237798.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5759 lossL: tensor(2189910.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5760 lossL: tensor(2363216.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5761 lossL: tensor(2270035.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5762 lossL: tensor(2314124.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5763 lossL: tensor(2235739.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5764 lossL: tensor(2351171., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5765 lossL: tensor(2308941.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5766 lossL: tensor(2211957.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5767 lossL: tensor(2248480.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5768 lossL: tensor(2181607.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5769 lossL: tensor(2438956.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5770 lossL: tensor(2272149.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5771 lossL: tensor(2163706.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5772 lossL: tensor(2203708.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5773 lossL: tensor(2235703.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5774 lossL: tensor(2178748.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5775 lossL: tensor(2249839.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5776 lossL: tensor(2234831., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5777 lossL: tensor(2206386., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5778 lossL: tensor(2263302., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5779 lossL: tensor(2278401.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5780 lossL: tensor(2321756.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5781 lossL: tensor(2333340.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5782 lossL: tensor(2318559.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5783 lossL: tensor(2445355., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5784 lossL: tensor(2355754.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5785 lossL: tensor(2132588.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5786 lossL: tensor(2250592.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5787 lossL: tensor(2246815., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5788 lossL: tensor(2342412.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5789 lossL: tensor(2273514.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5790 lossL: tensor(2225853., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5791 lossL: tensor(2444819.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5792 lossL: tensor(2502497.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5793 lossL: tensor(2276091.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5794 lossL: tensor(2269268.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5795 lossL: tensor(2228688.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5796 lossL: tensor(2324153.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5797 lossL: tensor(2276609., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5798 lossL: tensor(2329595.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5799 lossL: tensor(2336502.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5800 lossL: tensor(2202494., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5801 lossL: tensor(2198783.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5802 lossL: tensor(2376547.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5803 lossL: tensor(2174324.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5804 lossL: tensor(2300268.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5805 lossL: tensor(2170949.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5806 lossL: tensor(2327622.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5807 lossL: tensor(2310378.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5808 lossL: tensor(2263327.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5809 lossL: tensor(2348755.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5810 lossL: tensor(2395206.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5811 lossL: tensor(2323443.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5812 lossL: tensor(2317835.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5813 lossL: tensor(2463792.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5814 lossL: tensor(2149117.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5815 lossL: tensor(2226404., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5816 lossL: tensor(2234918.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5817 lossL: tensor(2178241.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5818 lossL: tensor(2343900., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5819 lossL: tensor(2083699.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5820 lossL: tensor(2286450.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5821 lossL: tensor(2319324.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5822 lossL: tensor(2328696.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5823 lossL: tensor(2435650.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5824 lossL: tensor(2337411.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5825 lossL: tensor(2347650.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5826 lossL: tensor(2280784.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5827 lossL: tensor(2304534.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5828 lossL: tensor(2306489.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5829 lossL: tensor(2293872., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5830 lossL: tensor(2180371.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5831 lossL: tensor(2234426.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5832 lossL: tensor(2250041.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5833 lossL: tensor(2180632.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5834 lossL: tensor(2335126.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5835 lossL: tensor(2170592.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5836 lossL: tensor(2228106.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5837 lossL: tensor(2393033.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5838 lossL: tensor(2261777.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5839 lossL: tensor(2305797., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5840 lossL: tensor(2223497.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5841 lossL: tensor(2421481., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5842 lossL: tensor(2378165.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5843 lossL: tensor(2258170.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5844 lossL: tensor(2338536.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5845 lossL: tensor(2160655.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5846 lossL: tensor(2216742.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5847 lossL: tensor(2340736., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5848 lossL: tensor(2342813.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5849 lossL: tensor(2425041.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5850 lossL: tensor(2263842.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5851 lossL: tensor(2348203.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5852 lossL: tensor(2185376.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5853 lossL: tensor(2280236., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5854 lossL: tensor(2399105., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5855 lossL: tensor(2315484., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5856 lossL: tensor(2322282.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5857 lossL: tensor(2324295.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5858 lossL: tensor(2120136.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5859 lossL: tensor(2192306.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5860 lossL: tensor(2361747.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5861 lossL: tensor(2402164., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5862 lossL: tensor(2248930.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5863 lossL: tensor(2264147., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5864 lossL: tensor(2194432.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5865 lossL: tensor(2113719., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5866 lossL: tensor(2187559.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5867 lossL: tensor(2389915.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5868 lossL: tensor(2238004.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5869 lossL: tensor(2351409.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5870 lossL: tensor(2198852.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5871 lossL: tensor(2355690.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5872 lossL: tensor(2185472.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5873 lossL: tensor(2327943.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5874 lossL: tensor(2231553., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5875 lossL: tensor(2302675.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5876 lossL: tensor(2436428.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5877 lossL: tensor(2257242.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5878 lossL: tensor(2190093., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5879 lossL: tensor(2273292.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5880 lossL: tensor(2325364.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5881 lossL: tensor(2224144.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5882 lossL: tensor(2247400.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5883 lossL: tensor(2308369.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5884 lossL: tensor(2476819.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5885 lossL: tensor(2136859.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5886 lossL: tensor(2291653.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5887 lossL: tensor(2329282.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5888 lossL: tensor(2273196.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5889 lossL: tensor(2349442.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5890 lossL: tensor(2322094.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5891 lossL: tensor(2254543.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5892 lossL: tensor(2237223.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5893 lossL: tensor(2215284.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5894 lossL: tensor(2426266.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5895 lossL: tensor(2350767.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5896 lossL: tensor(2237332.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5897 lossL: tensor(2263644.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5898 lossL: tensor(2238651.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5899 lossL: tensor(2325981.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5900 lossL: tensor(2137315.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5901 lossL: tensor(2219033.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5902 lossL: tensor(2264889., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5903 lossL: tensor(2314440., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5904 lossL: tensor(2290119.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5905 lossL: tensor(2215056., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5906 lossL: tensor(2184293.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5907 lossL: tensor(2181778.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5908 lossL: tensor(2140194., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5909 lossL: tensor(2156922.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5910 lossL: tensor(2468551.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5911 lossL: tensor(2201068.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5912 lossL: tensor(2230015.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5913 lossL: tensor(2316176.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5914 lossL: tensor(2242124.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5915 lossL: tensor(2141433.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5916 lossL: tensor(2204889.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5917 lossL: tensor(2194117.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5918 lossL: tensor(2115482.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5919 lossL: tensor(2230465.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5920 lossL: tensor(2268249.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5921 lossL: tensor(2288502.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5922 lossL: tensor(2278365.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5923 lossL: tensor(2444930.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5924 lossL: tensor(2197036.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5925 lossL: tensor(2349942.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5926 lossL: tensor(2208678., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5927 lossL: tensor(2059070., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "5928 lossL: tensor(2174430.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5929 lossL: tensor(2330342.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5930 lossL: tensor(2227053.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5931 lossL: tensor(2215322., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5932 lossL: tensor(2326636.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5933 lossL: tensor(2166877.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5934 lossL: tensor(2251049.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5935 lossL: tensor(2241066., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5936 lossL: tensor(2263779., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5937 lossL: tensor(2243889.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5938 lossL: tensor(2326467., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5939 lossL: tensor(2259089., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5940 lossL: tensor(2191728., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5941 lossL: tensor(2175140.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5942 lossL: tensor(2123814., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5943 lossL: tensor(2288101.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5944 lossL: tensor(2319611., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5945 lossL: tensor(2257749.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5946 lossL: tensor(2217177.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5947 lossL: tensor(2282330., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5948 lossL: tensor(2215498.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5949 lossL: tensor(2039960.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "5950 lossL: tensor(2180297.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5951 lossL: tensor(2183140.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5952 lossL: tensor(2279584.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5953 lossL: tensor(2248040.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5954 lossL: tensor(2192183.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5955 lossL: tensor(2184674., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5956 lossL: tensor(2236863., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5957 lossL: tensor(2274593., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5958 lossL: tensor(2260230.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5959 lossL: tensor(2290522.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5960 lossL: tensor(2234263.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5961 lossL: tensor(2293385.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5962 lossL: tensor(2134807.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5963 lossL: tensor(2373386., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5964 lossL: tensor(2281064.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5965 lossL: tensor(2201910.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5966 lossL: tensor(2247011.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5967 lossL: tensor(2297354.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5968 lossL: tensor(2283691.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5969 lossL: tensor(2207565.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5970 lossL: tensor(2273889.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5971 lossL: tensor(2239741., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5972 lossL: tensor(2151486.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5973 lossL: tensor(2246655.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5974 lossL: tensor(2250617., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5975 lossL: tensor(2399969.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5976 lossL: tensor(2210054., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5977 lossL: tensor(2198149.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5978 lossL: tensor(2181490.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5979 lossL: tensor(2335257.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5980 lossL: tensor(2196891., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5981 lossL: tensor(2219730.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5982 lossL: tensor(2245073.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5983 lossL: tensor(2254164.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5984 lossL: tensor(2218069., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5985 lossL: tensor(2144217., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5986 lossL: tensor(2234976.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5987 lossL: tensor(2054376.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5988 lossL: tensor(2209313., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5989 lossL: tensor(2419257.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5990 lossL: tensor(2234671.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5991 lossL: tensor(2329963.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5992 lossL: tensor(2278000., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5993 lossL: tensor(2427272.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5994 lossL: tensor(2223387.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5995 lossL: tensor(2212998.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5996 lossL: tensor(2354953.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5997 lossL: tensor(2239694., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5998 lossL: tensor(2289230.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "5999 lossL: tensor(2259000.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6000 lossL: tensor(2300753.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6001 lossL: tensor(2401796.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6002 lossL: tensor(2072645.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6003 lossL: tensor(2289980.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6004 lossL: tensor(2194619., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6005 lossL: tensor(2331751.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6006 lossL: tensor(2268314.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6007 lossL: tensor(2309975., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6008 lossL: tensor(2177175.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6009 lossL: tensor(2198366., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6010 lossL: tensor(2232332.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6011 lossL: tensor(2281199.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6012 lossL: tensor(2177011.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6013 lossL: tensor(2159259.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6014 lossL: tensor(2192901.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6015 lossL: tensor(2178088.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6016 lossL: tensor(2164098.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6017 lossL: tensor(2135031.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6018 lossL: tensor(2184623.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6019 lossL: tensor(2311884.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6020 lossL: tensor(2172238.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6021 lossL: tensor(2116951., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6022 lossL: tensor(2353636.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6023 lossL: tensor(2107837.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6024 lossL: tensor(2038195.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6025 lossL: tensor(2306512.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6026 lossL: tensor(2292939.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6027 lossL: tensor(2231861.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6028 lossL: tensor(2183607.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6029 lossL: tensor(2331367.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6030 lossL: tensor(2349884.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6031 lossL: tensor(2127527.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6032 lossL: tensor(2227595.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6033 lossL: tensor(2384213.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6034 lossL: tensor(2149226., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6035 lossL: tensor(2129249.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6036 lossL: tensor(2307341.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6037 lossL: tensor(2226022.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6038 lossL: tensor(2268104.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6039 lossL: tensor(2199588., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6040 lossL: tensor(2214475., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6041 lossL: tensor(2228559., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6042 lossL: tensor(2140128.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6043 lossL: tensor(2198671.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6044 lossL: tensor(2327196., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6045 lossL: tensor(2278565., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6046 lossL: tensor(2252668.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6047 lossL: tensor(2204095.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6048 lossL: tensor(2199957.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6049 lossL: tensor(2413035.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6050 lossL: tensor(2219992., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6051 lossL: tensor(2554081.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6052 lossL: tensor(2251277., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6053 lossL: tensor(2185512.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6054 lossL: tensor(2108185.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6055 lossL: tensor(2231045.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6056 lossL: tensor(2054371.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6057 lossL: tensor(2213406.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6058 lossL: tensor(2197975.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6059 lossL: tensor(2222566., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6060 lossL: tensor(2203659., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6061 lossL: tensor(2250400.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6062 lossL: tensor(2060954.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6063 lossL: tensor(2314524.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6064 lossL: tensor(2126566.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6065 lossL: tensor(2168158., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6066 lossL: tensor(2113783., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6067 lossL: tensor(2165712.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6068 lossL: tensor(2183794.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6069 lossL: tensor(2321057., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6070 lossL: tensor(2181406., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6071 lossL: tensor(2200794., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6072 lossL: tensor(2158296.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6073 lossL: tensor(2277748.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6074 lossL: tensor(2205971.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6075 lossL: tensor(2297080., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6076 lossL: tensor(2143500.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6077 lossL: tensor(2295630.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6078 lossL: tensor(2142882.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6079 lossL: tensor(2180033., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6080 lossL: tensor(2210687., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6081 lossL: tensor(2166588., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6082 lossL: tensor(2300348.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6083 lossL: tensor(2257327.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6084 lossL: tensor(2224657.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6085 lossL: tensor(2193655.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6086 lossL: tensor(2251297., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6087 lossL: tensor(2097700.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6088 lossL: tensor(2340238.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6089 lossL: tensor(2227047.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6090 lossL: tensor(2277112.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6091 lossL: tensor(2219295., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6092 lossL: tensor(2233119.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6093 lossL: tensor(2123280.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6094 lossL: tensor(2197527., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6095 lossL: tensor(2214856.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6096 lossL: tensor(2358428., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6097 lossL: tensor(2311559.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6098 lossL: tensor(2211187.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6099 lossL: tensor(2142101., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6100 lossL: tensor(2159099.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6101 lossL: tensor(2234262.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6102 lossL: tensor(2185129.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6103 lossL: tensor(2347548., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6104 lossL: tensor(2214601.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6105 lossL: tensor(2243801.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6106 lossL: tensor(2182989.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6107 lossL: tensor(2111915., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6108 lossL: tensor(2285710.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6109 lossL: tensor(2365008.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6110 lossL: tensor(2379259., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6111 lossL: tensor(2151930.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6112 lossL: tensor(2057343.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6113 lossL: tensor(2210553., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6114 lossL: tensor(2177716., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6115 lossL: tensor(2196087., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6116 lossL: tensor(2185844.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6117 lossL: tensor(2196162.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6118 lossL: tensor(2127855.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6119 lossL: tensor(2185884.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6120 lossL: tensor(2213594.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6121 lossL: tensor(2263973.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6122 lossL: tensor(2199292.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6123 lossL: tensor(2088691.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6124 lossL: tensor(2252590., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6125 lossL: tensor(2300715., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6126 lossL: tensor(2093401.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6127 lossL: tensor(2188804., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6128 lossL: tensor(2187041.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6129 lossL: tensor(2205354.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6130 lossL: tensor(2117841.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6131 lossL: tensor(2168674.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6132 lossL: tensor(2103169.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6133 lossL: tensor(2288967.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6134 lossL: tensor(2073295.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6135 lossL: tensor(2238611.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6136 lossL: tensor(2076611.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6137 lossL: tensor(2174874.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6138 lossL: tensor(2268754., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6139 lossL: tensor(1981190.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6140 lossL: tensor(2041559.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6141 lossL: tensor(2190474.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6142 lossL: tensor(2145106.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6143 lossL: tensor(2200792.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6144 lossL: tensor(2223888., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6145 lossL: tensor(2271114., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6146 lossL: tensor(2167262.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6147 lossL: tensor(2376066., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6148 lossL: tensor(2097478.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6149 lossL: tensor(2187348.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6150 lossL: tensor(2211188.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6151 lossL: tensor(2170121.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6152 lossL: tensor(2207760.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6153 lossL: tensor(2250301.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6154 lossL: tensor(2202511.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6155 lossL: tensor(2169389.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6156 lossL: tensor(2251334.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6157 lossL: tensor(2137456.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6158 lossL: tensor(2200143.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6159 lossL: tensor(2293497., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6160 lossL: tensor(2226614.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6161 lossL: tensor(2317583., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6162 lossL: tensor(2125458., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6163 lossL: tensor(2203118.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6164 lossL: tensor(2271288., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6165 lossL: tensor(2339697., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6166 lossL: tensor(2300862.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6167 lossL: tensor(2170940.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6168 lossL: tensor(2318635., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6169 lossL: tensor(2203259.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6170 lossL: tensor(2156463., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6171 lossL: tensor(2191428., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6172 lossL: tensor(2222746., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6173 lossL: tensor(2159976., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6174 lossL: tensor(2361456.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6175 lossL: tensor(2130303.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6176 lossL: tensor(2171750.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6177 lossL: tensor(2130441., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6178 lossL: tensor(2156060.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6179 lossL: tensor(1984010.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6180 lossL: tensor(2228160., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6181 lossL: tensor(2137494.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6182 lossL: tensor(2254108.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6183 lossL: tensor(2083766.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6184 lossL: tensor(2070357.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6185 lossL: tensor(2271383., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6186 lossL: tensor(2089161.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6187 lossL: tensor(2207159.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6188 lossL: tensor(2168786.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6189 lossL: tensor(2154631.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6190 lossL: tensor(2215336., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6191 lossL: tensor(2175532., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6192 lossL: tensor(2169487., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6193 lossL: tensor(2092710.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6194 lossL: tensor(2135586.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6195 lossL: tensor(2235416.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6196 lossL: tensor(2212694., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6197 lossL: tensor(2129969.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6198 lossL: tensor(2229569., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6199 lossL: tensor(2047510.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6200 lossL: tensor(2155777.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6201 lossL: tensor(2182037.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6202 lossL: tensor(2093399.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6203 lossL: tensor(2197409.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6204 lossL: tensor(2227969., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6205 lossL: tensor(2245039., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6206 lossL: tensor(2230621.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6207 lossL: tensor(2080766., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6208 lossL: tensor(2235386.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6209 lossL: tensor(2188678., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6210 lossL: tensor(2187024., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6211 lossL: tensor(2088118.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6212 lossL: tensor(2131971.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6213 lossL: tensor(2095400.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6214 lossL: tensor(2240522.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6215 lossL: tensor(2072841.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6216 lossL: tensor(2208864.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6217 lossL: tensor(2206686., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6218 lossL: tensor(2133481.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6219 lossL: tensor(2140401.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6220 lossL: tensor(2193829., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6221 lossL: tensor(2180045.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6222 lossL: tensor(2166503., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6223 lossL: tensor(2135273.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6224 lossL: tensor(2232223.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6225 lossL: tensor(2185188.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6226 lossL: tensor(2170872.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6227 lossL: tensor(2259636., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6228 lossL: tensor(2145304.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6229 lossL: tensor(2127743.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6230 lossL: tensor(2003047.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6231 lossL: tensor(2214526.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6232 lossL: tensor(2099082.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6233 lossL: tensor(2121715.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6234 lossL: tensor(2130878., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6235 lossL: tensor(2125620., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6236 lossL: tensor(2248737., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6237 lossL: tensor(2345755.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6238 lossL: tensor(2160350.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6239 lossL: tensor(2217146.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6240 lossL: tensor(2111860., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6241 lossL: tensor(2269276.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6242 lossL: tensor(2092782.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6243 lossL: tensor(2203189.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6244 lossL: tensor(2139612.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6245 lossL: tensor(2211360.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6246 lossL: tensor(2094502.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6247 lossL: tensor(2413005.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6248 lossL: tensor(2223892.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6249 lossL: tensor(2153970., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6250 lossL: tensor(2216682., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6251 lossL: tensor(2251497.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6252 lossL: tensor(2033740., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6253 lossL: tensor(2072437.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6254 lossL: tensor(2295644.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6255 lossL: tensor(2080385.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6256 lossL: tensor(2022160., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6257 lossL: tensor(2081856.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6258 lossL: tensor(2005983.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6259 lossL: tensor(1959283., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6260 lossL: tensor(2100063.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6261 lossL: tensor(2164520.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6262 lossL: tensor(2007676.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6263 lossL: tensor(2153036.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6264 lossL: tensor(2222947., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6265 lossL: tensor(2267610.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6266 lossL: tensor(2028111.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6267 lossL: tensor(2220995.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6268 lossL: tensor(2093635.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6269 lossL: tensor(2128506.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6270 lossL: tensor(2157747.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6271 lossL: tensor(2134193.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6272 lossL: tensor(2089858.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6273 lossL: tensor(2038229., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6274 lossL: tensor(2077229.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6275 lossL: tensor(2214076.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6276 lossL: tensor(2081922.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6277 lossL: tensor(1958155., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6278 lossL: tensor(2201213.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6279 lossL: tensor(2138206., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6280 lossL: tensor(2156865.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6281 lossL: tensor(2200644., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6282 lossL: tensor(2125373., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6283 lossL: tensor(2053346.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6284 lossL: tensor(2103126., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6285 lossL: tensor(2093880.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6286 lossL: tensor(2241961., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6287 lossL: tensor(2055565., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6288 lossL: tensor(2192742.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6289 lossL: tensor(2083436.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6290 lossL: tensor(2095171., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6291 lossL: tensor(2185661., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6292 lossL: tensor(2238157.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6293 lossL: tensor(2262546.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6294 lossL: tensor(2240355.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6295 lossL: tensor(2127405.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6296 lossL: tensor(2041424.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6297 lossL: tensor(2302882.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6298 lossL: tensor(2217843.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6299 lossL: tensor(2032768.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6300 lossL: tensor(2118719.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6301 lossL: tensor(2017810.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6302 lossL: tensor(2079317.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6303 lossL: tensor(2266527.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6304 lossL: tensor(2056970.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6305 lossL: tensor(2199874.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6306 lossL: tensor(2165543.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6307 lossL: tensor(2053495.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6308 lossL: tensor(2185424.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6309 lossL: tensor(1991907.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6310 lossL: tensor(2120600.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6311 lossL: tensor(2094092.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6312 lossL: tensor(2137455., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6313 lossL: tensor(2188733., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6314 lossL: tensor(2124160.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6315 lossL: tensor(2106791.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6316 lossL: tensor(2114128.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6317 lossL: tensor(2149343.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6318 lossL: tensor(2136036.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6319 lossL: tensor(2086099., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6320 lossL: tensor(2153016.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6321 lossL: tensor(2213935.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6322 lossL: tensor(2126472., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6323 lossL: tensor(2089945.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6324 lossL: tensor(2010252.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6325 lossL: tensor(2100923.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6326 lossL: tensor(2000189.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6327 lossL: tensor(2013456.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6328 lossL: tensor(2080677.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6329 lossL: tensor(1990207.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6330 lossL: tensor(2218829.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6331 lossL: tensor(2142133.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6332 lossL: tensor(2160218.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6333 lossL: tensor(2162759.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6334 lossL: tensor(2113774.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6335 lossL: tensor(2099104.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6336 lossL: tensor(2207117.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6337 lossL: tensor(2296433.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6338 lossL: tensor(2252054.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6339 lossL: tensor(2197428.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6340 lossL: tensor(2111638.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6341 lossL: tensor(2220906., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6342 lossL: tensor(2184555.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6343 lossL: tensor(2146788.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6344 lossL: tensor(2225759.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6345 lossL: tensor(2149280.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6346 lossL: tensor(2083750.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6347 lossL: tensor(2197511.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6348 lossL: tensor(2035325.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6349 lossL: tensor(2101021.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6350 lossL: tensor(2199183., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6351 lossL: tensor(2109458.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6352 lossL: tensor(2121254., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6353 lossL: tensor(1982417.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6354 lossL: tensor(1905070.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6355 lossL: tensor(2149299.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6356 lossL: tensor(2150770.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6357 lossL: tensor(2087791.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6358 lossL: tensor(2093492.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6359 lossL: tensor(2139606.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6360 lossL: tensor(2277051.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6361 lossL: tensor(2176208.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6362 lossL: tensor(2168152.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6363 lossL: tensor(1908145.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6364 lossL: tensor(2032231.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6365 lossL: tensor(2149680., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6366 lossL: tensor(1983310.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6367 lossL: tensor(2070922.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6368 lossL: tensor(2058221., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6369 lossL: tensor(1998967.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6370 lossL: tensor(2045401.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6371 lossL: tensor(2173411.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6372 lossL: tensor(2065741.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6373 lossL: tensor(2145779.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6374 lossL: tensor(2110468.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6375 lossL: tensor(2102459., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6376 lossL: tensor(2003257.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6377 lossL: tensor(2066109.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6378 lossL: tensor(2070281.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6379 lossL: tensor(2116726.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6380 lossL: tensor(2047561.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6381 lossL: tensor(2173234.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6382 lossL: tensor(2226691., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6383 lossL: tensor(2182363.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6384 lossL: tensor(2224624.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6385 lossL: tensor(2063485.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6386 lossL: tensor(2207863.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6387 lossL: tensor(2098667.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6388 lossL: tensor(2084506.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6389 lossL: tensor(2120149.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6390 lossL: tensor(2161423., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6391 lossL: tensor(2158279.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6392 lossL: tensor(2300895.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6393 lossL: tensor(1912769.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6394 lossL: tensor(2130340.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6395 lossL: tensor(2096995.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6396 lossL: tensor(2125212.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6397 lossL: tensor(2021861.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6398 lossL: tensor(2160574.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6399 lossL: tensor(2077852.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6400 lossL: tensor(2056135., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6401 lossL: tensor(2146505.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6402 lossL: tensor(2130980.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6403 lossL: tensor(2036099.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6404 lossL: tensor(2211253.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6405 lossL: tensor(1975701., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6406 lossL: tensor(2044126.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6407 lossL: tensor(2154509., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6408 lossL: tensor(2058605.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6409 lossL: tensor(2098761., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6410 lossL: tensor(2130810.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6411 lossL: tensor(2065564.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6412 lossL: tensor(1999711., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6413 lossL: tensor(2158693., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6414 lossL: tensor(2110225., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6415 lossL: tensor(2000213.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6416 lossL: tensor(2113203.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6417 lossL: tensor(2050651.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6418 lossL: tensor(2153026.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6419 lossL: tensor(2127084., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6420 lossL: tensor(2136786.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6421 lossL: tensor(1958820.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6422 lossL: tensor(2097007.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6423 lossL: tensor(2131504.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6424 lossL: tensor(2098073.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6425 lossL: tensor(1995615.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6426 lossL: tensor(2019177.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6427 lossL: tensor(2148672.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6428 lossL: tensor(2032682.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6429 lossL: tensor(2208305.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6430 lossL: tensor(2152998.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6431 lossL: tensor(2093372., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6432 lossL: tensor(2181079., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6433 lossL: tensor(2059349.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6434 lossL: tensor(2078830., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6435 lossL: tensor(2024797.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6436 lossL: tensor(1985779.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6437 lossL: tensor(2151530.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6438 lossL: tensor(2093667.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6439 lossL: tensor(2164146.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6440 lossL: tensor(2135492., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6441 lossL: tensor(2027268.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6442 lossL: tensor(2187407.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6443 lossL: tensor(2122600., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6444 lossL: tensor(2046771.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6445 lossL: tensor(1937948.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6446 lossL: tensor(2073158.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6447 lossL: tensor(2044308.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6448 lossL: tensor(2202570., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6449 lossL: tensor(2084717.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6450 lossL: tensor(2192205., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6451 lossL: tensor(2144383.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6452 lossL: tensor(2031297.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6453 lossL: tensor(2154190.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6454 lossL: tensor(1989614.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6455 lossL: tensor(2007022.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6456 lossL: tensor(2046905.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6457 lossL: tensor(2075088., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6458 lossL: tensor(2224482., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6459 lossL: tensor(1981350., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6460 lossL: tensor(1976379.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6461 lossL: tensor(2168038.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6462 lossL: tensor(2112896.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6463 lossL: tensor(2060080.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6464 lossL: tensor(2175040.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6465 lossL: tensor(1946082.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6466 lossL: tensor(2150377.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6467 lossL: tensor(2059592.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6468 lossL: tensor(2037808.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6469 lossL: tensor(2025975., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6470 lossL: tensor(2083742.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6471 lossL: tensor(1993875.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6472 lossL: tensor(2048028.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6473 lossL: tensor(2097557.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6474 lossL: tensor(2032709.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6475 lossL: tensor(2051828.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6476 lossL: tensor(2084336.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6477 lossL: tensor(2056302.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6478 lossL: tensor(2063715.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6479 lossL: tensor(2124118., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6480 lossL: tensor(2082008.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6481 lossL: tensor(2061204.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6482 lossL: tensor(2076094.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6483 lossL: tensor(2024985.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6484 lossL: tensor(1987005.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6485 lossL: tensor(1899369.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6486 lossL: tensor(2129411., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6487 lossL: tensor(2020670.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6488 lossL: tensor(2076644., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6489 lossL: tensor(2073010.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6490 lossL: tensor(2043328.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6491 lossL: tensor(2054628.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6492 lossL: tensor(1972142.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6493 lossL: tensor(2096858.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6494 lossL: tensor(2084969.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6495 lossL: tensor(2200061., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6496 lossL: tensor(2053749., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6497 lossL: tensor(2122191., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6498 lossL: tensor(2139955.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6499 lossL: tensor(2049001.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6500 lossL: tensor(2047119.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6501 lossL: tensor(1984178.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6502 lossL: tensor(2064018.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6503 lossL: tensor(1974010.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6504 lossL: tensor(2129983., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6505 lossL: tensor(1994127., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6506 lossL: tensor(2082981.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6507 lossL: tensor(2182097., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6508 lossL: tensor(1992886.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6509 lossL: tensor(2139759.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6510 lossL: tensor(1991222.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6511 lossL: tensor(1989059.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6512 lossL: tensor(1984106.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6513 lossL: tensor(1942086.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6514 lossL: tensor(2042586.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6515 lossL: tensor(2091058.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6516 lossL: tensor(2018195.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6517 lossL: tensor(2036706., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6518 lossL: tensor(1939558.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6519 lossL: tensor(2034289.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6520 lossL: tensor(2083800.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6521 lossL: tensor(2066051.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6522 lossL: tensor(1899723., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6523 lossL: tensor(1925914.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6524 lossL: tensor(1972259.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6525 lossL: tensor(2040727.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6526 lossL: tensor(1906222.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6527 lossL: tensor(1984627., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6528 lossL: tensor(1960002.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6529 lossL: tensor(2049670.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6530 lossL: tensor(2148150., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6531 lossL: tensor(2017784.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6532 lossL: tensor(1875546.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6533 lossL: tensor(2099706.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6534 lossL: tensor(2111252.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6535 lossL: tensor(2006529.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6536 lossL: tensor(1960694.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6537 lossL: tensor(1979744., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6538 lossL: tensor(1953856.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6539 lossL: tensor(1928106., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6540 lossL: tensor(2149292.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6541 lossL: tensor(2012576.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6542 lossL: tensor(1938534.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6543 lossL: tensor(2041257.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6544 lossL: tensor(2014103.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6545 lossL: tensor(1955801.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6546 lossL: tensor(1888214.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6547 lossL: tensor(1865876.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6548 lossL: tensor(2143390., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6549 lossL: tensor(1858752.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6550 lossL: tensor(2026132.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6551 lossL: tensor(1874968.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6552 lossL: tensor(2097047.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6553 lossL: tensor(1981668.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6554 lossL: tensor(2059408.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6555 lossL: tensor(1986850.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6556 lossL: tensor(1901630.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6557 lossL: tensor(1970273.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6558 lossL: tensor(1994708.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6559 lossL: tensor(2100537.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6560 lossL: tensor(1891662.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6561 lossL: tensor(1959399.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6562 lossL: tensor(1929690.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6563 lossL: tensor(1931154.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6564 lossL: tensor(2139476., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6565 lossL: tensor(1934859.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6566 lossL: tensor(2243179., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6567 lossL: tensor(2001138.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6568 lossL: tensor(1950512.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6569 lossL: tensor(2094558.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6570 lossL: tensor(1993511.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6571 lossL: tensor(1988224.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6572 lossL: tensor(1997336.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6573 lossL: tensor(1941478.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6574 lossL: tensor(1979172.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6575 lossL: tensor(2070766.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6576 lossL: tensor(2038462.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6577 lossL: tensor(2222493.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6578 lossL: tensor(2084105.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6579 lossL: tensor(2139709., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6580 lossL: tensor(1974028.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6581 lossL: tensor(1888334.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6582 lossL: tensor(2074157.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6583 lossL: tensor(1862232.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6584 lossL: tensor(1955789.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6585 lossL: tensor(1895920.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6586 lossL: tensor(2097615.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6587 lossL: tensor(1971587.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6588 lossL: tensor(1933576.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6589 lossL: tensor(1987138.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6590 lossL: tensor(2019389.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6591 lossL: tensor(2016121.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6592 lossL: tensor(1978847.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6593 lossL: tensor(2048532.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6594 lossL: tensor(2011846., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6595 lossL: tensor(1821697., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6596 lossL: tensor(2148757.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6597 lossL: tensor(2013696.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6598 lossL: tensor(2009555.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6599 lossL: tensor(2032266.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6600 lossL: tensor(1953130.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6601 lossL: tensor(1974248.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6602 lossL: tensor(2145945.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6603 lossL: tensor(1914440.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6604 lossL: tensor(1985805.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6605 lossL: tensor(1969359.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6606 lossL: tensor(1822578.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6607 lossL: tensor(1921565.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6608 lossL: tensor(1993456., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6609 lossL: tensor(1883052.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6610 lossL: tensor(1964011.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6611 lossL: tensor(2026715.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6612 lossL: tensor(2082248.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6613 lossL: tensor(2100001., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6614 lossL: tensor(2018475.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6615 lossL: tensor(1898760.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6616 lossL: tensor(1948395.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6617 lossL: tensor(2173125.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6618 lossL: tensor(1865915.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6619 lossL: tensor(2068711.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6620 lossL: tensor(2011416.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6621 lossL: tensor(2000531., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6622 lossL: tensor(2015130.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6623 lossL: tensor(1969030., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6624 lossL: tensor(2010736.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6625 lossL: tensor(1785628.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6626 lossL: tensor(1994381.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6627 lossL: tensor(2045490.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6628 lossL: tensor(2004257.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6629 lossL: tensor(2056797., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6630 lossL: tensor(2000996.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6631 lossL: tensor(2089033.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6632 lossL: tensor(2059518.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6633 lossL: tensor(1907202.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6634 lossL: tensor(1941205.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6635 lossL: tensor(2095856.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6636 lossL: tensor(1953535.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6637 lossL: tensor(1955665., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6638 lossL: tensor(1986955.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6639 lossL: tensor(2071309.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6640 lossL: tensor(1958070.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6641 lossL: tensor(1953063.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6642 lossL: tensor(2004889., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6643 lossL: tensor(1976898.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6644 lossL: tensor(2101141.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6645 lossL: tensor(1973106.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6646 lossL: tensor(2108837.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6647 lossL: tensor(2157248.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6648 lossL: tensor(1942419.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6649 lossL: tensor(1948300.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6650 lossL: tensor(2060489.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6651 lossL: tensor(1896128.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6652 lossL: tensor(2147439.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6653 lossL: tensor(1960978.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6654 lossL: tensor(1968619.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6655 lossL: tensor(2033213., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6656 lossL: tensor(1945720.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6657 lossL: tensor(2070980.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6658 lossL: tensor(1989450.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6659 lossL: tensor(1897363.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6660 lossL: tensor(1920468.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6661 lossL: tensor(2046294.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6662 lossL: tensor(1954963.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6663 lossL: tensor(1897774., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6664 lossL: tensor(1859385.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6665 lossL: tensor(1854255.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6666 lossL: tensor(2084382.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6667 lossL: tensor(2018229.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6668 lossL: tensor(2017866., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6669 lossL: tensor(2101662.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6670 lossL: tensor(1993342.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6671 lossL: tensor(1890580.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6672 lossL: tensor(1854446.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6673 lossL: tensor(1852181.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6674 lossL: tensor(1999703.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6675 lossL: tensor(1809202.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6676 lossL: tensor(1906963.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6677 lossL: tensor(1844611.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6678 lossL: tensor(1966411.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6679 lossL: tensor(1948141.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6680 lossL: tensor(2037733.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6681 lossL: tensor(1955504.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6682 lossL: tensor(1892249.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6683 lossL: tensor(1947554.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6684 lossL: tensor(1955362., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6685 lossL: tensor(2053090.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6686 lossL: tensor(1969582.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6687 lossL: tensor(2051521.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6688 lossL: tensor(1960768.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6689 lossL: tensor(2006672.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6690 lossL: tensor(1902599.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6691 lossL: tensor(1939290.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6692 lossL: tensor(1962321., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6693 lossL: tensor(2008068.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6694 lossL: tensor(1998227.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6695 lossL: tensor(1882330.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6696 lossL: tensor(1968118.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6697 lossL: tensor(1839266.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6698 lossL: tensor(1947932.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6699 lossL: tensor(1959152.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6700 lossL: tensor(1911797.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6701 lossL: tensor(1837387.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6702 lossL: tensor(1875603.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6703 lossL: tensor(1821195.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6704 lossL: tensor(1915727.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6705 lossL: tensor(1907733.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6706 lossL: tensor(2015341.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6707 lossL: tensor(1898131.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6708 lossL: tensor(1868425.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6709 lossL: tensor(2012933.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6710 lossL: tensor(1837023.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6711 lossL: tensor(2006371.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6712 lossL: tensor(2009378.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6713 lossL: tensor(1785149.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6714 lossL: tensor(1931854.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6715 lossL: tensor(1978001.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6716 lossL: tensor(1947924.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6717 lossL: tensor(1865086.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6718 lossL: tensor(1879803.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6719 lossL: tensor(1947333., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6720 lossL: tensor(1879218.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6721 lossL: tensor(1941072.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6722 lossL: tensor(2132307.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6723 lossL: tensor(1892218.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6724 lossL: tensor(1957854.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6725 lossL: tensor(1940588.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6726 lossL: tensor(1915425.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6727 lossL: tensor(1907915., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6728 lossL: tensor(1861766.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6729 lossL: tensor(1837247.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6730 lossL: tensor(1843661.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6731 lossL: tensor(1892190.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6732 lossL: tensor(1925359.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6733 lossL: tensor(1814529.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6734 lossL: tensor(1910729.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6735 lossL: tensor(1988835.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6736 lossL: tensor(1842926.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6737 lossL: tensor(2023348.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6738 lossL: tensor(1929274.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6739 lossL: tensor(1820375., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6740 lossL: tensor(1932680.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6741 lossL: tensor(1920176.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6742 lossL: tensor(1913799.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6743 lossL: tensor(1808490.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6744 lossL: tensor(1942774.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6745 lossL: tensor(1939207., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6746 lossL: tensor(1960702.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6747 lossL: tensor(1912548.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6748 lossL: tensor(1784406.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6749 lossL: tensor(1956168.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6750 lossL: tensor(1933792.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6751 lossL: tensor(1919405.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6752 lossL: tensor(1937454., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6753 lossL: tensor(1872361.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6754 lossL: tensor(1783776.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6755 lossL: tensor(1924866.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6756 lossL: tensor(1859533.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6757 lossL: tensor(1969424.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6758 lossL: tensor(1911504.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6759 lossL: tensor(1942049.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6760 lossL: tensor(1799308., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6761 lossL: tensor(1935774.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6762 lossL: tensor(1827200.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6763 lossL: tensor(1809134.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6764 lossL: tensor(1793488.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6765 lossL: tensor(1805507.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6766 lossL: tensor(1833272.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6767 lossL: tensor(1903813.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6768 lossL: tensor(1914748.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6769 lossL: tensor(1750519.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6770 lossL: tensor(1910672.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6771 lossL: tensor(1896878.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6772 lossL: tensor(1687247.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6773 lossL: tensor(1947078.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6774 lossL: tensor(1798933.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6775 lossL: tensor(1790099.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6776 lossL: tensor(1855259.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6777 lossL: tensor(1921230.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6778 lossL: tensor(1945414.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6779 lossL: tensor(1858588.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6780 lossL: tensor(1750517.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6781 lossL: tensor(1935350.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6782 lossL: tensor(1875220., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6783 lossL: tensor(2052395.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6784 lossL: tensor(1894048.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6785 lossL: tensor(1979262.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6786 lossL: tensor(1831645.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6787 lossL: tensor(1848143.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6788 lossL: tensor(1838301.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6789 lossL: tensor(1851604.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6790 lossL: tensor(1990577.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6791 lossL: tensor(1777497.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6792 lossL: tensor(1837029.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6793 lossL: tensor(1754936.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6794 lossL: tensor(1925713., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6795 lossL: tensor(1908609.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6796 lossL: tensor(1904033.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6797 lossL: tensor(1896726.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6798 lossL: tensor(1928223.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6799 lossL: tensor(1866470.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6800 lossL: tensor(1928289.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6801 lossL: tensor(1842206.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6802 lossL: tensor(1856249.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6803 lossL: tensor(1941061.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6804 lossL: tensor(1739461.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6805 lossL: tensor(1876472.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6806 lossL: tensor(1938134.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6807 lossL: tensor(1855312.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6808 lossL: tensor(1777930.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6809 lossL: tensor(1787492., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6810 lossL: tensor(1845748.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6811 lossL: tensor(1830834.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6812 lossL: tensor(1923414., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6813 lossL: tensor(1887386.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6814 lossL: tensor(1825744.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6815 lossL: tensor(1791267.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6816 lossL: tensor(1922241.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6817 lossL: tensor(1863635.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6818 lossL: tensor(1920666.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6819 lossL: tensor(1779748.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6820 lossL: tensor(1886757.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6821 lossL: tensor(1920626.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6822 lossL: tensor(1882626.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6823 lossL: tensor(1844273.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6824 lossL: tensor(1775789.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6825 lossL: tensor(2009825.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6826 lossL: tensor(1897738.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6827 lossL: tensor(1857755.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6828 lossL: tensor(1783568.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6829 lossL: tensor(1911974.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6830 lossL: tensor(1775847.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6831 lossL: tensor(1788506.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6832 lossL: tensor(1798532.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6833 lossL: tensor(1789521.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6834 lossL: tensor(1787034.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6835 lossL: tensor(1865404., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6836 lossL: tensor(1801767., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6837 lossL: tensor(1734057., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6838 lossL: tensor(1773653.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6839 lossL: tensor(1924187., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6840 lossL: tensor(1867650.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6841 lossL: tensor(1860989.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6842 lossL: tensor(1839529., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6843 lossL: tensor(2017971.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6844 lossL: tensor(1818638.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6845 lossL: tensor(1856040.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6846 lossL: tensor(2014445.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6847 lossL: tensor(1978312.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6848 lossL: tensor(1918439.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6849 lossL: tensor(1873272.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6850 lossL: tensor(1766213.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6851 lossL: tensor(1859867.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6852 lossL: tensor(1806770., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6853 lossL: tensor(1901195.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6854 lossL: tensor(1801524.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6855 lossL: tensor(1850836.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6856 lossL: tensor(1795089.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6857 lossL: tensor(1942852.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6858 lossL: tensor(1699199., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6859 lossL: tensor(1802176.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6860 lossL: tensor(1911804.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6861 lossL: tensor(2011281.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6862 lossL: tensor(1821712.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6863 lossL: tensor(1845494.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6864 lossL: tensor(1831127.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6865 lossL: tensor(1624548., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6866 lossL: tensor(1743496.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6867 lossL: tensor(1794462.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6868 lossL: tensor(1883673.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6869 lossL: tensor(1927242.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6870 lossL: tensor(1847419.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6871 lossL: tensor(1888372.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6872 lossL: tensor(1782136.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6873 lossL: tensor(1771074.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6874 lossL: tensor(1898600.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6875 lossL: tensor(1756286., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6876 lossL: tensor(1795720.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6877 lossL: tensor(2005587.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6878 lossL: tensor(1793768.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6879 lossL: tensor(1718751.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6880 lossL: tensor(1806551.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6881 lossL: tensor(1719707.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6882 lossL: tensor(1945462.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6883 lossL: tensor(1805704.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6884 lossL: tensor(1822908.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6885 lossL: tensor(1832179.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6886 lossL: tensor(1656693.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6887 lossL: tensor(1740248.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6888 lossL: tensor(1975941., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6889 lossL: tensor(1672981.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6890 lossL: tensor(1830432.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6891 lossL: tensor(1801905., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6892 lossL: tensor(1664289.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6893 lossL: tensor(1807241., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6894 lossL: tensor(1754831.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6895 lossL: tensor(1700426.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6896 lossL: tensor(1885657.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6897 lossL: tensor(1819567.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6898 lossL: tensor(1770458., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6899 lossL: tensor(1791929., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6900 lossL: tensor(1722502.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6901 lossL: tensor(1823189.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6902 lossL: tensor(1697816.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6903 lossL: tensor(1733342.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6904 lossL: tensor(1887048.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6905 lossL: tensor(1930278.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6906 lossL: tensor(1738370.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6907 lossL: tensor(1716428.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6908 lossL: tensor(1804542.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6909 lossL: tensor(1811348.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6910 lossL: tensor(1801574.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6911 lossL: tensor(1775464.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6912 lossL: tensor(1809621.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6913 lossL: tensor(1778044.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6914 lossL: tensor(1850105.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6915 lossL: tensor(1787260.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6916 lossL: tensor(1810399.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6917 lossL: tensor(1806592.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6918 lossL: tensor(1971374.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6919 lossL: tensor(1711621.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6920 lossL: tensor(1715292.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6921 lossL: tensor(1729920., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6922 lossL: tensor(1791151.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6923 lossL: tensor(1867598.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6924 lossL: tensor(1845011.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6925 lossL: tensor(1707459.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6926 lossL: tensor(1753773.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6927 lossL: tensor(1805674.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6928 lossL: tensor(1850629.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6929 lossL: tensor(1660277.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6930 lossL: tensor(1881247.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6931 lossL: tensor(1799830.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6932 lossL: tensor(1809031.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6933 lossL: tensor(1746369.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6934 lossL: tensor(1821842.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6935 lossL: tensor(1800593.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6936 lossL: tensor(1705708.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6937 lossL: tensor(1801115.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6938 lossL: tensor(1819281., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6939 lossL: tensor(1709928.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6940 lossL: tensor(1791008., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6941 lossL: tensor(1740144.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6942 lossL: tensor(1803527.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6943 lossL: tensor(1676558.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6944 lossL: tensor(1870100.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6945 lossL: tensor(1788911.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6946 lossL: tensor(1820726.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6947 lossL: tensor(1695612.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6948 lossL: tensor(1747665., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6949 lossL: tensor(1684725.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6950 lossL: tensor(1853664.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6951 lossL: tensor(1671379.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6952 lossL: tensor(1747911.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6953 lossL: tensor(1855760., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6954 lossL: tensor(1751175.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6955 lossL: tensor(1819679.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6956 lossL: tensor(1683149.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6957 lossL: tensor(1827705., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6958 lossL: tensor(1775523.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6959 lossL: tensor(1737884.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6960 lossL: tensor(1637625.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6961 lossL: tensor(1744759.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6962 lossL: tensor(1690092.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6963 lossL: tensor(1642074.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6964 lossL: tensor(1825151.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6965 lossL: tensor(1729266.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6966 lossL: tensor(1978462.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6967 lossL: tensor(1607360.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "6968 lossL: tensor(1723981., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6969 lossL: tensor(1849488.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6970 lossL: tensor(1772389.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6971 lossL: tensor(1795048., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6972 lossL: tensor(1706758.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6973 lossL: tensor(1753414.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6974 lossL: tensor(1762501.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6975 lossL: tensor(1760975.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6976 lossL: tensor(1807784.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6977 lossL: tensor(1881303.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6978 lossL: tensor(1800826.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6979 lossL: tensor(1722588., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6980 lossL: tensor(1769382.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6981 lossL: tensor(1684663.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6982 lossL: tensor(1794566., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6983 lossL: tensor(1751786., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6984 lossL: tensor(1727560.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6985 lossL: tensor(1695282.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6986 lossL: tensor(1730608.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6987 lossL: tensor(1705626.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6988 lossL: tensor(1738140.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6989 lossL: tensor(1771396.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6990 lossL: tensor(1717098.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6991 lossL: tensor(1790957.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6992 lossL: tensor(1717205.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6993 lossL: tensor(1815999.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6994 lossL: tensor(1776505.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6995 lossL: tensor(1690741.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6996 lossL: tensor(1655173.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6997 lossL: tensor(1708115.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6998 lossL: tensor(1782154.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "6999 lossL: tensor(1831870.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7000 lossL: tensor(1776897.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7001 lossL: tensor(1668173.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7002 lossL: tensor(1753768.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7003 lossL: tensor(1659836.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7004 lossL: tensor(1748251.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7005 lossL: tensor(1643534.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7006 lossL: tensor(1742370., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7007 lossL: tensor(1712837.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7008 lossL: tensor(1674779.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7009 lossL: tensor(1723695.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7010 lossL: tensor(1911907.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7011 lossL: tensor(1575648.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7012 lossL: tensor(1749252.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7013 lossL: tensor(1671925.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7014 lossL: tensor(1759011.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7015 lossL: tensor(1653524.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7016 lossL: tensor(1750205.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7017 lossL: tensor(1713993.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7018 lossL: tensor(1740331.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7019 lossL: tensor(1638302.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7020 lossL: tensor(1803097.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7021 lossL: tensor(1711577.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7022 lossL: tensor(1732190.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7023 lossL: tensor(1689327.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7024 lossL: tensor(1788358.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7025 lossL: tensor(1705785.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7026 lossL: tensor(1683594.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7027 lossL: tensor(1750415.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7028 lossL: tensor(1727084.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7029 lossL: tensor(1706344.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7030 lossL: tensor(1797529.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7031 lossL: tensor(1733299.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7032 lossL: tensor(1704822., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7033 lossL: tensor(1748990.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7034 lossL: tensor(1643293., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7035 lossL: tensor(1688143.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7036 lossL: tensor(1711394.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7037 lossL: tensor(1796667.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7038 lossL: tensor(1637962.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7039 lossL: tensor(1694372., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7040 lossL: tensor(1933190., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7041 lossL: tensor(1640489., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7042 lossL: tensor(1632115.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7043 lossL: tensor(1723137., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7044 lossL: tensor(1659696.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7045 lossL: tensor(1711957.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7046 lossL: tensor(1700688.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7047 lossL: tensor(1667586.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7048 lossL: tensor(1631007.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7049 lossL: tensor(1692820.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7050 lossL: tensor(1719114.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7051 lossL: tensor(1777887.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7052 lossL: tensor(1588999.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7053 lossL: tensor(1695113.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7054 lossL: tensor(1614541.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7055 lossL: tensor(1604497.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7056 lossL: tensor(1662339., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7057 lossL: tensor(1671452.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7058 lossL: tensor(1750868.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7059 lossL: tensor(1761917.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7060 lossL: tensor(1697328.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7061 lossL: tensor(1631176.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7062 lossL: tensor(1830408.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7063 lossL: tensor(1773409.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7064 lossL: tensor(1643726.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7065 lossL: tensor(1588847.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7066 lossL: tensor(1700584.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7067 lossL: tensor(1589544.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7068 lossL: tensor(1578724.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7069 lossL: tensor(1648097.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7070 lossL: tensor(1515403.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7071 lossL: tensor(1550916.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7072 lossL: tensor(1674948., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7073 lossL: tensor(1767769.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7074 lossL: tensor(1579109.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7075 lossL: tensor(1604235., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7076 lossL: tensor(1653740.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7077 lossL: tensor(1556336.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7078 lossL: tensor(1533997.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7079 lossL: tensor(1627003.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7080 lossL: tensor(1672956., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7081 lossL: tensor(1692464.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7082 lossL: tensor(1735068.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7083 lossL: tensor(1629625.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7084 lossL: tensor(1464988.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7085 lossL: tensor(1558339.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7086 lossL: tensor(1756282.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7087 lossL: tensor(1750055.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7088 lossL: tensor(1604733.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7089 lossL: tensor(1719503.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7090 lossL: tensor(1631720.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7091 lossL: tensor(1666031.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7092 lossL: tensor(1612237.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7093 lossL: tensor(1711295.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7094 lossL: tensor(1595705.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7095 lossL: tensor(1662208.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7096 lossL: tensor(1580502.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7097 lossL: tensor(1751819.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7098 lossL: tensor(1667400.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7099 lossL: tensor(1611843.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7100 lossL: tensor(1670233.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7101 lossL: tensor(1717511.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7102 lossL: tensor(1587082.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7103 lossL: tensor(1587594.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7104 lossL: tensor(1654113.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7105 lossL: tensor(1636086.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7106 lossL: tensor(1596245.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7107 lossL: tensor(1662944.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7108 lossL: tensor(1602751., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7109 lossL: tensor(1443179., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7110 lossL: tensor(1598761.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7111 lossL: tensor(1585732.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7112 lossL: tensor(1557489.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7113 lossL: tensor(1672986.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7114 lossL: tensor(1702694.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7115 lossL: tensor(1610955.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7116 lossL: tensor(1819409.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7117 lossL: tensor(1719631.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7118 lossL: tensor(1632965.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7119 lossL: tensor(1564411.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7120 lossL: tensor(1581982.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7121 lossL: tensor(1592850.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7122 lossL: tensor(1514337.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7123 lossL: tensor(1614295.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7124 lossL: tensor(1548360.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7125 lossL: tensor(1580181.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7126 lossL: tensor(1662827.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7127 lossL: tensor(1430980.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7128 lossL: tensor(1698880.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7129 lossL: tensor(1573864.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7130 lossL: tensor(1681359.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7131 lossL: tensor(1605371., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7132 lossL: tensor(1776849.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7133 lossL: tensor(1547720.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7134 lossL: tensor(1658114.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7135 lossL: tensor(1623743.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7136 lossL: tensor(1603054.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7137 lossL: tensor(1609451.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7138 lossL: tensor(1501987., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7139 lossL: tensor(1648672.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7140 lossL: tensor(1617375.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7141 lossL: tensor(1587190., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7142 lossL: tensor(1565354., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7143 lossL: tensor(1578185.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7144 lossL: tensor(1521985., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7145 lossL: tensor(1607920.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7146 lossL: tensor(1662971.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7147 lossL: tensor(1436861., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7148 lossL: tensor(1568310.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7149 lossL: tensor(1594281.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7150 lossL: tensor(1571947., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7151 lossL: tensor(1607157.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7152 lossL: tensor(1559919., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7153 lossL: tensor(1429721.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7154 lossL: tensor(1638019., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7155 lossL: tensor(1506983.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7156 lossL: tensor(1606756.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7157 lossL: tensor(1566813.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7158 lossL: tensor(1673112.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7159 lossL: tensor(1617229., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7160 lossL: tensor(1652698.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7161 lossL: tensor(1542537., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7162 lossL: tensor(1513412.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7163 lossL: tensor(1530699.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7164 lossL: tensor(1574106.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7165 lossL: tensor(1767105., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7166 lossL: tensor(1634426.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7167 lossL: tensor(1559037.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7168 lossL: tensor(1672617.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7169 lossL: tensor(1593594.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7170 lossL: tensor(1548283.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7171 lossL: tensor(1563330.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7172 lossL: tensor(1550598.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7173 lossL: tensor(1563699.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7174 lossL: tensor(1535447.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7175 lossL: tensor(1685979.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7176 lossL: tensor(1523598.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7177 lossL: tensor(1686913.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7178 lossL: tensor(1522546.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7179 lossL: tensor(1587129.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7180 lossL: tensor(1691378.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7181 lossL: tensor(1606682.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7182 lossL: tensor(1563380.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7183 lossL: tensor(1652102.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7184 lossL: tensor(1594233.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7185 lossL: tensor(1651364.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7186 lossL: tensor(1451001.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7187 lossL: tensor(1443699., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7188 lossL: tensor(1652035., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7189 lossL: tensor(1636282.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7190 lossL: tensor(1517169.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7191 lossL: tensor(1547090.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7192 lossL: tensor(1557937.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7193 lossL: tensor(1687665.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7194 lossL: tensor(1505656.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7195 lossL: tensor(1621167.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7196 lossL: tensor(1612746.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7197 lossL: tensor(1562473.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7198 lossL: tensor(1559396.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7199 lossL: tensor(1507919.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7200 lossL: tensor(1580137.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7201 lossL: tensor(1517196.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7202 lossL: tensor(1627711.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7203 lossL: tensor(1396408.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7204 lossL: tensor(1609286.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7205 lossL: tensor(1538963.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7206 lossL: tensor(1575693.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7207 lossL: tensor(1507431.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7208 lossL: tensor(1459148.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7209 lossL: tensor(1503967.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7210 lossL: tensor(1505141.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7211 lossL: tensor(1454178.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7212 lossL: tensor(1452965.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7213 lossL: tensor(1542794.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7214 lossL: tensor(1582050., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7215 lossL: tensor(1519004., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7216 lossL: tensor(1465209.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7217 lossL: tensor(1508249.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7218 lossL: tensor(1443380.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7219 lossL: tensor(1541617.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7220 lossL: tensor(1600542., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7221 lossL: tensor(1640807.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7222 lossL: tensor(1514502.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7223 lossL: tensor(1546309.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7224 lossL: tensor(1461390., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7225 lossL: tensor(1531797.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7226 lossL: tensor(1501778., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7227 lossL: tensor(1571981.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7228 lossL: tensor(1456539.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7229 lossL: tensor(1558292.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7230 lossL: tensor(1400635., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7231 lossL: tensor(1547538., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7232 lossL: tensor(1627256.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7233 lossL: tensor(1591208.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7234 lossL: tensor(1548763.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7235 lossL: tensor(1551802.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7236 lossL: tensor(1493289., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7237 lossL: tensor(1528364.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7238 lossL: tensor(1540152.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7239 lossL: tensor(1567402., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7240 lossL: tensor(1485299.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7241 lossL: tensor(1338198.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7242 lossL: tensor(1484044.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7243 lossL: tensor(1567440.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7244 lossL: tensor(1540856., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7245 lossL: tensor(1415396.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7246 lossL: tensor(1569871.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7247 lossL: tensor(1489030.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7248 lossL: tensor(1378547.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7249 lossL: tensor(1503920.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7250 lossL: tensor(1501992.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7251 lossL: tensor(1488068.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7252 lossL: tensor(1510499.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7253 lossL: tensor(1497012.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7254 lossL: tensor(1623567.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7255 lossL: tensor(1495658.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7256 lossL: tensor(1535235.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7257 lossL: tensor(1504863.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7258 lossL: tensor(1485388.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7259 lossL: tensor(1534192.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7260 lossL: tensor(1615914.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7261 lossL: tensor(1418488.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7262 lossL: tensor(1491038., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7263 lossL: tensor(1398079.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7264 lossL: tensor(1371968.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7265 lossL: tensor(1455615.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7266 lossL: tensor(1485368.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7267 lossL: tensor(1475374.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7268 lossL: tensor(1493849.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7269 lossL: tensor(1473435.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7270 lossL: tensor(1395609.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7271 lossL: tensor(1446764.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7272 lossL: tensor(1579421.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7273 lossL: tensor(1392640.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7274 lossL: tensor(1541281.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7275 lossL: tensor(1494158.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7276 lossL: tensor(1441179.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7277 lossL: tensor(1497245.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7278 lossL: tensor(1459700., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7279 lossL: tensor(1457380.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7280 lossL: tensor(1447404.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7281 lossL: tensor(1520861.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7282 lossL: tensor(1446800.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7283 lossL: tensor(1428679.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7284 lossL: tensor(1496333.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7285 lossL: tensor(1444904.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7286 lossL: tensor(1353084.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7287 lossL: tensor(1589496.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7288 lossL: tensor(1493608.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7289 lossL: tensor(1420173.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7290 lossL: tensor(1483874.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7291 lossL: tensor(1396534.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7292 lossL: tensor(1442869.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7293 lossL: tensor(1496626.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7294 lossL: tensor(1446868.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7295 lossL: tensor(1364542.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7296 lossL: tensor(1479169.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7297 lossL: tensor(1537577., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7298 lossL: tensor(1397918.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7299 lossL: tensor(1523775.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7300 lossL: tensor(1459522.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7301 lossL: tensor(1481571.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7302 lossL: tensor(1494448.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7303 lossL: tensor(1349209.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7304 lossL: tensor(1466325.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7305 lossL: tensor(1491471.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7306 lossL: tensor(1424491.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7307 lossL: tensor(1421271., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7308 lossL: tensor(1568881.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7309 lossL: tensor(1354814.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7310 lossL: tensor(1384001.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7311 lossL: tensor(1356906.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7312 lossL: tensor(1428684.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7313 lossL: tensor(1495958.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7314 lossL: tensor(1391009.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7315 lossL: tensor(1311124.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7316 lossL: tensor(1496517., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7317 lossL: tensor(1461326.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7318 lossL: tensor(1367509., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7319 lossL: tensor(1401429.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7320 lossL: tensor(1439860.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7321 lossL: tensor(1438852., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7322 lossL: tensor(1374432.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7323 lossL: tensor(1355024.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7324 lossL: tensor(1419550.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7325 lossL: tensor(1378375.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7326 lossL: tensor(1465402.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7327 lossL: tensor(1508488.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7328 lossL: tensor(1288221.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7329 lossL: tensor(1401943.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7330 lossL: tensor(1413422.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7331 lossL: tensor(1417697., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7332 lossL: tensor(1508041.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7333 lossL: tensor(1555550., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7334 lossL: tensor(1313645., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7335 lossL: tensor(1425494.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7336 lossL: tensor(1494255.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7337 lossL: tensor(1329797.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7338 lossL: tensor(1427645.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7339 lossL: tensor(1456224., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7340 lossL: tensor(1434944.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7341 lossL: tensor(1393749.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7342 lossL: tensor(1369068.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7343 lossL: tensor(1389085.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7344 lossL: tensor(1359593.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7345 lossL: tensor(1360233.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7346 lossL: tensor(1380304.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7347 lossL: tensor(1414503.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7348 lossL: tensor(1326422., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7349 lossL: tensor(1380522.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7350 lossL: tensor(1491226.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7351 lossL: tensor(1499750.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7352 lossL: tensor(1298826., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7353 lossL: tensor(1452346.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7354 lossL: tensor(1359897.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7355 lossL: tensor(1419309.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7356 lossL: tensor(1314527.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7357 lossL: tensor(1402840.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7358 lossL: tensor(1425350.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7359 lossL: tensor(1438558.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7360 lossL: tensor(1304630.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7361 lossL: tensor(1388394.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7362 lossL: tensor(1558610.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7363 lossL: tensor(1356041.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7364 lossL: tensor(1382469.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7365 lossL: tensor(1367351., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7366 lossL: tensor(1457830.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7367 lossL: tensor(1382855.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7368 lossL: tensor(1328506.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7369 lossL: tensor(1339149.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7370 lossL: tensor(1492737., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7371 lossL: tensor(1489415.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7372 lossL: tensor(1314904.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7373 lossL: tensor(1381601.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7374 lossL: tensor(1412825.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7375 lossL: tensor(1330654., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7376 lossL: tensor(1404352.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7377 lossL: tensor(1333062., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7378 lossL: tensor(1400761.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7379 lossL: tensor(1436511.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7380 lossL: tensor(1443715.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7381 lossL: tensor(1360169.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7382 lossL: tensor(1421505., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7383 lossL: tensor(1341995.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7384 lossL: tensor(1369720.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7385 lossL: tensor(1339991.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7386 lossL: tensor(1393279.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7387 lossL: tensor(1307370.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7388 lossL: tensor(1426167.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7389 lossL: tensor(1461474.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7390 lossL: tensor(1402420.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7391 lossL: tensor(1389218.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7392 lossL: tensor(1349276.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7393 lossL: tensor(1379115.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7394 lossL: tensor(1338549.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7395 lossL: tensor(1419056.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7396 lossL: tensor(1345613.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7397 lossL: tensor(1272952.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7398 lossL: tensor(1410584.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7399 lossL: tensor(1375446.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7400 lossL: tensor(1358193., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7401 lossL: tensor(1341670.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7402 lossL: tensor(1394604.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7403 lossL: tensor(1517215.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7404 lossL: tensor(1348746.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7405 lossL: tensor(1365585., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7406 lossL: tensor(1363569., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7407 lossL: tensor(1332119.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7408 lossL: tensor(1359368.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7409 lossL: tensor(1390119.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7410 lossL: tensor(1250527.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7411 lossL: tensor(1342542.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7412 lossL: tensor(1362713.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7413 lossL: tensor(1326725.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7414 lossL: tensor(1354846.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7415 lossL: tensor(1275853.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7416 lossL: tensor(1413538.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7417 lossL: tensor(1329015., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7418 lossL: tensor(1289963.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7419 lossL: tensor(1412607.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7420 lossL: tensor(1359914.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7421 lossL: tensor(1355533.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7422 lossL: tensor(1252765.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7423 lossL: tensor(1421859.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7424 lossL: tensor(1314004., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7425 lossL: tensor(1324675.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7426 lossL: tensor(1356987.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7427 lossL: tensor(1379514.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7428 lossL: tensor(1367611.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7429 lossL: tensor(1269325.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7430 lossL: tensor(1256245.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7431 lossL: tensor(1380352.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7432 lossL: tensor(1358410.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7433 lossL: tensor(1262988.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7434 lossL: tensor(1385945., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7435 lossL: tensor(1307081.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7436 lossL: tensor(1330486.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7437 lossL: tensor(1371120.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7438 lossL: tensor(1328795.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7439 lossL: tensor(1402694.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7440 lossL: tensor(1310178.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7441 lossL: tensor(1265716.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7442 lossL: tensor(1340542.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7443 lossL: tensor(1361170.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7444 lossL: tensor(1381042.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7445 lossL: tensor(1332735.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7446 lossL: tensor(1305291., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7447 lossL: tensor(1349461.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7448 lossL: tensor(1257051.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7449 lossL: tensor(1427806.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7450 lossL: tensor(1266628.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7451 lossL: tensor(1348951.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7452 lossL: tensor(1420688., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7453 lossL: tensor(1237659.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7454 lossL: tensor(1246237.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7455 lossL: tensor(1274608.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7456 lossL: tensor(1329764.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7457 lossL: tensor(1293428.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7458 lossL: tensor(1223469.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7459 lossL: tensor(1221467.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7460 lossL: tensor(1369770.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7461 lossL: tensor(1325548., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7462 lossL: tensor(1281588.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7463 lossL: tensor(1352049., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7464 lossL: tensor(1334323.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7465 lossL: tensor(1294028.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7466 lossL: tensor(1331227.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7467 lossL: tensor(1221121.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7468 lossL: tensor(1232410., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7469 lossL: tensor(1372271.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7470 lossL: tensor(1194836.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7471 lossL: tensor(1296650., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7472 lossL: tensor(1395670., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7473 lossL: tensor(1299269.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7474 lossL: tensor(1373598.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7475 lossL: tensor(1305691., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7476 lossL: tensor(1376413.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7477 lossL: tensor(1351617.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7478 lossL: tensor(1363044.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7479 lossL: tensor(1310355.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7480 lossL: tensor(1266922.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7481 lossL: tensor(1290279.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7482 lossL: tensor(1347851.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7483 lossL: tensor(1218796.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7484 lossL: tensor(1364771., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7485 lossL: tensor(1326434.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7486 lossL: tensor(1345139.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7487 lossL: tensor(1402657.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7488 lossL: tensor(1241382.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7489 lossL: tensor(1301048.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7490 lossL: tensor(1309250.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7491 lossL: tensor(1231424.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7492 lossL: tensor(1246586., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7493 lossL: tensor(1362033., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7494 lossL: tensor(1320642.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7495 lossL: tensor(1299511., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7496 lossL: tensor(1340755.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7497 lossL: tensor(1200848., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7498 lossL: tensor(1266780.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7499 lossL: tensor(1241029.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7500 lossL: tensor(1309453.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7501 lossL: tensor(1320774.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7502 lossL: tensor(1200049.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7503 lossL: tensor(1248416.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7504 lossL: tensor(1281939.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7505 lossL: tensor(1245545.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7506 lossL: tensor(1233633.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7507 lossL: tensor(1216000., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7508 lossL: tensor(1258216.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7509 lossL: tensor(1158607.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7510 lossL: tensor(1255583., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7511 lossL: tensor(1280582.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7512 lossL: tensor(1275552.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7513 lossL: tensor(1174587.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7514 lossL: tensor(1257424.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7515 lossL: tensor(1343258.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7516 lossL: tensor(1194915.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7517 lossL: tensor(1237991.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7518 lossL: tensor(1303774.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7519 lossL: tensor(1232368.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7520 lossL: tensor(1337505.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7521 lossL: tensor(1258781., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7522 lossL: tensor(1259021.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7523 lossL: tensor(1290608.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7524 lossL: tensor(1273266.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7525 lossL: tensor(1339852.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7526 lossL: tensor(1306743., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7527 lossL: tensor(1320221.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7528 lossL: tensor(1213760.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7529 lossL: tensor(1207722.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7530 lossL: tensor(1367057.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7531 lossL: tensor(1279646.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7532 lossL: tensor(1281858.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7533 lossL: tensor(1230121.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7534 lossL: tensor(1239298., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7535 lossL: tensor(1240163.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7536 lossL: tensor(1276439., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7537 lossL: tensor(1212345., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7538 lossL: tensor(1178114.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7539 lossL: tensor(1151183.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7540 lossL: tensor(1240472.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7541 lossL: tensor(1259137.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7542 lossL: tensor(1194671., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7543 lossL: tensor(1255667.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7544 lossL: tensor(1225535.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7545 lossL: tensor(1228652.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7546 lossL: tensor(1312300.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7547 lossL: tensor(1162675.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7548 lossL: tensor(1182600.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7549 lossL: tensor(1232788.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7550 lossL: tensor(1222806.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7551 lossL: tensor(1245831.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7552 lossL: tensor(1192985.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7553 lossL: tensor(1205570.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7554 lossL: tensor(1210018.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7555 lossL: tensor(1180556.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7556 lossL: tensor(1258590.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7557 lossL: tensor(1171058.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7558 lossL: tensor(1212143.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7559 lossL: tensor(1155753.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7560 lossL: tensor(1173892.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7561 lossL: tensor(1176447.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7562 lossL: tensor(1334348.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7563 lossL: tensor(1193047.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7564 lossL: tensor(1161039.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7565 lossL: tensor(1161368.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7566 lossL: tensor(1269305.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7567 lossL: tensor(1188995.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7568 lossL: tensor(1269770.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7569 lossL: tensor(1195869.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7570 lossL: tensor(1244036.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7571 lossL: tensor(1182842., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7572 lossL: tensor(1263702.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7573 lossL: tensor(1176957.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7574 lossL: tensor(1182361.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7575 lossL: tensor(1191679.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7576 lossL: tensor(1257165.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7577 lossL: tensor(1225877.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7578 lossL: tensor(1206169., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7579 lossL: tensor(1130596.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7580 lossL: tensor(1203302., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7581 lossL: tensor(1141596.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7582 lossL: tensor(1192336.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7583 lossL: tensor(1119430.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7584 lossL: tensor(1150852.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7585 lossL: tensor(1160062.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7586 lossL: tensor(1146919.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7587 lossL: tensor(1179446.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7588 lossL: tensor(1159986.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7589 lossL: tensor(1144331.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7590 lossL: tensor(1120140.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7591 lossL: tensor(1149769.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7592 lossL: tensor(1173425.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7593 lossL: tensor(1205049.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7594 lossL: tensor(1125503.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7595 lossL: tensor(1222966., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7596 lossL: tensor(1115342.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7597 lossL: tensor(1060741.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7598 lossL: tensor(1126662.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7599 lossL: tensor(1193109.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7600 lossL: tensor(1189251.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7601 lossL: tensor(1194218.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7602 lossL: tensor(1081977.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7603 lossL: tensor(1193388.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7604 lossL: tensor(1116517.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7605 lossL: tensor(1261002.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7606 lossL: tensor(1090353.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7607 lossL: tensor(1168928., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7608 lossL: tensor(1140122., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7609 lossL: tensor(1166190.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7610 lossL: tensor(1130081.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7611 lossL: tensor(1163147.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7612 lossL: tensor(1183136.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7613 lossL: tensor(1228730., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7614 lossL: tensor(1177593.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7615 lossL: tensor(1099553.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7616 lossL: tensor(1066633.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7617 lossL: tensor(1182761., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7618 lossL: tensor(1205160.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7619 lossL: tensor(1213985.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7620 lossL: tensor(1209063.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7621 lossL: tensor(1171148.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7622 lossL: tensor(1131881.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7623 lossL: tensor(1163985.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7624 lossL: tensor(1164847.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7625 lossL: tensor(1182976., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7626 lossL: tensor(1180920.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7627 lossL: tensor(1134902.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7628 lossL: tensor(1210665.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7629 lossL: tensor(1059497., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7630 lossL: tensor(1153913.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7631 lossL: tensor(1204478.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7632 lossL: tensor(1181171.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7633 lossL: tensor(1209993.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7634 lossL: tensor(1068181.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7635 lossL: tensor(1175720.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7636 lossL: tensor(1146287.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7637 lossL: tensor(1119832., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7638 lossL: tensor(1123028., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7639 lossL: tensor(1121050.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7640 lossL: tensor(1075925.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7641 lossL: tensor(1094615.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7642 lossL: tensor(1212171.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7643 lossL: tensor(1134544.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7644 lossL: tensor(1122095.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7645 lossL: tensor(1116690.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7646 lossL: tensor(1237329.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7647 lossL: tensor(1200856.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7648 lossL: tensor(1141460.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7649 lossL: tensor(1131351., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7650 lossL: tensor(1190936., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7651 lossL: tensor(1199363.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7652 lossL: tensor(1080822.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7653 lossL: tensor(1163490.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7654 lossL: tensor(1111694.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7655 lossL: tensor(1144794.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7656 lossL: tensor(1111341.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7657 lossL: tensor(1220207.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7658 lossL: tensor(1139773.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7659 lossL: tensor(1128389., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7660 lossL: tensor(1145997.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7661 lossL: tensor(1056291.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7662 lossL: tensor(1187626.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7663 lossL: tensor(995365.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7664 lossL: tensor(1042826.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7665 lossL: tensor(1033651.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7666 lossL: tensor(1107702.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7667 lossL: tensor(1054021.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7668 lossL: tensor(1056037., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7669 lossL: tensor(1113276., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7670 lossL: tensor(1076163.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7671 lossL: tensor(1061885., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7672 lossL: tensor(1075006.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7673 lossL: tensor(1074650.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7674 lossL: tensor(1188829.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7675 lossL: tensor(1136839., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7676 lossL: tensor(998218.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7677 lossL: tensor(1095832.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7678 lossL: tensor(1084459.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7679 lossL: tensor(1153916.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7680 lossL: tensor(1172067.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7681 lossL: tensor(1149902.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7682 lossL: tensor(1134749.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7683 lossL: tensor(1027586.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7684 lossL: tensor(1107294.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7685 lossL: tensor(1085462.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7686 lossL: tensor(1077754.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7687 lossL: tensor(1101233.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7688 lossL: tensor(1110393.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7689 lossL: tensor(1108502.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7690 lossL: tensor(1030485.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7691 lossL: tensor(1120298.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7692 lossL: tensor(1105255.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7693 lossL: tensor(1136980.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7694 lossL: tensor(1087788.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7695 lossL: tensor(1093289.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7696 lossL: tensor(1166560.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7697 lossL: tensor(1020424.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7698 lossL: tensor(1059989.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7699 lossL: tensor(1064574., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7700 lossL: tensor(1077047.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7701 lossL: tensor(1023159.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7702 lossL: tensor(1080677.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7703 lossL: tensor(1076643.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7704 lossL: tensor(957013.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7705 lossL: tensor(1112994., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7706 lossL: tensor(1053979.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7707 lossL: tensor(1052543.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7708 lossL: tensor(1077171.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7709 lossL: tensor(1064751.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7710 lossL: tensor(995919.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7711 lossL: tensor(1098626.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7712 lossL: tensor(1067489.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7713 lossL: tensor(1086096.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7714 lossL: tensor(1132859.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7715 lossL: tensor(1040342.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7716 lossL: tensor(1051248.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7717 lossL: tensor(1049556., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7718 lossL: tensor(1008921.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7719 lossL: tensor(1109471.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7720 lossL: tensor(1033078.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7721 lossL: tensor(990102.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7722 lossL: tensor(1002589.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7723 lossL: tensor(1067250.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7724 lossL: tensor(1075314.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7725 lossL: tensor(1083641.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7726 lossL: tensor(972703.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7727 lossL: tensor(1037868.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7728 lossL: tensor(1014422.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7729 lossL: tensor(977790.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7730 lossL: tensor(1075126., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7731 lossL: tensor(1017345.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7732 lossL: tensor(1023606.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7733 lossL: tensor(1047797.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7734 lossL: tensor(969866.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7735 lossL: tensor(1032112.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7736 lossL: tensor(954889.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7737 lossL: tensor(1083106.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7738 lossL: tensor(1017850.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7739 lossL: tensor(1050186.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7740 lossL: tensor(1067386.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7741 lossL: tensor(1075443.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7742 lossL: tensor(1038244.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7743 lossL: tensor(1050074.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7744 lossL: tensor(958007.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7745 lossL: tensor(1026711.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7746 lossL: tensor(1081906., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7747 lossL: tensor(1042526.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7748 lossL: tensor(1078847.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7749 lossL: tensor(1000199.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7750 lossL: tensor(1015063.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7751 lossL: tensor(1010881.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7752 lossL: tensor(955461.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7753 lossL: tensor(988461.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7754 lossL: tensor(989865.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7755 lossL: tensor(1054058.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7756 lossL: tensor(1014081.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7757 lossL: tensor(1036977.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7758 lossL: tensor(977071., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7759 lossL: tensor(990352., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7760 lossL: tensor(984502.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7761 lossL: tensor(1071550., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7762 lossL: tensor(1058684.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7763 lossL: tensor(979103.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7764 lossL: tensor(974841.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7765 lossL: tensor(938878.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7766 lossL: tensor(1013554.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7767 lossL: tensor(971449.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7768 lossL: tensor(999590.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7769 lossL: tensor(971853.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7770 lossL: tensor(972499.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7771 lossL: tensor(1071272., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7772 lossL: tensor(966898.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7773 lossL: tensor(1033876.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7774 lossL: tensor(1001453.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7775 lossL: tensor(1019778.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7776 lossL: tensor(977131.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7777 lossL: tensor(1058135.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7778 lossL: tensor(1074509.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7779 lossL: tensor(1115318.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7780 lossL: tensor(976384., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7781 lossL: tensor(975341.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7782 lossL: tensor(1020589.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7783 lossL: tensor(930615.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7784 lossL: tensor(999837.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7785 lossL: tensor(1011356.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7786 lossL: tensor(968674.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7787 lossL: tensor(954803.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7788 lossL: tensor(1009524.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7789 lossL: tensor(940848.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7790 lossL: tensor(964734.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7791 lossL: tensor(984511.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7792 lossL: tensor(983748.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7793 lossL: tensor(941579.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7794 lossL: tensor(1043812., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7795 lossL: tensor(941584.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7796 lossL: tensor(935432.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7797 lossL: tensor(999789.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7798 lossL: tensor(890250.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7799 lossL: tensor(948007.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7800 lossL: tensor(938997.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7801 lossL: tensor(1030623.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7802 lossL: tensor(946600.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7803 lossL: tensor(934646.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7804 lossL: tensor(1014496.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7805 lossL: tensor(957777.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7806 lossL: tensor(1022553.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7807 lossL: tensor(910793.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7808 lossL: tensor(939087.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7809 lossL: tensor(995791.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7810 lossL: tensor(919724.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7811 lossL: tensor(939399.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7812 lossL: tensor(1027223.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7813 lossL: tensor(988108.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7814 lossL: tensor(972702.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7815 lossL: tensor(892359.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7816 lossL: tensor(998262.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7817 lossL: tensor(989949.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7818 lossL: tensor(926035.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7819 lossL: tensor(1010627.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7820 lossL: tensor(1007215.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7821 lossL: tensor(929758.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7822 lossL: tensor(914600.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7823 lossL: tensor(863527.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7824 lossL: tensor(948080.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7825 lossL: tensor(970803.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7826 lossL: tensor(985692.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7827 lossL: tensor(957414., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7828 lossL: tensor(987436.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7829 lossL: tensor(920767.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7830 lossL: tensor(892416.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7831 lossL: tensor(884873., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7832 lossL: tensor(893349.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7833 lossL: tensor(909861., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7834 lossL: tensor(977688.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7835 lossL: tensor(914176.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7836 lossL: tensor(934982.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7837 lossL: tensor(880564.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7838 lossL: tensor(864633.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7839 lossL: tensor(945420., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7840 lossL: tensor(988535.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7841 lossL: tensor(850728.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7842 lossL: tensor(866743.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7843 lossL: tensor(967938., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7844 lossL: tensor(957954.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7845 lossL: tensor(951855.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7846 lossL: tensor(974875.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7847 lossL: tensor(899212.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7848 lossL: tensor(932612.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7849 lossL: tensor(904072.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7850 lossL: tensor(917088., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7851 lossL: tensor(960516.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7852 lossL: tensor(881481.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7853 lossL: tensor(916953.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7854 lossL: tensor(982614.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7855 lossL: tensor(971828.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7856 lossL: tensor(898020.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7857 lossL: tensor(971898.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7858 lossL: tensor(952205., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7859 lossL: tensor(974043.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7860 lossL: tensor(964999.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7861 lossL: tensor(976302.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7862 lossL: tensor(880249.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7863 lossL: tensor(960526.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7864 lossL: tensor(929575.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7865 lossL: tensor(925731.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7866 lossL: tensor(877111.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7867 lossL: tensor(883287.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7868 lossL: tensor(924173.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7869 lossL: tensor(892705.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7870 lossL: tensor(901020.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7871 lossL: tensor(852912.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7872 lossL: tensor(959125.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7873 lossL: tensor(905125.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7874 lossL: tensor(888030.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7875 lossL: tensor(872168.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7876 lossL: tensor(896905.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7877 lossL: tensor(906561.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7878 lossL: tensor(871073.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7879 lossL: tensor(921340.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7880 lossL: tensor(876702.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7881 lossL: tensor(949416.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7882 lossL: tensor(950521.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7883 lossL: tensor(866944.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7884 lossL: tensor(880530.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7885 lossL: tensor(952747.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7886 lossL: tensor(878551.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7887 lossL: tensor(923527.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7888 lossL: tensor(932308.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7889 lossL: tensor(943859.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7890 lossL: tensor(899094.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7891 lossL: tensor(944001.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7892 lossL: tensor(828009.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7893 lossL: tensor(905767.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7894 lossL: tensor(863096.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7895 lossL: tensor(819686.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7896 lossL: tensor(899264.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7897 lossL: tensor(908105.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7898 lossL: tensor(936268.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7899 lossL: tensor(922923.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7900 lossL: tensor(869753.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7901 lossL: tensor(800225., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7902 lossL: tensor(853403.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7903 lossL: tensor(821194.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7904 lossL: tensor(856799.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7905 lossL: tensor(802931.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7906 lossL: tensor(970683.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7907 lossL: tensor(889161., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7908 lossL: tensor(869759.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7909 lossL: tensor(847470.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7910 lossL: tensor(855279.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7911 lossL: tensor(816098.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7912 lossL: tensor(932542.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7913 lossL: tensor(836518.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7914 lossL: tensor(829233.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7915 lossL: tensor(856274.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7916 lossL: tensor(823675.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7917 lossL: tensor(881453.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7918 lossL: tensor(810833.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7919 lossL: tensor(822798.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7920 lossL: tensor(838457.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7921 lossL: tensor(820373.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7922 lossL: tensor(849378.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7923 lossL: tensor(897637.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7924 lossL: tensor(877607.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7925 lossL: tensor(809243.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7926 lossL: tensor(928663.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7927 lossL: tensor(808138.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7928 lossL: tensor(856506.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7929 lossL: tensor(878905.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7930 lossL: tensor(836547.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7931 lossL: tensor(868305.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7932 lossL: tensor(843258.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7933 lossL: tensor(868315.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7934 lossL: tensor(823087.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7935 lossL: tensor(872720.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7936 lossL: tensor(899417.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7937 lossL: tensor(876686., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7938 lossL: tensor(835660.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7939 lossL: tensor(838230.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7940 lossL: tensor(829597.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7941 lossL: tensor(930701.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7942 lossL: tensor(896897.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7943 lossL: tensor(797768.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7944 lossL: tensor(859894.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7945 lossL: tensor(837468.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7946 lossL: tensor(831150.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7947 lossL: tensor(778258.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7948 lossL: tensor(795219.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7949 lossL: tensor(816328.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7950 lossL: tensor(882998.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7951 lossL: tensor(766304.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7952 lossL: tensor(792691.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7953 lossL: tensor(784823.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7954 lossL: tensor(832388.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7955 lossL: tensor(815368.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7956 lossL: tensor(872456.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7957 lossL: tensor(831801.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7958 lossL: tensor(796678., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7959 lossL: tensor(795004.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7960 lossL: tensor(785323.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7961 lossL: tensor(891093.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7962 lossL: tensor(797586.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7963 lossL: tensor(827459.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7964 lossL: tensor(809587.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7965 lossL: tensor(804445.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7966 lossL: tensor(822414.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7967 lossL: tensor(818002.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7968 lossL: tensor(823121.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7969 lossL: tensor(875589.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7970 lossL: tensor(807052.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7971 lossL: tensor(835337.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7972 lossL: tensor(836048.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7973 lossL: tensor(767491.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7974 lossL: tensor(801959.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7975 lossL: tensor(866376.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7976 lossL: tensor(825622.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7977 lossL: tensor(846397.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7978 lossL: tensor(900979.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7979 lossL: tensor(766811.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7980 lossL: tensor(825505., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7981 lossL: tensor(754165.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "7982 lossL: tensor(764798., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7983 lossL: tensor(846942.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7984 lossL: tensor(799621.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7985 lossL: tensor(770064.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7986 lossL: tensor(762847.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7987 lossL: tensor(865687.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7988 lossL: tensor(812414.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7989 lossL: tensor(787738.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7990 lossL: tensor(848098.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7991 lossL: tensor(795572.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7992 lossL: tensor(759340.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7993 lossL: tensor(836644.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7994 lossL: tensor(805318.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7995 lossL: tensor(816592., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7996 lossL: tensor(819938.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7997 lossL: tensor(839889.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7998 lossL: tensor(775456.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "7999 lossL: tensor(825512.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8000 lossL: tensor(732406.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8001 lossL: tensor(782086.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8002 lossL: tensor(847394.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8003 lossL: tensor(866082.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8004 lossL: tensor(818443.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8005 lossL: tensor(790328.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8006 lossL: tensor(792681.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8007 lossL: tensor(829089.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8008 lossL: tensor(819768.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8009 lossL: tensor(834483.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8010 lossL: tensor(735953.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8011 lossL: tensor(783718.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8012 lossL: tensor(734258.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8013 lossL: tensor(762277.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8014 lossL: tensor(752358.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8015 lossL: tensor(779058., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8016 lossL: tensor(802909.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8017 lossL: tensor(748103.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8018 lossL: tensor(686584.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8019 lossL: tensor(776188.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8020 lossL: tensor(788451.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8021 lossL: tensor(760740.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8022 lossL: tensor(766919.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8023 lossL: tensor(772274.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8024 lossL: tensor(777401.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8025 lossL: tensor(835635.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8026 lossL: tensor(736029.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8027 lossL: tensor(725233.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8028 lossL: tensor(765692.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8029 lossL: tensor(822530.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8030 lossL: tensor(725904.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8031 lossL: tensor(834983.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8032 lossL: tensor(758222.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8033 lossL: tensor(740524.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8034 lossL: tensor(742072.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8035 lossL: tensor(757825.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8036 lossL: tensor(692020.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8037 lossL: tensor(736569.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8038 lossL: tensor(787474., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8039 lossL: tensor(808502.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8040 lossL: tensor(774019.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8041 lossL: tensor(739552.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8042 lossL: tensor(673141.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8043 lossL: tensor(760258.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8044 lossL: tensor(749409.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8045 lossL: tensor(741995.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8046 lossL: tensor(723058.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8047 lossL: tensor(753211., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8048 lossL: tensor(750260.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8049 lossL: tensor(771119.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8050 lossL: tensor(717845.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8051 lossL: tensor(763770.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8052 lossL: tensor(747189.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8053 lossL: tensor(749573.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8054 lossL: tensor(757862.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8055 lossL: tensor(704809.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8056 lossL: tensor(743141.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8057 lossL: tensor(753435., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8058 lossL: tensor(709487.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8059 lossL: tensor(677240.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8060 lossL: tensor(699211.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8061 lossL: tensor(671990.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8062 lossL: tensor(696253.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8063 lossL: tensor(817203.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8064 lossL: tensor(721301.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8065 lossL: tensor(720202.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8066 lossL: tensor(747352.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8067 lossL: tensor(670899.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8068 lossL: tensor(775386.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8069 lossL: tensor(788892.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8070 lossL: tensor(768516.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8071 lossL: tensor(709804.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8072 lossL: tensor(797642.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8073 lossL: tensor(714182.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8074 lossL: tensor(712001.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8075 lossL: tensor(716770.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8076 lossL: tensor(662151.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8077 lossL: tensor(732816.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8078 lossL: tensor(727381.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8079 lossL: tensor(742018.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8080 lossL: tensor(723153.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8081 lossL: tensor(729926.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8082 lossL: tensor(682357., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8083 lossL: tensor(754394.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8084 lossL: tensor(781763.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8085 lossL: tensor(706189.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8086 lossL: tensor(709385.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8087 lossL: tensor(731753.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8088 lossL: tensor(662954.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8089 lossL: tensor(663640.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8090 lossL: tensor(671748., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8091 lossL: tensor(690026.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8092 lossL: tensor(713428.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8093 lossL: tensor(741410.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8094 lossL: tensor(739919.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8095 lossL: tensor(734498.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8096 lossL: tensor(648840.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8097 lossL: tensor(675454.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8098 lossL: tensor(747375., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8099 lossL: tensor(781882.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8100 lossL: tensor(721476.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8101 lossL: tensor(714279.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8102 lossL: tensor(680179.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8103 lossL: tensor(731360.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8104 lossL: tensor(731402.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8105 lossL: tensor(700828.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8106 lossL: tensor(688443.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8107 lossL: tensor(645146.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8108 lossL: tensor(705966.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8109 lossL: tensor(758057., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8110 lossL: tensor(743782.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8111 lossL: tensor(708203., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8112 lossL: tensor(702262., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8113 lossL: tensor(758582., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8114 lossL: tensor(717720.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8115 lossL: tensor(718934.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8116 lossL: tensor(673463.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8117 lossL: tensor(699957.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8118 lossL: tensor(650013.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8119 lossL: tensor(685439.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8120 lossL: tensor(638812.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8121 lossL: tensor(738038.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8122 lossL: tensor(684220.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8123 lossL: tensor(750085.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8124 lossL: tensor(675974.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8125 lossL: tensor(752997.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8126 lossL: tensor(718246.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8127 lossL: tensor(693872.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8128 lossL: tensor(652630., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8129 lossL: tensor(670499.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8130 lossL: tensor(707496.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8131 lossL: tensor(624106.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8132 lossL: tensor(700549., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8133 lossL: tensor(689166.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8134 lossL: tensor(642685.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8135 lossL: tensor(699109.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8136 lossL: tensor(685250.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8137 lossL: tensor(750462.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8138 lossL: tensor(661572.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8139 lossL: tensor(692677.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8140 lossL: tensor(635412.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8141 lossL: tensor(796446.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8142 lossL: tensor(651358.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8143 lossL: tensor(723312.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8144 lossL: tensor(615516.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8145 lossL: tensor(706359.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8146 lossL: tensor(644369.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8147 lossL: tensor(704821.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8148 lossL: tensor(697181.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8149 lossL: tensor(701963.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8150 lossL: tensor(623200.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8151 lossL: tensor(595937.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8152 lossL: tensor(699182.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8153 lossL: tensor(607266.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8154 lossL: tensor(666893.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8155 lossL: tensor(631758.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8156 lossL: tensor(732858.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8157 lossL: tensor(645791.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8158 lossL: tensor(694508.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8159 lossL: tensor(683436., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8160 lossL: tensor(717678.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8161 lossL: tensor(717078.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8162 lossL: tensor(651361.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8163 lossL: tensor(678681., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8164 lossL: tensor(636589.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8165 lossL: tensor(635206.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8166 lossL: tensor(686325.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8167 lossL: tensor(623872.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8168 lossL: tensor(612419.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8169 lossL: tensor(673096.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8170 lossL: tensor(657685.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8171 lossL: tensor(680807.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8172 lossL: tensor(671569.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8173 lossL: tensor(594024.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8174 lossL: tensor(632383.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8175 lossL: tensor(620985.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8176 lossL: tensor(668326.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8177 lossL: tensor(734239.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8178 lossL: tensor(670961.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8179 lossL: tensor(628220.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8180 lossL: tensor(674355.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8181 lossL: tensor(602068.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8182 lossL: tensor(642919.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8183 lossL: tensor(658307.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8184 lossL: tensor(684726.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8185 lossL: tensor(672441.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8186 lossL: tensor(703806.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8187 lossL: tensor(651168.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8188 lossL: tensor(600678.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8189 lossL: tensor(640477.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8190 lossL: tensor(630589., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8191 lossL: tensor(618475.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8192 lossL: tensor(605208.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8193 lossL: tensor(666707.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8194 lossL: tensor(656073., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8195 lossL: tensor(582753.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8196 lossL: tensor(664743.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8197 lossL: tensor(602256.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8198 lossL: tensor(681631.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8199 lossL: tensor(613996.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8200 lossL: tensor(600432.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8201 lossL: tensor(625268.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8202 lossL: tensor(617784.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8203 lossL: tensor(670370.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8204 lossL: tensor(633020.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8205 lossL: tensor(660834.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8206 lossL: tensor(602722.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8207 lossL: tensor(678009.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8208 lossL: tensor(682209.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8209 lossL: tensor(646092.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8210 lossL: tensor(578621., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8211 lossL: tensor(722189.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8212 lossL: tensor(597760.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8213 lossL: tensor(586236.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8214 lossL: tensor(627409.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8215 lossL: tensor(669437.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8216 lossL: tensor(568598.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8217 lossL: tensor(567412.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8218 lossL: tensor(606990.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8219 lossL: tensor(649489.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8220 lossL: tensor(622850.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8221 lossL: tensor(583287.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8222 lossL: tensor(579973.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8223 lossL: tensor(629673., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8224 lossL: tensor(632612.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8225 lossL: tensor(559193., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8226 lossL: tensor(617706.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8227 lossL: tensor(632503.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8228 lossL: tensor(648390.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8229 lossL: tensor(546946.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8230 lossL: tensor(625104.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8231 lossL: tensor(639809.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8232 lossL: tensor(685114., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8233 lossL: tensor(604766.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8234 lossL: tensor(625496.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8235 lossL: tensor(591948.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8236 lossL: tensor(630800.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8237 lossL: tensor(582496.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8238 lossL: tensor(594336.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8239 lossL: tensor(615133.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8240 lossL: tensor(602600.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8241 lossL: tensor(640138.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8242 lossL: tensor(597715.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8243 lossL: tensor(574533.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8244 lossL: tensor(649897.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8245 lossL: tensor(583483.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8246 lossL: tensor(587951.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8247 lossL: tensor(583652.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8248 lossL: tensor(517819.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8249 lossL: tensor(584730.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8250 lossL: tensor(586780.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8251 lossL: tensor(594515.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8252 lossL: tensor(550175.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8253 lossL: tensor(631577.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8254 lossL: tensor(565559.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8255 lossL: tensor(624680.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8256 lossL: tensor(604254.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8257 lossL: tensor(607615.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8258 lossL: tensor(619780., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8259 lossL: tensor(630521.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8260 lossL: tensor(595496., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8261 lossL: tensor(600466.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8262 lossL: tensor(551119.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8263 lossL: tensor(602090.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8264 lossL: tensor(637029.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8265 lossL: tensor(507384.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8266 lossL: tensor(554981.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8267 lossL: tensor(547592.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8268 lossL: tensor(552757.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8269 lossL: tensor(572317.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8270 lossL: tensor(605187.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8271 lossL: tensor(571143.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8272 lossL: tensor(641605.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8273 lossL: tensor(588906.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8274 lossL: tensor(585071.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8275 lossL: tensor(565110.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8276 lossL: tensor(585553.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8277 lossL: tensor(567504.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8278 lossL: tensor(560519.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8279 lossL: tensor(627076.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8280 lossL: tensor(528786.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8281 lossL: tensor(616613.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8282 lossL: tensor(553349.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8283 lossL: tensor(575469.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8284 lossL: tensor(574770.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8285 lossL: tensor(619739.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8286 lossL: tensor(564893.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8287 lossL: tensor(636060.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8288 lossL: tensor(569021.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8289 lossL: tensor(570970.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8290 lossL: tensor(593184.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8291 lossL: tensor(572633.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8292 lossL: tensor(555277.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8293 lossL: tensor(567427.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8294 lossL: tensor(565159.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8295 lossL: tensor(569714.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8296 lossL: tensor(578227.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8297 lossL: tensor(578560.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8298 lossL: tensor(574515.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8299 lossL: tensor(530116.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8300 lossL: tensor(535776.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8301 lossL: tensor(590666.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8302 lossL: tensor(567061.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8303 lossL: tensor(556025.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8304 lossL: tensor(532282.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8305 lossL: tensor(535205.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8306 lossL: tensor(573088.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8307 lossL: tensor(536777.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8308 lossL: tensor(571429.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8309 lossL: tensor(581921.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8310 lossL: tensor(608520.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8311 lossL: tensor(577032.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8312 lossL: tensor(563824.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8313 lossL: tensor(570039., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8314 lossL: tensor(572334.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8315 lossL: tensor(517637.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8316 lossL: tensor(570263.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8317 lossL: tensor(539770.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8318 lossL: tensor(517078.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8319 lossL: tensor(548940.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8320 lossL: tensor(543308.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8321 lossL: tensor(492443.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8322 lossL: tensor(559130.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8323 lossL: tensor(529682.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8324 lossL: tensor(556800.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8325 lossL: tensor(502834.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8326 lossL: tensor(542209.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8327 lossL: tensor(530257.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8328 lossL: tensor(542162.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8329 lossL: tensor(494534.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8330 lossL: tensor(559554.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8331 lossL: tensor(551227.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8332 lossL: tensor(527481.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8333 lossL: tensor(535859.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8334 lossL: tensor(516205.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8335 lossL: tensor(631661.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8336 lossL: tensor(563230.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8337 lossL: tensor(573221., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8338 lossL: tensor(486809.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8339 lossL: tensor(534292.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8340 lossL: tensor(532759.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8341 lossL: tensor(560980.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8342 lossL: tensor(516607.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8343 lossL: tensor(567483.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8344 lossL: tensor(514928.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8345 lossL: tensor(529879.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8346 lossL: tensor(557561.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8347 lossL: tensor(553222.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8348 lossL: tensor(545600.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8349 lossL: tensor(553158.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8350 lossL: tensor(514559.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8351 lossL: tensor(522313.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8352 lossL: tensor(561820.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8353 lossL: tensor(563152.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8354 lossL: tensor(534498.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8355 lossL: tensor(526410.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8356 lossL: tensor(497214.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8357 lossL: tensor(510092.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8358 lossL: tensor(535338.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8359 lossL: tensor(523104.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8360 lossL: tensor(518139.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8361 lossL: tensor(497789.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8362 lossL: tensor(562090.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8363 lossL: tensor(496255.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8364 lossL: tensor(478730.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8365 lossL: tensor(508343.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8366 lossL: tensor(502683.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8367 lossL: tensor(535615.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8368 lossL: tensor(506880.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8369 lossL: tensor(493038.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8370 lossL: tensor(513951.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8371 lossL: tensor(496667.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8372 lossL: tensor(496365.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8373 lossL: tensor(572291.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8374 lossL: tensor(508589.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8375 lossL: tensor(542034.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8376 lossL: tensor(501425.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8377 lossL: tensor(514855.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8378 lossL: tensor(490599.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8379 lossL: tensor(546901.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8380 lossL: tensor(464689.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8381 lossL: tensor(472938.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8382 lossL: tensor(476631.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8383 lossL: tensor(481041.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8384 lossL: tensor(535704.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8385 lossL: tensor(518780.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8386 lossL: tensor(476113.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8387 lossL: tensor(506413.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8388 lossL: tensor(492086.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8389 lossL: tensor(484574.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8390 lossL: tensor(488793.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8391 lossL: tensor(472744.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8392 lossL: tensor(484948.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8393 lossL: tensor(525617.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8394 lossL: tensor(538205.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8395 lossL: tensor(490442.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8396 lossL: tensor(513523.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8397 lossL: tensor(537508.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8398 lossL: tensor(464517.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8399 lossL: tensor(483819.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8400 lossL: tensor(468992.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8401 lossL: tensor(491015.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8402 lossL: tensor(491810.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8403 lossL: tensor(514367.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8404 lossL: tensor(509437.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8405 lossL: tensor(479470.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8406 lossL: tensor(464886.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8407 lossL: tensor(524672.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8408 lossL: tensor(493792.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8409 lossL: tensor(471932.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8410 lossL: tensor(468359.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8411 lossL: tensor(482557.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8412 lossL: tensor(522538.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8413 lossL: tensor(524197.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8414 lossL: tensor(473849.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8415 lossL: tensor(453518.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8416 lossL: tensor(481492.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8417 lossL: tensor(483156.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8418 lossL: tensor(487357.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8419 lossL: tensor(489726.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8420 lossL: tensor(474491.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8421 lossL: tensor(497481.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8422 lossL: tensor(459117.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8423 lossL: tensor(482314.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8424 lossL: tensor(486987.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8425 lossL: tensor(498931.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8426 lossL: tensor(475875.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8427 lossL: tensor(487076.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8428 lossL: tensor(496641.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8429 lossL: tensor(496945.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8430 lossL: tensor(543568., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8431 lossL: tensor(496714.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8432 lossL: tensor(512588.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8433 lossL: tensor(466064.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8434 lossL: tensor(514559.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8435 lossL: tensor(495345.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8436 lossL: tensor(479443.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8437 lossL: tensor(525895.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8438 lossL: tensor(440213.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8439 lossL: tensor(479905.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8440 lossL: tensor(489385.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8441 lossL: tensor(453890.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8442 lossL: tensor(500096.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8443 lossL: tensor(491150.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8444 lossL: tensor(512581.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8445 lossL: tensor(445107.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8446 lossL: tensor(422483.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8447 lossL: tensor(473941.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8448 lossL: tensor(528681.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8449 lossL: tensor(458870.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8450 lossL: tensor(479426.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8451 lossL: tensor(425154.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8452 lossL: tensor(500559.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8453 lossL: tensor(470242.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8454 lossL: tensor(447956.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8455 lossL: tensor(443103.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8456 lossL: tensor(484572.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8457 lossL: tensor(452825.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8458 lossL: tensor(492071.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8459 lossL: tensor(427459.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8460 lossL: tensor(442044.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8461 lossL: tensor(466341.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8462 lossL: tensor(512941.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8463 lossL: tensor(447131.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8464 lossL: tensor(490052.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8465 lossL: tensor(492347.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8466 lossL: tensor(475190.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8467 lossL: tensor(462126.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8468 lossL: tensor(448992.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8469 lossL: tensor(423780.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8470 lossL: tensor(438099.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8471 lossL: tensor(450783.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8472 lossL: tensor(438813.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8473 lossL: tensor(501365.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8474 lossL: tensor(468271.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8475 lossL: tensor(443971.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8476 lossL: tensor(502688.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8477 lossL: tensor(477674.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8478 lossL: tensor(478231.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8479 lossL: tensor(490471.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8480 lossL: tensor(422631.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8481 lossL: tensor(427965.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8482 lossL: tensor(481640.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8483 lossL: tensor(425478.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8484 lossL: tensor(399140.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8485 lossL: tensor(440574.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8486 lossL: tensor(442024.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8487 lossL: tensor(431978.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8488 lossL: tensor(434471.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8489 lossL: tensor(391017.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8490 lossL: tensor(417010.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8491 lossL: tensor(477382.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8492 lossL: tensor(406025.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8493 lossL: tensor(450986.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8494 lossL: tensor(417383.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8495 lossL: tensor(440647.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8496 lossL: tensor(424393.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8497 lossL: tensor(421807.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8498 lossL: tensor(441371.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8499 lossL: tensor(437851.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8500 lossL: tensor(415906.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8501 lossL: tensor(432223.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8502 lossL: tensor(423566.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8503 lossL: tensor(397925.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8504 lossL: tensor(447064.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8505 lossL: tensor(441392.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8506 lossL: tensor(465962.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8507 lossL: tensor(447937.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8508 lossL: tensor(429550.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8509 lossL: tensor(429245.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8510 lossL: tensor(460159.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8511 lossL: tensor(416685.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8512 lossL: tensor(445203.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8513 lossL: tensor(431219.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8514 lossL: tensor(452996.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8515 lossL: tensor(434131.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8516 lossL: tensor(457775.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8517 lossL: tensor(422446.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8518 lossL: tensor(464647.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8519 lossL: tensor(408797.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8520 lossL: tensor(488150.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8521 lossL: tensor(368621.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8522 lossL: tensor(447719.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8523 lossL: tensor(425287.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8524 lossL: tensor(379070.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8525 lossL: tensor(425550.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8526 lossL: tensor(437288.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8527 lossL: tensor(441116.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8528 lossL: tensor(431122.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8529 lossL: tensor(413197.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8530 lossL: tensor(433220.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8531 lossL: tensor(408392.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8532 lossL: tensor(471673.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8533 lossL: tensor(449338.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8534 lossL: tensor(373146., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8535 lossL: tensor(449692.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8536 lossL: tensor(415921.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8537 lossL: tensor(392053.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8538 lossL: tensor(428905.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8539 lossL: tensor(401909.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8540 lossL: tensor(400090.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8541 lossL: tensor(422200.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8542 lossL: tensor(418901.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8543 lossL: tensor(449347.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8544 lossL: tensor(421164.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8545 lossL: tensor(405773.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8546 lossL: tensor(444994.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8547 lossL: tensor(424327.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8548 lossL: tensor(382394.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8549 lossL: tensor(410787.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8550 lossL: tensor(430169.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8551 lossL: tensor(423227.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8552 lossL: tensor(429266.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8553 lossL: tensor(393249.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8554 lossL: tensor(375171.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8555 lossL: tensor(472436.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8556 lossL: tensor(397436.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8557 lossL: tensor(405464.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8558 lossL: tensor(412055.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8559 lossL: tensor(439220.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8560 lossL: tensor(404529.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8561 lossL: tensor(433812.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8562 lossL: tensor(430410.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8563 lossL: tensor(431580.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8564 lossL: tensor(411281.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8565 lossL: tensor(420724., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8566 lossL: tensor(408027.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8567 lossL: tensor(403182.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8568 lossL: tensor(329252.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8569 lossL: tensor(405558., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8570 lossL: tensor(442678.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8571 lossL: tensor(392822.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8572 lossL: tensor(365540.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8573 lossL: tensor(416142.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8574 lossL: tensor(413658.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8575 lossL: tensor(419495.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8576 lossL: tensor(368599.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8577 lossL: tensor(359287.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8578 lossL: tensor(413690.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8579 lossL: tensor(445590.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8580 lossL: tensor(375063.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8581 lossL: tensor(418538.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8582 lossL: tensor(365102.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8583 lossL: tensor(401804.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8584 lossL: tensor(422317.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8585 lossL: tensor(438565.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8586 lossL: tensor(418654., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8587 lossL: tensor(427172.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8588 lossL: tensor(400015.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8589 lossL: tensor(364248.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8590 lossL: tensor(386394.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8591 lossL: tensor(396630.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8592 lossL: tensor(369176.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8593 lossL: tensor(368444.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8594 lossL: tensor(402624.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8595 lossL: tensor(375236.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8596 lossL: tensor(385101.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8597 lossL: tensor(428252.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8598 lossL: tensor(381909.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8599 lossL: tensor(391523.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8600 lossL: tensor(405631., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8601 lossL: tensor(387808.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8602 lossL: tensor(400774.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8603 lossL: tensor(383399.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8604 lossL: tensor(422385.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8605 lossL: tensor(417358.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8606 lossL: tensor(364528.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8607 lossL: tensor(375893.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8608 lossL: tensor(370638.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8609 lossL: tensor(368364.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8610 lossL: tensor(381452., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8611 lossL: tensor(393141.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8612 lossL: tensor(351056.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8613 lossL: tensor(363062.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8614 lossL: tensor(360919.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8615 lossL: tensor(357194.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8616 lossL: tensor(366399.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8617 lossL: tensor(382793.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8618 lossL: tensor(402259.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8619 lossL: tensor(398500.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8620 lossL: tensor(345809., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8621 lossL: tensor(403546.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8622 lossL: tensor(380140.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8623 lossL: tensor(357825.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8624 lossL: tensor(362154.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8625 lossL: tensor(361226.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8626 lossL: tensor(397113.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8627 lossL: tensor(371200.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8628 lossL: tensor(418939.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8629 lossL: tensor(414455.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8630 lossL: tensor(392948.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8631 lossL: tensor(385191.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8632 lossL: tensor(372866.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8633 lossL: tensor(360279.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8634 lossL: tensor(403433.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8635 lossL: tensor(336211.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8636 lossL: tensor(353601.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8637 lossL: tensor(379414.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8638 lossL: tensor(326990.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8639 lossL: tensor(386671.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8640 lossL: tensor(368483.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8641 lossL: tensor(376630.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8642 lossL: tensor(380618.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8643 lossL: tensor(381476.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8644 lossL: tensor(386823.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8645 lossL: tensor(363712.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8646 lossL: tensor(358433.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8647 lossL: tensor(382030.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8648 lossL: tensor(379785.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8649 lossL: tensor(401884.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8650 lossL: tensor(408337.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8651 lossL: tensor(384459.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8652 lossL: tensor(346279.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8653 lossL: tensor(406344.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8654 lossL: tensor(376990.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8655 lossL: tensor(394127.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8656 lossL: tensor(352782.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8657 lossL: tensor(378560.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8658 lossL: tensor(368404.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8659 lossL: tensor(346450.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8660 lossL: tensor(329649.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8661 lossL: tensor(349881.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8662 lossL: tensor(340739.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8663 lossL: tensor(389364.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8664 lossL: tensor(367827.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8665 lossL: tensor(379631.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8666 lossL: tensor(367574.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8667 lossL: tensor(391018.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8668 lossL: tensor(347635.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8669 lossL: tensor(358094.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8670 lossL: tensor(364639.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8671 lossL: tensor(373369.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8672 lossL: tensor(378626.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8673 lossL: tensor(325063.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8674 lossL: tensor(387594.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8675 lossL: tensor(379096.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8676 lossL: tensor(357465.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8677 lossL: tensor(317579.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8678 lossL: tensor(340325.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8679 lossL: tensor(334173.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8680 lossL: tensor(352006.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8681 lossL: tensor(362580.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8682 lossL: tensor(363756.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8683 lossL: tensor(319105.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8684 lossL: tensor(381506.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8685 lossL: tensor(346253.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8686 lossL: tensor(386135.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8687 lossL: tensor(329413.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8688 lossL: tensor(384251.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8689 lossL: tensor(320073.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8690 lossL: tensor(352133.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8691 lossL: tensor(391068.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8692 lossL: tensor(335543.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8693 lossL: tensor(376808.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8694 lossL: tensor(316912.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8695 lossL: tensor(347933.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8696 lossL: tensor(381628.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8697 lossL: tensor(308276.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8698 lossL: tensor(317862.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8699 lossL: tensor(331878.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8700 lossL: tensor(335344.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8701 lossL: tensor(344564.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8702 lossL: tensor(346080.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8703 lossL: tensor(360147.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8704 lossL: tensor(336233.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8705 lossL: tensor(362552.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8706 lossL: tensor(324043.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8707 lossL: tensor(337593.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8708 lossL: tensor(369976.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8709 lossL: tensor(326136.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8710 lossL: tensor(328811.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8711 lossL: tensor(368757.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8712 lossL: tensor(334678.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8713 lossL: tensor(338329.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8714 lossL: tensor(314313.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8715 lossL: tensor(345789.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8716 lossL: tensor(367016.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8717 lossL: tensor(343837.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8718 lossL: tensor(322593.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8719 lossL: tensor(365812.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8720 lossL: tensor(299532.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8721 lossL: tensor(384404.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8722 lossL: tensor(337826.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8723 lossL: tensor(313636.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8724 lossL: tensor(317390.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8725 lossL: tensor(309988.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8726 lossL: tensor(310290.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8727 lossL: tensor(331991.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8728 lossL: tensor(327405.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8729 lossL: tensor(324981.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8730 lossL: tensor(336048.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8731 lossL: tensor(324625.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8732 lossL: tensor(336248.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8733 lossL: tensor(331901.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8734 lossL: tensor(333376.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8735 lossL: tensor(349046.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8736 lossL: tensor(312425.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8737 lossL: tensor(329375., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8738 lossL: tensor(317386.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8739 lossL: tensor(323310.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8740 lossL: tensor(319917.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8741 lossL: tensor(315516.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8742 lossL: tensor(320844.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8743 lossL: tensor(314898.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8744 lossL: tensor(335973.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8745 lossL: tensor(304985.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8746 lossL: tensor(321838.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8747 lossL: tensor(283168.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8748 lossL: tensor(316188.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8749 lossL: tensor(292288.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8750 lossL: tensor(310449.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8751 lossL: tensor(343841.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8752 lossL: tensor(332632.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8753 lossL: tensor(322082.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8754 lossL: tensor(360755.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8755 lossL: tensor(308848.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8756 lossL: tensor(312919.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8757 lossL: tensor(325217.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8758 lossL: tensor(312840.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8759 lossL: tensor(355712.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8760 lossL: tensor(321214.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8761 lossL: tensor(279914.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8762 lossL: tensor(295685.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8763 lossL: tensor(290281.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8764 lossL: tensor(312791., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8765 lossL: tensor(351485.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8766 lossL: tensor(294191.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8767 lossL: tensor(320555.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8768 lossL: tensor(339340.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8769 lossL: tensor(277027.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8770 lossL: tensor(289695.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8771 lossL: tensor(293196.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8772 lossL: tensor(302617.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8773 lossL: tensor(291942.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8774 lossL: tensor(346948.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8775 lossL: tensor(275891.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8776 lossL: tensor(316494.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8777 lossL: tensor(296284.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8778 lossL: tensor(323201.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8779 lossL: tensor(301179.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8780 lossL: tensor(303355.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8781 lossL: tensor(332176.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8782 lossL: tensor(315106.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8783 lossL: tensor(306541.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8784 lossL: tensor(317314.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8785 lossL: tensor(299873.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8786 lossL: tensor(311243.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8787 lossL: tensor(299576.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8788 lossL: tensor(326743.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8789 lossL: tensor(317066.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8790 lossL: tensor(293893.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8791 lossL: tensor(308537.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8792 lossL: tensor(289683.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8793 lossL: tensor(284870.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8794 lossL: tensor(294842.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8795 lossL: tensor(288466.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8796 lossL: tensor(283842.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8797 lossL: tensor(287743.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8798 lossL: tensor(296878.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8799 lossL: tensor(298055.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8800 lossL: tensor(289436.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8801 lossL: tensor(296989.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8802 lossL: tensor(277195.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8803 lossL: tensor(291818.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8804 lossL: tensor(307561.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8805 lossL: tensor(306818.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8806 lossL: tensor(334853.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8807 lossL: tensor(294686.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8808 lossL: tensor(357680.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8809 lossL: tensor(273002.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8810 lossL: tensor(311073.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8811 lossL: tensor(297292.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8812 lossL: tensor(283996.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8813 lossL: tensor(294488., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8814 lossL: tensor(301478.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8815 lossL: tensor(299601.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8816 lossL: tensor(275225.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8817 lossL: tensor(289088.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8818 lossL: tensor(275782.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8819 lossL: tensor(279774.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8820 lossL: tensor(275599.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8821 lossL: tensor(279779.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8822 lossL: tensor(288750.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8823 lossL: tensor(293402.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8824 lossL: tensor(299043.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8825 lossL: tensor(281430.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8826 lossL: tensor(288265., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8827 lossL: tensor(308643.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8828 lossL: tensor(258910., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8829 lossL: tensor(271223.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8830 lossL: tensor(261464.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8831 lossL: tensor(297971.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8832 lossL: tensor(292715.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8833 lossL: tensor(308176.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8834 lossL: tensor(268200.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8835 lossL: tensor(286404.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8836 lossL: tensor(304944.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8837 lossL: tensor(293973.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8838 lossL: tensor(299832.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8839 lossL: tensor(291776.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8840 lossL: tensor(297056.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8841 lossL: tensor(300114.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8842 lossL: tensor(271309.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8843 lossL: tensor(276027.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8844 lossL: tensor(279048.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8845 lossL: tensor(282846.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8846 lossL: tensor(285569.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8847 lossL: tensor(269031.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8848 lossL: tensor(289607.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8849 lossL: tensor(263788.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8850 lossL: tensor(280800.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8851 lossL: tensor(288510.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8852 lossL: tensor(297796.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8853 lossL: tensor(304584.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8854 lossL: tensor(300118.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8855 lossL: tensor(296642.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8856 lossL: tensor(297513.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8857 lossL: tensor(284632.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8858 lossL: tensor(288747.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8859 lossL: tensor(286721.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8860 lossL: tensor(264201.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8861 lossL: tensor(291008.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8862 lossL: tensor(260152.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8863 lossL: tensor(314076.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8864 lossL: tensor(272182.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8865 lossL: tensor(274971.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8866 lossL: tensor(296514.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8867 lossL: tensor(262238.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8868 lossL: tensor(305287.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8869 lossL: tensor(293103.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8870 lossL: tensor(242398.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8871 lossL: tensor(242851.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8872 lossL: tensor(288672.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8873 lossL: tensor(305323.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8874 lossL: tensor(296757.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8875 lossL: tensor(291367.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8876 lossL: tensor(309786.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8877 lossL: tensor(295673.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8878 lossL: tensor(263048.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8879 lossL: tensor(262305.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8880 lossL: tensor(303093.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8881 lossL: tensor(256975.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8882 lossL: tensor(291418.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8883 lossL: tensor(261530.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8884 lossL: tensor(298048.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8885 lossL: tensor(291003.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8886 lossL: tensor(287040.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8887 lossL: tensor(263904.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8888 lossL: tensor(305878.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8889 lossL: tensor(305596.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8890 lossL: tensor(260780.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8891 lossL: tensor(257835.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8892 lossL: tensor(257106.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8893 lossL: tensor(271451.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8894 lossL: tensor(262056.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8895 lossL: tensor(274666.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8896 lossL: tensor(265420.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8897 lossL: tensor(254359.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8898 lossL: tensor(259605.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8899 lossL: tensor(293640.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8900 lossL: tensor(264014.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8901 lossL: tensor(256568.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8902 lossL: tensor(263387.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8903 lossL: tensor(266349.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8904 lossL: tensor(245604.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8905 lossL: tensor(246725.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8906 lossL: tensor(260815.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8907 lossL: tensor(263226.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8908 lossL: tensor(261619.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8909 lossL: tensor(255114.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8910 lossL: tensor(254522.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8911 lossL: tensor(251712.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8912 lossL: tensor(266897.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8913 lossL: tensor(272185.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8914 lossL: tensor(238864.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8915 lossL: tensor(261473.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8916 lossL: tensor(256042.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8917 lossL: tensor(238881.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8918 lossL: tensor(285090.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8919 lossL: tensor(273481.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8920 lossL: tensor(264653.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8921 lossL: tensor(266190.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8922 lossL: tensor(251296.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8923 lossL: tensor(249953.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8924 lossL: tensor(277740.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8925 lossL: tensor(266663.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8926 lossL: tensor(276592.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8927 lossL: tensor(236054.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8928 lossL: tensor(251657.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8929 lossL: tensor(255289.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8930 lossL: tensor(231846.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8931 lossL: tensor(274741.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8932 lossL: tensor(265235., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8933 lossL: tensor(265229.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8934 lossL: tensor(263269.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8935 lossL: tensor(249916.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8936 lossL: tensor(258634.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8937 lossL: tensor(272654.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8938 lossL: tensor(282846.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8939 lossL: tensor(272431.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8940 lossL: tensor(253047.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8941 lossL: tensor(249959.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8942 lossL: tensor(251602.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8943 lossL: tensor(232582.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8944 lossL: tensor(274364.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8945 lossL: tensor(244198.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8946 lossL: tensor(249239.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8947 lossL: tensor(272221.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8948 lossL: tensor(243778.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8949 lossL: tensor(221643.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8950 lossL: tensor(245107.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8951 lossL: tensor(266211.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8952 lossL: tensor(241343.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8953 lossL: tensor(277103.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8954 lossL: tensor(266331.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8955 lossL: tensor(242528.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8956 lossL: tensor(266343.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8957 lossL: tensor(265081.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8958 lossL: tensor(247362.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8959 lossL: tensor(222825.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8960 lossL: tensor(250504.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8961 lossL: tensor(250583.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8962 lossL: tensor(249242.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8963 lossL: tensor(241653.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8964 lossL: tensor(268952.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8965 lossL: tensor(248572.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8966 lossL: tensor(225239.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8967 lossL: tensor(224289.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8968 lossL: tensor(237503., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8969 lossL: tensor(224838.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8970 lossL: tensor(244445.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8971 lossL: tensor(234408.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8972 lossL: tensor(234127.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8973 lossL: tensor(260449.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8974 lossL: tensor(235244.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8975 lossL: tensor(250278.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8976 lossL: tensor(246862.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8977 lossL: tensor(219901.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8978 lossL: tensor(257278.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8979 lossL: tensor(249494.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8980 lossL: tensor(241888.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8981 lossL: tensor(248906.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8982 lossL: tensor(244148.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8983 lossL: tensor(243215.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8984 lossL: tensor(250347.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8985 lossL: tensor(224967.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8986 lossL: tensor(263727.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8987 lossL: tensor(251024.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8988 lossL: tensor(222278.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8989 lossL: tensor(237888.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8990 lossL: tensor(213134.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "8991 lossL: tensor(243321.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8992 lossL: tensor(219723.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8993 lossL: tensor(287199.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8994 lossL: tensor(243821.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8995 lossL: tensor(253398.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8996 lossL: tensor(235873.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8997 lossL: tensor(270591., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8998 lossL: tensor(255764.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "8999 lossL: tensor(231556.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9000 lossL: tensor(217543.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9001 lossL: tensor(253828.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9002 lossL: tensor(222827.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9003 lossL: tensor(218580.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9004 lossL: tensor(208008.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9005 lossL: tensor(242708.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9006 lossL: tensor(244753.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9007 lossL: tensor(234505.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9008 lossL: tensor(237751.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9009 lossL: tensor(221362.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9010 lossL: tensor(214812.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9011 lossL: tensor(225358.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9012 lossL: tensor(232571.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9013 lossL: tensor(228311.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9014 lossL: tensor(236558.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9015 lossL: tensor(220384.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9016 lossL: tensor(215628.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9017 lossL: tensor(218840.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9018 lossL: tensor(243416.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9019 lossL: tensor(239330.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9020 lossL: tensor(253611.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9021 lossL: tensor(246808.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9022 lossL: tensor(251391.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9023 lossL: tensor(246590.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9024 lossL: tensor(229518.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9025 lossL: tensor(226446.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9026 lossL: tensor(232332.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9027 lossL: tensor(226049.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9028 lossL: tensor(252262.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9029 lossL: tensor(222513.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9030 lossL: tensor(228320.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9031 lossL: tensor(217174.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9032 lossL: tensor(219866.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9033 lossL: tensor(219077.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9034 lossL: tensor(241369.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9035 lossL: tensor(207498.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9036 lossL: tensor(264946.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9037 lossL: tensor(244994.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9038 lossL: tensor(207449.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9039 lossL: tensor(211500.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9040 lossL: tensor(237373.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9041 lossL: tensor(201466.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9042 lossL: tensor(223953.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9043 lossL: tensor(249695.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9044 lossL: tensor(213910.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9045 lossL: tensor(223591.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9046 lossL: tensor(237903.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9047 lossL: tensor(231145.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9048 lossL: tensor(213767.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9049 lossL: tensor(192527.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9050 lossL: tensor(220211.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9051 lossL: tensor(226610.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9052 lossL: tensor(244622.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9053 lossL: tensor(228700.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9054 lossL: tensor(221431.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9055 lossL: tensor(247310.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9056 lossL: tensor(205967.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9057 lossL: tensor(206045.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9058 lossL: tensor(210399.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9059 lossL: tensor(219205.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9060 lossL: tensor(233143.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9061 lossL: tensor(234727.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9062 lossL: tensor(195959., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9063 lossL: tensor(217733.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9064 lossL: tensor(210296.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9065 lossL: tensor(227148.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9066 lossL: tensor(221511.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9067 lossL: tensor(203428.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9068 lossL: tensor(206736.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9069 lossL: tensor(190468.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9070 lossL: tensor(237083.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9071 lossL: tensor(201946.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9072 lossL: tensor(231163.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9073 lossL: tensor(203034.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9074 lossL: tensor(230902.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9075 lossL: tensor(195539.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9076 lossL: tensor(218536.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9077 lossL: tensor(216055.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9078 lossL: tensor(191253.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9079 lossL: tensor(220404.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9080 lossL: tensor(215090.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9081 lossL: tensor(200471.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9082 lossL: tensor(227250.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9083 lossL: tensor(200806.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9084 lossL: tensor(224229.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9085 lossL: tensor(213185.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9086 lossL: tensor(223676.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9087 lossL: tensor(224551.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9088 lossL: tensor(223883.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9089 lossL: tensor(221793.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9090 lossL: tensor(237351.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9091 lossL: tensor(209659.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9092 lossL: tensor(214809.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9093 lossL: tensor(226060.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9094 lossL: tensor(225873.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9095 lossL: tensor(215950.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9096 lossL: tensor(201239.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9097 lossL: tensor(221432.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9098 lossL: tensor(200935.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9099 lossL: tensor(241079.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9100 lossL: tensor(192263.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9101 lossL: tensor(197044.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9102 lossL: tensor(206626.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9103 lossL: tensor(196011.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9104 lossL: tensor(237562.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9105 lossL: tensor(195227.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9106 lossL: tensor(193476.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9107 lossL: tensor(214345.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9108 lossL: tensor(189667.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9109 lossL: tensor(209677.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9110 lossL: tensor(184509.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9111 lossL: tensor(197877.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9112 lossL: tensor(206509.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9113 lossL: tensor(219124.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9114 lossL: tensor(210601.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9115 lossL: tensor(200611.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9116 lossL: tensor(221613.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9117 lossL: tensor(205388.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9118 lossL: tensor(203934.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9119 lossL: tensor(203418.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9120 lossL: tensor(216062.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9121 lossL: tensor(201937.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9122 lossL: tensor(196115.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9123 lossL: tensor(192072.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9124 lossL: tensor(227992.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9125 lossL: tensor(219893.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9126 lossL: tensor(206199.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9127 lossL: tensor(215474.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9128 lossL: tensor(223940.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9129 lossL: tensor(224359.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9130 lossL: tensor(189259.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9131 lossL: tensor(208473.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9132 lossL: tensor(184028.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9133 lossL: tensor(227687.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9134 lossL: tensor(220318.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9135 lossL: tensor(190718.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9136 lossL: tensor(202210.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9137 lossL: tensor(182424.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9138 lossL: tensor(210704.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9139 lossL: tensor(185888.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9140 lossL: tensor(186058.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9141 lossL: tensor(195947.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9142 lossL: tensor(207383.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9143 lossL: tensor(211827.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9144 lossL: tensor(211742.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9145 lossL: tensor(195851.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9146 lossL: tensor(210033.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9147 lossL: tensor(225047.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9148 lossL: tensor(191068.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9149 lossL: tensor(194328.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9150 lossL: tensor(184634.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9151 lossL: tensor(187139.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9152 lossL: tensor(196309.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9153 lossL: tensor(183698.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9154 lossL: tensor(180751.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9155 lossL: tensor(196834.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9156 lossL: tensor(177753., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9157 lossL: tensor(193278.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9158 lossL: tensor(200198.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9159 lossL: tensor(196716.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9160 lossL: tensor(210973.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9161 lossL: tensor(190362.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9162 lossL: tensor(174254.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9163 lossL: tensor(190397.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9164 lossL: tensor(186245.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9165 lossL: tensor(198809.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9166 lossL: tensor(188911.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9167 lossL: tensor(182319.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9168 lossL: tensor(157904.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9169 lossL: tensor(206673.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9170 lossL: tensor(181883.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9171 lossL: tensor(177403.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9172 lossL: tensor(197173.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9173 lossL: tensor(204629.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9174 lossL: tensor(179766.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9175 lossL: tensor(172944.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9176 lossL: tensor(206585.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9177 lossL: tensor(175603.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9178 lossL: tensor(181189.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9179 lossL: tensor(180284.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9180 lossL: tensor(186007.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9181 lossL: tensor(189996.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9182 lossL: tensor(196165.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9183 lossL: tensor(188387.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9184 lossL: tensor(198385.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9185 lossL: tensor(176360.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9186 lossL: tensor(182677.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9187 lossL: tensor(194840.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9188 lossL: tensor(177939.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9189 lossL: tensor(178251.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9190 lossL: tensor(202938.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9191 lossL: tensor(187596.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9192 lossL: tensor(167276.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9193 lossL: tensor(161987.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9194 lossL: tensor(196756.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9195 lossL: tensor(191359.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9196 lossL: tensor(207793.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9197 lossL: tensor(181070.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9198 lossL: tensor(182060.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9199 lossL: tensor(178497.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9200 lossL: tensor(187114.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9201 lossL: tensor(165124.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9202 lossL: tensor(190712.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9203 lossL: tensor(173460.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9204 lossL: tensor(172368.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9205 lossL: tensor(172251.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9206 lossL: tensor(206147.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9207 lossL: tensor(182898.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9208 lossL: tensor(167501.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9209 lossL: tensor(182373.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9210 lossL: tensor(192879.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9211 lossL: tensor(174892.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9212 lossL: tensor(164785.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9213 lossL: tensor(170068.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9214 lossL: tensor(184358.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9215 lossL: tensor(175693.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9216 lossL: tensor(178550.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9217 lossL: tensor(153160.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9218 lossL: tensor(197782.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9219 lossL: tensor(174363.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9220 lossL: tensor(172953.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9221 lossL: tensor(175817.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9222 lossL: tensor(190751.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9223 lossL: tensor(184879.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9224 lossL: tensor(194224.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9225 lossL: tensor(178430.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9226 lossL: tensor(169394.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9227 lossL: tensor(184151.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9228 lossL: tensor(188436.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9229 lossL: tensor(163165.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9230 lossL: tensor(171495.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9231 lossL: tensor(169359.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9232 lossL: tensor(168265.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9233 lossL: tensor(172248.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9234 lossL: tensor(177077., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9235 lossL: tensor(179856.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9236 lossL: tensor(191667.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9237 lossL: tensor(168999.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9238 lossL: tensor(193884.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9239 lossL: tensor(183813.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9240 lossL: tensor(179016.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9241 lossL: tensor(186434.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9242 lossL: tensor(175960.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9243 lossL: tensor(160754.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9244 lossL: tensor(165767.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9245 lossL: tensor(183837.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9246 lossL: tensor(153082.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9247 lossL: tensor(164217.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9248 lossL: tensor(196898.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9249 lossL: tensor(164570.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9250 lossL: tensor(163932.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9251 lossL: tensor(154892.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9252 lossL: tensor(152094.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9253 lossL: tensor(175220.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9254 lossL: tensor(167017.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9255 lossL: tensor(182051.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9256 lossL: tensor(193088.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9257 lossL: tensor(205919.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9258 lossL: tensor(171163.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9259 lossL: tensor(161000.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9260 lossL: tensor(168796.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9261 lossL: tensor(187426.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9262 lossL: tensor(197227.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9263 lossL: tensor(150153.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9264 lossL: tensor(169616.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9265 lossL: tensor(167092.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9266 lossL: tensor(145843.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9267 lossL: tensor(145843.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9268 lossL: tensor(188065.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9269 lossL: tensor(194233.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9270 lossL: tensor(172821.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9271 lossL: tensor(174510.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9272 lossL: tensor(179665.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9273 lossL: tensor(167701.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9274 lossL: tensor(179830.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9275 lossL: tensor(178925.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9276 lossL: tensor(169502.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9277 lossL: tensor(179036.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9278 lossL: tensor(178936.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9279 lossL: tensor(174762.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9280 lossL: tensor(164634.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9281 lossL: tensor(171691.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9282 lossL: tensor(152043.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9283 lossL: tensor(163417.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9284 lossL: tensor(177162.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9285 lossL: tensor(169929.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9286 lossL: tensor(175893.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9287 lossL: tensor(180041.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9288 lossL: tensor(145763., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9289 lossL: tensor(157270.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9290 lossL: tensor(177522.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9291 lossL: tensor(156169.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9292 lossL: tensor(218159.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9293 lossL: tensor(164741.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9294 lossL: tensor(138112.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9295 lossL: tensor(164133.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9296 lossL: tensor(166631.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9297 lossL: tensor(160988.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9298 lossL: tensor(169930.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9299 lossL: tensor(164157.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9300 lossL: tensor(159393., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9301 lossL: tensor(168711.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9302 lossL: tensor(152977.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9303 lossL: tensor(144874.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9304 lossL: tensor(169695.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9305 lossL: tensor(165095.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9306 lossL: tensor(144898.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9307 lossL: tensor(158892.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9308 lossL: tensor(151424.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9309 lossL: tensor(170574.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9310 lossL: tensor(156401.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9311 lossL: tensor(165253.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9312 lossL: tensor(157404.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9313 lossL: tensor(158811.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9314 lossL: tensor(147515.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9315 lossL: tensor(156815.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9316 lossL: tensor(163662.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9317 lossL: tensor(150674.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9318 lossL: tensor(155125.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9319 lossL: tensor(153874.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9320 lossL: tensor(164798.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9321 lossL: tensor(153818.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9322 lossL: tensor(154240.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9323 lossL: tensor(185573.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9324 lossL: tensor(155527.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9325 lossL: tensor(184178.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9326 lossL: tensor(181682.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9327 lossL: tensor(165622.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9328 lossL: tensor(158025.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9329 lossL: tensor(131057.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9330 lossL: tensor(155300.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9331 lossL: tensor(158530.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9332 lossL: tensor(129106.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9333 lossL: tensor(161446.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9334 lossL: tensor(156317.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9335 lossL: tensor(164847.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9336 lossL: tensor(164706.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9337 lossL: tensor(173603.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9338 lossL: tensor(161748.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9339 lossL: tensor(156240.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9340 lossL: tensor(173655.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9341 lossL: tensor(153351.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9342 lossL: tensor(139330.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9343 lossL: tensor(166533.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9344 lossL: tensor(157665.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9345 lossL: tensor(169347.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9346 lossL: tensor(149085.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9347 lossL: tensor(150407.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9348 lossL: tensor(155141.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9349 lossL: tensor(167964.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9350 lossL: tensor(156872.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9351 lossL: tensor(142949.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9352 lossL: tensor(135430.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9353 lossL: tensor(143046.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9354 lossL: tensor(161568.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9355 lossL: tensor(148392.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9356 lossL: tensor(149644.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9357 lossL: tensor(165440.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9358 lossL: tensor(146862.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9359 lossL: tensor(141142.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9360 lossL: tensor(164099.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9361 lossL: tensor(153148.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9362 lossL: tensor(147661.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9363 lossL: tensor(163292.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9364 lossL: tensor(149996.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9365 lossL: tensor(146656.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9366 lossL: tensor(148340.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9367 lossL: tensor(151770.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9368 lossL: tensor(158894.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9369 lossL: tensor(142589.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9370 lossL: tensor(148060.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9371 lossL: tensor(140598.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9372 lossL: tensor(158958.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9373 lossL: tensor(148950.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9374 lossL: tensor(179624.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9375 lossL: tensor(146197.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9376 lossL: tensor(161842.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9377 lossL: tensor(145463.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9378 lossL: tensor(128764.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9379 lossL: tensor(137380.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9380 lossL: tensor(150668.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9381 lossL: tensor(148652.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9382 lossL: tensor(138393.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9383 lossL: tensor(137185.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9384 lossL: tensor(156913.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9385 lossL: tensor(156825.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9386 lossL: tensor(136263.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9387 lossL: tensor(127744.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9388 lossL: tensor(130528.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9389 lossL: tensor(134226.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9390 lossL: tensor(166304.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9391 lossL: tensor(185557.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9392 lossL: tensor(126430.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9393 lossL: tensor(172565.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9394 lossL: tensor(145758.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9395 lossL: tensor(140368.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9396 lossL: tensor(124396.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9397 lossL: tensor(142576.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9398 lossL: tensor(158880.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9399 lossL: tensor(147961.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9400 lossL: tensor(135388.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9401 lossL: tensor(151071.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9402 lossL: tensor(146825.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9403 lossL: tensor(147787.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9404 lossL: tensor(143516.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9405 lossL: tensor(129916.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9406 lossL: tensor(137961.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9407 lossL: tensor(160319.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9408 lossL: tensor(156598.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9409 lossL: tensor(136218.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9410 lossL: tensor(160272.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9411 lossL: tensor(153109.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9412 lossL: tensor(138755.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9413 lossL: tensor(168427.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9414 lossL: tensor(142368.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9415 lossL: tensor(147147.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9416 lossL: tensor(136701.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9417 lossL: tensor(136122.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9418 lossL: tensor(139859.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9419 lossL: tensor(126158.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9420 lossL: tensor(142132.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9421 lossL: tensor(136177.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9422 lossL: tensor(136980.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9423 lossL: tensor(127561.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9424 lossL: tensor(137985.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9425 lossL: tensor(145034.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9426 lossL: tensor(159323.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9427 lossL: tensor(140604.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9428 lossL: tensor(149378.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9429 lossL: tensor(135210.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9430 lossL: tensor(148566.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9431 lossL: tensor(154376.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9432 lossL: tensor(135809.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9433 lossL: tensor(138000.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9434 lossL: tensor(134705.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9435 lossL: tensor(143111.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9436 lossL: tensor(144524.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9437 lossL: tensor(133879.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9438 lossL: tensor(131696.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9439 lossL: tensor(127992.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9440 lossL: tensor(143011.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9441 lossL: tensor(141895.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9442 lossL: tensor(144161.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9443 lossL: tensor(161928.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9444 lossL: tensor(142548.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9445 lossL: tensor(141387.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9446 lossL: tensor(136264.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9447 lossL: tensor(137176.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9448 lossL: tensor(138251., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9449 lossL: tensor(110596.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9450 lossL: tensor(140930.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9451 lossL: tensor(135797.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9452 lossL: tensor(148188.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9453 lossL: tensor(136044.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9454 lossL: tensor(136367.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9455 lossL: tensor(135648.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9456 lossL: tensor(137521.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9457 lossL: tensor(131313.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9458 lossL: tensor(132430.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9459 lossL: tensor(127372.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9460 lossL: tensor(139489.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9461 lossL: tensor(119037.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9462 lossL: tensor(130248.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9463 lossL: tensor(121052.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9464 lossL: tensor(133098.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9465 lossL: tensor(136552.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9466 lossL: tensor(147128.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9467 lossL: tensor(130999.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9468 lossL: tensor(132029.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9469 lossL: tensor(119898.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9470 lossL: tensor(125888.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9471 lossL: tensor(136186.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9472 lossL: tensor(142562.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9473 lossL: tensor(126988.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9474 lossL: tensor(118483.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9475 lossL: tensor(134382.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9476 lossL: tensor(125213.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9477 lossL: tensor(127003.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9478 lossL: tensor(128404.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9479 lossL: tensor(132063.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9480 lossL: tensor(132658.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9481 lossL: tensor(138891.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9482 lossL: tensor(135957.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9483 lossL: tensor(144913.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9484 lossL: tensor(158571.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9485 lossL: tensor(148367.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9486 lossL: tensor(142745.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9487 lossL: tensor(129376.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9488 lossL: tensor(137587.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9489 lossL: tensor(130645.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9490 lossL: tensor(134565.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9491 lossL: tensor(121218.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9492 lossL: tensor(119104.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9493 lossL: tensor(134643.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9494 lossL: tensor(121568.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9495 lossL: tensor(132983.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9496 lossL: tensor(141025.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9497 lossL: tensor(151626.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9498 lossL: tensor(127444.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9499 lossL: tensor(130768.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9500 lossL: tensor(148172.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9501 lossL: tensor(127223.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9502 lossL: tensor(130066.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9503 lossL: tensor(121515.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9504 lossL: tensor(124628.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9505 lossL: tensor(124029.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9506 lossL: tensor(133159., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9507 lossL: tensor(126323.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9508 lossL: tensor(138000.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9509 lossL: tensor(132211.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9510 lossL: tensor(127691.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9511 lossL: tensor(140607.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9512 lossL: tensor(129553.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9513 lossL: tensor(128699.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9514 lossL: tensor(140736.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9515 lossL: tensor(125543.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9516 lossL: tensor(133129.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9517 lossL: tensor(145566.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9518 lossL: tensor(120639.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9519 lossL: tensor(105183.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9520 lossL: tensor(121804.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9521 lossL: tensor(142838.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9522 lossL: tensor(129818.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9523 lossL: tensor(114102.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9524 lossL: tensor(139174.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9525 lossL: tensor(122512.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9526 lossL: tensor(111443.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9527 lossL: tensor(121131.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9528 lossL: tensor(120020.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9529 lossL: tensor(136457.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9530 lossL: tensor(129722.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9531 lossL: tensor(131498.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9532 lossL: tensor(119685.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9533 lossL: tensor(121575.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9534 lossL: tensor(127736.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9535 lossL: tensor(128453.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9536 lossL: tensor(133121.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9537 lossL: tensor(119528.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9538 lossL: tensor(118482.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9539 lossL: tensor(163901.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9540 lossL: tensor(123453.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9541 lossL: tensor(126377.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9542 lossL: tensor(136143.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9543 lossL: tensor(123813.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9544 lossL: tensor(125680.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9545 lossL: tensor(127330.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9546 lossL: tensor(123387.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9547 lossL: tensor(120506.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9548 lossL: tensor(127757.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9549 lossL: tensor(127491.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9550 lossL: tensor(133995.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9551 lossL: tensor(116997.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9552 lossL: tensor(125675.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9553 lossL: tensor(144148.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9554 lossL: tensor(123855.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9555 lossL: tensor(128871.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9556 lossL: tensor(115661.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9557 lossL: tensor(109882.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9558 lossL: tensor(110399.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9559 lossL: tensor(124778.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9560 lossL: tensor(115737.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9561 lossL: tensor(111021.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9562 lossL: tensor(119509.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9563 lossL: tensor(125737.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9564 lossL: tensor(117935.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9565 lossL: tensor(106954.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9566 lossL: tensor(129951.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9567 lossL: tensor(120921.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9568 lossL: tensor(136993.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9569 lossL: tensor(107899.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9570 lossL: tensor(127337.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9571 lossL: tensor(119364.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9572 lossL: tensor(119785.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9573 lossL: tensor(109836.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9574 lossL: tensor(129300.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9575 lossL: tensor(125690.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9576 lossL: tensor(122852.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9577 lossL: tensor(130957.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9578 lossL: tensor(115418.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9579 lossL: tensor(120014.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9580 lossL: tensor(123810.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9581 lossL: tensor(112521.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9582 lossL: tensor(116820.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9583 lossL: tensor(93799.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9584 lossL: tensor(116966.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9585 lossL: tensor(114346.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9586 lossL: tensor(104302.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9587 lossL: tensor(122586.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9588 lossL: tensor(117141.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9589 lossL: tensor(117953.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9590 lossL: tensor(133564.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9591 lossL: tensor(127044.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9592 lossL: tensor(112739.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9593 lossL: tensor(124913.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9594 lossL: tensor(114478.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9595 lossL: tensor(120720.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9596 lossL: tensor(115803.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9597 lossL: tensor(124124.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9598 lossL: tensor(100224.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9599 lossL: tensor(108311.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9600 lossL: tensor(119240.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9601 lossL: tensor(110559.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9602 lossL: tensor(131685.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9603 lossL: tensor(125307.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9604 lossL: tensor(120242.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9605 lossL: tensor(114937.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9606 lossL: tensor(121395.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9607 lossL: tensor(119976.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9608 lossL: tensor(103428.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9609 lossL: tensor(114503.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9610 lossL: tensor(113998.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9611 lossL: tensor(122181.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9612 lossL: tensor(118254.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9613 lossL: tensor(114680.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9614 lossL: tensor(108530.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9615 lossL: tensor(103287.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9616 lossL: tensor(118713.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9617 lossL: tensor(106259.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9618 lossL: tensor(112270.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9619 lossL: tensor(126006.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9620 lossL: tensor(119792.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9621 lossL: tensor(126925.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9622 lossL: tensor(99828.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9623 lossL: tensor(131885.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9624 lossL: tensor(131166.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9625 lossL: tensor(122463.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9626 lossL: tensor(115112.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9627 lossL: tensor(102225.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9628 lossL: tensor(107883.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9629 lossL: tensor(135871.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9630 lossL: tensor(108611.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9631 lossL: tensor(108808.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9632 lossL: tensor(109170.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9633 lossL: tensor(112302.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9634 lossL: tensor(114870.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9635 lossL: tensor(114601.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9636 lossL: tensor(104223.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9637 lossL: tensor(118309.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9638 lossL: tensor(96597.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9639 lossL: tensor(117753.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9640 lossL: tensor(107768.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9641 lossL: tensor(130621.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9642 lossL: tensor(105175.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9643 lossL: tensor(111338.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9644 lossL: tensor(115208.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9645 lossL: tensor(117040.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9646 lossL: tensor(116274.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9647 lossL: tensor(128607.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9648 lossL: tensor(98959.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9649 lossL: tensor(108588.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9650 lossL: tensor(115900.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9651 lossL: tensor(130931.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9652 lossL: tensor(101621.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9653 lossL: tensor(101633.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9654 lossL: tensor(98907.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9655 lossL: tensor(110636.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9656 lossL: tensor(98930.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9657 lossL: tensor(109072.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9658 lossL: tensor(111379.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9659 lossL: tensor(99133.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9660 lossL: tensor(114259.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9661 lossL: tensor(121151.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9662 lossL: tensor(106376.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9663 lossL: tensor(121027.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9664 lossL: tensor(114409.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9665 lossL: tensor(113247.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9666 lossL: tensor(107362.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9667 lossL: tensor(102542.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9668 lossL: tensor(108723.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9669 lossL: tensor(109403.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9670 lossL: tensor(99203.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9671 lossL: tensor(107340.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9672 lossL: tensor(104451.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9673 lossL: tensor(98982.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9674 lossL: tensor(108409.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9675 lossL: tensor(122137.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9676 lossL: tensor(99336.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9677 lossL: tensor(110211.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9678 lossL: tensor(103243.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9679 lossL: tensor(116381.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9680 lossL: tensor(93537.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9681 lossL: tensor(105243.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9682 lossL: tensor(104179.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9683 lossL: tensor(108644.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9684 lossL: tensor(90847.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9685 lossL: tensor(108830.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9686 lossL: tensor(103815., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9687 lossL: tensor(97064.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9688 lossL: tensor(124526.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9689 lossL: tensor(108228.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9690 lossL: tensor(108481.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9691 lossL: tensor(113908.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9692 lossL: tensor(110698.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9693 lossL: tensor(92712.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9694 lossL: tensor(98404.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9695 lossL: tensor(103119.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9696 lossL: tensor(110556.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9697 lossL: tensor(91504.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9698 lossL: tensor(102783.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9699 lossL: tensor(101728.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9700 lossL: tensor(106022.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9701 lossL: tensor(107252.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9702 lossL: tensor(129644.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9703 lossL: tensor(119706.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9704 lossL: tensor(106798.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9705 lossL: tensor(113450.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9706 lossL: tensor(99964.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9707 lossL: tensor(99647.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9708 lossL: tensor(101107.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9709 lossL: tensor(111318.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9710 lossL: tensor(94432.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9711 lossL: tensor(100921.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9712 lossL: tensor(110477.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9713 lossL: tensor(110850.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9714 lossL: tensor(104504.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9715 lossL: tensor(97719.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9716 lossL: tensor(105276.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9717 lossL: tensor(96435.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9718 lossL: tensor(92778.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9719 lossL: tensor(112930.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9720 lossL: tensor(103186.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9721 lossL: tensor(93507.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9722 lossL: tensor(94170.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9723 lossL: tensor(105501.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9724 lossL: tensor(87632.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9725 lossL: tensor(89066.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9726 lossL: tensor(101287.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9727 lossL: tensor(119307.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9728 lossL: tensor(101146.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9729 lossL: tensor(103249.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9730 lossL: tensor(105324.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9731 lossL: tensor(105042.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9732 lossL: tensor(94669.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9733 lossL: tensor(108490.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9734 lossL: tensor(110313.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9735 lossL: tensor(104432.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9736 lossL: tensor(97602.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9737 lossL: tensor(102898.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9738 lossL: tensor(92532.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9739 lossL: tensor(94469.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9740 lossL: tensor(105920.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9741 lossL: tensor(100156.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9742 lossL: tensor(111118.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9743 lossL: tensor(86031.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9744 lossL: tensor(96695.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9745 lossL: tensor(97883.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9746 lossL: tensor(100686.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9747 lossL: tensor(94141.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9748 lossL: tensor(93276.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9749 lossL: tensor(102085.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9750 lossL: tensor(95123.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9751 lossL: tensor(114875.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9752 lossL: tensor(119264.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9753 lossL: tensor(106657.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9754 lossL: tensor(108706.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9755 lossL: tensor(96892.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9756 lossL: tensor(112576.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9757 lossL: tensor(87900.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9758 lossL: tensor(98344.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9759 lossL: tensor(91735.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9760 lossL: tensor(95169.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9761 lossL: tensor(96417.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9762 lossL: tensor(99847.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9763 lossL: tensor(95764.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9764 lossL: tensor(112160.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9765 lossL: tensor(98628.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9766 lossL: tensor(91532.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9767 lossL: tensor(89668.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9768 lossL: tensor(72758.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9769 lossL: tensor(105463.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9770 lossL: tensor(101199.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9771 lossL: tensor(102839.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9772 lossL: tensor(97832.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9773 lossL: tensor(116873.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9774 lossL: tensor(87840.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9775 lossL: tensor(92108.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9776 lossL: tensor(114584.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9777 lossL: tensor(89018.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9778 lossL: tensor(93456.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9779 lossL: tensor(98436.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9780 lossL: tensor(88971.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9781 lossL: tensor(95290.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9782 lossL: tensor(96776.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9783 lossL: tensor(90017.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9784 lossL: tensor(94827.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9785 lossL: tensor(96346.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9786 lossL: tensor(86905.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9787 lossL: tensor(99326.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9788 lossL: tensor(71415.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9789 lossL: tensor(90582.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9790 lossL: tensor(100827.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9791 lossL: tensor(101936.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9792 lossL: tensor(100598.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9793 lossL: tensor(89092.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9794 lossL: tensor(98926.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9795 lossL: tensor(97391.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9796 lossL: tensor(88939.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9797 lossL: tensor(97347.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9798 lossL: tensor(84080.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9799 lossL: tensor(94583.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9800 lossL: tensor(89608., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9801 lossL: tensor(88756.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9802 lossL: tensor(102101.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9803 lossL: tensor(105147.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9804 lossL: tensor(84938.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9805 lossL: tensor(83761.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9806 lossL: tensor(96163.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9807 lossL: tensor(86064.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9808 lossL: tensor(94100.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9809 lossL: tensor(110495.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9810 lossL: tensor(93498.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9811 lossL: tensor(87665.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9812 lossL: tensor(99414.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9813 lossL: tensor(86196.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9814 lossL: tensor(79038.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9815 lossL: tensor(98705.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9816 lossL: tensor(101572.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9817 lossL: tensor(106368.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9818 lossL: tensor(92039.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9819 lossL: tensor(88803.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9820 lossL: tensor(103928.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9821 lossL: tensor(101681.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9822 lossL: tensor(93025.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9823 lossL: tensor(92555.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9824 lossL: tensor(94800.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9825 lossL: tensor(89788.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9826 lossL: tensor(85804.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9827 lossL: tensor(61629.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "9828 lossL: tensor(97337.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9829 lossL: tensor(81474.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9830 lossL: tensor(87021.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9831 lossL: tensor(98713.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9832 lossL: tensor(91640.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9833 lossL: tensor(85742.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9834 lossL: tensor(90809.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9835 lossL: tensor(75657.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9836 lossL: tensor(80100.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9837 lossL: tensor(91212.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9838 lossL: tensor(80400.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9839 lossL: tensor(88529.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9840 lossL: tensor(88107.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9841 lossL: tensor(91624.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9842 lossL: tensor(94539.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9843 lossL: tensor(87459.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9844 lossL: tensor(90803.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9845 lossL: tensor(82437.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9846 lossL: tensor(80404.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9847 lossL: tensor(89140.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9848 lossL: tensor(84533.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9849 lossL: tensor(92168.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9850 lossL: tensor(90284.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9851 lossL: tensor(97305.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9852 lossL: tensor(89803.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9853 lossL: tensor(78212.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9854 lossL: tensor(101668.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9855 lossL: tensor(75441.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9856 lossL: tensor(105547.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9857 lossL: tensor(87944.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9858 lossL: tensor(95653.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9859 lossL: tensor(102682.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9860 lossL: tensor(77899.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9861 lossL: tensor(84593.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9862 lossL: tensor(78886.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9863 lossL: tensor(83804.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9864 lossL: tensor(85571.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9865 lossL: tensor(85931.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9866 lossL: tensor(77373.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9867 lossL: tensor(90101.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9868 lossL: tensor(77375.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9869 lossL: tensor(88594.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9870 lossL: tensor(95027.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9871 lossL: tensor(81622.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9872 lossL: tensor(92723.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9873 lossL: tensor(89928.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9874 lossL: tensor(81271.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9875 lossL: tensor(94662.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9876 lossL: tensor(84962.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9877 lossL: tensor(84519.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9878 lossL: tensor(99428.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9879 lossL: tensor(90554.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9880 lossL: tensor(74468.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9881 lossL: tensor(85421.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9882 lossL: tensor(84889.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9883 lossL: tensor(74494.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9884 lossL: tensor(87391.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9885 lossL: tensor(80710.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9886 lossL: tensor(80458.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9887 lossL: tensor(75222.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9888 lossL: tensor(85222.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9889 lossL: tensor(81978.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9890 lossL: tensor(87021.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9891 lossL: tensor(86873.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9892 lossL: tensor(91016.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9893 lossL: tensor(89431.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9894 lossL: tensor(80914.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9895 lossL: tensor(85719.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9896 lossL: tensor(89505.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9897 lossL: tensor(83039.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9898 lossL: tensor(84936.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9899 lossL: tensor(94065.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9900 lossL: tensor(88688.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9901 lossL: tensor(93659.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9902 lossL: tensor(84014.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9903 lossL: tensor(89897.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9904 lossL: tensor(84563.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9905 lossL: tensor(70065.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9906 lossL: tensor(78338.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9907 lossL: tensor(71731.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9908 lossL: tensor(76424.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9909 lossL: tensor(88096.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9910 lossL: tensor(85440.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9911 lossL: tensor(82695.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9912 lossL: tensor(83232.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9913 lossL: tensor(79204.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9914 lossL: tensor(82994.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9915 lossL: tensor(76036.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9916 lossL: tensor(89116.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9917 lossL: tensor(75657.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9918 lossL: tensor(77634.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9919 lossL: tensor(79099.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9920 lossL: tensor(98926.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9921 lossL: tensor(83912.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9922 lossL: tensor(76095.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9923 lossL: tensor(88321.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9924 lossL: tensor(81957.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9925 lossL: tensor(82263.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9926 lossL: tensor(76582.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9927 lossL: tensor(74679.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9928 lossL: tensor(88043.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9929 lossL: tensor(77119.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9930 lossL: tensor(77542.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9931 lossL: tensor(94625.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9932 lossL: tensor(81888.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9933 lossL: tensor(88866.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9934 lossL: tensor(77637.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9935 lossL: tensor(80553.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9936 lossL: tensor(77818.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9937 lossL: tensor(80055.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9938 lossL: tensor(71231.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9939 lossL: tensor(80715.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9940 lossL: tensor(81935.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9941 lossL: tensor(80459.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9942 lossL: tensor(80105.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9943 lossL: tensor(75024.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9944 lossL: tensor(73558.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9945 lossL: tensor(73430.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9946 lossL: tensor(75878.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9947 lossL: tensor(78184.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9948 lossL: tensor(67009.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9949 lossL: tensor(83424.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9950 lossL: tensor(88096.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9951 lossL: tensor(88518.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9952 lossL: tensor(75164.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9953 lossL: tensor(72349.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9954 lossL: tensor(78714.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9955 lossL: tensor(69883.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9956 lossL: tensor(75841.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9957 lossL: tensor(80457.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9958 lossL: tensor(79456.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9959 lossL: tensor(73051.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9960 lossL: tensor(78290.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9961 lossL: tensor(71384.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9962 lossL: tensor(87587.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9963 lossL: tensor(83721.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9964 lossL: tensor(82270.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9965 lossL: tensor(84548.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9966 lossL: tensor(76493.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9967 lossL: tensor(81657.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9968 lossL: tensor(78167.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9969 lossL: tensor(86352.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9970 lossL: tensor(85431.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9971 lossL: tensor(69257.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9972 lossL: tensor(84231.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9973 lossL: tensor(71464.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9974 lossL: tensor(80248.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9975 lossL: tensor(76195.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9976 lossL: tensor(70423.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9977 lossL: tensor(66466.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9978 lossL: tensor(78278.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9979 lossL: tensor(68381.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9980 lossL: tensor(72242.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9981 lossL: tensor(78110.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9982 lossL: tensor(69351.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9983 lossL: tensor(70444.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9984 lossL: tensor(74607.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9985 lossL: tensor(73187.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9986 lossL: tensor(68959.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9987 lossL: tensor(76795.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9988 lossL: tensor(62027.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9989 lossL: tensor(75045.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9990 lossL: tensor(86436.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9991 lossL: tensor(82437.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9992 lossL: tensor(90057.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9993 lossL: tensor(83980.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9994 lossL: tensor(84690.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9995 lossL: tensor(85667.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9996 lossL: tensor(78859.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9997 lossL: tensor(72620.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9998 lossL: tensor(89666.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "9999 lossL: tensor(76050.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10000 lossL: tensor(71011.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10001 lossL: tensor(79341.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10002 lossL: tensor(76499.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10003 lossL: tensor(81106.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10004 lossL: tensor(80555.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10005 lossL: tensor(76685.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10006 lossL: tensor(64673.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10007 lossL: tensor(70288.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10008 lossL: tensor(69003.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10009 lossL: tensor(71373.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10010 lossL: tensor(78278., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10011 lossL: tensor(87531.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10012 lossL: tensor(75056.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10013 lossL: tensor(67136.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10014 lossL: tensor(71475.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10015 lossL: tensor(82934.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10016 lossL: tensor(74536.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10017 lossL: tensor(70515.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10018 lossL: tensor(75669.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10019 lossL: tensor(65070.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10020 lossL: tensor(70839.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10021 lossL: tensor(79253.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10022 lossL: tensor(87199.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10023 lossL: tensor(71136.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10024 lossL: tensor(73248.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10025 lossL: tensor(62684.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10026 lossL: tensor(74759.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10027 lossL: tensor(74238.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10028 lossL: tensor(69079.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10029 lossL: tensor(65139.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10030 lossL: tensor(71649.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10031 lossL: tensor(67568.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10032 lossL: tensor(65002.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10033 lossL: tensor(67273.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10034 lossL: tensor(60168.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10035 lossL: tensor(67420.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10036 lossL: tensor(77333.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10037 lossL: tensor(76551.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10038 lossL: tensor(68011.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10039 lossL: tensor(75907.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10040 lossL: tensor(72171.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10041 lossL: tensor(69238.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10042 lossL: tensor(73555.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10043 lossL: tensor(70369.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10044 lossL: tensor(69456.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10045 lossL: tensor(81357.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10046 lossL: tensor(69618.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10047 lossL: tensor(73285.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10048 lossL: tensor(78671.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10049 lossL: tensor(72592.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10050 lossL: tensor(71406.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10051 lossL: tensor(67858.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10052 lossL: tensor(59345.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10053 lossL: tensor(72196.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10054 lossL: tensor(62160.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10055 lossL: tensor(75676.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10056 lossL: tensor(60652.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10057 lossL: tensor(58959.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10058 lossL: tensor(72146.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10059 lossL: tensor(71550.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10060 lossL: tensor(64328.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10061 lossL: tensor(71697.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10062 lossL: tensor(93266.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10063 lossL: tensor(64133.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10064 lossL: tensor(64353.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10065 lossL: tensor(72570.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10066 lossL: tensor(73924.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10067 lossL: tensor(67683.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10068 lossL: tensor(82490.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10069 lossL: tensor(74919.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10070 lossL: tensor(75452.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10071 lossL: tensor(64991.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10072 lossL: tensor(61990.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10073 lossL: tensor(72870.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10074 lossL: tensor(71214.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10075 lossL: tensor(62932.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10076 lossL: tensor(65712.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10077 lossL: tensor(64717.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10078 lossL: tensor(73235.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10079 lossL: tensor(74223.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10080 lossL: tensor(62458.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10081 lossL: tensor(66065.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10082 lossL: tensor(78047.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10083 lossL: tensor(73856.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10084 lossL: tensor(68128.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10085 lossL: tensor(73987.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10086 lossL: tensor(65175.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10087 lossL: tensor(66645.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10088 lossL: tensor(68043.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10089 lossL: tensor(60932.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10090 lossL: tensor(62000.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10091 lossL: tensor(59920.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10092 lossL: tensor(63472.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10093 lossL: tensor(62599.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10094 lossL: tensor(66019.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10095 lossL: tensor(63629.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10096 lossL: tensor(77822.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10097 lossL: tensor(64231.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10098 lossL: tensor(66288.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10099 lossL: tensor(85202.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10100 lossL: tensor(78089.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10101 lossL: tensor(76201.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10102 lossL: tensor(74459.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10103 lossL: tensor(68085.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10104 lossL: tensor(70467.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10105 lossL: tensor(67099.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10106 lossL: tensor(72022.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10107 lossL: tensor(68819.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10108 lossL: tensor(74998.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10109 lossL: tensor(67817.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10110 lossL: tensor(73217.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10111 lossL: tensor(72162.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10112 lossL: tensor(70591.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10113 lossL: tensor(73809.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10114 lossL: tensor(74739.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10115 lossL: tensor(66950.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10116 lossL: tensor(66868.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10117 lossL: tensor(57063.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10118 lossL: tensor(69278.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10119 lossL: tensor(59406.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10120 lossL: tensor(69054.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10121 lossL: tensor(51663.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10122 lossL: tensor(69097.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10123 lossL: tensor(58113.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10124 lossL: tensor(64330.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10125 lossL: tensor(55574.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10126 lossL: tensor(59326.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10127 lossL: tensor(65516.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10128 lossL: tensor(62396.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10129 lossL: tensor(73452.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10130 lossL: tensor(55869.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10131 lossL: tensor(65859.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10132 lossL: tensor(64356.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10133 lossL: tensor(72015.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10134 lossL: tensor(64508.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10135 lossL: tensor(69074.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10136 lossL: tensor(69931.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10137 lossL: tensor(69313.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10138 lossL: tensor(59511.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10139 lossL: tensor(70743.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10140 lossL: tensor(67403.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10141 lossL: tensor(66135.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10142 lossL: tensor(58265.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10143 lossL: tensor(63772.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10144 lossL: tensor(62697.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10145 lossL: tensor(65794.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10146 lossL: tensor(69802.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10147 lossL: tensor(57492.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10148 lossL: tensor(55572.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10149 lossL: tensor(63990.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10150 lossL: tensor(64280.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10151 lossL: tensor(67055.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10152 lossL: tensor(71651.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10153 lossL: tensor(75152.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10154 lossL: tensor(56480.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10155 lossL: tensor(86037.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10156 lossL: tensor(60055.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10157 lossL: tensor(63842.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10158 lossL: tensor(58199.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10159 lossL: tensor(65708.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10160 lossL: tensor(58133.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10161 lossL: tensor(68685.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10162 lossL: tensor(63445.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10163 lossL: tensor(63283.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10164 lossL: tensor(59329.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10165 lossL: tensor(72068.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10166 lossL: tensor(61315.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10167 lossL: tensor(65637.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10168 lossL: tensor(63927.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10169 lossL: tensor(57921.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10170 lossL: tensor(60731.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10171 lossL: tensor(61983.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10172 lossL: tensor(62290.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10173 lossL: tensor(56854.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10174 lossL: tensor(52756.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10175 lossL: tensor(68950.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10176 lossL: tensor(57183.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10177 lossL: tensor(60498.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10178 lossL: tensor(77702.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10179 lossL: tensor(59814.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10180 lossL: tensor(66662.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10181 lossL: tensor(58251.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10182 lossL: tensor(65277.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10183 lossL: tensor(54372.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10184 lossL: tensor(63363.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10185 lossL: tensor(66445.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10186 lossL: tensor(55951.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10187 lossL: tensor(61266.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10188 lossL: tensor(52977.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10189 lossL: tensor(67213.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10190 lossL: tensor(59371.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10191 lossL: tensor(59325.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10192 lossL: tensor(55715.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10193 lossL: tensor(57873.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10194 lossL: tensor(58264.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10195 lossL: tensor(62129.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10196 lossL: tensor(60977.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10197 lossL: tensor(53504.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10198 lossL: tensor(62870.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10199 lossL: tensor(60555.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10200 lossL: tensor(67979.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10201 lossL: tensor(60830.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10202 lossL: tensor(63421.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10203 lossL: tensor(64826.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10204 lossL: tensor(69739.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10205 lossL: tensor(63660.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10206 lossL: tensor(58020.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10207 lossL: tensor(69317.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10208 lossL: tensor(61735.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10209 lossL: tensor(56785.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10210 lossL: tensor(60834.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10211 lossL: tensor(61260.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10212 lossL: tensor(63698.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10213 lossL: tensor(70099.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10214 lossL: tensor(52406.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10215 lossL: tensor(53100.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10216 lossL: tensor(65128.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10217 lossL: tensor(67374.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10218 lossL: tensor(59078.6211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10219 lossL: tensor(58611.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10220 lossL: tensor(58428.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10221 lossL: tensor(62508.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10222 lossL: tensor(59278.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10223 lossL: tensor(65033.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10224 lossL: tensor(54268.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10225 lossL: tensor(53578.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10226 lossL: tensor(70250.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10227 lossL: tensor(65161.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10228 lossL: tensor(57998.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10229 lossL: tensor(60045.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10230 lossL: tensor(57727.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10231 lossL: tensor(60373.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10232 lossL: tensor(65108.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10233 lossL: tensor(56484.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10234 lossL: tensor(53560.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10235 lossL: tensor(59670.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10236 lossL: tensor(63317.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10237 lossL: tensor(56566.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10238 lossL: tensor(58938.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10239 lossL: tensor(52349.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10240 lossL: tensor(49255.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10241 lossL: tensor(55700.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10242 lossL: tensor(50895.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10243 lossL: tensor(71597.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10244 lossL: tensor(59270.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10245 lossL: tensor(60988.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10246 lossL: tensor(64420.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10247 lossL: tensor(63676.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10248 lossL: tensor(67622.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10249 lossL: tensor(60393.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10250 lossL: tensor(60626.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10251 lossL: tensor(62039.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10252 lossL: tensor(51209.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10253 lossL: tensor(62108.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10254 lossL: tensor(58986.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10255 lossL: tensor(67329.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10256 lossL: tensor(54440.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10257 lossL: tensor(55942.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10258 lossL: tensor(55122.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10259 lossL: tensor(58347.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10260 lossL: tensor(53289.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10261 lossL: tensor(56530.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10262 lossL: tensor(55402.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10263 lossL: tensor(65967.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10264 lossL: tensor(55101.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10265 lossL: tensor(65582.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10266 lossL: tensor(66058.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10267 lossL: tensor(62774.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10268 lossL: tensor(62338.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10269 lossL: tensor(60289.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10270 lossL: tensor(56550.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10271 lossL: tensor(48875.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10272 lossL: tensor(63056.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10273 lossL: tensor(66211.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10274 lossL: tensor(49424.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10275 lossL: tensor(50006.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10276 lossL: tensor(49949.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10277 lossL: tensor(59357.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10278 lossL: tensor(43490.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10279 lossL: tensor(46788.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10280 lossL: tensor(56375.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10281 lossL: tensor(55472.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10282 lossL: tensor(48843.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10283 lossL: tensor(52397.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10284 lossL: tensor(60923.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10285 lossL: tensor(55877.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10286 lossL: tensor(60422.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10287 lossL: tensor(61492.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10288 lossL: tensor(59171.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10289 lossL: tensor(56125.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10290 lossL: tensor(51418.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10291 lossL: tensor(47732.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10292 lossL: tensor(59579.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10293 lossL: tensor(61808.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10294 lossL: tensor(61109.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10295 lossL: tensor(55950.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10296 lossL: tensor(64025.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10297 lossL: tensor(56333.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10298 lossL: tensor(60513.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10299 lossL: tensor(49688.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10300 lossL: tensor(61007.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10301 lossL: tensor(52288.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10302 lossL: tensor(60222.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10303 lossL: tensor(53787.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10304 lossL: tensor(62819.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10305 lossL: tensor(58141.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10306 lossL: tensor(58853.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10307 lossL: tensor(52606.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10308 lossL: tensor(52834.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10309 lossL: tensor(48073.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10310 lossL: tensor(66618.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10311 lossL: tensor(52453.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10312 lossL: tensor(49382.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10313 lossL: tensor(52095.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10314 lossL: tensor(52736.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10315 lossL: tensor(55782.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10316 lossL: tensor(55108.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10317 lossL: tensor(56701.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10318 lossL: tensor(64079.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10319 lossL: tensor(53063.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10320 lossL: tensor(54437.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10321 lossL: tensor(58727.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10322 lossL: tensor(54735.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10323 lossL: tensor(52336.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10324 lossL: tensor(52305.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10325 lossL: tensor(57007.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10326 lossL: tensor(55778.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10327 lossL: tensor(51801.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10328 lossL: tensor(54354.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10329 lossL: tensor(61551.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10330 lossL: tensor(52454.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10331 lossL: tensor(60485.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10332 lossL: tensor(58447.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10333 lossL: tensor(52618.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10334 lossL: tensor(51838.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10335 lossL: tensor(56784.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10336 lossL: tensor(55002.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10337 lossL: tensor(50243.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10338 lossL: tensor(54636.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10339 lossL: tensor(60319.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10340 lossL: tensor(51825.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10341 lossL: tensor(50300.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10342 lossL: tensor(53949.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10343 lossL: tensor(52995.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10344 lossL: tensor(54179.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10345 lossL: tensor(61335.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10346 lossL: tensor(47563.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10347 lossL: tensor(57973.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10348 lossL: tensor(48517.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10349 lossL: tensor(46946.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10350 lossL: tensor(58191.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10351 lossL: tensor(53078.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10352 lossL: tensor(57083.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10353 lossL: tensor(59509.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10354 lossL: tensor(54837.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10355 lossL: tensor(61965.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10356 lossL: tensor(56558.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10357 lossL: tensor(54543.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10358 lossL: tensor(53017.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10359 lossL: tensor(55241.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10360 lossL: tensor(61318.3633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10361 lossL: tensor(50604.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10362 lossL: tensor(55644.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10363 lossL: tensor(51402.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10364 lossL: tensor(52090.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10365 lossL: tensor(55103.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10366 lossL: tensor(50128.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10367 lossL: tensor(50947.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10368 lossL: tensor(55825.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10369 lossL: tensor(49183.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10370 lossL: tensor(52052.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10371 lossL: tensor(57311.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10372 lossL: tensor(55361.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10373 lossL: tensor(52950.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10374 lossL: tensor(53295.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10375 lossL: tensor(44687.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10376 lossL: tensor(63005.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10377 lossL: tensor(50198.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10378 lossL: tensor(55166.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10379 lossL: tensor(56766.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10380 lossL: tensor(58319.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10381 lossL: tensor(54592.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10382 lossL: tensor(49578.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10383 lossL: tensor(50376.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10384 lossL: tensor(51908.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10385 lossL: tensor(56729.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10386 lossL: tensor(47466.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10387 lossL: tensor(46752.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10388 lossL: tensor(55894.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10389 lossL: tensor(48136.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10390 lossL: tensor(52740.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10391 lossL: tensor(56883.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10392 lossL: tensor(56003.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10393 lossL: tensor(54250.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10394 lossL: tensor(52402.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10395 lossL: tensor(51432.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10396 lossL: tensor(42340.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10397 lossL: tensor(49878.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10398 lossL: tensor(54813.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10399 lossL: tensor(56796.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10400 lossL: tensor(68122.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10401 lossL: tensor(55836.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10402 lossL: tensor(51905.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10403 lossL: tensor(57313.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10404 lossL: tensor(47323.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10405 lossL: tensor(51769.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10406 lossL: tensor(52032.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10407 lossL: tensor(53009.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10408 lossL: tensor(47561.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10409 lossL: tensor(47636.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10410 lossL: tensor(43958.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10411 lossL: tensor(48939.5430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10412 lossL: tensor(51170.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10413 lossL: tensor(49245.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10414 lossL: tensor(51526.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10415 lossL: tensor(52221.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10416 lossL: tensor(58278.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10417 lossL: tensor(45959.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10418 lossL: tensor(63908.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10419 lossL: tensor(56816.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10420 lossL: tensor(48342.5430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10421 lossL: tensor(43125.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10422 lossL: tensor(46850.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10423 lossL: tensor(53641.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10424 lossL: tensor(49956.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10425 lossL: tensor(42643.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10426 lossL: tensor(52509.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10427 lossL: tensor(41770.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10428 lossL: tensor(48459.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10429 lossL: tensor(49348.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10430 lossL: tensor(47836.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10431 lossL: tensor(45202.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10432 lossL: tensor(42072.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10433 lossL: tensor(45068.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10434 lossL: tensor(44958.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10435 lossL: tensor(51511.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10436 lossL: tensor(48565.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10437 lossL: tensor(52042.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10438 lossL: tensor(55450.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10439 lossL: tensor(49285.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10440 lossL: tensor(50884.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10441 lossL: tensor(52079.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10442 lossL: tensor(53920.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10443 lossL: tensor(42204.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10444 lossL: tensor(45322.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10445 lossL: tensor(51174.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10446 lossL: tensor(41875.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10447 lossL: tensor(52927.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10448 lossL: tensor(46590.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10449 lossL: tensor(53306.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10450 lossL: tensor(46445.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10451 lossL: tensor(47023.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10452 lossL: tensor(58022.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10453 lossL: tensor(48863.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10454 lossL: tensor(48773.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10455 lossL: tensor(45215.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10456 lossL: tensor(56203.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10457 lossL: tensor(49664.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10458 lossL: tensor(46916.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10459 lossL: tensor(45875.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10460 lossL: tensor(61582.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10461 lossL: tensor(46547.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10462 lossL: tensor(50901.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10463 lossL: tensor(43812.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10464 lossL: tensor(47871.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10465 lossL: tensor(45322.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10466 lossL: tensor(56510.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10467 lossL: tensor(45790.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10468 lossL: tensor(57557.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10469 lossL: tensor(49237.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10470 lossL: tensor(40116.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10471 lossL: tensor(54733.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10472 lossL: tensor(44059.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10473 lossL: tensor(45551.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10474 lossL: tensor(46352.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10475 lossL: tensor(42082.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10476 lossL: tensor(47456.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10477 lossL: tensor(50888.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10478 lossL: tensor(50754.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10479 lossL: tensor(36424.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10480 lossL: tensor(58665.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10481 lossL: tensor(50990.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10482 lossL: tensor(37026.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10483 lossL: tensor(49065.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10484 lossL: tensor(42881.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10485 lossL: tensor(48355.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10486 lossL: tensor(47829.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10487 lossL: tensor(41759.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10488 lossL: tensor(45822.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10489 lossL: tensor(44068.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10490 lossL: tensor(43749.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10491 lossL: tensor(49485.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10492 lossL: tensor(40990.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10493 lossL: tensor(48708.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10494 lossL: tensor(50967.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10495 lossL: tensor(49897.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10496 lossL: tensor(39580.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10497 lossL: tensor(44532.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10498 lossL: tensor(43898.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10499 lossL: tensor(46789.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10500 lossL: tensor(45547.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10501 lossL: tensor(40562.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10502 lossL: tensor(41979.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10503 lossL: tensor(46060.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10504 lossL: tensor(46528.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10505 lossL: tensor(49064.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10506 lossL: tensor(43932.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10507 lossL: tensor(49407.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10508 lossL: tensor(52771.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10509 lossL: tensor(47327.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10510 lossL: tensor(38205.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10511 lossL: tensor(40775.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10512 lossL: tensor(43140.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10513 lossL: tensor(40149.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10514 lossL: tensor(43550.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10515 lossL: tensor(37979.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10516 lossL: tensor(46752.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10517 lossL: tensor(41930.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10518 lossL: tensor(46692.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10519 lossL: tensor(42799.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10520 lossL: tensor(49678.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10521 lossL: tensor(42012.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10522 lossL: tensor(37716.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10523 lossL: tensor(42706.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10524 lossL: tensor(47931.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10525 lossL: tensor(44029.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10526 lossL: tensor(42862.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10527 lossL: tensor(51000.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10528 lossL: tensor(45198.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10529 lossL: tensor(44186.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10530 lossL: tensor(45607.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10531 lossL: tensor(45690.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10532 lossL: tensor(44356.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10533 lossL: tensor(42515.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10534 lossL: tensor(49423.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10535 lossL: tensor(46282.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10536 lossL: tensor(43090.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10537 lossL: tensor(44471.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10538 lossL: tensor(49728.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10539 lossL: tensor(43414.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10540 lossL: tensor(47139.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10541 lossL: tensor(43880.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10542 lossL: tensor(58394.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10543 lossL: tensor(48364.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10544 lossL: tensor(54083.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10545 lossL: tensor(47455.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10546 lossL: tensor(36333.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10547 lossL: tensor(41759.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10548 lossL: tensor(43869.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10549 lossL: tensor(41700.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10550 lossL: tensor(43413.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10551 lossL: tensor(42767.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10552 lossL: tensor(46155.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10553 lossL: tensor(44615.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10554 lossL: tensor(47053.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10555 lossL: tensor(46910.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10556 lossL: tensor(48656.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10557 lossL: tensor(41984.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10558 lossL: tensor(43391.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10559 lossL: tensor(45961.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10560 lossL: tensor(45256.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10561 lossL: tensor(44580.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10562 lossL: tensor(47269.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10563 lossL: tensor(42166.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10564 lossL: tensor(45817.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10565 lossL: tensor(41325.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10566 lossL: tensor(42199.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10567 lossL: tensor(47119.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10568 lossL: tensor(41889.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10569 lossL: tensor(38014.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10570 lossL: tensor(38444.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10571 lossL: tensor(46936.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10572 lossL: tensor(42805.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10573 lossL: tensor(38996.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10574 lossL: tensor(38675.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10575 lossL: tensor(44655.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10576 lossL: tensor(44884.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10577 lossL: tensor(39762.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10578 lossL: tensor(42592.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10579 lossL: tensor(48442.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10580 lossL: tensor(46422.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10581 lossL: tensor(49539.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10582 lossL: tensor(39034.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10583 lossL: tensor(43888.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10584 lossL: tensor(41009.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10585 lossL: tensor(37455.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10586 lossL: tensor(30316.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10587 lossL: tensor(45815.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10588 lossL: tensor(38500.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10589 lossL: tensor(44371.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10590 lossL: tensor(36334.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10591 lossL: tensor(43560.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10592 lossL: tensor(46446.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10593 lossL: tensor(46258.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10594 lossL: tensor(41479.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10595 lossL: tensor(36409.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10596 lossL: tensor(48684.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10597 lossL: tensor(44078.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10598 lossL: tensor(47884.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10599 lossL: tensor(44390.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10600 lossL: tensor(43244.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10601 lossL: tensor(38680.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10602 lossL: tensor(43776.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10603 lossL: tensor(37084.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10604 lossL: tensor(41661.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10605 lossL: tensor(34615.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10606 lossL: tensor(41568.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10607 lossL: tensor(40678.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10608 lossL: tensor(43383.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10609 lossL: tensor(47405.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10610 lossL: tensor(40749.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10611 lossL: tensor(45483.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10612 lossL: tensor(38484.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10613 lossL: tensor(44393.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10614 lossL: tensor(37933.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10615 lossL: tensor(39529.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10616 lossL: tensor(44063.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10617 lossL: tensor(44903.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10618 lossL: tensor(40978.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10619 lossL: tensor(46567.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10620 lossL: tensor(44673.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10621 lossL: tensor(47105.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10622 lossL: tensor(44058.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10623 lossL: tensor(41831.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10624 lossL: tensor(43275.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10625 lossL: tensor(39232.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10626 lossL: tensor(41105.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10627 lossL: tensor(43030.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10628 lossL: tensor(50443.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10629 lossL: tensor(35970.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10630 lossL: tensor(48301.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10631 lossL: tensor(44111.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10632 lossL: tensor(43941.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10633 lossL: tensor(39012.3633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10634 lossL: tensor(37332.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10635 lossL: tensor(39225.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10636 lossL: tensor(43608.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10637 lossL: tensor(39795.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10638 lossL: tensor(40864.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10639 lossL: tensor(37670.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10640 lossL: tensor(44953.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10641 lossL: tensor(40935.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10642 lossL: tensor(35673.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10643 lossL: tensor(49224.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10644 lossL: tensor(35692.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10645 lossL: tensor(37524.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10646 lossL: tensor(40863.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10647 lossL: tensor(45745.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10648 lossL: tensor(38724.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10649 lossL: tensor(44697.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10650 lossL: tensor(35990.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10651 lossL: tensor(40529.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10652 lossL: tensor(39337.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10653 lossL: tensor(43742.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10654 lossL: tensor(42428.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10655 lossL: tensor(38926.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10656 lossL: tensor(41170.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10657 lossL: tensor(37719.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10658 lossL: tensor(40448.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10659 lossL: tensor(40552.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10660 lossL: tensor(39664.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10661 lossL: tensor(39163.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10662 lossL: tensor(38952.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10663 lossL: tensor(47502.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10664 lossL: tensor(43356.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10665 lossL: tensor(42185.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10666 lossL: tensor(47139.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10667 lossL: tensor(36561.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10668 lossL: tensor(44742.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10669 lossL: tensor(39278.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10670 lossL: tensor(38963.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10671 lossL: tensor(42423.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10672 lossL: tensor(43747.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10673 lossL: tensor(44121.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10674 lossL: tensor(42454.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10675 lossL: tensor(44839.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10676 lossL: tensor(39789.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10677 lossL: tensor(34455.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10678 lossL: tensor(42098.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10679 lossL: tensor(34880.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10680 lossL: tensor(47824.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10681 lossL: tensor(37329.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10682 lossL: tensor(41662.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10683 lossL: tensor(37748.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10684 lossL: tensor(41959.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10685 lossL: tensor(42654.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10686 lossL: tensor(37149.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10687 lossL: tensor(42451.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10688 lossL: tensor(48402.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10689 lossL: tensor(35169.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10690 lossL: tensor(35302.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10691 lossL: tensor(33182.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10692 lossL: tensor(32951.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10693 lossL: tensor(45581.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10694 lossL: tensor(40028.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10695 lossL: tensor(36474.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10696 lossL: tensor(37531.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10697 lossL: tensor(34689.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10698 lossL: tensor(37154.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10699 lossL: tensor(38284.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10700 lossL: tensor(43365.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10701 lossL: tensor(39732.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10702 lossL: tensor(34888.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10703 lossL: tensor(40456.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10704 lossL: tensor(36235.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10705 lossL: tensor(36207.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10706 lossL: tensor(42422.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10707 lossL: tensor(36804.5430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10708 lossL: tensor(31486.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10709 lossL: tensor(39584.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10710 lossL: tensor(34639.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10711 lossL: tensor(41254.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10712 lossL: tensor(38183.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10713 lossL: tensor(35346.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10714 lossL: tensor(41961.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10715 lossL: tensor(37985.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10716 lossL: tensor(40642.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10717 lossL: tensor(34586.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10718 lossL: tensor(50647.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10719 lossL: tensor(38527.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10720 lossL: tensor(37439.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10721 lossL: tensor(39795.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10722 lossL: tensor(43217.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10723 lossL: tensor(34546.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10724 lossL: tensor(36180.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10725 lossL: tensor(37613.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10726 lossL: tensor(40515.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10727 lossL: tensor(38835.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10728 lossL: tensor(35717.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10729 lossL: tensor(35283.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10730 lossL: tensor(35494.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10731 lossL: tensor(36868.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10732 lossL: tensor(35995.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10733 lossL: tensor(32017.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10734 lossL: tensor(35030.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10735 lossL: tensor(33719.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10736 lossL: tensor(46314.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10737 lossL: tensor(38610.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10738 lossL: tensor(35534.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10739 lossL: tensor(39043.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10740 lossL: tensor(34731.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10741 lossL: tensor(27072.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10742 lossL: tensor(39774.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10743 lossL: tensor(40436.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10744 lossL: tensor(33645.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10745 lossL: tensor(36447.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10746 lossL: tensor(36099.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10747 lossL: tensor(46802.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10748 lossL: tensor(31190.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10749 lossL: tensor(41346.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10750 lossL: tensor(34215.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10751 lossL: tensor(40295.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10752 lossL: tensor(39220.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10753 lossL: tensor(30896.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10754 lossL: tensor(38003.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10755 lossL: tensor(39090.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10756 lossL: tensor(39251.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10757 lossL: tensor(36521.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10758 lossL: tensor(34689.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10759 lossL: tensor(46073.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10760 lossL: tensor(38752.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10761 lossL: tensor(33020.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10762 lossL: tensor(38233.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10763 lossL: tensor(34735.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10764 lossL: tensor(38448.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10765 lossL: tensor(38175.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10766 lossL: tensor(39268.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10767 lossL: tensor(32258.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10768 lossL: tensor(39508.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10769 lossL: tensor(33223.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10770 lossL: tensor(42023.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10771 lossL: tensor(30624.2480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10772 lossL: tensor(36615.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10773 lossL: tensor(33249.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10774 lossL: tensor(34977.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10775 lossL: tensor(32700.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10776 lossL: tensor(31406.7012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10777 lossL: tensor(38706.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10778 lossL: tensor(32476.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10779 lossL: tensor(37410.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10780 lossL: tensor(38596.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10781 lossL: tensor(34092.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10782 lossL: tensor(36313.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10783 lossL: tensor(40828.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10784 lossL: tensor(37626.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10785 lossL: tensor(30224.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10786 lossL: tensor(35768.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10787 lossL: tensor(39948.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10788 lossL: tensor(33073.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10789 lossL: tensor(41327.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10790 lossL: tensor(35009.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10791 lossL: tensor(38786.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10792 lossL: tensor(39844.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10793 lossL: tensor(39933.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10794 lossL: tensor(33493.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10795 lossL: tensor(32719.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10796 lossL: tensor(36338.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10797 lossL: tensor(31021.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10798 lossL: tensor(34743.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10799 lossL: tensor(28796.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10800 lossL: tensor(42003.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10801 lossL: tensor(29515.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10802 lossL: tensor(37290.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10803 lossL: tensor(40590.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10804 lossL: tensor(36799.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10805 lossL: tensor(35273.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10806 lossL: tensor(35753.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10807 lossL: tensor(30914.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10808 lossL: tensor(32512.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10809 lossL: tensor(34223.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10810 lossL: tensor(36684.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10811 lossL: tensor(40523.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10812 lossL: tensor(32365.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10813 lossL: tensor(30756.9434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10814 lossL: tensor(32611.0605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10815 lossL: tensor(41332.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10816 lossL: tensor(34623.6211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10817 lossL: tensor(33679.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10818 lossL: tensor(30557.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10819 lossL: tensor(38179.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10820 lossL: tensor(40828.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10821 lossL: tensor(39274.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10822 lossL: tensor(37730.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10823 lossL: tensor(37769.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10824 lossL: tensor(38910.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10825 lossL: tensor(32838.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10826 lossL: tensor(30704.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10827 lossL: tensor(38831.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10828 lossL: tensor(37019.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10829 lossL: tensor(39899.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10830 lossL: tensor(39091.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10831 lossL: tensor(32382.6230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10832 lossL: tensor(36432.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10833 lossL: tensor(36823.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10834 lossL: tensor(30233.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10835 lossL: tensor(29523.2598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10836 lossL: tensor(35075.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10837 lossL: tensor(32918.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10838 lossL: tensor(40534.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10839 lossL: tensor(41586.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10840 lossL: tensor(34574.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10841 lossL: tensor(39760.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10842 lossL: tensor(31968.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10843 lossL: tensor(34345.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10844 lossL: tensor(39989.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10845 lossL: tensor(33202.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10846 lossL: tensor(36212.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10847 lossL: tensor(30251.9824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10848 lossL: tensor(36926.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10849 lossL: tensor(30286.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10850 lossL: tensor(35776.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10851 lossL: tensor(33373.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10852 lossL: tensor(29810.0605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10853 lossL: tensor(37239.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10854 lossL: tensor(32063.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10855 lossL: tensor(32606.8105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10856 lossL: tensor(37706.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10857 lossL: tensor(28656.1582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10858 lossL: tensor(27511.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10859 lossL: tensor(36952.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10860 lossL: tensor(36702.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10861 lossL: tensor(32767.6211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10862 lossL: tensor(31677.6211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10863 lossL: tensor(33796.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10864 lossL: tensor(32988.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10865 lossL: tensor(32287.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10866 lossL: tensor(27912.0918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10867 lossL: tensor(26164.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10868 lossL: tensor(32615.8496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10869 lossL: tensor(28679.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10870 lossL: tensor(32833.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10871 lossL: tensor(35238.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10872 lossL: tensor(36934.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10873 lossL: tensor(32476.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10874 lossL: tensor(32512.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10875 lossL: tensor(31705.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10876 lossL: tensor(28410.6387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10877 lossL: tensor(36254.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10878 lossL: tensor(33826.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10879 lossL: tensor(35202.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10880 lossL: tensor(32359.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10881 lossL: tensor(29728.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10882 lossL: tensor(35239.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10883 lossL: tensor(37593.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10884 lossL: tensor(31653.1816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10885 lossL: tensor(29750.9473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10886 lossL: tensor(32927.5430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10887 lossL: tensor(32859.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10888 lossL: tensor(36454.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10889 lossL: tensor(36347.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10890 lossL: tensor(26956.8926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10891 lossL: tensor(37370.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10892 lossL: tensor(36591.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10893 lossL: tensor(30289.7520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10894 lossL: tensor(34562.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10895 lossL: tensor(35446.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10896 lossL: tensor(31825.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10897 lossL: tensor(37234.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10898 lossL: tensor(30247.9160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10899 lossL: tensor(31129.6348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10900 lossL: tensor(37310.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10901 lossL: tensor(29614.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10902 lossL: tensor(33040.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10903 lossL: tensor(33964.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10904 lossL: tensor(33051.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10905 lossL: tensor(35184.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10906 lossL: tensor(36896.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10907 lossL: tensor(30225.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10908 lossL: tensor(29278.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10909 lossL: tensor(32331.8340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10910 lossL: tensor(32007.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10911 lossL: tensor(32360.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10912 lossL: tensor(26560.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10913 lossL: tensor(26164.6465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10914 lossL: tensor(36282.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10915 lossL: tensor(28108.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10916 lossL: tensor(36410.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10917 lossL: tensor(33298.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10918 lossL: tensor(37677.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10919 lossL: tensor(32292.9082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10920 lossL: tensor(32420.5684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10921 lossL: tensor(35960.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10922 lossL: tensor(30933.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10923 lossL: tensor(29876.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10924 lossL: tensor(25559.6152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10925 lossL: tensor(27657.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10926 lossL: tensor(33008.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10927 lossL: tensor(32525.6465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10928 lossL: tensor(30476.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10929 lossL: tensor(29263.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10930 lossL: tensor(34980.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10931 lossL: tensor(33484.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10932 lossL: tensor(28852.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10933 lossL: tensor(35864.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10934 lossL: tensor(29905.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10935 lossL: tensor(42478.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10936 lossL: tensor(30236.9668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10937 lossL: tensor(32007.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10938 lossL: tensor(26492.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10939 lossL: tensor(35347.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10940 lossL: tensor(36000.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10941 lossL: tensor(28117.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10942 lossL: tensor(26443.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10943 lossL: tensor(34230.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10944 lossL: tensor(25951.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10945 lossL: tensor(31818.8770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10946 lossL: tensor(33895.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10947 lossL: tensor(35476.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10948 lossL: tensor(31865.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10949 lossL: tensor(31460.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10950 lossL: tensor(33795.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10951 lossL: tensor(35951.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10952 lossL: tensor(30023.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10953 lossL: tensor(33561.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10954 lossL: tensor(29555.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10955 lossL: tensor(33292.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10956 lossL: tensor(29952.7559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10957 lossL: tensor(37005.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10958 lossL: tensor(35224.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10959 lossL: tensor(31771.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10960 lossL: tensor(26097.5918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10961 lossL: tensor(31555.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10962 lossL: tensor(32294.2402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10963 lossL: tensor(31272.5332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10964 lossL: tensor(34615.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10965 lossL: tensor(30447.9355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10966 lossL: tensor(32897.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10967 lossL: tensor(33391.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10968 lossL: tensor(23412.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "10969 lossL: tensor(31241.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10970 lossL: tensor(32283.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10971 lossL: tensor(31192.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10972 lossL: tensor(29979.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10973 lossL: tensor(33558.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10974 lossL: tensor(30901.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10975 lossL: tensor(26625.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10976 lossL: tensor(30925.5098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10977 lossL: tensor(32895.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10978 lossL: tensor(29668.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10979 lossL: tensor(31295.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10980 lossL: tensor(33938.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10981 lossL: tensor(27895.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10982 lossL: tensor(31158.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10983 lossL: tensor(30515.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10984 lossL: tensor(35982.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10985 lossL: tensor(31026.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10986 lossL: tensor(28446.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10987 lossL: tensor(33747.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10988 lossL: tensor(28968.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10989 lossL: tensor(28571.4512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10990 lossL: tensor(29192.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10991 lossL: tensor(27943.0098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10992 lossL: tensor(35001.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10993 lossL: tensor(34691.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10994 lossL: tensor(31364.0059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10995 lossL: tensor(32778.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10996 lossL: tensor(32274.8027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10997 lossL: tensor(27744.5801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10998 lossL: tensor(34265.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "10999 lossL: tensor(31443.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11000 lossL: tensor(26647.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11001 lossL: tensor(30515.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11002 lossL: tensor(34907.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11003 lossL: tensor(27477.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11004 lossL: tensor(29802.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11005 lossL: tensor(29705.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11006 lossL: tensor(35557.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11007 lossL: tensor(32361.6660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11008 lossL: tensor(29251.6152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11009 lossL: tensor(33011.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11010 lossL: tensor(29229.7910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11011 lossL: tensor(27941.5098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11012 lossL: tensor(27378.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11013 lossL: tensor(26590.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11014 lossL: tensor(33993.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11015 lossL: tensor(34292.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11016 lossL: tensor(29052.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11017 lossL: tensor(33292.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11018 lossL: tensor(28584.2090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11019 lossL: tensor(30748.5215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11020 lossL: tensor(29636.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11021 lossL: tensor(26465.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11022 lossL: tensor(27822.6504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11023 lossL: tensor(34704.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11024 lossL: tensor(24488.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11025 lossL: tensor(28856.1816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11026 lossL: tensor(27282.1660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11027 lossL: tensor(35191.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11028 lossL: tensor(29773.9473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11029 lossL: tensor(34817.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11030 lossL: tensor(31843.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11031 lossL: tensor(33723.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11032 lossL: tensor(26777.8965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11033 lossL: tensor(36094.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11034 lossL: tensor(27623.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11035 lossL: tensor(34588.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11036 lossL: tensor(30653.8770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11037 lossL: tensor(27706.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11038 lossL: tensor(28448.4004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11039 lossL: tensor(30278.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11040 lossL: tensor(27955.3066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11041 lossL: tensor(29652.0332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11042 lossL: tensor(32003.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11043 lossL: tensor(29654.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11044 lossL: tensor(28606.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11045 lossL: tensor(27130.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11046 lossL: tensor(29981.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11047 lossL: tensor(34476.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11048 lossL: tensor(28450.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11049 lossL: tensor(31650.1660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11050 lossL: tensor(28951.6816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11051 lossL: tensor(27749.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11052 lossL: tensor(30906.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11053 lossL: tensor(27074.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11054 lossL: tensor(28944.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11055 lossL: tensor(23973.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11056 lossL: tensor(33685., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11057 lossL: tensor(29986.7559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11058 lossL: tensor(27542.5137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11059 lossL: tensor(29586.1504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11060 lossL: tensor(24959.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11061 lossL: tensor(30382.9863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11062 lossL: tensor(30709.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11063 lossL: tensor(28067.9316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11064 lossL: tensor(28011.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11065 lossL: tensor(27111.3613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11066 lossL: tensor(37256.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11067 lossL: tensor(28671.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11068 lossL: tensor(35485.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11069 lossL: tensor(27433.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11070 lossL: tensor(28653.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11071 lossL: tensor(33096.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11072 lossL: tensor(26982.9668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11073 lossL: tensor(36219.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11074 lossL: tensor(26864.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11075 lossL: tensor(30179.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11076 lossL: tensor(30724.1934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11077 lossL: tensor(24774.9355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11078 lossL: tensor(24232.2754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11079 lossL: tensor(32508.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11080 lossL: tensor(28171.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11081 lossL: tensor(21206.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "11082 lossL: tensor(28992.2715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11083 lossL: tensor(31997.8652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11084 lossL: tensor(30841.7207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11085 lossL: tensor(26613.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11086 lossL: tensor(31324.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11087 lossL: tensor(26973.5527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11088 lossL: tensor(30335.2168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11089 lossL: tensor(28837.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11090 lossL: tensor(28259.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11091 lossL: tensor(30640.8340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11092 lossL: tensor(34149.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11093 lossL: tensor(26285.0723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11094 lossL: tensor(23581.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11095 lossL: tensor(29777.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11096 lossL: tensor(31365.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11097 lossL: tensor(28227.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11098 lossL: tensor(26044.0449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11099 lossL: tensor(28704.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11100 lossL: tensor(26352.2676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11101 lossL: tensor(21942.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11102 lossL: tensor(32716.5762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11103 lossL: tensor(27870.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11104 lossL: tensor(31603.9551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11105 lossL: tensor(24860.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11106 lossL: tensor(37523.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11107 lossL: tensor(24609.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11108 lossL: tensor(31166.3652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11109 lossL: tensor(28843.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11110 lossL: tensor(27897.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11111 lossL: tensor(28985.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11112 lossL: tensor(26641.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11113 lossL: tensor(27525.6348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11114 lossL: tensor(32036.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11115 lossL: tensor(28452.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11116 lossL: tensor(29586.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11117 lossL: tensor(25740.1426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11118 lossL: tensor(23361.5918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11119 lossL: tensor(33247.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11120 lossL: tensor(23917.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11121 lossL: tensor(24450.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11122 lossL: tensor(27831.1230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11123 lossL: tensor(27788.8809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11124 lossL: tensor(24215.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11125 lossL: tensor(26399.4160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11126 lossL: tensor(25375.2520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11127 lossL: tensor(31034.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11128 lossL: tensor(24942.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11129 lossL: tensor(26548.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11130 lossL: tensor(33133.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11131 lossL: tensor(28669.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11132 lossL: tensor(29919.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11133 lossL: tensor(27042.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11134 lossL: tensor(27096.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11135 lossL: tensor(26395.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11136 lossL: tensor(30036.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11137 lossL: tensor(22177.4707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11138 lossL: tensor(26159.3418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11139 lossL: tensor(24010.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11140 lossL: tensor(22196.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11141 lossL: tensor(35304.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11142 lossL: tensor(28864.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11143 lossL: tensor(27654.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11144 lossL: tensor(31458.8789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11145 lossL: tensor(31330.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11146 lossL: tensor(30027.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11147 lossL: tensor(28142.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11148 lossL: tensor(25244.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11149 lossL: tensor(26274.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11150 lossL: tensor(24661.5059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11151 lossL: tensor(27935.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11152 lossL: tensor(24200.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11153 lossL: tensor(27209.3652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11154 lossL: tensor(25488.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11155 lossL: tensor(23504.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11156 lossL: tensor(26675.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11157 lossL: tensor(28667.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11158 lossL: tensor(27475.6387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11159 lossL: tensor(27520.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11160 lossL: tensor(23427.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11161 lossL: tensor(29163.7051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11162 lossL: tensor(28335.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11163 lossL: tensor(28400.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11164 lossL: tensor(29219.7207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11165 lossL: tensor(29618.6504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11166 lossL: tensor(30139.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11167 lossL: tensor(25250.5449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11168 lossL: tensor(23210.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11169 lossL: tensor(25370.7402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11170 lossL: tensor(28754.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11171 lossL: tensor(25015.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11172 lossL: tensor(30650.0410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11173 lossL: tensor(28048.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11174 lossL: tensor(28816.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11175 lossL: tensor(26729.6855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11176 lossL: tensor(29625.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11177 lossL: tensor(33875.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11178 lossL: tensor(24085.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11179 lossL: tensor(25453.5645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11180 lossL: tensor(27388.1035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11181 lossL: tensor(28857.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11182 lossL: tensor(23532.8535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11183 lossL: tensor(23352.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11184 lossL: tensor(25753.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11185 lossL: tensor(25840.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11186 lossL: tensor(24345.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11187 lossL: tensor(26558.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11188 lossL: tensor(22424.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11189 lossL: tensor(24427.7207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11190 lossL: tensor(26503.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11191 lossL: tensor(26649.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11192 lossL: tensor(25684.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11193 lossL: tensor(25337.2598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11194 lossL: tensor(22853.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11195 lossL: tensor(28417.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11196 lossL: tensor(23472.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11197 lossL: tensor(27324.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11198 lossL: tensor(24476.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11199 lossL: tensor(26600.6699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11200 lossL: tensor(26844.6816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11201 lossL: tensor(30505.1543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11202 lossL: tensor(25274.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11203 lossL: tensor(28565.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11204 lossL: tensor(23437.6465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11205 lossL: tensor(28785.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11206 lossL: tensor(24820.6348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11207 lossL: tensor(28281.4902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11208 lossL: tensor(28256.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11209 lossL: tensor(31819.8730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11210 lossL: tensor(27370.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11211 lossL: tensor(28882.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11212 lossL: tensor(24839.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11213 lossL: tensor(27433.7441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11214 lossL: tensor(25391.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11215 lossL: tensor(23937.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11216 lossL: tensor(27893.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11217 lossL: tensor(28296.5723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11218 lossL: tensor(26735.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11219 lossL: tensor(26806.4863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11220 lossL: tensor(26627.4512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11221 lossL: tensor(27778.9824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11222 lossL: tensor(23835.2559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11223 lossL: tensor(25323.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11224 lossL: tensor(24611.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11225 lossL: tensor(26205.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11226 lossL: tensor(28153.8184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11227 lossL: tensor(24601.2129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11228 lossL: tensor(25698.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11229 lossL: tensor(22794.5957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11230 lossL: tensor(25143.5684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11231 lossL: tensor(22500.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11232 lossL: tensor(28866.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11233 lossL: tensor(24321.6738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11234 lossL: tensor(26212.5371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11235 lossL: tensor(21888.4629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11236 lossL: tensor(24791.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11237 lossL: tensor(26691.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11238 lossL: tensor(26182.8223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11239 lossL: tensor(24947.0527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11240 lossL: tensor(25437.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11241 lossL: tensor(26255.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11242 lossL: tensor(25090.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11243 lossL: tensor(29212.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11244 lossL: tensor(26397.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11245 lossL: tensor(26323.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11246 lossL: tensor(26080.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11247 lossL: tensor(25866.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11248 lossL: tensor(20162.7285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "11249 lossL: tensor(27311.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11250 lossL: tensor(26264.3652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11251 lossL: tensor(26436.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11252 lossL: tensor(21397.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11253 lossL: tensor(29001.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11254 lossL: tensor(25196.1855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11255 lossL: tensor(19423.9238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "11256 lossL: tensor(21703.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11257 lossL: tensor(26056.4043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11258 lossL: tensor(19795.6191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11259 lossL: tensor(30474.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11260 lossL: tensor(29534.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11261 lossL: tensor(26446.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11262 lossL: tensor(24970.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11263 lossL: tensor(25824.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11264 lossL: tensor(27318.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11265 lossL: tensor(26154.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11266 lossL: tensor(25511.4512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11267 lossL: tensor(23015.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11268 lossL: tensor(21535.1738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11269 lossL: tensor(22884.0996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11270 lossL: tensor(24250.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11271 lossL: tensor(29523.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11272 lossL: tensor(23370.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11273 lossL: tensor(25003.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11274 lossL: tensor(23941.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11275 lossL: tensor(25087.1973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11276 lossL: tensor(25076.6348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11277 lossL: tensor(23274.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11278 lossL: tensor(26038.1191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11279 lossL: tensor(19490.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11280 lossL: tensor(26709.0918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11281 lossL: tensor(23757.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11282 lossL: tensor(22316.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11283 lossL: tensor(20385.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11284 lossL: tensor(23604.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11285 lossL: tensor(22538.9668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11286 lossL: tensor(22559.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11287 lossL: tensor(26628.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11288 lossL: tensor(24146.0918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11289 lossL: tensor(23713.1152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11290 lossL: tensor(22152.4160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11291 lossL: tensor(23013.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11292 lossL: tensor(20708.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11293 lossL: tensor(18585.0723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "11294 lossL: tensor(24657.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11295 lossL: tensor(25333.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11296 lossL: tensor(29579.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11297 lossL: tensor(27905.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11298 lossL: tensor(25294.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11299 lossL: tensor(22741.2285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11300 lossL: tensor(21506.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11301 lossL: tensor(28118.1152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11302 lossL: tensor(27533.2676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11303 lossL: tensor(26317.7051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11304 lossL: tensor(24943.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11305 lossL: tensor(22841.3770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11306 lossL: tensor(25186.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11307 lossL: tensor(23552.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11308 lossL: tensor(24073.7949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11309 lossL: tensor(21472.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11310 lossL: tensor(19868.0059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11311 lossL: tensor(22268.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11312 lossL: tensor(27229.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11313 lossL: tensor(23386.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11314 lossL: tensor(28858.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11315 lossL: tensor(23356.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11316 lossL: tensor(24583.4121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11317 lossL: tensor(29608.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11318 lossL: tensor(22084.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11319 lossL: tensor(29411.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11320 lossL: tensor(28237.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11321 lossL: tensor(24756.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11322 lossL: tensor(27917.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11323 lossL: tensor(22804.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11324 lossL: tensor(20853.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11325 lossL: tensor(23355.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11326 lossL: tensor(23366.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11327 lossL: tensor(22875.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11328 lossL: tensor(24856.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11329 lossL: tensor(23266.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11330 lossL: tensor(23354.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11331 lossL: tensor(22804.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11332 lossL: tensor(28096.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11333 lossL: tensor(23353.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11334 lossL: tensor(21069.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11335 lossL: tensor(27271.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11336 lossL: tensor(23996.8965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11337 lossL: tensor(26490.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11338 lossL: tensor(19760.1621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11339 lossL: tensor(22409.2715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11340 lossL: tensor(29986.8184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11341 lossL: tensor(23459.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11342 lossL: tensor(23029.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11343 lossL: tensor(22489.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11344 lossL: tensor(22835.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11345 lossL: tensor(24926.1582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11346 lossL: tensor(23788.3105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11347 lossL: tensor(24632.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11348 lossL: tensor(27039.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11349 lossL: tensor(23561.7949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11350 lossL: tensor(24887.2480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11351 lossL: tensor(24039.7637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11352 lossL: tensor(23198.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11353 lossL: tensor(20643.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11354 lossL: tensor(19295.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11355 lossL: tensor(23690.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11356 lossL: tensor(23188.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11357 lossL: tensor(24150.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11358 lossL: tensor(21951.3379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11359 lossL: tensor(18946.6191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11360 lossL: tensor(28806.9824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11361 lossL: tensor(23035.5449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11362 lossL: tensor(24271.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11363 lossL: tensor(24089.2559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11364 lossL: tensor(25130.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11365 lossL: tensor(23161.0879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11366 lossL: tensor(23386.3418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11367 lossL: tensor(24176.1113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11368 lossL: tensor(22985.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11369 lossL: tensor(22572.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11370 lossL: tensor(26838.0332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11371 lossL: tensor(26037.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11372 lossL: tensor(23268.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11373 lossL: tensor(27032.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11374 lossL: tensor(23188.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11375 lossL: tensor(22739.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11376 lossL: tensor(22991.2285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11377 lossL: tensor(24442.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11378 lossL: tensor(28711.3105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11379 lossL: tensor(20165.2598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11380 lossL: tensor(20057.2246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11381 lossL: tensor(22317.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11382 lossL: tensor(21905.5137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11383 lossL: tensor(23931.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11384 lossL: tensor(23438.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11385 lossL: tensor(24206.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11386 lossL: tensor(18713.5957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11387 lossL: tensor(21996.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11388 lossL: tensor(20640.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11389 lossL: tensor(22118.7090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11390 lossL: tensor(21774.9238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11391 lossL: tensor(26203.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11392 lossL: tensor(21132.5215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11393 lossL: tensor(22337.0254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11394 lossL: tensor(23767.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11395 lossL: tensor(23841.0645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11396 lossL: tensor(21985.2793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11397 lossL: tensor(22686.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11398 lossL: tensor(24155.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11399 lossL: tensor(24101.8691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11400 lossL: tensor(26521.3730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11401 lossL: tensor(23735.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11402 lossL: tensor(23970.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11403 lossL: tensor(25001.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11404 lossL: tensor(26913.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11405 lossL: tensor(22695.9902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11406 lossL: tensor(24289.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11407 lossL: tensor(21036.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11408 lossL: tensor(22533.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11409 lossL: tensor(18356.0723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "11410 lossL: tensor(19474.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11411 lossL: tensor(20253.6738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11412 lossL: tensor(21666., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11413 lossL: tensor(22847.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11414 lossL: tensor(18802.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11415 lossL: tensor(22529.5488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11416 lossL: tensor(22926.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11417 lossL: tensor(23709.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11418 lossL: tensor(25637.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11419 lossL: tensor(22377.5371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11420 lossL: tensor(22140.1191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11421 lossL: tensor(22893.8809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11422 lossL: tensor(19361.0254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11423 lossL: tensor(26598.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11424 lossL: tensor(23401.9160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11425 lossL: tensor(20303.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11426 lossL: tensor(23888.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11427 lossL: tensor(21530.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11428 lossL: tensor(24025.8965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11429 lossL: tensor(25465.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11430 lossL: tensor(21385.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11431 lossL: tensor(24413.6543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11432 lossL: tensor(21606.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11433 lossL: tensor(22977.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11434 lossL: tensor(24023.6270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11435 lossL: tensor(18609.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11436 lossL: tensor(21989.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11437 lossL: tensor(22806.8340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11438 lossL: tensor(22835.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11439 lossL: tensor(18710.4551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11440 lossL: tensor(20230.7051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11441 lossL: tensor(19252.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11442 lossL: tensor(18899.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11443 lossL: tensor(22587.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11444 lossL: tensor(24615.8730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11445 lossL: tensor(18937.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11446 lossL: tensor(22197.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11447 lossL: tensor(19992.0371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11448 lossL: tensor(24447.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11449 lossL: tensor(20765.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11450 lossL: tensor(17572.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "11451 lossL: tensor(22934.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11452 lossL: tensor(21093.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11453 lossL: tensor(22495.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11454 lossL: tensor(20723.7324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11455 lossL: tensor(19130.6270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11456 lossL: tensor(20480.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11457 lossL: tensor(23933.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11458 lossL: tensor(21505.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11459 lossL: tensor(18994.6211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11460 lossL: tensor(22050.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11461 lossL: tensor(21452.5215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11462 lossL: tensor(21338.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11463 lossL: tensor(23105.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11464 lossL: tensor(21471.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11465 lossL: tensor(20992.8223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11466 lossL: tensor(21364.5332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11467 lossL: tensor(20084.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11468 lossL: tensor(24062.5430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11469 lossL: tensor(24976.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11470 lossL: tensor(22854.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11471 lossL: tensor(20028.9902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11472 lossL: tensor(28268.5645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11473 lossL: tensor(22805.9551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11474 lossL: tensor(24788.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11475 lossL: tensor(22948.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11476 lossL: tensor(23025.2012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11477 lossL: tensor(25507.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11478 lossL: tensor(20485.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11479 lossL: tensor(22989.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11480 lossL: tensor(20230.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11481 lossL: tensor(21023.7246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11482 lossL: tensor(22306.9863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11483 lossL: tensor(29021.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11484 lossL: tensor(18245.2168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11485 lossL: tensor(22594.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11486 lossL: tensor(21592.5137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11487 lossL: tensor(21031.3066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11488 lossL: tensor(22966.0176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11489 lossL: tensor(17647.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11490 lossL: tensor(19344.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11491 lossL: tensor(23878.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11492 lossL: tensor(20077.6973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11493 lossL: tensor(21903.3926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11494 lossL: tensor(20392.7949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11495 lossL: tensor(19822.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11496 lossL: tensor(20780.8340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11497 lossL: tensor(18995.0410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11498 lossL: tensor(24571.0605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11499 lossL: tensor(24430.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11500 lossL: tensor(22415.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11501 lossL: tensor(18474.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11502 lossL: tensor(24105.2832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11503 lossL: tensor(21823.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11504 lossL: tensor(20415.9238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11505 lossL: tensor(21015.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11506 lossL: tensor(19398.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11507 lossL: tensor(24017.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11508 lossL: tensor(19550.7168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11509 lossL: tensor(22431.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11510 lossL: tensor(20293.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11511 lossL: tensor(22461.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11512 lossL: tensor(19494.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11513 lossL: tensor(21914.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11514 lossL: tensor(18250.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11515 lossL: tensor(20697.8496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11516 lossL: tensor(23659.2559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11517 lossL: tensor(15696.5635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "11518 lossL: tensor(20092.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11519 lossL: tensor(19515.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11520 lossL: tensor(24418.2598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11521 lossL: tensor(22252.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11522 lossL: tensor(25009.5957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11523 lossL: tensor(23086.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11524 lossL: tensor(21403.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11525 lossL: tensor(17474.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11526 lossL: tensor(21956.9824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11527 lossL: tensor(20159.4746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11528 lossL: tensor(23163.6074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11529 lossL: tensor(19907.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11530 lossL: tensor(25343.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11531 lossL: tensor(20738.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11532 lossL: tensor(19269.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11533 lossL: tensor(18405.6621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11534 lossL: tensor(22023.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11535 lossL: tensor(18162.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11536 lossL: tensor(17574.5098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11537 lossL: tensor(21359.9941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11538 lossL: tensor(18161.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11539 lossL: tensor(22250.5332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11540 lossL: tensor(21176.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11541 lossL: tensor(20031.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11542 lossL: tensor(20552.0098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11543 lossL: tensor(17814.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11544 lossL: tensor(21966.8027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11545 lossL: tensor(19789.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11546 lossL: tensor(21403.5215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11547 lossL: tensor(22009.8789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11548 lossL: tensor(21353.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11549 lossL: tensor(18919.7910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11550 lossL: tensor(21614.3301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11551 lossL: tensor(20797.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11552 lossL: tensor(17911.8496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11553 lossL: tensor(22309.5879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11554 lossL: tensor(21301.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11555 lossL: tensor(19873.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11556 lossL: tensor(17579.6309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11557 lossL: tensor(22722.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11558 lossL: tensor(23278.7910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11559 lossL: tensor(16489.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11560 lossL: tensor(21891.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11561 lossL: tensor(22734.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11562 lossL: tensor(21265.1504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11563 lossL: tensor(17824.6211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11564 lossL: tensor(20198.3574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11565 lossL: tensor(20846.2480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11566 lossL: tensor(19378.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11567 lossL: tensor(24588.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11568 lossL: tensor(22441.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11569 lossL: tensor(20684.3965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11570 lossL: tensor(21556.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11571 lossL: tensor(18600.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11572 lossL: tensor(17336.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11573 lossL: tensor(22329.0840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11574 lossL: tensor(21577.2832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11575 lossL: tensor(18327.4707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11576 lossL: tensor(16632.1777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11577 lossL: tensor(17383.9785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11578 lossL: tensor(20415.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11579 lossL: tensor(21549.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11580 lossL: tensor(14404.1230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "11581 lossL: tensor(21573.2676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11582 lossL: tensor(19943.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11583 lossL: tensor(25146.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11584 lossL: tensor(19727.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11585 lossL: tensor(19817.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11586 lossL: tensor(16372.4619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11587 lossL: tensor(20611.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11588 lossL: tensor(20090.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11589 lossL: tensor(19915.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11590 lossL: tensor(21167.4707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11591 lossL: tensor(18691.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11592 lossL: tensor(20716.9395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11593 lossL: tensor(24353.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11594 lossL: tensor(16428.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11595 lossL: tensor(19771.9863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11596 lossL: tensor(17192.1426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11597 lossL: tensor(21797.1230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11598 lossL: tensor(19424.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11599 lossL: tensor(16118.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11600 lossL: tensor(19285.7012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11601 lossL: tensor(20036.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11602 lossL: tensor(18480.4512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11603 lossL: tensor(17366.1582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11604 lossL: tensor(18299.6309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11605 lossL: tensor(19985.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11606 lossL: tensor(18700.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11607 lossL: tensor(19430.9316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11608 lossL: tensor(19383.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11609 lossL: tensor(16702.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11610 lossL: tensor(19744.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11611 lossL: tensor(21676.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11612 lossL: tensor(18191.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11613 lossL: tensor(17225.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11614 lossL: tensor(19718.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11615 lossL: tensor(25699.0840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11616 lossL: tensor(18975.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11617 lossL: tensor(15956.9355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11618 lossL: tensor(19663.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11619 lossL: tensor(21094.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11620 lossL: tensor(19002.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11621 lossL: tensor(20517.5137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11622 lossL: tensor(18957.5176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11623 lossL: tensor(18781.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11624 lossL: tensor(17378.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11625 lossL: tensor(18987.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11626 lossL: tensor(19037.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11627 lossL: tensor(19789.6309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11628 lossL: tensor(21898.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11629 lossL: tensor(18092.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11630 lossL: tensor(18221.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11631 lossL: tensor(19036.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11632 lossL: tensor(18219.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11633 lossL: tensor(18678.4121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11634 lossL: tensor(19329.3301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11635 lossL: tensor(20452.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11636 lossL: tensor(19889.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11637 lossL: tensor(19767.5371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11638 lossL: tensor(17311.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11639 lossL: tensor(22086.6973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11640 lossL: tensor(18902.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11641 lossL: tensor(19831.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11642 lossL: tensor(21211.2148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11643 lossL: tensor(17224.0918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11644 lossL: tensor(21596.5293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11645 lossL: tensor(16850.4824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11646 lossL: tensor(18114.1543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11647 lossL: tensor(18414.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11648 lossL: tensor(14847.1865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11649 lossL: tensor(19534.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11650 lossL: tensor(19357.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11651 lossL: tensor(19063.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11652 lossL: tensor(19840.0527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11653 lossL: tensor(20482.8809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11654 lossL: tensor(20617.8418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11655 lossL: tensor(24176.7949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11656 lossL: tensor(21841.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11657 lossL: tensor(17070.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11658 lossL: tensor(18247.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11659 lossL: tensor(17343.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11660 lossL: tensor(19443.4863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11661 lossL: tensor(17408.6035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11662 lossL: tensor(19305.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11663 lossL: tensor(21871.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11664 lossL: tensor(21586.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11665 lossL: tensor(21393.8887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11666 lossL: tensor(18747.9473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11667 lossL: tensor(20386.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11668 lossL: tensor(18556.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11669 lossL: tensor(22999.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11670 lossL: tensor(19502.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11671 lossL: tensor(16380.4873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11672 lossL: tensor(16074.4785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11673 lossL: tensor(17523.4746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11674 lossL: tensor(17749.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11675 lossL: tensor(24774.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11676 lossL: tensor(21311.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11677 lossL: tensor(18599.1465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11678 lossL: tensor(19868.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11679 lossL: tensor(19798.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11680 lossL: tensor(19426.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11681 lossL: tensor(20455.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11682 lossL: tensor(19633.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11683 lossL: tensor(20872.1152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11684 lossL: tensor(17326.8262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11685 lossL: tensor(19079.7637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11686 lossL: tensor(20562.3262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11687 lossL: tensor(23108.1113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11688 lossL: tensor(20548.0723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11689 lossL: tensor(18629.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11690 lossL: tensor(18325.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11691 lossL: tensor(18824.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11692 lossL: tensor(17626.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11693 lossL: tensor(18587.3613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11694 lossL: tensor(21238.6074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11695 lossL: tensor(15854.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11696 lossL: tensor(16882.5645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11697 lossL: tensor(14706.3408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11698 lossL: tensor(18252.7363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11699 lossL: tensor(20705.7520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11700 lossL: tensor(16249.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11701 lossL: tensor(18403.9199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11702 lossL: tensor(18876.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11703 lossL: tensor(20644.5762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11704 lossL: tensor(18674.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11705 lossL: tensor(18431.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11706 lossL: tensor(21129.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11707 lossL: tensor(18473.1934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11708 lossL: tensor(20596.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11709 lossL: tensor(19419.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11710 lossL: tensor(18168.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11711 lossL: tensor(18731.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11712 lossL: tensor(17281.1113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11713 lossL: tensor(14386.1191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "11714 lossL: tensor(17451.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11715 lossL: tensor(15239.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11716 lossL: tensor(17914.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11717 lossL: tensor(22930.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11718 lossL: tensor(17938.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11719 lossL: tensor(19893.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11720 lossL: tensor(19970.8066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11721 lossL: tensor(19245.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11722 lossL: tensor(19325.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11723 lossL: tensor(22281.0215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11724 lossL: tensor(18298.0176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11725 lossL: tensor(20575.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11726 lossL: tensor(17014.1621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11727 lossL: tensor(21635.7676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11728 lossL: tensor(16881.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11729 lossL: tensor(21572.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11730 lossL: tensor(17294.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11731 lossL: tensor(17302.9316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11732 lossL: tensor(15771.3613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11733 lossL: tensor(17825.1816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11734 lossL: tensor(18860.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11735 lossL: tensor(16859.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11736 lossL: tensor(18775.9902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11737 lossL: tensor(20039.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11738 lossL: tensor(20012.6348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11739 lossL: tensor(18444.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11740 lossL: tensor(19245.9785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11741 lossL: tensor(18404.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11742 lossL: tensor(16795.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11743 lossL: tensor(16502.0293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11744 lossL: tensor(22208.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11745 lossL: tensor(17262.8887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11746 lossL: tensor(14504.9209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11747 lossL: tensor(14562.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11748 lossL: tensor(18486.9160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11749 lossL: tensor(16035.5215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11750 lossL: tensor(19517.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11751 lossL: tensor(17716.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11752 lossL: tensor(18032.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11753 lossL: tensor(18360.2285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11754 lossL: tensor(18583.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11755 lossL: tensor(22732.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11756 lossL: tensor(18462.3379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11757 lossL: tensor(19507.7402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11758 lossL: tensor(16627.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11759 lossL: tensor(18893.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11760 lossL: tensor(18249.3066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11761 lossL: tensor(18407.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11762 lossL: tensor(20259.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11763 lossL: tensor(19222.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11764 lossL: tensor(15650.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11765 lossL: tensor(17836.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11766 lossL: tensor(16942.2637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11767 lossL: tensor(15530.8330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11768 lossL: tensor(19244.7988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11769 lossL: tensor(14582.9795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11770 lossL: tensor(18994.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11771 lossL: tensor(17934.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11772 lossL: tensor(17143.7949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11773 lossL: tensor(16649.4102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11774 lossL: tensor(15148.1123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11775 lossL: tensor(19017.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11776 lossL: tensor(18797.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11777 lossL: tensor(17700.9082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11778 lossL: tensor(17821.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11779 lossL: tensor(18156.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11780 lossL: tensor(20906.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11781 lossL: tensor(15504.8418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11782 lossL: tensor(18346.8809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11783 lossL: tensor(17473.5332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11784 lossL: tensor(16456.8301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11785 lossL: tensor(16600.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11786 lossL: tensor(14711.9150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11787 lossL: tensor(18100.7910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11788 lossL: tensor(17592.6855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11789 lossL: tensor(19659.0371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11790 lossL: tensor(15760.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11791 lossL: tensor(15374.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11792 lossL: tensor(20545.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11793 lossL: tensor(18857.0293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11794 lossL: tensor(16030., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11795 lossL: tensor(13801.5518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "11796 lossL: tensor(16271.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11797 lossL: tensor(18747.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11798 lossL: tensor(20010.9824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11799 lossL: tensor(17232.1387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11800 lossL: tensor(18515.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11801 lossL: tensor(18335.5527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11802 lossL: tensor(18125.0918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11803 lossL: tensor(18571.7832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11804 lossL: tensor(19346.5449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11805 lossL: tensor(16348.5088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11806 lossL: tensor(16339.5840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11807 lossL: tensor(16543.7676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11808 lossL: tensor(18645.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11809 lossL: tensor(19914.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11810 lossL: tensor(16588.7285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11811 lossL: tensor(13832.8340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11812 lossL: tensor(20583.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11813 lossL: tensor(14869.6553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11814 lossL: tensor(15371.5088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11815 lossL: tensor(14920.4209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11816 lossL: tensor(13163.9121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "11817 lossL: tensor(17037.0918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11818 lossL: tensor(15740.1826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11819 lossL: tensor(16643.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11820 lossL: tensor(15929.6514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11821 lossL: tensor(19109.0371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11822 lossL: tensor(16489.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11823 lossL: tensor(18853.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11824 lossL: tensor(16033.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11825 lossL: tensor(15734.0225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11826 lossL: tensor(16714.3613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11827 lossL: tensor(18945.5762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11828 lossL: tensor(19038.7285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11829 lossL: tensor(18211.3379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11830 lossL: tensor(15487.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11831 lossL: tensor(12706.4863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "11832 lossL: tensor(14798.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11833 lossL: tensor(16737.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11834 lossL: tensor(17276.4004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11835 lossL: tensor(14831.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11836 lossL: tensor(17827.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11837 lossL: tensor(13911.1904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11838 lossL: tensor(15806.4541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11839 lossL: tensor(18720.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11840 lossL: tensor(19165.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11841 lossL: tensor(17692.3926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11842 lossL: tensor(16846.6543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11843 lossL: tensor(15016.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11844 lossL: tensor(21409.1973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11845 lossL: tensor(18731.3535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11846 lossL: tensor(18088.1855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11847 lossL: tensor(15394.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11848 lossL: tensor(17284.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11849 lossL: tensor(17231.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11850 lossL: tensor(17629.7168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11851 lossL: tensor(17445.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11852 lossL: tensor(15328.7588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11853 lossL: tensor(17284.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11854 lossL: tensor(17718.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11855 lossL: tensor(15997.2090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11856 lossL: tensor(17756.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11857 lossL: tensor(15663.1387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11858 lossL: tensor(19567.8926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11859 lossL: tensor(17547.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11860 lossL: tensor(15612.6631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11861 lossL: tensor(13793.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11862 lossL: tensor(12984.6035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11863 lossL: tensor(16875.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11864 lossL: tensor(17834.4863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11865 lossL: tensor(19742.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11866 lossL: tensor(18126.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11867 lossL: tensor(18433.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11868 lossL: tensor(18647.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11869 lossL: tensor(15730.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11870 lossL: tensor(19943.7676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11871 lossL: tensor(20408.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11872 lossL: tensor(15760.3252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11873 lossL: tensor(12711.9209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11874 lossL: tensor(19687.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11875 lossL: tensor(17946.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11876 lossL: tensor(15596.7451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11877 lossL: tensor(15615.1904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11878 lossL: tensor(18427.4434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11879 lossL: tensor(16779.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11880 lossL: tensor(16293.2725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11881 lossL: tensor(18395.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11882 lossL: tensor(15717.6240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11883 lossL: tensor(14916.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11884 lossL: tensor(16272.3721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11885 lossL: tensor(17950.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11886 lossL: tensor(18352.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11887 lossL: tensor(13629.6865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11888 lossL: tensor(15021.8691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11889 lossL: tensor(17692.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11890 lossL: tensor(14233.3213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11891 lossL: tensor(19164.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11892 lossL: tensor(14557.9463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11893 lossL: tensor(16843.5449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11894 lossL: tensor(17449.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11895 lossL: tensor(15671.4150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11896 lossL: tensor(16394.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11897 lossL: tensor(15929.2197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11898 lossL: tensor(20513.9863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11899 lossL: tensor(14725.4561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11900 lossL: tensor(15619.1494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11901 lossL: tensor(17559.0059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11902 lossL: tensor(19162.4199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11903 lossL: tensor(15723.8213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11904 lossL: tensor(15311.9199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11905 lossL: tensor(19459.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11906 lossL: tensor(19308.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11907 lossL: tensor(15799.4561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11908 lossL: tensor(14751.8271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11909 lossL: tensor(15736.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11910 lossL: tensor(16102.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11911 lossL: tensor(17267.2207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11912 lossL: tensor(18202.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11913 lossL: tensor(15695.5869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11914 lossL: tensor(16839.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11915 lossL: tensor(16431.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11916 lossL: tensor(14838.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11917 lossL: tensor(15322.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11918 lossL: tensor(16290.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11919 lossL: tensor(14651.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11920 lossL: tensor(17556.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11921 lossL: tensor(16558.7988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11922 lossL: tensor(15445.0088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11923 lossL: tensor(16437.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11924 lossL: tensor(15977.8105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11925 lossL: tensor(17185.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11926 lossL: tensor(16298.1162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11927 lossL: tensor(14584.0059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11928 lossL: tensor(15345.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11929 lossL: tensor(15649.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11930 lossL: tensor(16882.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11931 lossL: tensor(13609.5176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11932 lossL: tensor(11863.6318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "11933 lossL: tensor(14347.4248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11934 lossL: tensor(18180.9004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11935 lossL: tensor(15073.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11936 lossL: tensor(15483.7725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11937 lossL: tensor(15967.4033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11938 lossL: tensor(15299.2949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11939 lossL: tensor(16544.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11940 lossL: tensor(13524.1035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11941 lossL: tensor(13309.9473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11942 lossL: tensor(18603.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11943 lossL: tensor(15672.4092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11944 lossL: tensor(17219.3652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11945 lossL: tensor(17404.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11946 lossL: tensor(16425.1855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11947 lossL: tensor(15324.5420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11948 lossL: tensor(12545.9463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11949 lossL: tensor(13808.9150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11950 lossL: tensor(15296.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11951 lossL: tensor(17172.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11952 lossL: tensor(15318.7881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11953 lossL: tensor(15673.4785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11954 lossL: tensor(16203.8350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11955 lossL: tensor(16338.2432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11956 lossL: tensor(12481.8818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11957 lossL: tensor(12859.8994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11958 lossL: tensor(18830.2363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11959 lossL: tensor(14610.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11960 lossL: tensor(15588.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11961 lossL: tensor(14143.8389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11962 lossL: tensor(18225.6543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11963 lossL: tensor(16072.3174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11964 lossL: tensor(19481.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11965 lossL: tensor(15225.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11966 lossL: tensor(16316.6504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11967 lossL: tensor(17330.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11968 lossL: tensor(18432.4199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11969 lossL: tensor(18216.2246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11970 lossL: tensor(18952.4355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11971 lossL: tensor(18128.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11972 lossL: tensor(14839.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11973 lossL: tensor(18002.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11974 lossL: tensor(14578.0967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11975 lossL: tensor(12780.6104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11976 lossL: tensor(15414.9854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11977 lossL: tensor(19329.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11978 lossL: tensor(12705.4229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11979 lossL: tensor(15697.5830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11980 lossL: tensor(15995.0127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11981 lossL: tensor(16043.9521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11982 lossL: tensor(16858.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11983 lossL: tensor(18829.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11984 lossL: tensor(12677.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11985 lossL: tensor(14973.6494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11986 lossL: tensor(17041.7949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11987 lossL: tensor(17187.5449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11988 lossL: tensor(15154.2041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11989 lossL: tensor(14011.3408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11990 lossL: tensor(15807.5361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11991 lossL: tensor(15465.2041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11992 lossL: tensor(17651.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11993 lossL: tensor(17007.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11994 lossL: tensor(16284.7832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11995 lossL: tensor(15137.3652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11996 lossL: tensor(14055.2236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11997 lossL: tensor(14212.1318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11998 lossL: tensor(15429.1318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "11999 lossL: tensor(13824.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12000 lossL: tensor(13241.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12001 lossL: tensor(15209.1650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12002 lossL: tensor(14173.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12003 lossL: tensor(12864.9717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12004 lossL: tensor(15610.9160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12005 lossL: tensor(17840.2832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12006 lossL: tensor(14794.6504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12007 lossL: tensor(14322.3682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12008 lossL: tensor(18342.1504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12009 lossL: tensor(15585.6475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12010 lossL: tensor(16356.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12011 lossL: tensor(13333.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12012 lossL: tensor(15771.5049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12013 lossL: tensor(13175.5713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12014 lossL: tensor(16600.6270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12015 lossL: tensor(16961.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12016 lossL: tensor(17784.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12017 lossL: tensor(17296.8730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12018 lossL: tensor(13341.9736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12019 lossL: tensor(14889.1299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12020 lossL: tensor(12650.8389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12021 lossL: tensor(15088.2949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12022 lossL: tensor(15919.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12023 lossL: tensor(13748.4268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12024 lossL: tensor(11251.8262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "12025 lossL: tensor(16298.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12026 lossL: tensor(15433.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12027 lossL: tensor(14918.5957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12028 lossL: tensor(15117.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12029 lossL: tensor(15766.5225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12030 lossL: tensor(16127.4893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12031 lossL: tensor(17041.0371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12032 lossL: tensor(13805.1318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12033 lossL: tensor(15077.0596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12034 lossL: tensor(15207.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12035 lossL: tensor(16305.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12036 lossL: tensor(16279.6826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12037 lossL: tensor(14092.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12038 lossL: tensor(13839.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12039 lossL: tensor(15985.5107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12040 lossL: tensor(17619.6699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12041 lossL: tensor(16059.9795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12042 lossL: tensor(13945.3096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12043 lossL: tensor(13138.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12044 lossL: tensor(13746.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12045 lossL: tensor(17542.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12046 lossL: tensor(15276.8291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12047 lossL: tensor(15538.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12048 lossL: tensor(17853.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12049 lossL: tensor(12488.6201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12050 lossL: tensor(13645.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12051 lossL: tensor(13520.6348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12052 lossL: tensor(12692.1318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12053 lossL: tensor(13465.4824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12054 lossL: tensor(12054.8750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12055 lossL: tensor(12285.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12056 lossL: tensor(14549.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12057 lossL: tensor(13216.0322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12058 lossL: tensor(13327.0410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12059 lossL: tensor(14266.0283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12060 lossL: tensor(13692.3604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12061 lossL: tensor(16496.8457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12062 lossL: tensor(15508.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12063 lossL: tensor(11651.8037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12064 lossL: tensor(15517.6738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12065 lossL: tensor(13209.6650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12066 lossL: tensor(19098.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12067 lossL: tensor(17623.1953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12068 lossL: tensor(14749.9912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12069 lossL: tensor(15766.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12070 lossL: tensor(14167.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12071 lossL: tensor(12685.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12072 lossL: tensor(14088.8896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12073 lossL: tensor(19900.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12074 lossL: tensor(11908.0527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12075 lossL: tensor(12932.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12076 lossL: tensor(13752.0342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12077 lossL: tensor(13504.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12078 lossL: tensor(17789.6660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12079 lossL: tensor(13239.7803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12080 lossL: tensor(14749.0381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12081 lossL: tensor(13994.1025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12082 lossL: tensor(14108.1162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12083 lossL: tensor(17263.1465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12084 lossL: tensor(12426.3965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12085 lossL: tensor(13003.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12086 lossL: tensor(16166.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12087 lossL: tensor(13284.7002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12088 lossL: tensor(16050.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12089 lossL: tensor(14217.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12090 lossL: tensor(14087.5420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12091 lossL: tensor(12920.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12092 lossL: tensor(13767.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12093 lossL: tensor(16457.9238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12094 lossL: tensor(17566.1621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12095 lossL: tensor(15230.1270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12096 lossL: tensor(14831.3965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12097 lossL: tensor(13079.9561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12098 lossL: tensor(15977.4785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12099 lossL: tensor(15145.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12100 lossL: tensor(13835.7510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12101 lossL: tensor(15188.5264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12102 lossL: tensor(14239.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12103 lossL: tensor(16650.1582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12104 lossL: tensor(16970.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12105 lossL: tensor(11559.3965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12106 lossL: tensor(11675.2021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12107 lossL: tensor(13177.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12108 lossL: tensor(17237.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12109 lossL: tensor(14956.8857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12110 lossL: tensor(16077.0293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12111 lossL: tensor(16384.4004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12112 lossL: tensor(14740.4512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12113 lossL: tensor(13395.8652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12114 lossL: tensor(17856.5449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12115 lossL: tensor(12854.6162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12116 lossL: tensor(15533.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12117 lossL: tensor(14805.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12118 lossL: tensor(13581.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12119 lossL: tensor(14272.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12120 lossL: tensor(16354.9678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12121 lossL: tensor(11240.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "12122 lossL: tensor(14413.6807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12123 lossL: tensor(13754.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12124 lossL: tensor(15039.9199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12125 lossL: tensor(13639.7080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12126 lossL: tensor(14512.4639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12127 lossL: tensor(17653.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12128 lossL: tensor(13733.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12129 lossL: tensor(15413.7246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12130 lossL: tensor(15890.3604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12131 lossL: tensor(14016.7354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12132 lossL: tensor(12782.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12133 lossL: tensor(12015.2314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12134 lossL: tensor(15905.5498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12135 lossL: tensor(13388.2480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12136 lossL: tensor(12515.2275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12137 lossL: tensor(13197.4639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12138 lossL: tensor(15998.7246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12139 lossL: tensor(15653.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12140 lossL: tensor(12626.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12141 lossL: tensor(13141.2451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12142 lossL: tensor(14012.1035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12143 lossL: tensor(15118.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12144 lossL: tensor(12640.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12145 lossL: tensor(14356.1514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12146 lossL: tensor(14898.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12147 lossL: tensor(15618.8682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12148 lossL: tensor(13289.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12149 lossL: tensor(12396.0869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12150 lossL: tensor(10981.7285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "12151 lossL: tensor(13779.3721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12152 lossL: tensor(10135.1777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "12153 lossL: tensor(14045.1514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12154 lossL: tensor(12599.9736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12155 lossL: tensor(12583.3291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12156 lossL: tensor(13701.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12157 lossL: tensor(14789.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12158 lossL: tensor(11064.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12159 lossL: tensor(13166.0840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12160 lossL: tensor(13092.9912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12161 lossL: tensor(13271.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12162 lossL: tensor(16809.5098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12163 lossL: tensor(12557.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12164 lossL: tensor(15251.6709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12165 lossL: tensor(13760.1387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12166 lossL: tensor(11026.0049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12167 lossL: tensor(17527.8730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12168 lossL: tensor(16055.7051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12169 lossL: tensor(12940.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12170 lossL: tensor(13072.4814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12171 lossL: tensor(12956.1240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12172 lossL: tensor(13094.2637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12173 lossL: tensor(14735.2061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12174 lossL: tensor(15283.5283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12175 lossL: tensor(15776.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12176 lossL: tensor(13664.2559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12177 lossL: tensor(11941.3213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12178 lossL: tensor(12520.5449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12179 lossL: tensor(13110.2529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12180 lossL: tensor(13115.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12181 lossL: tensor(14747.7217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12182 lossL: tensor(12239.5029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12183 lossL: tensor(14323.4111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12184 lossL: tensor(15135.0869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12185 lossL: tensor(14063.0225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12186 lossL: tensor(13914.4170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12187 lossL: tensor(13253.5830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12188 lossL: tensor(15196.0449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12189 lossL: tensor(11615.8232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12190 lossL: tensor(13747.7041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12191 lossL: tensor(14859.5146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12192 lossL: tensor(12664.1338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12193 lossL: tensor(14473.2705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12194 lossL: tensor(14325.6973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12195 lossL: tensor(15209.7432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12196 lossL: tensor(17524.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12197 lossL: tensor(14046.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12198 lossL: tensor(15087.6855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12199 lossL: tensor(14637.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12200 lossL: tensor(13758.2559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12201 lossL: tensor(13432.5420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12202 lossL: tensor(12943.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12203 lossL: tensor(16136.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12204 lossL: tensor(14037.8486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12205 lossL: tensor(10458.4463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12206 lossL: tensor(14668.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12207 lossL: tensor(12220.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12208 lossL: tensor(14331.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12209 lossL: tensor(11503.1201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12210 lossL: tensor(13529.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12211 lossL: tensor(13179.6533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12212 lossL: tensor(13744.2451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12213 lossL: tensor(14670.5225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12214 lossL: tensor(11879.7607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12215 lossL: tensor(14470.7197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12216 lossL: tensor(14599.0771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12217 lossL: tensor(16478.8809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12218 lossL: tensor(15002.0059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12219 lossL: tensor(12731.5566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12220 lossL: tensor(14297.7090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12221 lossL: tensor(13111.2061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12222 lossL: tensor(10782.0889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12223 lossL: tensor(15470.5830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12224 lossL: tensor(14741.9268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12225 lossL: tensor(11578.2881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12226 lossL: tensor(13509.9434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12227 lossL: tensor(12096.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12228 lossL: tensor(13514.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12229 lossL: tensor(15629.2900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12230 lossL: tensor(14159.8408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12231 lossL: tensor(13138.0410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12232 lossL: tensor(12815.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12233 lossL: tensor(14687.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12234 lossL: tensor(12955.5498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12235 lossL: tensor(14866.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12236 lossL: tensor(11599.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12237 lossL: tensor(13912.8232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12238 lossL: tensor(12251.0176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12239 lossL: tensor(12447.7920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12240 lossL: tensor(14992.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12241 lossL: tensor(14592.6240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12242 lossL: tensor(13118.0918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12243 lossL: tensor(12750.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12244 lossL: tensor(14215.1260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12245 lossL: tensor(13822.3262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12246 lossL: tensor(14144.6855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12247 lossL: tensor(12492.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12248 lossL: tensor(11184.1777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12249 lossL: tensor(12670.2236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12250 lossL: tensor(14754.8408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12251 lossL: tensor(15041.6855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12252 lossL: tensor(17291.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12253 lossL: tensor(13767.8350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12254 lossL: tensor(14449.6865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12255 lossL: tensor(11113.3262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12256 lossL: tensor(10899.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12257 lossL: tensor(14316.7783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12258 lossL: tensor(11860.1514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12259 lossL: tensor(13373.8408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12260 lossL: tensor(14176.8223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12261 lossL: tensor(14131.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12262 lossL: tensor(14499.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12263 lossL: tensor(13355.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12264 lossL: tensor(15000.1191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12265 lossL: tensor(11558.5684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12266 lossL: tensor(12356.8525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12267 lossL: tensor(12098.4932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12268 lossL: tensor(14135.9043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12269 lossL: tensor(12945.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12270 lossL: tensor(14577.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12271 lossL: tensor(11918.3809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12272 lossL: tensor(13900.4521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12273 lossL: tensor(12180.3105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12274 lossL: tensor(13762.0205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12275 lossL: tensor(12962.0557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12276 lossL: tensor(11631.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12277 lossL: tensor(12808.8350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12278 lossL: tensor(10619.4697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12279 lossL: tensor(13074.6924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12280 lossL: tensor(13633.8213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12281 lossL: tensor(13252.6260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12282 lossL: tensor(12732.0361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12283 lossL: tensor(14389.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12284 lossL: tensor(12281.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12285 lossL: tensor(11816.0869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12286 lossL: tensor(13003.4717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12287 lossL: tensor(13798.7949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12288 lossL: tensor(12516.2207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12289 lossL: tensor(13447.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12290 lossL: tensor(15398.4814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12291 lossL: tensor(11400.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12292 lossL: tensor(12678.2959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12293 lossL: tensor(13463.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12294 lossL: tensor(12605.3633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12295 lossL: tensor(13939.4004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12296 lossL: tensor(10272.9932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12297 lossL: tensor(11741.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12298 lossL: tensor(13396.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12299 lossL: tensor(16337.9170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12300 lossL: tensor(12325.5986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12301 lossL: tensor(13195.7402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12302 lossL: tensor(10774.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12303 lossL: tensor(11851.2080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12304 lossL: tensor(12177.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12305 lossL: tensor(12105.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12306 lossL: tensor(13996.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12307 lossL: tensor(9704.1699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "12308 lossL: tensor(12266.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12309 lossL: tensor(10119.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12310 lossL: tensor(11902.1152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12311 lossL: tensor(12459.4951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12312 lossL: tensor(12918.3643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12313 lossL: tensor(11581.0186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12314 lossL: tensor(13260.6807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12315 lossL: tensor(14032.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12316 lossL: tensor(9600.0557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "12317 lossL: tensor(13372.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12318 lossL: tensor(9930.1230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12319 lossL: tensor(11853.5518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12320 lossL: tensor(11584.4736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12321 lossL: tensor(11279.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12322 lossL: tensor(12100.6064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12323 lossL: tensor(11300.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12324 lossL: tensor(10685.9248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12325 lossL: tensor(11245.2676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12326 lossL: tensor(10952.3467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12327 lossL: tensor(11287.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12328 lossL: tensor(14910.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12329 lossL: tensor(12064.2051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12330 lossL: tensor(12362.1904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12331 lossL: tensor(10370.6152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12332 lossL: tensor(12826.3936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12333 lossL: tensor(11727.9502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12334 lossL: tensor(14209.7510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12335 lossL: tensor(13964.6768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12336 lossL: tensor(13252.0166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12337 lossL: tensor(15575.2744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12338 lossL: tensor(12760.3037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12339 lossL: tensor(10862.6182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12340 lossL: tensor(13826.5459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12341 lossL: tensor(12078.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12342 lossL: tensor(14484.3936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12343 lossL: tensor(15121.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12344 lossL: tensor(14934.9131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12345 lossL: tensor(12565.6904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12346 lossL: tensor(14164.6670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12347 lossL: tensor(14608.7637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12348 lossL: tensor(13846.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12349 lossL: tensor(11223.5732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12350 lossL: tensor(14410.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12351 lossL: tensor(13419.7764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12352 lossL: tensor(12859.1982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12353 lossL: tensor(13558.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12354 lossL: tensor(11507.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12355 lossL: tensor(11760.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12356 lossL: tensor(11816.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12357 lossL: tensor(12320.6846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12358 lossL: tensor(11660.5723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12359 lossL: tensor(12205.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12360 lossL: tensor(11423.8066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12361 lossL: tensor(12583.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12362 lossL: tensor(14017.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12363 lossL: tensor(13286.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12364 lossL: tensor(12291.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12365 lossL: tensor(12849.9248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12366 lossL: tensor(12306.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12367 lossL: tensor(11174.1973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12368 lossL: tensor(13157.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12369 lossL: tensor(12001.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12370 lossL: tensor(12734.0732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12371 lossL: tensor(13967.2236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12372 lossL: tensor(12637.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12373 lossL: tensor(11619.0771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12374 lossL: tensor(11117.9912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12375 lossL: tensor(11677.4043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12376 lossL: tensor(13363.2363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12377 lossL: tensor(11960.2324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12378 lossL: tensor(11876.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12379 lossL: tensor(13220.6943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12380 lossL: tensor(12034.6846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12381 lossL: tensor(13203.2002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12382 lossL: tensor(11836.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12383 lossL: tensor(11854.1572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12384 lossL: tensor(13245.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12385 lossL: tensor(13088.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12386 lossL: tensor(12347.8643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12387 lossL: tensor(12606.6553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12388 lossL: tensor(10771.4795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12389 lossL: tensor(11077.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12390 lossL: tensor(13401.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12391 lossL: tensor(13030.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12392 lossL: tensor(12810.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12393 lossL: tensor(12261.8447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12394 lossL: tensor(11485.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12395 lossL: tensor(12794.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12396 lossL: tensor(10346.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12397 lossL: tensor(9245.9199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "12398 lossL: tensor(11860.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12399 lossL: tensor(12703.2080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12400 lossL: tensor(14157.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12401 lossL: tensor(11730.8975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12402 lossL: tensor(11775.1826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12403 lossL: tensor(13248.5771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12404 lossL: tensor(13927.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12405 lossL: tensor(13371.7988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12406 lossL: tensor(11083.9053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12407 lossL: tensor(12328.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12408 lossL: tensor(11937.3232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12409 lossL: tensor(10942.5830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12410 lossL: tensor(16323.3311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12411 lossL: tensor(10604.0342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12412 lossL: tensor(9785.9873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12413 lossL: tensor(14769.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12414 lossL: tensor(12815.7002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12415 lossL: tensor(15490.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12416 lossL: tensor(10721.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12417 lossL: tensor(15121.3379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12418 lossL: tensor(12041.1807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12419 lossL: tensor(12248.2939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12420 lossL: tensor(12266.6377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12421 lossL: tensor(12072.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12422 lossL: tensor(11792.8428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12423 lossL: tensor(12751.0732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12424 lossL: tensor(13720.4824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12425 lossL: tensor(12379.0264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12426 lossL: tensor(11517.2051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12427 lossL: tensor(11162.0898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12428 lossL: tensor(11896.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12429 lossL: tensor(13113.8301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12430 lossL: tensor(12134.5088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12431 lossL: tensor(11167.6396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12432 lossL: tensor(12510.2744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12433 lossL: tensor(11484.8496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12434 lossL: tensor(11478.5752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12435 lossL: tensor(11702.5479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12436 lossL: tensor(9679.1230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12437 lossL: tensor(11628.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12438 lossL: tensor(11013.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12439 lossL: tensor(11861.9863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12440 lossL: tensor(12421.8584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12441 lossL: tensor(11963.3291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12442 lossL: tensor(12248.4775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12443 lossL: tensor(11709.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12444 lossL: tensor(12129.5537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12445 lossL: tensor(8365.8057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "12446 lossL: tensor(11814.6543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12447 lossL: tensor(13226.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12448 lossL: tensor(10354.2021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12449 lossL: tensor(9514.3604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12450 lossL: tensor(12596.4619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12451 lossL: tensor(12363.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12452 lossL: tensor(13887.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12453 lossL: tensor(12490.3135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12454 lossL: tensor(11301.7939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12455 lossL: tensor(13950.8496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12456 lossL: tensor(10795.2832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12457 lossL: tensor(12400.3096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12458 lossL: tensor(11057.9541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12459 lossL: tensor(14148.0410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12460 lossL: tensor(12014.9756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12461 lossL: tensor(13076.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12462 lossL: tensor(14205.5801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12463 lossL: tensor(11751.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12464 lossL: tensor(10841.7041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12465 lossL: tensor(12395.7373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12466 lossL: tensor(11718.6533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12467 lossL: tensor(13186.8066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12468 lossL: tensor(11203.6348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12469 lossL: tensor(14289.4775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12470 lossL: tensor(13888.6221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12471 lossL: tensor(12510.9902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12472 lossL: tensor(11972.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12473 lossL: tensor(12347.4482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12474 lossL: tensor(10821.4521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12475 lossL: tensor(12469.9736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12476 lossL: tensor(12443., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12477 lossL: tensor(14171.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12478 lossL: tensor(12731.5498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12479 lossL: tensor(10305.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12480 lossL: tensor(11293.6465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12481 lossL: tensor(11637.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12482 lossL: tensor(13106.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12483 lossL: tensor(11426.8545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12484 lossL: tensor(13023.8232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12485 lossL: tensor(10899.0332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12486 lossL: tensor(14473.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12487 lossL: tensor(14578.6152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12488 lossL: tensor(9969.6377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12489 lossL: tensor(9455.6973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12490 lossL: tensor(9937.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12491 lossL: tensor(11024.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12492 lossL: tensor(14045.9004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12493 lossL: tensor(9752.0459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12494 lossL: tensor(10988.2197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12495 lossL: tensor(11276.9287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12496 lossL: tensor(10466.1572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12497 lossL: tensor(11444.8252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12498 lossL: tensor(11446.2295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12499 lossL: tensor(11281.8877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12500 lossL: tensor(12774.5381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12501 lossL: tensor(9189.1816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12502 lossL: tensor(12282.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12503 lossL: tensor(12034.0654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12504 lossL: tensor(9992.8662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12505 lossL: tensor(11707.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12506 lossL: tensor(12033.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12507 lossL: tensor(12718.9873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12508 lossL: tensor(9154.5537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12509 lossL: tensor(10725.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12510 lossL: tensor(12089.0879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12511 lossL: tensor(8894.5693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12512 lossL: tensor(12392.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12513 lossL: tensor(10264.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12514 lossL: tensor(12380.0186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12515 lossL: tensor(11374.8877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12516 lossL: tensor(9634.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12517 lossL: tensor(11457.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12518 lossL: tensor(11333.0684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12519 lossL: tensor(13838.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12520 lossL: tensor(11495.0244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12521 lossL: tensor(10117.5947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12522 lossL: tensor(10926.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12523 lossL: tensor(11857.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12524 lossL: tensor(18007.2051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12525 lossL: tensor(11627.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12526 lossL: tensor(12847.0283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12527 lossL: tensor(13008.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12528 lossL: tensor(10676.7881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12529 lossL: tensor(10431.5186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12530 lossL: tensor(12210.1514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12531 lossL: tensor(10779.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12532 lossL: tensor(11351.6543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12533 lossL: tensor(14215.2529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12534 lossL: tensor(9702.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12535 lossL: tensor(10913.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12536 lossL: tensor(13709.6855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12537 lossL: tensor(10965.5176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12538 lossL: tensor(10642.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12539 lossL: tensor(11570.6064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12540 lossL: tensor(10556.7432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12541 lossL: tensor(11256.1338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12542 lossL: tensor(11478.5254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12543 lossL: tensor(10606.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12544 lossL: tensor(8889.6973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12545 lossL: tensor(9761.1572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12546 lossL: tensor(9883.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12547 lossL: tensor(11415.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12548 lossL: tensor(10469.0576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12549 lossL: tensor(9686.2646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12550 lossL: tensor(11533.3037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12551 lossL: tensor(11343.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12552 lossL: tensor(11334.2061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12553 lossL: tensor(10737.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12554 lossL: tensor(12132.6992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12555 lossL: tensor(10095.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12556 lossL: tensor(8836.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12557 lossL: tensor(12688.1123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12558 lossL: tensor(12365.5537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12559 lossL: tensor(11472.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12560 lossL: tensor(10538.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12561 lossL: tensor(10931.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12562 lossL: tensor(11356.7100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12563 lossL: tensor(11060.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12564 lossL: tensor(10344.1748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12565 lossL: tensor(12194.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12566 lossL: tensor(11663.3408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12567 lossL: tensor(12136.6191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12568 lossL: tensor(11278.5361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12569 lossL: tensor(11520.9600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12570 lossL: tensor(9394.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12571 lossL: tensor(10054.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12572 lossL: tensor(9646.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12573 lossL: tensor(11751.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12574 lossL: tensor(9566.2705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12575 lossL: tensor(10394.0420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12576 lossL: tensor(10866.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12577 lossL: tensor(8960.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12578 lossL: tensor(12853.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12579 lossL: tensor(12272.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12580 lossL: tensor(12935.7510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12581 lossL: tensor(11450.7236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12582 lossL: tensor(11864.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12583 lossL: tensor(11097.9248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12584 lossL: tensor(11333.3799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12585 lossL: tensor(11383.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12586 lossL: tensor(9684.3643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12587 lossL: tensor(10232.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12588 lossL: tensor(10050.0635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12589 lossL: tensor(8515.9482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12590 lossL: tensor(9908.5830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12591 lossL: tensor(12576.0088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12592 lossL: tensor(11167.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12593 lossL: tensor(10510.6533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12594 lossL: tensor(10158.0479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12595 lossL: tensor(11523.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12596 lossL: tensor(11398.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12597 lossL: tensor(10717.4785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12598 lossL: tensor(10384.3613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12599 lossL: tensor(10019.5322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12600 lossL: tensor(12478.1338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12601 lossL: tensor(11538.1240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12602 lossL: tensor(10859.7861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12603 lossL: tensor(8580.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12604 lossL: tensor(11519.4941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12605 lossL: tensor(11511.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12606 lossL: tensor(9351.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12607 lossL: tensor(10210.2842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12608 lossL: tensor(10492.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12609 lossL: tensor(9831.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12610 lossL: tensor(10107.2256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12611 lossL: tensor(11107.2900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12612 lossL: tensor(11098.6270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12613 lossL: tensor(8848.3066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12614 lossL: tensor(11084.6738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12615 lossL: tensor(10397.4990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12616 lossL: tensor(10938.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12617 lossL: tensor(9828.8965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12618 lossL: tensor(10144.5869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12619 lossL: tensor(10743.3730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12620 lossL: tensor(11437.6611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12621 lossL: tensor(12260.9658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12622 lossL: tensor(10629.4834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12623 lossL: tensor(11530.9424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12624 lossL: tensor(11053.4199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12625 lossL: tensor(9494.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12626 lossL: tensor(9540.7412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12627 lossL: tensor(10798.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12628 lossL: tensor(12857.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12629 lossL: tensor(10063.2256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12630 lossL: tensor(10534.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12631 lossL: tensor(9852.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12632 lossL: tensor(9910.3604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12633 lossL: tensor(9048.3428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12634 lossL: tensor(12751.9424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12635 lossL: tensor(9580.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12636 lossL: tensor(11793.1475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12637 lossL: tensor(10356.0928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12638 lossL: tensor(9195.3916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12639 lossL: tensor(9781.5098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12640 lossL: tensor(10567.2168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12641 lossL: tensor(11996.2168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12642 lossL: tensor(11449.7334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12643 lossL: tensor(12142.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12644 lossL: tensor(11581.5186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12645 lossL: tensor(10377.4209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12646 lossL: tensor(11110.6572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12647 lossL: tensor(10194.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12648 lossL: tensor(10883.9209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12649 lossL: tensor(11173.4707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12650 lossL: tensor(12659.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12651 lossL: tensor(11030.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12652 lossL: tensor(10439.9404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12653 lossL: tensor(11339.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12654 lossL: tensor(10849.4043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12655 lossL: tensor(9582.9824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12656 lossL: tensor(8621.3545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12657 lossL: tensor(10753.2861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12658 lossL: tensor(10470.2295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12659 lossL: tensor(11131.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12660 lossL: tensor(11261.6914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12661 lossL: tensor(9497.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12662 lossL: tensor(10311.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12663 lossL: tensor(10988.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12664 lossL: tensor(9977.3809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12665 lossL: tensor(8911.8691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12666 lossL: tensor(11101.4365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12667 lossL: tensor(8961.5342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12668 lossL: tensor(7971.5024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "12669 lossL: tensor(11500.1084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12670 lossL: tensor(10785.3535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12671 lossL: tensor(9575.0332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12672 lossL: tensor(11272.7197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12673 lossL: tensor(9806.7764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12674 lossL: tensor(10452.2295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12675 lossL: tensor(9565.2275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12676 lossL: tensor(10265.8936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12677 lossL: tensor(8369.8887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12678 lossL: tensor(10894.1611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12679 lossL: tensor(10461.6475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12680 lossL: tensor(11211.5957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12681 lossL: tensor(9380.9072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12682 lossL: tensor(10345.8848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12683 lossL: tensor(10208.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12684 lossL: tensor(11847.2627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12685 lossL: tensor(7841.9600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "12686 lossL: tensor(11050.0459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12687 lossL: tensor(9507.9043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12688 lossL: tensor(10491.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12689 lossL: tensor(9241.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12690 lossL: tensor(11804.6973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12691 lossL: tensor(13007.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12692 lossL: tensor(11638.2314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12693 lossL: tensor(11267.5605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12694 lossL: tensor(8090.4658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12695 lossL: tensor(10187.7725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12696 lossL: tensor(12125.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12697 lossL: tensor(9011.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12698 lossL: tensor(8476.7441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12699 lossL: tensor(10689.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12700 lossL: tensor(11829.5518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12701 lossL: tensor(9391.4199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12702 lossL: tensor(9415.8428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12703 lossL: tensor(9418.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12704 lossL: tensor(11396.1035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12705 lossL: tensor(11339.2490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12706 lossL: tensor(8875.2207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12707 lossL: tensor(10540.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12708 lossL: tensor(10276.6748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12709 lossL: tensor(12160.2217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12710 lossL: tensor(9958.5986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12711 lossL: tensor(9188.6572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12712 lossL: tensor(11566.0322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12713 lossL: tensor(10135.1318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12714 lossL: tensor(10334.8311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12715 lossL: tensor(10791.4824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12716 lossL: tensor(9358.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12717 lossL: tensor(9612.6572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12718 lossL: tensor(9457.6826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12719 lossL: tensor(10624.7041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12720 lossL: tensor(9799.5947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12721 lossL: tensor(9778.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12722 lossL: tensor(10321.4854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12723 lossL: tensor(11231.8721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12724 lossL: tensor(10319.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12725 lossL: tensor(8852.6553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12726 lossL: tensor(9113.1113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12727 lossL: tensor(9610.6904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12728 lossL: tensor(9364.3096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12729 lossL: tensor(8992.4355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12730 lossL: tensor(9313.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12731 lossL: tensor(11159.3525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12732 lossL: tensor(7608.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "12733 lossL: tensor(9011.7061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12734 lossL: tensor(11413.1416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12735 lossL: tensor(10469.5645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12736 lossL: tensor(12190.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12737 lossL: tensor(10654.1465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12738 lossL: tensor(9089.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12739 lossL: tensor(9441.9980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12740 lossL: tensor(10967.9990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12741 lossL: tensor(9752.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12742 lossL: tensor(9738.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12743 lossL: tensor(10205.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12744 lossL: tensor(9706.2676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12745 lossL: tensor(9583.5029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12746 lossL: tensor(9109.1787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12747 lossL: tensor(9858.7168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12748 lossL: tensor(10697.8584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12749 lossL: tensor(10773.7363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12750 lossL: tensor(10473.1416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12751 lossL: tensor(10652.0811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12752 lossL: tensor(10319.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12753 lossL: tensor(9890.7861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12754 lossL: tensor(9441.0967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12755 lossL: tensor(8793.0029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12756 lossL: tensor(10516.0791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12757 lossL: tensor(10466.9795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12758 lossL: tensor(11141.7354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12759 lossL: tensor(9818.9092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12760 lossL: tensor(10613.1689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12761 lossL: tensor(10562.8887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12762 lossL: tensor(9225.0811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12763 lossL: tensor(10570.2939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12764 lossL: tensor(10861.2979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12765 lossL: tensor(9822.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12766 lossL: tensor(9525.4004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12767 lossL: tensor(11725.7568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12768 lossL: tensor(11451.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12769 lossL: tensor(11384.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12770 lossL: tensor(7996.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12771 lossL: tensor(8983.9824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12772 lossL: tensor(11468.3848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12773 lossL: tensor(10177.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12774 lossL: tensor(8706.8926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12775 lossL: tensor(9003.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12776 lossL: tensor(9765.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12777 lossL: tensor(11400.3760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12778 lossL: tensor(11266.4600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12779 lossL: tensor(9774.1904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12780 lossL: tensor(12102.3135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12781 lossL: tensor(9138.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12782 lossL: tensor(10705.1904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12783 lossL: tensor(9367.1182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12784 lossL: tensor(9600.2607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12785 lossL: tensor(8956.8975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12786 lossL: tensor(10607.4209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12787 lossL: tensor(10526.2588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12788 lossL: tensor(8719.7100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12789 lossL: tensor(11653.5498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12790 lossL: tensor(8827.6465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12791 lossL: tensor(9638.5059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12792 lossL: tensor(11516.4268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12793 lossL: tensor(9656.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12794 lossL: tensor(10205.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12795 lossL: tensor(9787.7314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12796 lossL: tensor(11178.5068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12797 lossL: tensor(11313.9121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12798 lossL: tensor(10968.3076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12799 lossL: tensor(11016.9668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12800 lossL: tensor(8733.7842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12801 lossL: tensor(10221.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12802 lossL: tensor(9819.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12803 lossL: tensor(9373.8115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12804 lossL: tensor(9530.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12805 lossL: tensor(8846.6787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12806 lossL: tensor(8569.3154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12807 lossL: tensor(8460.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12808 lossL: tensor(9287.3965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12809 lossL: tensor(10311.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12810 lossL: tensor(10754.5137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12811 lossL: tensor(10906.7979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12812 lossL: tensor(9353.2080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12813 lossL: tensor(9922.5205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12814 lossL: tensor(9607.2783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12815 lossL: tensor(9649.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12816 lossL: tensor(9557.2178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12817 lossL: tensor(9509.9658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12818 lossL: tensor(9376.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12819 lossL: tensor(9508.0283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12820 lossL: tensor(9101.9775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12821 lossL: tensor(10079.6035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12822 lossL: tensor(9356.6348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12823 lossL: tensor(10115.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12824 lossL: tensor(10343.2764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12825 lossL: tensor(10343.6533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12826 lossL: tensor(10358.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12827 lossL: tensor(7895.7119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12828 lossL: tensor(9218.3564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12829 lossL: tensor(10667.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12830 lossL: tensor(8932.1650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12831 lossL: tensor(10034.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12832 lossL: tensor(10312.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12833 lossL: tensor(9857.1982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12834 lossL: tensor(8139.3140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12835 lossL: tensor(10768.9082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12836 lossL: tensor(10056.9863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12837 lossL: tensor(8938.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12838 lossL: tensor(8627.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12839 lossL: tensor(8674.5635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12840 lossL: tensor(9391.2666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12841 lossL: tensor(8925.9346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12842 lossL: tensor(8314.5059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12843 lossL: tensor(9721.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12844 lossL: tensor(9833.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12845 lossL: tensor(9303.0869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12846 lossL: tensor(9807.6240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12847 lossL: tensor(9216.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12848 lossL: tensor(8926.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12849 lossL: tensor(7619.8301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12850 lossL: tensor(11396.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12851 lossL: tensor(9748.1230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12852 lossL: tensor(9514.0967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12853 lossL: tensor(10009.0811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12854 lossL: tensor(8455.6504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12855 lossL: tensor(8506.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12856 lossL: tensor(10025.9131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12857 lossL: tensor(10369.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12858 lossL: tensor(7985.8062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12859 lossL: tensor(9144.2451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12860 lossL: tensor(9089.0332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12861 lossL: tensor(9435.6025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12862 lossL: tensor(10865.8213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12863 lossL: tensor(8161.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12864 lossL: tensor(7961.5415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12865 lossL: tensor(9513.6816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12866 lossL: tensor(9546.4854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12867 lossL: tensor(9614.7959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12868 lossL: tensor(10365.6660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12869 lossL: tensor(9181.1982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12870 lossL: tensor(8555.4619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12871 lossL: tensor(9400.3379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12872 lossL: tensor(8681.9434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12873 lossL: tensor(8860.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12874 lossL: tensor(9346.1377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12875 lossL: tensor(8980.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12876 lossL: tensor(9207.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12877 lossL: tensor(8859.9033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12878 lossL: tensor(10068.2939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12879 lossL: tensor(8091.7651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12880 lossL: tensor(7558.2373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "12881 lossL: tensor(7999.1489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12882 lossL: tensor(8784.1699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12883 lossL: tensor(9941.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12884 lossL: tensor(9376.2207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12885 lossL: tensor(8728.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12886 lossL: tensor(10359.7949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12887 lossL: tensor(11333.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12888 lossL: tensor(8142.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12889 lossL: tensor(10254.4150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12890 lossL: tensor(8983.1064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12891 lossL: tensor(7869.3022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12892 lossL: tensor(10041.9395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12893 lossL: tensor(8999.7705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12894 lossL: tensor(9565.7676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12895 lossL: tensor(10190.5957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12896 lossL: tensor(8541.7207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12897 lossL: tensor(9495.5088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12898 lossL: tensor(9628.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12899 lossL: tensor(9048.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12900 lossL: tensor(8763.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12901 lossL: tensor(9026.6592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12902 lossL: tensor(11115.7939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12903 lossL: tensor(10519.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12904 lossL: tensor(9424.8682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12905 lossL: tensor(9051.4697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12906 lossL: tensor(8822.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12907 lossL: tensor(9099.5908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12908 lossL: tensor(9910.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12909 lossL: tensor(8262.8154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12910 lossL: tensor(8322.1855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12911 lossL: tensor(11117.4346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12912 lossL: tensor(7540.4854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "12913 lossL: tensor(9089.0889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12914 lossL: tensor(9996.1230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12915 lossL: tensor(10152.0244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12916 lossL: tensor(10758.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12917 lossL: tensor(6808.9634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "12918 lossL: tensor(8559.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12919 lossL: tensor(9724.4209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12920 lossL: tensor(9471.4434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12921 lossL: tensor(7819.5142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12922 lossL: tensor(9949.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12923 lossL: tensor(8400.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12924 lossL: tensor(8253.4346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12925 lossL: tensor(9415.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12926 lossL: tensor(8519.2646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12927 lossL: tensor(9010.3574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12928 lossL: tensor(8164.8267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12929 lossL: tensor(8742.5811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12930 lossL: tensor(9324.8428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12931 lossL: tensor(8831.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12932 lossL: tensor(9963.1387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12933 lossL: tensor(10515.4053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12934 lossL: tensor(10276.7051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12935 lossL: tensor(10342.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12936 lossL: tensor(9146.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12937 lossL: tensor(8376.8350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12938 lossL: tensor(9355.3545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12939 lossL: tensor(9339.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12940 lossL: tensor(10417.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12941 lossL: tensor(11512.2744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12942 lossL: tensor(7319.2588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12943 lossL: tensor(10748.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12944 lossL: tensor(11554.4072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12945 lossL: tensor(8309.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12946 lossL: tensor(8264.4951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12947 lossL: tensor(8799.0498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12948 lossL: tensor(10177.4561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12949 lossL: tensor(9275.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12950 lossL: tensor(9889.1973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12951 lossL: tensor(9265.4355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12952 lossL: tensor(8236.0645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12953 lossL: tensor(9317.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12954 lossL: tensor(8736.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12955 lossL: tensor(8804.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12956 lossL: tensor(9435.6709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12957 lossL: tensor(9169.2236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12958 lossL: tensor(10128.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12959 lossL: tensor(9129.6572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12960 lossL: tensor(7924.2144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12961 lossL: tensor(8414.4951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12962 lossL: tensor(9478.0059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12963 lossL: tensor(7182.6885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12964 lossL: tensor(7794.7954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12965 lossL: tensor(10100.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12966 lossL: tensor(8426.9570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12967 lossL: tensor(10183.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12968 lossL: tensor(9199.9150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12969 lossL: tensor(9589.4619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12970 lossL: tensor(8164.5103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12971 lossL: tensor(7645.9321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12972 lossL: tensor(9476.8545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12973 lossL: tensor(9739.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12974 lossL: tensor(8381.1582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12975 lossL: tensor(8395.7314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12976 lossL: tensor(7930.0439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12977 lossL: tensor(9685.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12978 lossL: tensor(9168.3037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12979 lossL: tensor(7876.0010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12980 lossL: tensor(9440.7588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12981 lossL: tensor(8286.9482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12982 lossL: tensor(8930.5645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12983 lossL: tensor(8653.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12984 lossL: tensor(9611.1650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12985 lossL: tensor(8888.7412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12986 lossL: tensor(11244.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12987 lossL: tensor(8235.8066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12988 lossL: tensor(9477.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12989 lossL: tensor(8517.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12990 lossL: tensor(10239.5850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12991 lossL: tensor(8740.4512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12992 lossL: tensor(10269.1035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12993 lossL: tensor(8940.3311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12994 lossL: tensor(9281.0459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12995 lossL: tensor(9595.8643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12996 lossL: tensor(9137.5059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12997 lossL: tensor(7871.4878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12998 lossL: tensor(7801.5444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "12999 lossL: tensor(9379.8506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13000 lossL: tensor(8939.9395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13001 lossL: tensor(8218.9756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13002 lossL: tensor(10197.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13003 lossL: tensor(9194.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13004 lossL: tensor(9473.4941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13005 lossL: tensor(10977.7764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13006 lossL: tensor(10320.3535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13007 lossL: tensor(8375.4404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13008 lossL: tensor(8121.8442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13009 lossL: tensor(7393.1304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13010 lossL: tensor(8625.2090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13011 lossL: tensor(10423.2744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13012 lossL: tensor(8325.3447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13013 lossL: tensor(7502.6279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13014 lossL: tensor(11134.7432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13015 lossL: tensor(8167.1001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13016 lossL: tensor(7171.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13017 lossL: tensor(8699.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13018 lossL: tensor(8988.4375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13019 lossL: tensor(9070.3936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13020 lossL: tensor(6959.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13021 lossL: tensor(9253.4492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13022 lossL: tensor(8381.9736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13023 lossL: tensor(10777.2285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13024 lossL: tensor(11023.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13025 lossL: tensor(9577.3389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13026 lossL: tensor(8780.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13027 lossL: tensor(9626.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13028 lossL: tensor(8604.8262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13029 lossL: tensor(9108.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13030 lossL: tensor(10285.2598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13031 lossL: tensor(9412.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13032 lossL: tensor(8016.7671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13033 lossL: tensor(8372.1943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13034 lossL: tensor(9247.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13035 lossL: tensor(8204.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13036 lossL: tensor(7102.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13037 lossL: tensor(8747.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13038 lossL: tensor(8819.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13039 lossL: tensor(8250.1045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13040 lossL: tensor(8179.8291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13041 lossL: tensor(8649.9561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13042 lossL: tensor(9192.9600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13043 lossL: tensor(7827.8545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13044 lossL: tensor(7184.3584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13045 lossL: tensor(9466.5498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13046 lossL: tensor(8032.6636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13047 lossL: tensor(7787.1973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13048 lossL: tensor(8567.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13049 lossL: tensor(6937.4644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13050 lossL: tensor(7410.5396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13051 lossL: tensor(9956.1357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13052 lossL: tensor(8248.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13053 lossL: tensor(9126.4443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13054 lossL: tensor(9243.2207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13055 lossL: tensor(7677.0601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13056 lossL: tensor(8019.5210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13057 lossL: tensor(7919.0996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13058 lossL: tensor(9963.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13059 lossL: tensor(8086.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13060 lossL: tensor(9188.1768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13061 lossL: tensor(7972.9810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13062 lossL: tensor(7333.3901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13063 lossL: tensor(8080.7505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13064 lossL: tensor(8479.6553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13065 lossL: tensor(7961.1924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13066 lossL: tensor(8403.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13067 lossL: tensor(9757.5645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13068 lossL: tensor(7482.8032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13069 lossL: tensor(8082.1362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13070 lossL: tensor(8447.4785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13071 lossL: tensor(7996.1675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13072 lossL: tensor(7386.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13073 lossL: tensor(8957.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13074 lossL: tensor(8233.5645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13075 lossL: tensor(8296.4893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13076 lossL: tensor(7847.8950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13077 lossL: tensor(9498.0791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13078 lossL: tensor(9708.2832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13079 lossL: tensor(7088.1621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13080 lossL: tensor(8545.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13081 lossL: tensor(8201.6104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13082 lossL: tensor(8913.2676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13083 lossL: tensor(7550.2495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13084 lossL: tensor(9290.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13085 lossL: tensor(6447.5845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "13086 lossL: tensor(8948.2686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13087 lossL: tensor(8121.1685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13088 lossL: tensor(8547.3271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13089 lossL: tensor(8989.4971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13090 lossL: tensor(10732.9121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13091 lossL: tensor(8031.4619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13092 lossL: tensor(6978.0132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13093 lossL: tensor(9353.3203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13094 lossL: tensor(8365.9561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13095 lossL: tensor(6980.0649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13096 lossL: tensor(7708.5566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13097 lossL: tensor(8225.1240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13098 lossL: tensor(8059.6104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13099 lossL: tensor(8718.2197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13100 lossL: tensor(7396.7769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13101 lossL: tensor(7364.5835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13102 lossL: tensor(7685.8647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13103 lossL: tensor(8139.0737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13104 lossL: tensor(9987.5127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13105 lossL: tensor(7082.0728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13106 lossL: tensor(9603.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13107 lossL: tensor(7183.1655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13108 lossL: tensor(9483.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13109 lossL: tensor(7317.2036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13110 lossL: tensor(7671.2681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13111 lossL: tensor(7594.4785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13112 lossL: tensor(7779.8228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13113 lossL: tensor(8322.1465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13114 lossL: tensor(10059.2539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13115 lossL: tensor(6370.1206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "13116 lossL: tensor(8858.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13117 lossL: tensor(7379.6621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13118 lossL: tensor(6640.6538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13119 lossL: tensor(8280.1035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13120 lossL: tensor(8481.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13121 lossL: tensor(7701.1611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13122 lossL: tensor(8190.6670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13123 lossL: tensor(8200.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13124 lossL: tensor(8132.0972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13125 lossL: tensor(8494.2314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13126 lossL: tensor(7818.6060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13127 lossL: tensor(10041.7803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13128 lossL: tensor(7898.6030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13129 lossL: tensor(9055.2979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13130 lossL: tensor(7129.5557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13131 lossL: tensor(7339.7847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13132 lossL: tensor(8548.5215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13133 lossL: tensor(7362.6357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13134 lossL: tensor(7422.5522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13135 lossL: tensor(7322.6045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13136 lossL: tensor(9051.7012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13137 lossL: tensor(6655.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13138 lossL: tensor(7826.8955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13139 lossL: tensor(8154.7563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13140 lossL: tensor(9600.2764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13141 lossL: tensor(9132.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13142 lossL: tensor(9466.4629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13143 lossL: tensor(8371.8193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13144 lossL: tensor(8974.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13145 lossL: tensor(7264.0181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13146 lossL: tensor(7171.5718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13147 lossL: tensor(6685.4966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13148 lossL: tensor(6921.7847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13149 lossL: tensor(6625.4341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13150 lossL: tensor(6803.7075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13151 lossL: tensor(8556.0537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13152 lossL: tensor(7388.6128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13153 lossL: tensor(8586.3262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13154 lossL: tensor(7944.6709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13155 lossL: tensor(7659.6890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13156 lossL: tensor(10039.7988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13157 lossL: tensor(8562.5635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13158 lossL: tensor(7599.5728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13159 lossL: tensor(8997.9443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13160 lossL: tensor(8315.4268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13161 lossL: tensor(7599.0239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13162 lossL: tensor(7371.5386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13163 lossL: tensor(8732.0732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13164 lossL: tensor(9067.3291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13165 lossL: tensor(7946.1279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13166 lossL: tensor(8350.7998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13167 lossL: tensor(6903.8345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13168 lossL: tensor(10250.0967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13169 lossL: tensor(8808.7168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13170 lossL: tensor(7376.6050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13171 lossL: tensor(8241.1221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13172 lossL: tensor(7864.5264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13173 lossL: tensor(7029.7212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13174 lossL: tensor(8607.9121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13175 lossL: tensor(6473.3970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13176 lossL: tensor(8080.4165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13177 lossL: tensor(7576.5063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13178 lossL: tensor(8279.1240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13179 lossL: tensor(8376.9824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13180 lossL: tensor(7152.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13181 lossL: tensor(9184.3613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13182 lossL: tensor(7152.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13183 lossL: tensor(6844.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13184 lossL: tensor(8488.1973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13185 lossL: tensor(7230.8721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13186 lossL: tensor(6632.5688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13187 lossL: tensor(8427.0410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13188 lossL: tensor(7342.2764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13189 lossL: tensor(7416.9932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13190 lossL: tensor(7541.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13191 lossL: tensor(7305.9155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13192 lossL: tensor(8476.7373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13193 lossL: tensor(9667.4873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13194 lossL: tensor(7476.7749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13195 lossL: tensor(8324.6211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13196 lossL: tensor(7615.2627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13197 lossL: tensor(8619.2002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13198 lossL: tensor(8296.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13199 lossL: tensor(6876.6377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13200 lossL: tensor(6854.5806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13201 lossL: tensor(9464.3574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13202 lossL: tensor(6752.6089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13203 lossL: tensor(9169.7529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13204 lossL: tensor(7470.9170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13205 lossL: tensor(7363.2358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13206 lossL: tensor(9595.5947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13207 lossL: tensor(8199.3643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13208 lossL: tensor(6604.3706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13209 lossL: tensor(10092.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13210 lossL: tensor(9292.1934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13211 lossL: tensor(6364.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "13212 lossL: tensor(7821.8848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13213 lossL: tensor(9236.5811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13214 lossL: tensor(7418.1689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13215 lossL: tensor(7448.9771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13216 lossL: tensor(6771.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13217 lossL: tensor(8067.4629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13218 lossL: tensor(5651.3120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "13219 lossL: tensor(7343.9575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13220 lossL: tensor(8322.3838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13221 lossL: tensor(7330.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13222 lossL: tensor(9511.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13223 lossL: tensor(8352.7646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13224 lossL: tensor(8530.6982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13225 lossL: tensor(6402.8521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13226 lossL: tensor(8608.6807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13227 lossL: tensor(6224.3267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13228 lossL: tensor(6159.0181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13229 lossL: tensor(8100.6733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13230 lossL: tensor(8765.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13231 lossL: tensor(7822.5142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13232 lossL: tensor(7419.5791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13233 lossL: tensor(7270.0864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13234 lossL: tensor(6872.1318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13235 lossL: tensor(6767.1465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13236 lossL: tensor(6511.0503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13237 lossL: tensor(7412.2192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13238 lossL: tensor(7843.5444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13239 lossL: tensor(7531.2056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13240 lossL: tensor(8370.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13241 lossL: tensor(7485.4380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13242 lossL: tensor(8427.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13243 lossL: tensor(6456.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13244 lossL: tensor(8588.9814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13245 lossL: tensor(6588.2192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13246 lossL: tensor(7854.5479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13247 lossL: tensor(7547.5132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13248 lossL: tensor(6787.1846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13249 lossL: tensor(7832.3979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13250 lossL: tensor(7713.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13251 lossL: tensor(7420.1235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13252 lossL: tensor(7749.3501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13253 lossL: tensor(6886.5322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13254 lossL: tensor(8080.1582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13255 lossL: tensor(7750.6807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13256 lossL: tensor(8075.8535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13257 lossL: tensor(6835.6919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13258 lossL: tensor(8231.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13259 lossL: tensor(7728.0576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13260 lossL: tensor(7110.6489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13261 lossL: tensor(8935.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13262 lossL: tensor(7206.0483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13263 lossL: tensor(7606.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13264 lossL: tensor(8009.3813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13265 lossL: tensor(8144.7563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13266 lossL: tensor(7609.2944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13267 lossL: tensor(7179.6880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13268 lossL: tensor(7039.6118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13269 lossL: tensor(8386.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13270 lossL: tensor(8260.8525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13271 lossL: tensor(8610.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13272 lossL: tensor(7088.8032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13273 lossL: tensor(7256.6455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13274 lossL: tensor(7880.0112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13275 lossL: tensor(8086.6392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13276 lossL: tensor(9730.1357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13277 lossL: tensor(6985.6982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13278 lossL: tensor(7312.5278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13279 lossL: tensor(9134.2764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13280 lossL: tensor(7704.8960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13281 lossL: tensor(9121.0752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13282 lossL: tensor(7490.9761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13283 lossL: tensor(7938.6216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13284 lossL: tensor(6664.6221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13285 lossL: tensor(8126.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13286 lossL: tensor(8236.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13287 lossL: tensor(8676.5498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13288 lossL: tensor(6321.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13289 lossL: tensor(7507.1426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13290 lossL: tensor(10044.4707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13291 lossL: tensor(7840.7988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13292 lossL: tensor(7682.5757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13293 lossL: tensor(7761.0254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13294 lossL: tensor(6949.1333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13295 lossL: tensor(7863.8188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13296 lossL: tensor(6737.1929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13297 lossL: tensor(6753.1182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13298 lossL: tensor(7770.9604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13299 lossL: tensor(8624.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13300 lossL: tensor(8553.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13301 lossL: tensor(7453.5010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13302 lossL: tensor(7100.5132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13303 lossL: tensor(6236.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13304 lossL: tensor(7242.3442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13305 lossL: tensor(8621.5742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13306 lossL: tensor(6900.5054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13307 lossL: tensor(7870.1387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13308 lossL: tensor(8523.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13309 lossL: tensor(8313.6152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13310 lossL: tensor(7814.6997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13311 lossL: tensor(7084.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13312 lossL: tensor(7307.8511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13313 lossL: tensor(7177.3892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13314 lossL: tensor(9899.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13315 lossL: tensor(8693.8311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13316 lossL: tensor(7918.4863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13317 lossL: tensor(7979.2754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13318 lossL: tensor(7032.3838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13319 lossL: tensor(6382.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13320 lossL: tensor(9093.1592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13321 lossL: tensor(6358.9771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13322 lossL: tensor(8119.3901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13323 lossL: tensor(8516.3105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13324 lossL: tensor(6656.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13325 lossL: tensor(7112.3271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13326 lossL: tensor(8216.2197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13327 lossL: tensor(7786.3374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13328 lossL: tensor(7443.2588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13329 lossL: tensor(7515.8711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13330 lossL: tensor(7224.6504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13331 lossL: tensor(7433.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13332 lossL: tensor(6952.7207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13333 lossL: tensor(7676.1987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13334 lossL: tensor(6555.7393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13335 lossL: tensor(7211.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13336 lossL: tensor(7596.3140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13337 lossL: tensor(6284.7559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13338 lossL: tensor(7644.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13339 lossL: tensor(6468.7896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13340 lossL: tensor(7628.2515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13341 lossL: tensor(7712.6079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13342 lossL: tensor(6234.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13343 lossL: tensor(8154.5850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13344 lossL: tensor(7992.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13345 lossL: tensor(7142.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13346 lossL: tensor(7161.6489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13347 lossL: tensor(7659.9229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13348 lossL: tensor(6949.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13349 lossL: tensor(7401.3545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13350 lossL: tensor(7848.8037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13351 lossL: tensor(8059.3511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13352 lossL: tensor(7001.8198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13353 lossL: tensor(8668.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13354 lossL: tensor(7318.6006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13355 lossL: tensor(7154.0933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13356 lossL: tensor(6300.5713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13357 lossL: tensor(8191.6509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13358 lossL: tensor(6407.6182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13359 lossL: tensor(8890.5811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13360 lossL: tensor(7238.3506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13361 lossL: tensor(7704.6729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13362 lossL: tensor(8588.3115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13363 lossL: tensor(6410.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13364 lossL: tensor(6751.0728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13365 lossL: tensor(6990.4746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13366 lossL: tensor(7413.4399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13367 lossL: tensor(6665.5576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13368 lossL: tensor(7539.0918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13369 lossL: tensor(7257.7935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13370 lossL: tensor(6331.8770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13371 lossL: tensor(6616.0698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13372 lossL: tensor(7197.1616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13373 lossL: tensor(7011.2505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13374 lossL: tensor(7705.9165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13375 lossL: tensor(7029.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13376 lossL: tensor(6210.9185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13377 lossL: tensor(7369.3569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13378 lossL: tensor(6241.3462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13379 lossL: tensor(7764.7847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13380 lossL: tensor(5492.1479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "13381 lossL: tensor(6052.1606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13382 lossL: tensor(6178.6235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13383 lossL: tensor(6668.6284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13384 lossL: tensor(7111.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13385 lossL: tensor(6276.6255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13386 lossL: tensor(6228.8267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13387 lossL: tensor(8391.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13388 lossL: tensor(5879.7285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13389 lossL: tensor(6458.6675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13390 lossL: tensor(6807.2788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13391 lossL: tensor(5863.2124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13392 lossL: tensor(6673.3848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13393 lossL: tensor(6899.7002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13394 lossL: tensor(8520.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13395 lossL: tensor(7921.5879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13396 lossL: tensor(7563.0562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13397 lossL: tensor(7606.3188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13398 lossL: tensor(7781.4590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13399 lossL: tensor(8485.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13400 lossL: tensor(6100.9863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13401 lossL: tensor(8322.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13402 lossL: tensor(8199.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13403 lossL: tensor(7998.8311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13404 lossL: tensor(7990.5488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13405 lossL: tensor(6056.7192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13406 lossL: tensor(8311.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13407 lossL: tensor(7650.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13408 lossL: tensor(5673.6084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13409 lossL: tensor(8060.7563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13410 lossL: tensor(6477.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13411 lossL: tensor(6190.7451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13412 lossL: tensor(8012.7554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13413 lossL: tensor(7231.0249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13414 lossL: tensor(5897.7075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13415 lossL: tensor(8147.1343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13416 lossL: tensor(7550.6699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13417 lossL: tensor(7011.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13418 lossL: tensor(7767.7271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13419 lossL: tensor(6601.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13420 lossL: tensor(7420.3657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13421 lossL: tensor(5754.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13422 lossL: tensor(7431.7080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13423 lossL: tensor(6224.4214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13424 lossL: tensor(7327.3813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13425 lossL: tensor(7809.7456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13426 lossL: tensor(7406.4927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13427 lossL: tensor(7212.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13428 lossL: tensor(7665.3286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13429 lossL: tensor(8095.0786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13430 lossL: tensor(6464.9180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13431 lossL: tensor(7577.7017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13432 lossL: tensor(6451.8169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13433 lossL: tensor(6389.8862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13434 lossL: tensor(7556.6670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13435 lossL: tensor(7208.3374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13436 lossL: tensor(7887.5576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13437 lossL: tensor(6814.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13438 lossL: tensor(6878.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13439 lossL: tensor(7173.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13440 lossL: tensor(6747.8696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13441 lossL: tensor(7785.3848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13442 lossL: tensor(6445.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13443 lossL: tensor(7705.3096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13444 lossL: tensor(7029.6948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13445 lossL: tensor(6049.3726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13446 lossL: tensor(6773.2490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13447 lossL: tensor(7875.7236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13448 lossL: tensor(6434.7407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13449 lossL: tensor(6517.3643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13450 lossL: tensor(5913.2432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13451 lossL: tensor(6517.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13452 lossL: tensor(8549.2646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13453 lossL: tensor(6973.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13454 lossL: tensor(6481.9282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13455 lossL: tensor(7429.8892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13456 lossL: tensor(7364.0171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13457 lossL: tensor(7356.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13458 lossL: tensor(7542.5093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13459 lossL: tensor(7359.4819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13460 lossL: tensor(6216.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13461 lossL: tensor(7544.4658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13462 lossL: tensor(7729.4087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13463 lossL: tensor(6618.1265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13464 lossL: tensor(6498.7090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13465 lossL: tensor(5770.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13466 lossL: tensor(6974.3955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13467 lossL: tensor(7036.6543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13468 lossL: tensor(6848.1670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13469 lossL: tensor(6380.2363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13470 lossL: tensor(6103.4644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13471 lossL: tensor(6699.4556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13472 lossL: tensor(6629.3130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13473 lossL: tensor(6407.1582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13474 lossL: tensor(6346.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13475 lossL: tensor(5985.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13476 lossL: tensor(6844.0298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13477 lossL: tensor(8086.9937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13478 lossL: tensor(6882.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13479 lossL: tensor(6011., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13480 lossL: tensor(6396.3042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13481 lossL: tensor(7623.5645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13482 lossL: tensor(7153.4976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13483 lossL: tensor(6469.6733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13484 lossL: tensor(8201.0410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13485 lossL: tensor(6007.2178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13486 lossL: tensor(8711.6963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13487 lossL: tensor(6480.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13488 lossL: tensor(5889.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13489 lossL: tensor(5260.8486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "13490 lossL: tensor(6015.8110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13491 lossL: tensor(7300.6313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13492 lossL: tensor(8340.0557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13493 lossL: tensor(6556.3267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13494 lossL: tensor(6261.7417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13495 lossL: tensor(7389.1929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13496 lossL: tensor(7879.3774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13497 lossL: tensor(7214.4761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13498 lossL: tensor(7078.1123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13499 lossL: tensor(8422.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13500 lossL: tensor(7002.1387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13501 lossL: tensor(7621.5322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13502 lossL: tensor(6623.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13503 lossL: tensor(8735.8330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13504 lossL: tensor(6842.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13505 lossL: tensor(7681.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13506 lossL: tensor(6204.7671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13507 lossL: tensor(8015.2642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13508 lossL: tensor(7525.1816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13509 lossL: tensor(7580.9033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13510 lossL: tensor(7873.0771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13511 lossL: tensor(7241.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13512 lossL: tensor(7377.3433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13513 lossL: tensor(7082.7271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13514 lossL: tensor(8366.6436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13515 lossL: tensor(5966.4814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13516 lossL: tensor(8381.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13517 lossL: tensor(6571.5054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13518 lossL: tensor(7397.1035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13519 lossL: tensor(6969.1665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13520 lossL: tensor(6732.6831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13521 lossL: tensor(6727.7451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13522 lossL: tensor(7824.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13523 lossL: tensor(7176.2393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13524 lossL: tensor(7939.4717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13525 lossL: tensor(5831.0400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13526 lossL: tensor(6995.2480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13527 lossL: tensor(5955.9243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13528 lossL: tensor(6670.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13529 lossL: tensor(7101.5737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13530 lossL: tensor(6033.8457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13531 lossL: tensor(6069.2324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13532 lossL: tensor(6422.7153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13533 lossL: tensor(6964.9834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13534 lossL: tensor(8120.7310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13535 lossL: tensor(6823.4263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13536 lossL: tensor(5501.5737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13537 lossL: tensor(7569.2529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13538 lossL: tensor(6673.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13539 lossL: tensor(6782.0474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13540 lossL: tensor(6305.2148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13541 lossL: tensor(7926.2612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13542 lossL: tensor(5741.6948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13543 lossL: tensor(5728.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13544 lossL: tensor(6831.1069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13545 lossL: tensor(6319.2417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13546 lossL: tensor(6473.1494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13547 lossL: tensor(7432.0083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13548 lossL: tensor(7061.4263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13549 lossL: tensor(5596.5757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13550 lossL: tensor(7465.1709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13551 lossL: tensor(5686.8809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13552 lossL: tensor(7597.3530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13553 lossL: tensor(7075.7021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13554 lossL: tensor(7360.6382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13555 lossL: tensor(6872.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13556 lossL: tensor(7463.9429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13557 lossL: tensor(7425.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13558 lossL: tensor(6241.8062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13559 lossL: tensor(6496.6768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13560 lossL: tensor(6828.8306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13561 lossL: tensor(6477.4888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13562 lossL: tensor(6474.1440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13563 lossL: tensor(7025.5254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13564 lossL: tensor(6670.0552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13565 lossL: tensor(5390.2832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13566 lossL: tensor(6547.0991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13567 lossL: tensor(7023.5962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13568 lossL: tensor(7804.6392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13569 lossL: tensor(5979.2271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13570 lossL: tensor(6989.5835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13571 lossL: tensor(6659.6440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13572 lossL: tensor(6734.5498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13573 lossL: tensor(6304.9106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13574 lossL: tensor(6853.8765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13575 lossL: tensor(7333.7231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13576 lossL: tensor(5838.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13577 lossL: tensor(6273.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13578 lossL: tensor(6942.5918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13579 lossL: tensor(8103.3936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13580 lossL: tensor(6351.3716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13581 lossL: tensor(6128.7007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13582 lossL: tensor(6979.5342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13583 lossL: tensor(7076.1567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13584 lossL: tensor(5841.2227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13585 lossL: tensor(5904.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13586 lossL: tensor(6330.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13587 lossL: tensor(5625.7695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13588 lossL: tensor(6535.9360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13589 lossL: tensor(6999.1426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13590 lossL: tensor(7209.2412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13591 lossL: tensor(6621.4126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13592 lossL: tensor(5466.9429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13593 lossL: tensor(7244.1885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13594 lossL: tensor(7282.0049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13595 lossL: tensor(6130.3740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13596 lossL: tensor(7470.6538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13597 lossL: tensor(6570.8057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13598 lossL: tensor(5840.1357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13599 lossL: tensor(6711.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13600 lossL: tensor(6154.2183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13601 lossL: tensor(5856.8569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13602 lossL: tensor(6415.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13603 lossL: tensor(5921.8716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13604 lossL: tensor(6124.6348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13605 lossL: tensor(6516.0806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13606 lossL: tensor(7035.1060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13607 lossL: tensor(6974.4951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13608 lossL: tensor(6485.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13609 lossL: tensor(6478.0552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13610 lossL: tensor(7259.8599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13611 lossL: tensor(5393.8872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13612 lossL: tensor(5959.4307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13613 lossL: tensor(6417.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13614 lossL: tensor(6659.5225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13615 lossL: tensor(6946.3442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13616 lossL: tensor(6254.1904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13617 lossL: tensor(6682.6880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13618 lossL: tensor(6745.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13619 lossL: tensor(5809.8208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13620 lossL: tensor(5333.0537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13621 lossL: tensor(6713.2632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13622 lossL: tensor(6865.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13623 lossL: tensor(6802.8184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13624 lossL: tensor(5579.1099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13625 lossL: tensor(6834.8218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13626 lossL: tensor(6228.2407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13627 lossL: tensor(6255.4985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13628 lossL: tensor(6775.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13629 lossL: tensor(7297.7373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13630 lossL: tensor(6687.8896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13631 lossL: tensor(5548.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13632 lossL: tensor(5879.0903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13633 lossL: tensor(6077.5889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13634 lossL: tensor(7428.4014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13635 lossL: tensor(6952.0645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13636 lossL: tensor(6785.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13637 lossL: tensor(6500.5688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13638 lossL: tensor(7242.6074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13639 lossL: tensor(8122.9907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13640 lossL: tensor(6248.6743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13641 lossL: tensor(6868.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13642 lossL: tensor(6029.2437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13643 lossL: tensor(6681.2119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13644 lossL: tensor(5030.3926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "13645 lossL: tensor(6336.6782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13646 lossL: tensor(6751.6245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13647 lossL: tensor(6559.8818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13648 lossL: tensor(6633.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13649 lossL: tensor(5617.7466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13650 lossL: tensor(7469.1294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13651 lossL: tensor(5906.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13652 lossL: tensor(6826.1577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13653 lossL: tensor(6809.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13654 lossL: tensor(7458.9600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13655 lossL: tensor(7484.0044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13656 lossL: tensor(6797.6182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13657 lossL: tensor(5855.5107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13658 lossL: tensor(7233.0825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13659 lossL: tensor(6416.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13660 lossL: tensor(7186.3613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13661 lossL: tensor(6224.9678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13662 lossL: tensor(6327.0288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13663 lossL: tensor(5740.3130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13664 lossL: tensor(6803.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13665 lossL: tensor(6543.8799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13666 lossL: tensor(6375.9146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13667 lossL: tensor(7422.5684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13668 lossL: tensor(6831.3032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13669 lossL: tensor(6307.6885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13670 lossL: tensor(6528.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13671 lossL: tensor(5889.4839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13672 lossL: tensor(5710.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13673 lossL: tensor(7326.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13674 lossL: tensor(5835.5044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13675 lossL: tensor(6290.6851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13676 lossL: tensor(6301.9468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13677 lossL: tensor(5122.8091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13678 lossL: tensor(7091.4360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13679 lossL: tensor(6396.4048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13680 lossL: tensor(5759.6240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13681 lossL: tensor(6860.0225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13682 lossL: tensor(6835.8521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13683 lossL: tensor(5618.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13684 lossL: tensor(5863.2271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13685 lossL: tensor(5600.6860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13686 lossL: tensor(5796.4868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13687 lossL: tensor(6286.6099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13688 lossL: tensor(5597.8042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13689 lossL: tensor(4939.5967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "13690 lossL: tensor(6707.3052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13691 lossL: tensor(5811.2637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13692 lossL: tensor(5816.1255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13693 lossL: tensor(5887.1748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13694 lossL: tensor(6956.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13695 lossL: tensor(5010.6455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13696 lossL: tensor(7002.0396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13697 lossL: tensor(5938.5088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13698 lossL: tensor(6389.3413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13699 lossL: tensor(6710.1167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13700 lossL: tensor(6107.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13701 lossL: tensor(6668.8350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13702 lossL: tensor(7028.5879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13703 lossL: tensor(5695.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13704 lossL: tensor(6749.1802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13705 lossL: tensor(6036.1182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13706 lossL: tensor(6532.6333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13707 lossL: tensor(7247.2549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13708 lossL: tensor(6877.6187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13709 lossL: tensor(6728.3442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13710 lossL: tensor(6548.2158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13711 lossL: tensor(6321.0454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13712 lossL: tensor(6880.3169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13713 lossL: tensor(6698.3071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13714 lossL: tensor(8427.1738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13715 lossL: tensor(7676.2700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13716 lossL: tensor(6656.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13717 lossL: tensor(6854.1934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13718 lossL: tensor(5951.9653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13719 lossL: tensor(5874.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13720 lossL: tensor(6605.3350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13721 lossL: tensor(6322.4458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13722 lossL: tensor(6115.2700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13723 lossL: tensor(7114.6807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13724 lossL: tensor(7450.9136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13725 lossL: tensor(6687.1030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13726 lossL: tensor(6048.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13727 lossL: tensor(6923.8965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13728 lossL: tensor(5570.7183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13729 lossL: tensor(7061.4932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13730 lossL: tensor(5259.1514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13731 lossL: tensor(6231.8604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13732 lossL: tensor(5773.3062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13733 lossL: tensor(5311.3813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13734 lossL: tensor(5583.8975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13735 lossL: tensor(5613.5371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13736 lossL: tensor(5004.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13737 lossL: tensor(6793.3926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13738 lossL: tensor(5939.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13739 lossL: tensor(5487.3169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13740 lossL: tensor(6397.3560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13741 lossL: tensor(7127.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13742 lossL: tensor(5465.7861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13743 lossL: tensor(5921.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13744 lossL: tensor(7140.0200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13745 lossL: tensor(5427.5435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13746 lossL: tensor(5271.1416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13747 lossL: tensor(5664.3735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13748 lossL: tensor(5953.2729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13749 lossL: tensor(7716.6123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13750 lossL: tensor(7636.3198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13751 lossL: tensor(5567.5449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13752 lossL: tensor(5851.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13753 lossL: tensor(5991.2114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13754 lossL: tensor(6670.0815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13755 lossL: tensor(6269.8462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13756 lossL: tensor(5906.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13757 lossL: tensor(6799.3931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13758 lossL: tensor(5162.6060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13759 lossL: tensor(5179.7456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13760 lossL: tensor(6627.3525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13761 lossL: tensor(5078.9019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13762 lossL: tensor(6016.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13763 lossL: tensor(7132.8506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13764 lossL: tensor(5801.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13765 lossL: tensor(7004.7197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13766 lossL: tensor(6885.9355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13767 lossL: tensor(6731.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13768 lossL: tensor(4992.3105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13769 lossL: tensor(5533.0728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13770 lossL: tensor(4739.2710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "13771 lossL: tensor(5531.2095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13772 lossL: tensor(5085.8486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13773 lossL: tensor(7153.1030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13774 lossL: tensor(6316.3384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13775 lossL: tensor(5904.2412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13776 lossL: tensor(7300.4800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13777 lossL: tensor(6556.9150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13778 lossL: tensor(6438.2319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13779 lossL: tensor(5802.4780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13780 lossL: tensor(4939.9966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13781 lossL: tensor(7088.5747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13782 lossL: tensor(5226.6279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13783 lossL: tensor(6736.3442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13784 lossL: tensor(6584.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13785 lossL: tensor(6282.0083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13786 lossL: tensor(7015.2700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13787 lossL: tensor(6481.9038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13788 lossL: tensor(6654.1631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13789 lossL: tensor(6344.8262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13790 lossL: tensor(6501.9741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13791 lossL: tensor(5257.2319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13792 lossL: tensor(6161.6147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13793 lossL: tensor(6877.6606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13794 lossL: tensor(5944.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13795 lossL: tensor(5715.6201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13796 lossL: tensor(5688.7534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13797 lossL: tensor(7097.3618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13798 lossL: tensor(5596.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13799 lossL: tensor(6069.4746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13800 lossL: tensor(5988.2881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13801 lossL: tensor(6040.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13802 lossL: tensor(6270.6460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13803 lossL: tensor(5146.9370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13804 lossL: tensor(6445.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13805 lossL: tensor(5834.3921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13806 lossL: tensor(5717.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13807 lossL: tensor(6174.6792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13808 lossL: tensor(5324.3872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13809 lossL: tensor(5851.3433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13810 lossL: tensor(6498.0532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13811 lossL: tensor(5802.5996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13812 lossL: tensor(5365.7329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13813 lossL: tensor(6586.9995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13814 lossL: tensor(5563.8872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13815 lossL: tensor(5181.9326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13816 lossL: tensor(5449.3545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13817 lossL: tensor(5781.0815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13818 lossL: tensor(5118.0708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13819 lossL: tensor(6529.2837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13820 lossL: tensor(5544.8232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13821 lossL: tensor(5576.8218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13822 lossL: tensor(5533.0200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13823 lossL: tensor(4918.3350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13824 lossL: tensor(5720.9785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13825 lossL: tensor(5650.3076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13826 lossL: tensor(6562.0400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13827 lossL: tensor(5395.8364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13828 lossL: tensor(5894.6768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13829 lossL: tensor(5545.1465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13830 lossL: tensor(6450.9282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13831 lossL: tensor(6179.4829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13832 lossL: tensor(5402.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13833 lossL: tensor(5882.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13834 lossL: tensor(5431.9316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13835 lossL: tensor(6179.4053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13836 lossL: tensor(5715.5620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13837 lossL: tensor(5996.5239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13838 lossL: tensor(5756.7729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13839 lossL: tensor(6075.0552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13840 lossL: tensor(5876.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13841 lossL: tensor(5064.9209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13842 lossL: tensor(6353.2397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13843 lossL: tensor(5651.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13844 lossL: tensor(6984.6475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13845 lossL: tensor(5789.0205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13846 lossL: tensor(6736.1675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13847 lossL: tensor(6227.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13848 lossL: tensor(5412.3027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13849 lossL: tensor(5984.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13850 lossL: tensor(5667.6377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13851 lossL: tensor(5562.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13852 lossL: tensor(6032.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13853 lossL: tensor(6286.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13854 lossL: tensor(5808.2817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13855 lossL: tensor(4717.0723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "13856 lossL: tensor(6456.5435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13857 lossL: tensor(6419.0288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13858 lossL: tensor(5667.6001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13859 lossL: tensor(5334.8188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13860 lossL: tensor(6469.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13861 lossL: tensor(5634.5522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13862 lossL: tensor(7592.0107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13863 lossL: tensor(6246.9614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13864 lossL: tensor(6018.2373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13865 lossL: tensor(5814.4937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13866 lossL: tensor(5826.7192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13867 lossL: tensor(6789.5552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13868 lossL: tensor(6170.8540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13869 lossL: tensor(7353.9365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13870 lossL: tensor(7099.9624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13871 lossL: tensor(5393.6382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13872 lossL: tensor(5994.2769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13873 lossL: tensor(5749.9390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13874 lossL: tensor(5481.5879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13875 lossL: tensor(7024.1650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13876 lossL: tensor(6264.6631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13877 lossL: tensor(6532.1865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13878 lossL: tensor(5761.7100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13879 lossL: tensor(6884.7251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13880 lossL: tensor(6260.9780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13881 lossL: tensor(5610.4692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13882 lossL: tensor(6917.8267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13883 lossL: tensor(5239.8389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13884 lossL: tensor(6346.3833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13885 lossL: tensor(5489.7124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13886 lossL: tensor(7016.2007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13887 lossL: tensor(5305.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13888 lossL: tensor(5802.3760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13889 lossL: tensor(6698.5659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13890 lossL: tensor(4889.2715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13891 lossL: tensor(5688.6738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13892 lossL: tensor(7271.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13893 lossL: tensor(5738.8931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13894 lossL: tensor(6127.7798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13895 lossL: tensor(5176.4580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13896 lossL: tensor(5297.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13897 lossL: tensor(5407.3130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13898 lossL: tensor(6474.1787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13899 lossL: tensor(6638.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13900 lossL: tensor(7055.8252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13901 lossL: tensor(5197.0527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13902 lossL: tensor(4882.6865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13903 lossL: tensor(6609.3442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13904 lossL: tensor(5567.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13905 lossL: tensor(5634.3696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13906 lossL: tensor(5661.6147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13907 lossL: tensor(5763.3389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13908 lossL: tensor(6657.8857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13909 lossL: tensor(6687.2388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13910 lossL: tensor(5348.5654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13911 lossL: tensor(5927.1494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13912 lossL: tensor(5732.4497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13913 lossL: tensor(6569.8818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13914 lossL: tensor(5255.3999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13915 lossL: tensor(6168.2842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13916 lossL: tensor(5648.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13917 lossL: tensor(5887.8052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13918 lossL: tensor(6004.3066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13919 lossL: tensor(5561.6826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13920 lossL: tensor(5431.2676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13921 lossL: tensor(5771.0225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13922 lossL: tensor(6037.7715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13923 lossL: tensor(5566.4434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13924 lossL: tensor(5413.8374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13925 lossL: tensor(6382.3076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13926 lossL: tensor(6258.1870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13927 lossL: tensor(5456.8433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13928 lossL: tensor(5528.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13929 lossL: tensor(5919.1714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13930 lossL: tensor(6500.9116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13931 lossL: tensor(5147.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13932 lossL: tensor(5562.4722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13933 lossL: tensor(5038.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13934 lossL: tensor(5734.7612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13935 lossL: tensor(5697.6240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13936 lossL: tensor(5796.8350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13937 lossL: tensor(6751.9932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13938 lossL: tensor(5949.5640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13939 lossL: tensor(6973.7769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13940 lossL: tensor(5629.3091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13941 lossL: tensor(4882.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13942 lossL: tensor(6166.0957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13943 lossL: tensor(5628.6064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13944 lossL: tensor(5461.0161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13945 lossL: tensor(5767.5132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13946 lossL: tensor(5961.5811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13947 lossL: tensor(5318.9194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13948 lossL: tensor(6223.1304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13949 lossL: tensor(5423.4209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13950 lossL: tensor(5325.8877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13951 lossL: tensor(5313.8882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13952 lossL: tensor(5938.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13953 lossL: tensor(6148.7451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13954 lossL: tensor(5822.3765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13955 lossL: tensor(5953.2529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13956 lossL: tensor(5576.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13957 lossL: tensor(4662.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "13958 lossL: tensor(6122.3511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13959 lossL: tensor(4690.8232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13960 lossL: tensor(5342.1504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13961 lossL: tensor(6489.4907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13962 lossL: tensor(5925.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13963 lossL: tensor(5061.2754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13964 lossL: tensor(5273.5718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13965 lossL: tensor(6584.8345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13966 lossL: tensor(5022.2124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13967 lossL: tensor(5589.1768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13968 lossL: tensor(5452.8545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13969 lossL: tensor(5641.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13970 lossL: tensor(4911.8770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13971 lossL: tensor(6967.4893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13972 lossL: tensor(4977.6016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13973 lossL: tensor(6412.2583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13974 lossL: tensor(5019.2168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13975 lossL: tensor(5253.9717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13976 lossL: tensor(5992.7979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13977 lossL: tensor(5425.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13978 lossL: tensor(5931.7056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13979 lossL: tensor(5311.5371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13980 lossL: tensor(5898.7646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13981 lossL: tensor(7053.7881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13982 lossL: tensor(4753.7373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13983 lossL: tensor(5531.1924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13984 lossL: tensor(5106.0942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13985 lossL: tensor(5927.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13986 lossL: tensor(5171.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13987 lossL: tensor(5560.3257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13988 lossL: tensor(5317.6353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13989 lossL: tensor(5426.5825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13990 lossL: tensor(4393.5864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "13991 lossL: tensor(5518.2217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13992 lossL: tensor(5864.9268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13993 lossL: tensor(5776.7222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13994 lossL: tensor(5413.9902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13995 lossL: tensor(6029.1611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13996 lossL: tensor(5687.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13997 lossL: tensor(5232.9912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "13998 lossL: tensor(4272.6963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "13999 lossL: tensor(4711.6108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14000 lossL: tensor(5698.1118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14001 lossL: tensor(6424.2256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14002 lossL: tensor(5781.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14003 lossL: tensor(5840.8979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14004 lossL: tensor(6528.2866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14005 lossL: tensor(5576.4873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14006 lossL: tensor(4892.5063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14007 lossL: tensor(5665.6309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14008 lossL: tensor(5208.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14009 lossL: tensor(4931.5605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14010 lossL: tensor(5397.2573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14011 lossL: tensor(4424.2212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14012 lossL: tensor(5119.2749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14013 lossL: tensor(5261.9731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14014 lossL: tensor(5027.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14015 lossL: tensor(5512.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14016 lossL: tensor(6182.7339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14017 lossL: tensor(5598.8032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14018 lossL: tensor(5591.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14019 lossL: tensor(5230.4717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14020 lossL: tensor(5683.9565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14021 lossL: tensor(5406.3643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14022 lossL: tensor(5790.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14023 lossL: tensor(4985.8853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14024 lossL: tensor(5229.9692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14025 lossL: tensor(5328.5342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14026 lossL: tensor(5780.0845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14027 lossL: tensor(5806.5220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14028 lossL: tensor(5036.1060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14029 lossL: tensor(5171.6372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14030 lossL: tensor(5732.6392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14031 lossL: tensor(5381.3086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14032 lossL: tensor(5940.2827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14033 lossL: tensor(4865.5288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14034 lossL: tensor(4665.6489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14035 lossL: tensor(6495.2822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14036 lossL: tensor(7222.9575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14037 lossL: tensor(6584.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14038 lossL: tensor(6094.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14039 lossL: tensor(5851.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14040 lossL: tensor(6577.9946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14041 lossL: tensor(4722.3755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14042 lossL: tensor(6029.3774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14043 lossL: tensor(6392.8779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14044 lossL: tensor(5420.5044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14045 lossL: tensor(5855.8838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14046 lossL: tensor(6930.3271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14047 lossL: tensor(5145.4722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14048 lossL: tensor(5556.6177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14049 lossL: tensor(5188.7026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14050 lossL: tensor(5694.6060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14051 lossL: tensor(6445.2373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14052 lossL: tensor(5517.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14053 lossL: tensor(5074.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14054 lossL: tensor(6008.2939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14055 lossL: tensor(5788.1479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14056 lossL: tensor(5510.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14057 lossL: tensor(6587.3354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14058 lossL: tensor(5270.6396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14059 lossL: tensor(5023.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14060 lossL: tensor(4519.9390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14061 lossL: tensor(5820.7778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14062 lossL: tensor(4951.2520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14063 lossL: tensor(5989.8306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14064 lossL: tensor(4665.7920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14065 lossL: tensor(5552.8755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14066 lossL: tensor(4846.6450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14067 lossL: tensor(6242.6064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14068 lossL: tensor(4857.6753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14069 lossL: tensor(4908.4966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14070 lossL: tensor(5861.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14071 lossL: tensor(5030.0415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14072 lossL: tensor(5702.5967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14073 lossL: tensor(5013.1807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14074 lossL: tensor(6135.1826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14075 lossL: tensor(6374.6465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14076 lossL: tensor(4053.5967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "14077 lossL: tensor(6320.8540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14078 lossL: tensor(5336.4951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14079 lossL: tensor(4772.0840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14080 lossL: tensor(5012.8306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14081 lossL: tensor(4832.3750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14082 lossL: tensor(5675.7021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14083 lossL: tensor(4564.6216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14084 lossL: tensor(4738.2471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14085 lossL: tensor(6271.6782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14086 lossL: tensor(5746.8701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14087 lossL: tensor(5169.9155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14088 lossL: tensor(5308.2627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14089 lossL: tensor(5252.3169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14090 lossL: tensor(5889.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14091 lossL: tensor(4995.8599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14092 lossL: tensor(4873.8389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14093 lossL: tensor(4540.5708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14094 lossL: tensor(4900.1182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14095 lossL: tensor(4955.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14096 lossL: tensor(6455.2573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14097 lossL: tensor(5331.5317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14098 lossL: tensor(5093.5688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14099 lossL: tensor(5158.2725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14100 lossL: tensor(5102.1460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14101 lossL: tensor(6595.3604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14102 lossL: tensor(6173.2632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14103 lossL: tensor(5677.2554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14104 lossL: tensor(4978.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14105 lossL: tensor(5862.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14106 lossL: tensor(4688.5439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14107 lossL: tensor(4335.3037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14108 lossL: tensor(5293.5171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14109 lossL: tensor(5447.5913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14110 lossL: tensor(4153.7910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14111 lossL: tensor(5299.1616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14112 lossL: tensor(5666.3394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14113 lossL: tensor(5573.1582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14114 lossL: tensor(5191.0454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14115 lossL: tensor(5774.4443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14116 lossL: tensor(5179.9624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14117 lossL: tensor(5707.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14118 lossL: tensor(5666.9946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14119 lossL: tensor(5304.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14120 lossL: tensor(5170.0649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14121 lossL: tensor(5298.5688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14122 lossL: tensor(6530.8003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14123 lossL: tensor(5289.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14124 lossL: tensor(5103.2983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14125 lossL: tensor(5009.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14126 lossL: tensor(6248.2529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14127 lossL: tensor(5290.3965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14128 lossL: tensor(4574.9507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14129 lossL: tensor(5930.8525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14130 lossL: tensor(5394.1479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14131 lossL: tensor(4888.6650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14132 lossL: tensor(4893.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14133 lossL: tensor(6292.0166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14134 lossL: tensor(6047.9644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14135 lossL: tensor(4752.7471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14136 lossL: tensor(5403.2368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14137 lossL: tensor(5197.2559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14138 lossL: tensor(4535.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14139 lossL: tensor(5481.6440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14140 lossL: tensor(4680.1865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14141 lossL: tensor(5201.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14142 lossL: tensor(4723.5034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14143 lossL: tensor(5491.8193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14144 lossL: tensor(4902.3599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14145 lossL: tensor(5051.1343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14146 lossL: tensor(4938.3091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14147 lossL: tensor(5008.2866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14148 lossL: tensor(5431.4307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14149 lossL: tensor(5899.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14150 lossL: tensor(5098.1064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14151 lossL: tensor(4756.1377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14152 lossL: tensor(5837.6509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14153 lossL: tensor(5710.4580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14154 lossL: tensor(5224.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14155 lossL: tensor(5235.2085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14156 lossL: tensor(4775.7783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14157 lossL: tensor(4563.9312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14158 lossL: tensor(5109.7388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14159 lossL: tensor(4752.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14160 lossL: tensor(4917.1553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14161 lossL: tensor(5170.6714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14162 lossL: tensor(4877.3657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14163 lossL: tensor(4276.1030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14164 lossL: tensor(4969.6011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14165 lossL: tensor(5271.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14166 lossL: tensor(4736.6982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14167 lossL: tensor(4855.8374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14168 lossL: tensor(5687.1577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14169 lossL: tensor(4644.4185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14170 lossL: tensor(5114.1543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14171 lossL: tensor(5589.4878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14172 lossL: tensor(5666.3638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14173 lossL: tensor(5823.6226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14174 lossL: tensor(5609.3354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14175 lossL: tensor(5803.0479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14176 lossL: tensor(5548.9692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14177 lossL: tensor(5231.1938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14178 lossL: tensor(4974.0386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14179 lossL: tensor(5492.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14180 lossL: tensor(4885.7861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14181 lossL: tensor(5500.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14182 lossL: tensor(4797.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14183 lossL: tensor(5527.9556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14184 lossL: tensor(4975.3042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14185 lossL: tensor(5194.7568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14186 lossL: tensor(4617.1616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14187 lossL: tensor(4606.2124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14188 lossL: tensor(5310.3491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14189 lossL: tensor(5233.3623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14190 lossL: tensor(4789.7603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14191 lossL: tensor(5035.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14192 lossL: tensor(4331.5098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14193 lossL: tensor(4879.2378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14194 lossL: tensor(5127.3838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14195 lossL: tensor(5678.8564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14196 lossL: tensor(4924.9756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14197 lossL: tensor(5124.7085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14198 lossL: tensor(4955.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14199 lossL: tensor(5866.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14200 lossL: tensor(4438.7847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14201 lossL: tensor(4799.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14202 lossL: tensor(4461.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14203 lossL: tensor(4806.1450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14204 lossL: tensor(4560.6694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14205 lossL: tensor(5309.3335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14206 lossL: tensor(5207.2881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14207 lossL: tensor(6073.1245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14208 lossL: tensor(4745.0864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14209 lossL: tensor(4787.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14210 lossL: tensor(6647.9087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14211 lossL: tensor(5054.9561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14212 lossL: tensor(5738.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14213 lossL: tensor(5139.0181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14214 lossL: tensor(4661.0894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14215 lossL: tensor(5958.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14216 lossL: tensor(4787.7217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14217 lossL: tensor(4462.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14218 lossL: tensor(5732.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14219 lossL: tensor(6238.5493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14220 lossL: tensor(5609.0303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14221 lossL: tensor(4685.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14222 lossL: tensor(4408.5762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14223 lossL: tensor(5621.2622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14224 lossL: tensor(4580.4556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14225 lossL: tensor(5307.5024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14226 lossL: tensor(4862.4746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14227 lossL: tensor(5125.3237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14228 lossL: tensor(5227.6099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14229 lossL: tensor(5008.3428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14230 lossL: tensor(4856.4897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14231 lossL: tensor(5123.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14232 lossL: tensor(4518.7319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14233 lossL: tensor(5249.2563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14234 lossL: tensor(5139.6323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14235 lossL: tensor(5124.3916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14236 lossL: tensor(5149.2026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14237 lossL: tensor(5305.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14238 lossL: tensor(4912.9756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14239 lossL: tensor(6039.9307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14240 lossL: tensor(5235.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14241 lossL: tensor(4762.3525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14242 lossL: tensor(5394.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14243 lossL: tensor(5832.1450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14244 lossL: tensor(4785.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14245 lossL: tensor(4461.6216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14246 lossL: tensor(4909.9468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14247 lossL: tensor(5606.2939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14248 lossL: tensor(5590.6108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14249 lossL: tensor(5315.4507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14250 lossL: tensor(5101.7568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14251 lossL: tensor(4391.2197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14252 lossL: tensor(4805.3394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14253 lossL: tensor(4969.3389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14254 lossL: tensor(6272.2749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14255 lossL: tensor(5178.5767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14256 lossL: tensor(5080.0303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14257 lossL: tensor(6092.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14258 lossL: tensor(4847.5503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14259 lossL: tensor(4507.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14260 lossL: tensor(4853.9819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14261 lossL: tensor(4795.2334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14262 lossL: tensor(5535.9980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14263 lossL: tensor(4553.8423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14264 lossL: tensor(4660.0425, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14265 lossL: tensor(4413.8345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14266 lossL: tensor(4700.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14267 lossL: tensor(4964.4775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14268 lossL: tensor(6060.0293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14269 lossL: tensor(4392.5620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14270 lossL: tensor(5504.4858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14271 lossL: tensor(4438.8560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14272 lossL: tensor(5238.1909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14273 lossL: tensor(4153.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14274 lossL: tensor(5036.8232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14275 lossL: tensor(6016.0244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14276 lossL: tensor(5297.7808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14277 lossL: tensor(4634.0298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14278 lossL: tensor(4388.9126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14279 lossL: tensor(5367.7466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14280 lossL: tensor(4561.8418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14281 lossL: tensor(4858.5356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14282 lossL: tensor(6528.5815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14283 lossL: tensor(5242.7295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14284 lossL: tensor(5919.3550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14285 lossL: tensor(4827.2876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14286 lossL: tensor(5031.9165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14287 lossL: tensor(5039.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14288 lossL: tensor(5420.1191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14289 lossL: tensor(6187.6104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14290 lossL: tensor(5321.7666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14291 lossL: tensor(5331.1685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14292 lossL: tensor(4637.3960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14293 lossL: tensor(5174.2959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14294 lossL: tensor(3932.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "14295 lossL: tensor(4747.6812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14296 lossL: tensor(5470.7993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14297 lossL: tensor(5440.9473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14298 lossL: tensor(5047.5908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14299 lossL: tensor(4548.0708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14300 lossL: tensor(5044.2480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14301 lossL: tensor(4636.8486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14302 lossL: tensor(5076.4976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14303 lossL: tensor(5688.0698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14304 lossL: tensor(4643.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14305 lossL: tensor(4586.6411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14306 lossL: tensor(4640.1152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14307 lossL: tensor(4706.6729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14308 lossL: tensor(4521.1113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14309 lossL: tensor(4880.2197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14310 lossL: tensor(3842.8630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "14311 lossL: tensor(4853.0200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14312 lossL: tensor(5672.0132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14313 lossL: tensor(4607.8652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14314 lossL: tensor(5058.4424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14315 lossL: tensor(5217.2598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14316 lossL: tensor(5028.9111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14317 lossL: tensor(4390.8862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14318 lossL: tensor(4034.0261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14319 lossL: tensor(4649.9316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14320 lossL: tensor(4664.2949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14321 lossL: tensor(4880.0220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14322 lossL: tensor(4907.8086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14323 lossL: tensor(5544.1016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14324 lossL: tensor(4888.2046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14325 lossL: tensor(4707.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14326 lossL: tensor(4790.5830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14327 lossL: tensor(4101.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14328 lossL: tensor(6974.3726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14329 lossL: tensor(5361.6597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14330 lossL: tensor(5642.9526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14331 lossL: tensor(4664.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14332 lossL: tensor(5401.7017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14333 lossL: tensor(4654.3354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14334 lossL: tensor(4252.3623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14335 lossL: tensor(4666.1182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14336 lossL: tensor(5712.7061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14337 lossL: tensor(5475.2061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14338 lossL: tensor(4500.2393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14339 lossL: tensor(4473.1694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14340 lossL: tensor(4507.2798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14341 lossL: tensor(5181.1436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14342 lossL: tensor(5327.0435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14343 lossL: tensor(5352.5952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14344 lossL: tensor(4944.2163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14345 lossL: tensor(4692.7847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14346 lossL: tensor(4281.5991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14347 lossL: tensor(5633.7026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14348 lossL: tensor(4412.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14349 lossL: tensor(4760.5986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14350 lossL: tensor(5035.0054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14351 lossL: tensor(5133.5044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14352 lossL: tensor(4069.0623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14353 lossL: tensor(4723.6270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14354 lossL: tensor(5143.7646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14355 lossL: tensor(4360.8452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14356 lossL: tensor(5978.6909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14357 lossL: tensor(4609.8291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14358 lossL: tensor(5056.1182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14359 lossL: tensor(4861.1772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14360 lossL: tensor(4374.8740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14361 lossL: tensor(4123.2510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14362 lossL: tensor(4594.2217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14363 lossL: tensor(4201.8247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14364 lossL: tensor(5651.8022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14365 lossL: tensor(4309.6782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14366 lossL: tensor(4327.5254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14367 lossL: tensor(4647.4009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14368 lossL: tensor(5337.4717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14369 lossL: tensor(4765.8848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14370 lossL: tensor(5040.9438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14371 lossL: tensor(5020.0806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14372 lossL: tensor(5010.3774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14373 lossL: tensor(5176.9551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14374 lossL: tensor(4805.5654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14375 lossL: tensor(4118.8872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14376 lossL: tensor(5294.5947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14377 lossL: tensor(4815.8560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14378 lossL: tensor(5526.5654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14379 lossL: tensor(5751.4937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14380 lossL: tensor(5077.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14381 lossL: tensor(5343.8862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14382 lossL: tensor(5084.9121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14383 lossL: tensor(5051.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14384 lossL: tensor(5315.9307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14385 lossL: tensor(5155.7046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14386 lossL: tensor(5919.9639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14387 lossL: tensor(5523.2744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14388 lossL: tensor(5575.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14389 lossL: tensor(4888.0825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14390 lossL: tensor(5298.6558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14391 lossL: tensor(4321.3794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14392 lossL: tensor(5789.3936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14393 lossL: tensor(5114.0454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14394 lossL: tensor(5285.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14395 lossL: tensor(4363.2490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14396 lossL: tensor(4410.3701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14397 lossL: tensor(4395.3770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14398 lossL: tensor(4822.9668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14399 lossL: tensor(5122.5981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14400 lossL: tensor(5597.9390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14401 lossL: tensor(4438.9380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14402 lossL: tensor(3846.6079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14403 lossL: tensor(5498.8545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14404 lossL: tensor(4050.6008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14405 lossL: tensor(4661.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14406 lossL: tensor(5191.2222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14407 lossL: tensor(5239.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14408 lossL: tensor(4421.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14409 lossL: tensor(5257.0840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14410 lossL: tensor(5180.4829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14411 lossL: tensor(5160.4858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14412 lossL: tensor(5285.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14413 lossL: tensor(4724.8115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14414 lossL: tensor(4875.8232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14415 lossL: tensor(4679.0986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14416 lossL: tensor(5943.6499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14417 lossL: tensor(5548.6025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14418 lossL: tensor(3943.5591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14419 lossL: tensor(5305.5161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14420 lossL: tensor(4511.6724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14421 lossL: tensor(5006.3906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14422 lossL: tensor(5032.2090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14423 lossL: tensor(4716.6470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14424 lossL: tensor(4761.4692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14425 lossL: tensor(5819.2051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14426 lossL: tensor(4435.7798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14427 lossL: tensor(4369.5024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14428 lossL: tensor(4788.6929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14429 lossL: tensor(4933.5605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14430 lossL: tensor(4246.9072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14431 lossL: tensor(4400.3569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14432 lossL: tensor(5437.5146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14433 lossL: tensor(5702.4634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14434 lossL: tensor(4664.0283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14435 lossL: tensor(4596.5811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14436 lossL: tensor(5212.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14437 lossL: tensor(5636.7246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14438 lossL: tensor(5310.2935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14439 lossL: tensor(5661.6772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14440 lossL: tensor(4688.0356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14441 lossL: tensor(4747.8291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14442 lossL: tensor(5844.4751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14443 lossL: tensor(4080.6372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14444 lossL: tensor(5652.2363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14445 lossL: tensor(4531.7905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14446 lossL: tensor(4238.6880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14447 lossL: tensor(4624.7339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14448 lossL: tensor(5136.1875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14449 lossL: tensor(5046.7651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14450 lossL: tensor(4789.3701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14451 lossL: tensor(4910.1333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14452 lossL: tensor(4937.3018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14453 lossL: tensor(4306.2798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14454 lossL: tensor(4218.9458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14455 lossL: tensor(4557.7998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14456 lossL: tensor(4701.8413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14457 lossL: tensor(4945.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14458 lossL: tensor(4480.6084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14459 lossL: tensor(4642.6987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14460 lossL: tensor(5223.7900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14461 lossL: tensor(4393.5063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14462 lossL: tensor(4593.2280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14463 lossL: tensor(5259.2651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14464 lossL: tensor(4699.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14465 lossL: tensor(5240.3613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14466 lossL: tensor(4527.3667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14467 lossL: tensor(4635.0967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14468 lossL: tensor(5289.1001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14469 lossL: tensor(4999.2900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14470 lossL: tensor(4999.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14471 lossL: tensor(4954.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14472 lossL: tensor(5022.1392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14473 lossL: tensor(4394.2456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14474 lossL: tensor(4394.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14475 lossL: tensor(4606.9985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14476 lossL: tensor(4871.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14477 lossL: tensor(5562.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14478 lossL: tensor(4327.0996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14479 lossL: tensor(4842.0386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14480 lossL: tensor(4835.4595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14481 lossL: tensor(4686.8198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14482 lossL: tensor(5167.4092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14483 lossL: tensor(4809.0645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14484 lossL: tensor(4461.5151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14485 lossL: tensor(4512.5908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14486 lossL: tensor(4924.6221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14487 lossL: tensor(5593.6348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14488 lossL: tensor(4609.0347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14489 lossL: tensor(4638.5693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14490 lossL: tensor(4550.4951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14491 lossL: tensor(5261.9678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14492 lossL: tensor(4484.6538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14493 lossL: tensor(5301.6450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14494 lossL: tensor(5219.6567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14495 lossL: tensor(4279.9033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14496 lossL: tensor(4732.7817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14497 lossL: tensor(4296.6553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14498 lossL: tensor(5122.4614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14499 lossL: tensor(3967.3528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14500 lossL: tensor(4424.3901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14501 lossL: tensor(4509.8442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14502 lossL: tensor(5119.2549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14503 lossL: tensor(4353.6509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14504 lossL: tensor(4419.2153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14505 lossL: tensor(4769.9575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14506 lossL: tensor(5060.6597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14507 lossL: tensor(4338.4248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14508 lossL: tensor(3904.1025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14509 lossL: tensor(4286.1899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14510 lossL: tensor(4584.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14511 lossL: tensor(4758.1040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14512 lossL: tensor(4563.8862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14513 lossL: tensor(5218.6431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14514 lossL: tensor(3897.4780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14515 lossL: tensor(5855.2056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14516 lossL: tensor(4493.8931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14517 lossL: tensor(4634.6362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14518 lossL: tensor(4871.6470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14519 lossL: tensor(4932.9160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14520 lossL: tensor(5924.0088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14521 lossL: tensor(4444.3267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14522 lossL: tensor(5359.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14523 lossL: tensor(4627.5571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14524 lossL: tensor(4714.4302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14525 lossL: tensor(5575.5908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14526 lossL: tensor(5036.2095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14527 lossL: tensor(5290.2432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14528 lossL: tensor(4945.5728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14529 lossL: tensor(4599.4507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14530 lossL: tensor(5846.5688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14531 lossL: tensor(5135.0840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14532 lossL: tensor(4618.6489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14533 lossL: tensor(5782.2100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14534 lossL: tensor(4377.9087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14535 lossL: tensor(4864.4712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14536 lossL: tensor(5406.2866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14537 lossL: tensor(4516.8291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14538 lossL: tensor(5467.4331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14539 lossL: tensor(4006.8550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14540 lossL: tensor(4092.6711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14541 lossL: tensor(4435.9771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14542 lossL: tensor(3955.9189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14543 lossL: tensor(4978.5537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14544 lossL: tensor(4041.4626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14545 lossL: tensor(5604.9697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14546 lossL: tensor(3924.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14547 lossL: tensor(4541.9434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14548 lossL: tensor(4458.6294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14549 lossL: tensor(4809.9600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14550 lossL: tensor(4040.7756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14551 lossL: tensor(4445.8511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14552 lossL: tensor(3808.4124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "14553 lossL: tensor(5011.2905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14554 lossL: tensor(4144.1226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14555 lossL: tensor(4296.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14556 lossL: tensor(3766.0652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "14557 lossL: tensor(4186.0708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14558 lossL: tensor(4336.8340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14559 lossL: tensor(3900.4753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14560 lossL: tensor(3867.2356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14561 lossL: tensor(4454.0610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14562 lossL: tensor(4628.9585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14563 lossL: tensor(4489.8647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14564 lossL: tensor(4048.0552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14565 lossL: tensor(5478.2500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14566 lossL: tensor(4289.4434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14567 lossL: tensor(4538.3257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14568 lossL: tensor(4902.8062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14569 lossL: tensor(4197.6060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14570 lossL: tensor(4148.4824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14571 lossL: tensor(3840., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14572 lossL: tensor(4615.5742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14573 lossL: tensor(4529.9810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14574 lossL: tensor(4249.7236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14575 lossL: tensor(4406.4580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14576 lossL: tensor(4296.8013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14577 lossL: tensor(4173.1396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14578 lossL: tensor(3884.2268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14579 lossL: tensor(4040.7524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14580 lossL: tensor(4399.1938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14581 lossL: tensor(3989.5007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14582 lossL: tensor(3771.1904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14583 lossL: tensor(4681.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14584 lossL: tensor(4335.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14585 lossL: tensor(4996.6440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14586 lossL: tensor(4702.8193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14587 lossL: tensor(5646.9473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14588 lossL: tensor(3666.3157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "14589 lossL: tensor(4317.9424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14590 lossL: tensor(4424.9536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14591 lossL: tensor(4341.8936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14592 lossL: tensor(4912.7207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14593 lossL: tensor(5185.0649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14594 lossL: tensor(4594.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14595 lossL: tensor(4256.8604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14596 lossL: tensor(3737.0076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14597 lossL: tensor(4728.4790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14598 lossL: tensor(3706.6040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14599 lossL: tensor(4137.2129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14600 lossL: tensor(4362.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14601 lossL: tensor(3572.8464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "14602 lossL: tensor(4045.3621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14603 lossL: tensor(3999.1951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14604 lossL: tensor(3926.2224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14605 lossL: tensor(4132.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14606 lossL: tensor(4169.4712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14607 lossL: tensor(4670.7998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14608 lossL: tensor(5328.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14609 lossL: tensor(5421.6299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14610 lossL: tensor(4900.8628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14611 lossL: tensor(4659.2266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14612 lossL: tensor(4491.5532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14613 lossL: tensor(4399.5459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14614 lossL: tensor(4935.4937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14615 lossL: tensor(4054.9089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14616 lossL: tensor(4722.1880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14617 lossL: tensor(4608.3154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14618 lossL: tensor(4486.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14619 lossL: tensor(5170.1572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14620 lossL: tensor(5026.4204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14621 lossL: tensor(4493.7441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14622 lossL: tensor(4348.9199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14623 lossL: tensor(4101.9600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14624 lossL: tensor(4941.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14625 lossL: tensor(4424.8223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14626 lossL: tensor(4261.4702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14627 lossL: tensor(4299.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14628 lossL: tensor(4209.7378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14629 lossL: tensor(4869.5103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14630 lossL: tensor(3790.4915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14631 lossL: tensor(5329.2710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14632 lossL: tensor(3939.7102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14633 lossL: tensor(5312.8833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14634 lossL: tensor(4484.4346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14635 lossL: tensor(4248.8115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14636 lossL: tensor(4622.9858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14637 lossL: tensor(4327.3315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14638 lossL: tensor(4269.4004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14639 lossL: tensor(4944.2559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14640 lossL: tensor(5398.9404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14641 lossL: tensor(4391.7471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14642 lossL: tensor(4317.4360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14643 lossL: tensor(4444.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14644 lossL: tensor(5409.8511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14645 lossL: tensor(4463.9473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14646 lossL: tensor(4384.5098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14647 lossL: tensor(4172.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14648 lossL: tensor(4389.3809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14649 lossL: tensor(3777.6074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14650 lossL: tensor(4720.6260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14651 lossL: tensor(4855.7212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14652 lossL: tensor(3677.9277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14653 lossL: tensor(4251.7124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14654 lossL: tensor(4782.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14655 lossL: tensor(4185.6973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14656 lossL: tensor(4350.9199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14657 lossL: tensor(4967.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14658 lossL: tensor(4991.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14659 lossL: tensor(4024.4978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14660 lossL: tensor(4606.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14661 lossL: tensor(3768.7490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14662 lossL: tensor(3946.5361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14663 lossL: tensor(4028.9995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14664 lossL: tensor(4823.1387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14665 lossL: tensor(4230.0576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14666 lossL: tensor(4393.6768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14667 lossL: tensor(4319.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14668 lossL: tensor(4739.7041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14669 lossL: tensor(4356.2339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14670 lossL: tensor(4115.8120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14671 lossL: tensor(3941.4800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14672 lossL: tensor(3983.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14673 lossL: tensor(4103.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14674 lossL: tensor(4454.4717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14675 lossL: tensor(3758.1519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14676 lossL: tensor(4433.4722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14677 lossL: tensor(4726.4355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14678 lossL: tensor(4181.0425, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14679 lossL: tensor(4474.1372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14680 lossL: tensor(4593.4053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14681 lossL: tensor(4829.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14682 lossL: tensor(4145.8755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14683 lossL: tensor(3835.5547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14684 lossL: tensor(4402.1538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14685 lossL: tensor(4112.3740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14686 lossL: tensor(3724.9399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14687 lossL: tensor(5081.7261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14688 lossL: tensor(4249.7856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14689 lossL: tensor(4258.1372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14690 lossL: tensor(3665.7971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14691 lossL: tensor(5029.5054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14692 lossL: tensor(3530.4353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "14693 lossL: tensor(4208.3657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14694 lossL: tensor(4461.4009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14695 lossL: tensor(4435.1177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14696 lossL: tensor(4256.8115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14697 lossL: tensor(4569.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14698 lossL: tensor(4750.5576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14699 lossL: tensor(4270.3486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14700 lossL: tensor(5024.8091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14701 lossL: tensor(4429.5088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14702 lossL: tensor(5238.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14703 lossL: tensor(4556.7603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14704 lossL: tensor(3815.4451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14705 lossL: tensor(5013.9282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14706 lossL: tensor(3965.1221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14707 lossL: tensor(5826.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14708 lossL: tensor(4170.4165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14709 lossL: tensor(3752.5906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14710 lossL: tensor(3903.5750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14711 lossL: tensor(3770.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14712 lossL: tensor(5257.0850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14713 lossL: tensor(3772.6431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14714 lossL: tensor(3909.1721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14715 lossL: tensor(4295.4233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14716 lossL: tensor(4627.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14717 lossL: tensor(4441.1377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14718 lossL: tensor(4253.5947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14719 lossL: tensor(4679.0464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14720 lossL: tensor(3740.0986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14721 lossL: tensor(4312.1479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14722 lossL: tensor(3513.3267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "14723 lossL: tensor(4711.6201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14724 lossL: tensor(4059.8232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14725 lossL: tensor(4314.1597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14726 lossL: tensor(4519.1221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14727 lossL: tensor(3992.9070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14728 lossL: tensor(3776.9795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14729 lossL: tensor(5674.2485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14730 lossL: tensor(4468.3857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14731 lossL: tensor(4817.8198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14732 lossL: tensor(4521.1763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14733 lossL: tensor(4513.6045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14734 lossL: tensor(4236.3271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14735 lossL: tensor(3830.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14736 lossL: tensor(4024.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14737 lossL: tensor(5028.7832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14738 lossL: tensor(4901.4448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14739 lossL: tensor(3811.2417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14740 lossL: tensor(4896.7319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14741 lossL: tensor(5093.3706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14742 lossL: tensor(4709.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14743 lossL: tensor(4933.7339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14744 lossL: tensor(3955.6101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14745 lossL: tensor(5297.6597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14746 lossL: tensor(4707.9546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14747 lossL: tensor(4488.9668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14748 lossL: tensor(5139.9160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14749 lossL: tensor(4093.0923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14750 lossL: tensor(4439.3120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14751 lossL: tensor(4244.5752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14752 lossL: tensor(3982.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14753 lossL: tensor(4082.7559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14754 lossL: tensor(4225.9033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14755 lossL: tensor(4238.9233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14756 lossL: tensor(3957.0422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14757 lossL: tensor(4413.5659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14758 lossL: tensor(4231.8071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14759 lossL: tensor(3892.7761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14760 lossL: tensor(3744.6218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14761 lossL: tensor(4157.6660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14762 lossL: tensor(3814.6501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14763 lossL: tensor(4248.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14764 lossL: tensor(4402.4517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14765 lossL: tensor(4100.2090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14766 lossL: tensor(4070.6816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14767 lossL: tensor(3829.5532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14768 lossL: tensor(3974.5696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14769 lossL: tensor(4524.7446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14770 lossL: tensor(4551.8403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14771 lossL: tensor(4202.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14772 lossL: tensor(4141.7065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14773 lossL: tensor(4367.4502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14774 lossL: tensor(4466.0449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14775 lossL: tensor(3923.5161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14776 lossL: tensor(4604.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14777 lossL: tensor(3895.9868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14778 lossL: tensor(4093.6008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14779 lossL: tensor(3901.8923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14780 lossL: tensor(3732.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14781 lossL: tensor(3896.2844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14782 lossL: tensor(4226.4136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14783 lossL: tensor(3603.6499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14784 lossL: tensor(3632.2061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14785 lossL: tensor(4532.7212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14786 lossL: tensor(4410.6577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14787 lossL: tensor(4509.5269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14788 lossL: tensor(3967.8552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14789 lossL: tensor(4012.7942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14790 lossL: tensor(3698.6814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14791 lossL: tensor(4814.7925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14792 lossL: tensor(4233.9619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14793 lossL: tensor(4138.2358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14794 lossL: tensor(3695.8647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14795 lossL: tensor(4946.6860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14796 lossL: tensor(4359.9438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14797 lossL: tensor(4308.2446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14798 lossL: tensor(4395.8496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14799 lossL: tensor(3833.9607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14800 lossL: tensor(4761.7993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14801 lossL: tensor(4754.2163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14802 lossL: tensor(3989.2749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14803 lossL: tensor(5088.7046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14804 lossL: tensor(4367.3208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14805 lossL: tensor(4380.2437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14806 lossL: tensor(4063.5691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14807 lossL: tensor(4548.3237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14808 lossL: tensor(3970.7441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14809 lossL: tensor(3621.3960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14810 lossL: tensor(3918.8550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14811 lossL: tensor(4509.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14812 lossL: tensor(3938.8630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14813 lossL: tensor(4541.7524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14814 lossL: tensor(4130.7314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14815 lossL: tensor(4517.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14816 lossL: tensor(4363.3403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14817 lossL: tensor(4100.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14818 lossL: tensor(3625.3845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14819 lossL: tensor(3779.0674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14820 lossL: tensor(3885.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14821 lossL: tensor(3859.7717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14822 lossL: tensor(4599.8101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14823 lossL: tensor(3868.9421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14824 lossL: tensor(3981.4502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14825 lossL: tensor(4245.1851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14826 lossL: tensor(4072.3662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14827 lossL: tensor(3538.1951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14828 lossL: tensor(3874.2566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14829 lossL: tensor(4202.1475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14830 lossL: tensor(4236.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14831 lossL: tensor(4214.7666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14832 lossL: tensor(4086.7126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14833 lossL: tensor(3915.9250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14834 lossL: tensor(4089.0464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14835 lossL: tensor(3829.5940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14836 lossL: tensor(4269.5752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14837 lossL: tensor(4327.6221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14838 lossL: tensor(4511.6704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14839 lossL: tensor(3874.7651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14840 lossL: tensor(3653.9277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14841 lossL: tensor(3510.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "14842 lossL: tensor(4325.4546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14843 lossL: tensor(4575.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14844 lossL: tensor(3726.4949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14845 lossL: tensor(4668.8457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14846 lossL: tensor(3735.7590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14847 lossL: tensor(4271.4551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14848 lossL: tensor(4011.0730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14849 lossL: tensor(4344.4653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14850 lossL: tensor(3987.1130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14851 lossL: tensor(3902.6953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14852 lossL: tensor(4053.1345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14853 lossL: tensor(4157.8799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14854 lossL: tensor(4572.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14855 lossL: tensor(3853.7495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14856 lossL: tensor(4469.4341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14857 lossL: tensor(3548.7605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14858 lossL: tensor(3951.9700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14859 lossL: tensor(4400.8096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14860 lossL: tensor(3913.5054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14861 lossL: tensor(3906.0830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14862 lossL: tensor(4003.9395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14863 lossL: tensor(4223.9014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14864 lossL: tensor(3357.2637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "14865 lossL: tensor(3923.0718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14866 lossL: tensor(4056.5981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14867 lossL: tensor(3587.4700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14868 lossL: tensor(4180.1011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14869 lossL: tensor(3994.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14870 lossL: tensor(3737.1279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14871 lossL: tensor(4065.1919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14872 lossL: tensor(4237.1357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14873 lossL: tensor(3559.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14874 lossL: tensor(4315.5654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14875 lossL: tensor(4182.7583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14876 lossL: tensor(3644.6702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14877 lossL: tensor(3764.1165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14878 lossL: tensor(3942.7966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14879 lossL: tensor(4011.4417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14880 lossL: tensor(3784.2529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14881 lossL: tensor(4827.2817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14882 lossL: tensor(3225.0828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "14883 lossL: tensor(3795.1038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14884 lossL: tensor(3912.9941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14885 lossL: tensor(3885.9314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14886 lossL: tensor(4258.7944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14887 lossL: tensor(3596.8621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14888 lossL: tensor(3681.2192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14889 lossL: tensor(4059.2620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14890 lossL: tensor(3781.7332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14891 lossL: tensor(4290.0112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14892 lossL: tensor(3952.6174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14893 lossL: tensor(4244.1084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14894 lossL: tensor(4219.9683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14895 lossL: tensor(3780.6116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14896 lossL: tensor(3749.6775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14897 lossL: tensor(3655.0808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14898 lossL: tensor(3975.6848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14899 lossL: tensor(4573.6025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14900 lossL: tensor(3464.3481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14901 lossL: tensor(3971.0847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14902 lossL: tensor(4557.7983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14903 lossL: tensor(3561.0894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14904 lossL: tensor(3831.2036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14905 lossL: tensor(3956.4224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14906 lossL: tensor(3840.7407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14907 lossL: tensor(4140.8130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14908 lossL: tensor(3817.0466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14909 lossL: tensor(4491.2676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14910 lossL: tensor(4024.1155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14911 lossL: tensor(4427.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14912 lossL: tensor(4164.4819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14913 lossL: tensor(3495.6311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14914 lossL: tensor(3670.0840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14915 lossL: tensor(3481.1191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14916 lossL: tensor(4345.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14917 lossL: tensor(3787.1636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14918 lossL: tensor(3867.4722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14919 lossL: tensor(3472.8706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14920 lossL: tensor(4077.5361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14921 lossL: tensor(3708.8640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14922 lossL: tensor(4006.8914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14923 lossL: tensor(4446.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14924 lossL: tensor(4397.2817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14925 lossL: tensor(3887.3210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14926 lossL: tensor(4696.7627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14927 lossL: tensor(3511.7466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14928 lossL: tensor(3727.8667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14929 lossL: tensor(3601.2478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14930 lossL: tensor(3889.4548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14931 lossL: tensor(3298.9470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14932 lossL: tensor(3868.6538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14933 lossL: tensor(3580.8345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14934 lossL: tensor(4031.6892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14935 lossL: tensor(3989.6960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14936 lossL: tensor(4169.4834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14937 lossL: tensor(4005.2952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14938 lossL: tensor(3435.2559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14939 lossL: tensor(4310.0771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14940 lossL: tensor(3859.3499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14941 lossL: tensor(4000.4895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14942 lossL: tensor(4557.9541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14943 lossL: tensor(3987.8716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14944 lossL: tensor(3874.5959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14945 lossL: tensor(4184.4976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14946 lossL: tensor(4005.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14947 lossL: tensor(3830.2766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14948 lossL: tensor(3748.5344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14949 lossL: tensor(3654.9541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14950 lossL: tensor(3983.1321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14951 lossL: tensor(3842.6907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14952 lossL: tensor(3950.4229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14953 lossL: tensor(4955.5259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14954 lossL: tensor(4005.5491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14955 lossL: tensor(4372.1865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14956 lossL: tensor(3991.9277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14957 lossL: tensor(3436.6626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14958 lossL: tensor(3836.7170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14959 lossL: tensor(4291.7314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14960 lossL: tensor(4279.5146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14961 lossL: tensor(4156.1411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14962 lossL: tensor(4413.5630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14963 lossL: tensor(4060.2407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14964 lossL: tensor(3780.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14965 lossL: tensor(3696.4358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14966 lossL: tensor(3710.2673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14967 lossL: tensor(4090.9058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14968 lossL: tensor(4363.5815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14969 lossL: tensor(3706.3503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14970 lossL: tensor(3718.9126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14971 lossL: tensor(4209.3687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14972 lossL: tensor(4079.7112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14973 lossL: tensor(4248.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14974 lossL: tensor(4113.4834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14975 lossL: tensor(3719.9036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14976 lossL: tensor(3405.2805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14977 lossL: tensor(3984.3586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14978 lossL: tensor(3249.6169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14979 lossL: tensor(3695.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14980 lossL: tensor(3498.6421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14981 lossL: tensor(4045.2554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14982 lossL: tensor(3917.8186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14983 lossL: tensor(3764.3823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14984 lossL: tensor(3832.3816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14985 lossL: tensor(3807.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14986 lossL: tensor(4840.2725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14987 lossL: tensor(3555.1152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14988 lossL: tensor(3446.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14989 lossL: tensor(4433.2471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14990 lossL: tensor(3849.0327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14991 lossL: tensor(3893.1865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14992 lossL: tensor(4226.7490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14993 lossL: tensor(3649.6726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14994 lossL: tensor(4412.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14995 lossL: tensor(4191.3877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14996 lossL: tensor(4440.9619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14997 lossL: tensor(3784.6187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14998 lossL: tensor(3420.1038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "14999 lossL: tensor(4730.8188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15000 lossL: tensor(3951.5771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15001 lossL: tensor(4591.1821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15002 lossL: tensor(4335.8428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15003 lossL: tensor(3916.0469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15004 lossL: tensor(4730.6133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15005 lossL: tensor(3957.0095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15006 lossL: tensor(4410.7124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15007 lossL: tensor(3782.7212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15008 lossL: tensor(3727.6052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15009 lossL: tensor(4640.7261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15010 lossL: tensor(3757.8267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15011 lossL: tensor(3954.8809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15012 lossL: tensor(4085.2649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15013 lossL: tensor(4224.4521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15014 lossL: tensor(3666.7720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15015 lossL: tensor(3578.7751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15016 lossL: tensor(3692.8484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15017 lossL: tensor(3780.9819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15018 lossL: tensor(3632.5984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15019 lossL: tensor(4120.5264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15020 lossL: tensor(3633.8997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15021 lossL: tensor(3861.9197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15022 lossL: tensor(3669.0046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15023 lossL: tensor(4729.0483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15024 lossL: tensor(3823.1379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15025 lossL: tensor(4374.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15026 lossL: tensor(3864.6306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15027 lossL: tensor(3728.2285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15028 lossL: tensor(3764.1243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15029 lossL: tensor(3918.1755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15030 lossL: tensor(4253.7715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15031 lossL: tensor(4355.9619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15032 lossL: tensor(4324.1460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15033 lossL: tensor(4002.0286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15034 lossL: tensor(4616.3779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15035 lossL: tensor(3540.3303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15036 lossL: tensor(3590.0786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15037 lossL: tensor(3816.1250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15038 lossL: tensor(3922.1284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15039 lossL: tensor(4226.4634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15040 lossL: tensor(3392.1565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15041 lossL: tensor(3717.8760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15042 lossL: tensor(4102.5806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15043 lossL: tensor(4084.2834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15044 lossL: tensor(3301.9031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15045 lossL: tensor(3983.3257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15046 lossL: tensor(3606.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15047 lossL: tensor(4068.1636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15048 lossL: tensor(3198.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "15049 lossL: tensor(4172.9800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15050 lossL: tensor(3888.2324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15051 lossL: tensor(4328.5674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15052 lossL: tensor(3876.0496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15053 lossL: tensor(3929.3792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15054 lossL: tensor(4013.5481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15055 lossL: tensor(4237.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15056 lossL: tensor(3277.1997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15057 lossL: tensor(3791.4807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15058 lossL: tensor(3807.2791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15059 lossL: tensor(3890.6106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15060 lossL: tensor(3517.4995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15061 lossL: tensor(3431.1292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15062 lossL: tensor(3960.0889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15063 lossL: tensor(3654.8411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15064 lossL: tensor(4100.5122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15065 lossL: tensor(3566.3772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15066 lossL: tensor(4009.3933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15067 lossL: tensor(3480.1208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15068 lossL: tensor(3705.7788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15069 lossL: tensor(3562.8665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15070 lossL: tensor(3530.3232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15071 lossL: tensor(4225.3813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15072 lossL: tensor(3928.6091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15073 lossL: tensor(3408.3618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15074 lossL: tensor(3314.9277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15075 lossL: tensor(3865.4629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15076 lossL: tensor(3374.4932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15077 lossL: tensor(3731.2080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15078 lossL: tensor(3371.8948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15079 lossL: tensor(3684.9646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15080 lossL: tensor(3464.3962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15081 lossL: tensor(3506.4209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15082 lossL: tensor(3534.8682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15083 lossL: tensor(3763.0071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15084 lossL: tensor(3816.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15085 lossL: tensor(3972.0225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15086 lossL: tensor(3426.8457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15087 lossL: tensor(3726.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15088 lossL: tensor(3893.5464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15089 lossL: tensor(3380.5510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15090 lossL: tensor(3665.7612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15091 lossL: tensor(3370.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15092 lossL: tensor(3734.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15093 lossL: tensor(3929.6355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15094 lossL: tensor(3410.2732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15095 lossL: tensor(3714.5649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15096 lossL: tensor(3930.9587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15097 lossL: tensor(3736.8662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15098 lossL: tensor(3923.4060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15099 lossL: tensor(3660.5623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15100 lossL: tensor(3421.3179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15101 lossL: tensor(3709.2991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15102 lossL: tensor(3998.9587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15103 lossL: tensor(4405.8657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15104 lossL: tensor(4359.8667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15105 lossL: tensor(4200.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15106 lossL: tensor(3350.7942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15107 lossL: tensor(4093.6296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15108 lossL: tensor(3715.1829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15109 lossL: tensor(4194.2080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15110 lossL: tensor(3571.3555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15111 lossL: tensor(3695.9556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15112 lossL: tensor(5471.2827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15113 lossL: tensor(3828.7356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15114 lossL: tensor(3890.5759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15115 lossL: tensor(4661.0083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15116 lossL: tensor(4044.2993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15117 lossL: tensor(3785.1885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15118 lossL: tensor(3231.4343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15119 lossL: tensor(3867.2717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15120 lossL: tensor(3240.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15121 lossL: tensor(3521.0083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15122 lossL: tensor(4175.4443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15123 lossL: tensor(4364.8833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15124 lossL: tensor(3739.2012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15125 lossL: tensor(3269.4470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15126 lossL: tensor(4039.5647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15127 lossL: tensor(3639.8074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15128 lossL: tensor(3632.5696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15129 lossL: tensor(3499.1150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15130 lossL: tensor(3646.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15131 lossL: tensor(3494.3904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15132 lossL: tensor(3931.0972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15133 lossL: tensor(3874.1858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15134 lossL: tensor(3493.7097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15135 lossL: tensor(3660.1938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15136 lossL: tensor(3963.1145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15137 lossL: tensor(3720.1118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15138 lossL: tensor(3624.8342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15139 lossL: tensor(3741.8057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15140 lossL: tensor(2954.6079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "15141 lossL: tensor(3559.9109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15142 lossL: tensor(3606.6833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15143 lossL: tensor(3615.2710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15144 lossL: tensor(4385.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15145 lossL: tensor(4280.7646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15146 lossL: tensor(4156.3481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15147 lossL: tensor(3724.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15148 lossL: tensor(3805.6299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15149 lossL: tensor(3831.3394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15150 lossL: tensor(4119.4917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15151 lossL: tensor(3465.8669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15152 lossL: tensor(3858.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15153 lossL: tensor(3667.9172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15154 lossL: tensor(3732.7222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15155 lossL: tensor(3188.5947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15156 lossL: tensor(3793.1816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15157 lossL: tensor(3358.0793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15158 lossL: tensor(3634.7603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15159 lossL: tensor(3789.8088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15160 lossL: tensor(3728.5398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15161 lossL: tensor(3818.7991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15162 lossL: tensor(4006.1167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15163 lossL: tensor(3314.4526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15164 lossL: tensor(3667.9517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15165 lossL: tensor(3406.8879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15166 lossL: tensor(3309.3347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15167 lossL: tensor(4351.9663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15168 lossL: tensor(3772.2029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15169 lossL: tensor(3420.7502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15170 lossL: tensor(3473.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15171 lossL: tensor(3674.9785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15172 lossL: tensor(3737.5295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15173 lossL: tensor(3724.6924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15174 lossL: tensor(3167.4272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15175 lossL: tensor(3163.9568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15176 lossL: tensor(3378.7153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15177 lossL: tensor(3412.3665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15178 lossL: tensor(4079.4053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15179 lossL: tensor(4014.7002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15180 lossL: tensor(3547.1255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15181 lossL: tensor(3571.3579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15182 lossL: tensor(3354.8130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15183 lossL: tensor(3400.2583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15184 lossL: tensor(3307.8562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15185 lossL: tensor(3738.1450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15186 lossL: tensor(4179.4858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15187 lossL: tensor(4444.7651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15188 lossL: tensor(3989.6611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15189 lossL: tensor(3765.0129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15190 lossL: tensor(3415.7649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15191 lossL: tensor(3671.6484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15192 lossL: tensor(3753.3809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15193 lossL: tensor(4182.4634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15194 lossL: tensor(4112.6787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15195 lossL: tensor(3686.7161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15196 lossL: tensor(3802.2273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15197 lossL: tensor(3392.4321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15198 lossL: tensor(3465.0698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15199 lossL: tensor(3484.3210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15200 lossL: tensor(3715.1064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15201 lossL: tensor(3470.4744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15202 lossL: tensor(3631.8523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15203 lossL: tensor(3478.1572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15204 lossL: tensor(3411.4045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15205 lossL: tensor(3756.3391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15206 lossL: tensor(3595.4380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15207 lossL: tensor(3187.2588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15208 lossL: tensor(3580.0615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15209 lossL: tensor(3515.8176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15210 lossL: tensor(3604.2229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15211 lossL: tensor(3623.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15212 lossL: tensor(4262.2212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15213 lossL: tensor(3274.6257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15214 lossL: tensor(3104.9287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15215 lossL: tensor(3549.9656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15216 lossL: tensor(3176.5288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15217 lossL: tensor(3759.8916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15218 lossL: tensor(3659.9729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15219 lossL: tensor(3772.3955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15220 lossL: tensor(3840.4014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15221 lossL: tensor(3735.8198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15222 lossL: tensor(3766.2542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15223 lossL: tensor(3393.7686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15224 lossL: tensor(3384.2815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15225 lossL: tensor(3432.2007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15226 lossL: tensor(3246.1248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15227 lossL: tensor(3623.4958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15228 lossL: tensor(3788.8213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15229 lossL: tensor(3275.0229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15230 lossL: tensor(5118.5308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15231 lossL: tensor(3113.0459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15232 lossL: tensor(3738.5437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15233 lossL: tensor(4088.6924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15234 lossL: tensor(3747.1143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15235 lossL: tensor(3848.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15236 lossL: tensor(4263.3765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15237 lossL: tensor(3601.0188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15238 lossL: tensor(3501.6267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15239 lossL: tensor(3680.4009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15240 lossL: tensor(3434.5635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15241 lossL: tensor(3511.9954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15242 lossL: tensor(3977.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15243 lossL: tensor(3719.5332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15244 lossL: tensor(3293.4233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15245 lossL: tensor(3197.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15246 lossL: tensor(3885.6838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15247 lossL: tensor(3597.6570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15248 lossL: tensor(3912.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15249 lossL: tensor(3462.6626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15250 lossL: tensor(3727.9565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15251 lossL: tensor(3636.2144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15252 lossL: tensor(3925.7798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15253 lossL: tensor(3944.2561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15254 lossL: tensor(3803.6338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15255 lossL: tensor(3832.0732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15256 lossL: tensor(3715.8701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15257 lossL: tensor(3576.8638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15258 lossL: tensor(3948.3596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15259 lossL: tensor(3381.4995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15260 lossL: tensor(3181.3101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15261 lossL: tensor(3593.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15262 lossL: tensor(3808.2739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15263 lossL: tensor(4189.9575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15264 lossL: tensor(3552.4187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15265 lossL: tensor(3560.7402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15266 lossL: tensor(3319.0398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15267 lossL: tensor(2781.5581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "15268 lossL: tensor(3561.2693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15269 lossL: tensor(3477.5310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15270 lossL: tensor(3510.3315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15271 lossL: tensor(3433.0894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15272 lossL: tensor(3824.4526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15273 lossL: tensor(3508.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15274 lossL: tensor(3821.7146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15275 lossL: tensor(3676.5344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15276 lossL: tensor(3258.8865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15277 lossL: tensor(4237.7593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15278 lossL: tensor(3712.9004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15279 lossL: tensor(3826.7673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15280 lossL: tensor(3695.6387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15281 lossL: tensor(3524.0325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15282 lossL: tensor(3916.4128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15283 lossL: tensor(3849.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15284 lossL: tensor(3604.7874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15285 lossL: tensor(3966.5627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15286 lossL: tensor(3951.6868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15287 lossL: tensor(3594.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15288 lossL: tensor(3813.9644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15289 lossL: tensor(3424.7661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15290 lossL: tensor(3274.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15291 lossL: tensor(3220.5774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15292 lossL: tensor(3915.4429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15293 lossL: tensor(3322.7710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15294 lossL: tensor(3519.3511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15295 lossL: tensor(3646.6550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15296 lossL: tensor(2884.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15297 lossL: tensor(3602.5154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15298 lossL: tensor(3379.0210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15299 lossL: tensor(3733.5200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15300 lossL: tensor(3764.5088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15301 lossL: tensor(2949.7693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15302 lossL: tensor(4229.6592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15303 lossL: tensor(3555.6851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15304 lossL: tensor(3565.7727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15305 lossL: tensor(3643.8228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15306 lossL: tensor(3705.8687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15307 lossL: tensor(3657.5652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15308 lossL: tensor(3062.5642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15309 lossL: tensor(3311.7483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15310 lossL: tensor(3557.4617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15311 lossL: tensor(2749.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "15312 lossL: tensor(3509.3003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15313 lossL: tensor(3786.8154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15314 lossL: tensor(3940.6460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15315 lossL: tensor(4096.8770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15316 lossL: tensor(3346.4641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15317 lossL: tensor(3747.6147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15318 lossL: tensor(3529.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15319 lossL: tensor(3671.8118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15320 lossL: tensor(3166.0205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15321 lossL: tensor(3760.9985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15322 lossL: tensor(4099.2515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15323 lossL: tensor(3710.2883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15324 lossL: tensor(3819.7568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15325 lossL: tensor(3109.9875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15326 lossL: tensor(3489.4424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15327 lossL: tensor(3364.3657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15328 lossL: tensor(2972.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15329 lossL: tensor(3463.4456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15330 lossL: tensor(3142.5137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15331 lossL: tensor(3093.9692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15332 lossL: tensor(3433.1885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15333 lossL: tensor(3604.9114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15334 lossL: tensor(3536.9858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15335 lossL: tensor(2903.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15336 lossL: tensor(3775.4858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15337 lossL: tensor(3305.6890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15338 lossL: tensor(3885.0225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15339 lossL: tensor(3545.4893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15340 lossL: tensor(3347.0066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15341 lossL: tensor(3094.0930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15342 lossL: tensor(3643.6768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15343 lossL: tensor(3839.5901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15344 lossL: tensor(3698.7349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15345 lossL: tensor(3278.5981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15346 lossL: tensor(3795.5464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15347 lossL: tensor(3236.9456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15348 lossL: tensor(3004.6167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15349 lossL: tensor(3181.9016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15350 lossL: tensor(4014.8674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15351 lossL: tensor(4511.3652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15352 lossL: tensor(3550.6140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15353 lossL: tensor(3033.6450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15354 lossL: tensor(3534.1858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15355 lossL: tensor(3266.4824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15356 lossL: tensor(3663.2837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15357 lossL: tensor(3866.6169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15358 lossL: tensor(3420.7349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15359 lossL: tensor(3637.4509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15360 lossL: tensor(3661.8445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15361 lossL: tensor(3048.4717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15362 lossL: tensor(3374.1541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15363 lossL: tensor(4048.5151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15364 lossL: tensor(3690.1890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15365 lossL: tensor(3230.7053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15366 lossL: tensor(3279.7041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15367 lossL: tensor(3481.7534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15368 lossL: tensor(3850.8044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15369 lossL: tensor(3631.1697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15370 lossL: tensor(3229.5808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15371 lossL: tensor(3648.1208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15372 lossL: tensor(3346.6421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15373 lossL: tensor(3372.8540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15374 lossL: tensor(3302.8027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15375 lossL: tensor(3165.3257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15376 lossL: tensor(3936.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15377 lossL: tensor(3123.5032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15378 lossL: tensor(3475.9827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15379 lossL: tensor(3072.1252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15380 lossL: tensor(3071.2708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15381 lossL: tensor(3576.5593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15382 lossL: tensor(3098.8315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15383 lossL: tensor(3237.4934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15384 lossL: tensor(3184.6226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15385 lossL: tensor(2928.5786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15386 lossL: tensor(3761.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15387 lossL: tensor(2940.3821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15388 lossL: tensor(3320.3970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15389 lossL: tensor(3319.3391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15390 lossL: tensor(3615.7417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15391 lossL: tensor(3337.5493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15392 lossL: tensor(3846.7334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15393 lossL: tensor(3108.5698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15394 lossL: tensor(3487.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15395 lossL: tensor(3544.9980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15396 lossL: tensor(3245.2544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15397 lossL: tensor(3583.9463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15398 lossL: tensor(3244.6321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15399 lossL: tensor(3565.7703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15400 lossL: tensor(3935.6855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15401 lossL: tensor(3379.7988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15402 lossL: tensor(2729.5981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "15403 lossL: tensor(3104.8154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15404 lossL: tensor(3129.0693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15405 lossL: tensor(3687.1035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15406 lossL: tensor(3330.1316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15407 lossL: tensor(3323.4177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15408 lossL: tensor(3378.0872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15409 lossL: tensor(3952.8333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15410 lossL: tensor(3341.7195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15411 lossL: tensor(3937.1379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15412 lossL: tensor(3742.3298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15413 lossL: tensor(3831.3113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15414 lossL: tensor(3371.6741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15415 lossL: tensor(3088.5332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15416 lossL: tensor(3440.7688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15417 lossL: tensor(3285.3513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15418 lossL: tensor(3357.3232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15419 lossL: tensor(2965.2507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15420 lossL: tensor(3164.2549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15421 lossL: tensor(3342.3726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15422 lossL: tensor(3552.1748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15423 lossL: tensor(3450.6643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15424 lossL: tensor(3618.5754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15425 lossL: tensor(4063.9126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15426 lossL: tensor(3253.9824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15427 lossL: tensor(3779.8318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15428 lossL: tensor(3050.6072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15429 lossL: tensor(3345.1765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15430 lossL: tensor(2962.9333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15431 lossL: tensor(3218.8174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15432 lossL: tensor(3388.5488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15433 lossL: tensor(3535.8496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15434 lossL: tensor(3750.5603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15435 lossL: tensor(3391.0942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15436 lossL: tensor(3410.6667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15437 lossL: tensor(3181.1753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15438 lossL: tensor(3739.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15439 lossL: tensor(3506.5002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15440 lossL: tensor(3091.5676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15441 lossL: tensor(3271.1470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15442 lossL: tensor(4242.8535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15443 lossL: tensor(3419.5579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15444 lossL: tensor(3364.3657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15445 lossL: tensor(3654.8831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15446 lossL: tensor(2815.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15447 lossL: tensor(3630.0693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15448 lossL: tensor(3306.4202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15449 lossL: tensor(3442.2034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15450 lossL: tensor(3210.8994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15451 lossL: tensor(2913.7329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15452 lossL: tensor(3271.5862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15453 lossL: tensor(3075.5510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15454 lossL: tensor(3864.1890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15455 lossL: tensor(3136.3638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15456 lossL: tensor(3556.5076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15457 lossL: tensor(3329.0549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15458 lossL: tensor(3142.7156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15459 lossL: tensor(3357.1521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15460 lossL: tensor(3140.4014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15461 lossL: tensor(3172.3638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15462 lossL: tensor(3573.3960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15463 lossL: tensor(3313.6350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15464 lossL: tensor(3423.5752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15465 lossL: tensor(3368.1616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15466 lossL: tensor(3037.0833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15467 lossL: tensor(3710.4385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15468 lossL: tensor(3002.6516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15469 lossL: tensor(3105.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15470 lossL: tensor(3048.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15471 lossL: tensor(3235.3562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15472 lossL: tensor(3036.8787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15473 lossL: tensor(3604.4612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15474 lossL: tensor(3080.2244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15475 lossL: tensor(2997.3000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15476 lossL: tensor(3344.4563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15477 lossL: tensor(3116.1526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15478 lossL: tensor(3600.4248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15479 lossL: tensor(3244.1067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15480 lossL: tensor(3367.6553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15481 lossL: tensor(3302.4294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15482 lossL: tensor(3440.1028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15483 lossL: tensor(3601.8494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15484 lossL: tensor(3048.7761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15485 lossL: tensor(3265.0449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15486 lossL: tensor(3009.0781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15487 lossL: tensor(2960.9312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15488 lossL: tensor(3848.3845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15489 lossL: tensor(3308.4456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15490 lossL: tensor(3832.5693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15491 lossL: tensor(3226.5500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15492 lossL: tensor(4128.7432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15493 lossL: tensor(3034.8206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15494 lossL: tensor(4074.1821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15495 lossL: tensor(3442.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15496 lossL: tensor(2986.0374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15497 lossL: tensor(3547.0825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15498 lossL: tensor(3183.8833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15499 lossL: tensor(3667.9976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15500 lossL: tensor(3317.0063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15501 lossL: tensor(3397.7397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15502 lossL: tensor(3446.8848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15503 lossL: tensor(2904.8652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15504 lossL: tensor(3138.7820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15505 lossL: tensor(3328.7322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15506 lossL: tensor(3173.1975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15507 lossL: tensor(3119.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15508 lossL: tensor(3263.5034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15509 lossL: tensor(3286.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15510 lossL: tensor(3228.9934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15511 lossL: tensor(3678.4475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15512 lossL: tensor(3416.4766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15513 lossL: tensor(3238.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15514 lossL: tensor(3422.2378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15515 lossL: tensor(3093.4075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15516 lossL: tensor(3709.7224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15517 lossL: tensor(3329.5264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15518 lossL: tensor(3271.0806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15519 lossL: tensor(3369.2566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15520 lossL: tensor(3244.2791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15521 lossL: tensor(3851.2358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15522 lossL: tensor(3258.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15523 lossL: tensor(3285.8962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15524 lossL: tensor(3992.5933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15525 lossL: tensor(3486.9026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15526 lossL: tensor(3574.4917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15527 lossL: tensor(2856.2021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15528 lossL: tensor(4190.8853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15529 lossL: tensor(3180.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15530 lossL: tensor(3099.2437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15531 lossL: tensor(3937.8813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15532 lossL: tensor(3274.8662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15533 lossL: tensor(3014.5845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15534 lossL: tensor(3345.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15535 lossL: tensor(2834.3101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15536 lossL: tensor(3758.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15537 lossL: tensor(3444.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15538 lossL: tensor(3512.7161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15539 lossL: tensor(3571.8191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15540 lossL: tensor(3087.2917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15541 lossL: tensor(3293.8367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15542 lossL: tensor(3276.6091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15543 lossL: tensor(3351.4683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15544 lossL: tensor(3527.0486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15545 lossL: tensor(3724.1313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15546 lossL: tensor(3094.6196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15547 lossL: tensor(3032.5488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15548 lossL: tensor(3248.7395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15549 lossL: tensor(3104.2815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15550 lossL: tensor(2825.5945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15551 lossL: tensor(2905.5989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15552 lossL: tensor(3299.6799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15553 lossL: tensor(3282.8108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15554 lossL: tensor(3555.2664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15555 lossL: tensor(3194.5029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15556 lossL: tensor(3275.9927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15557 lossL: tensor(3618.4011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15558 lossL: tensor(3427.3052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15559 lossL: tensor(3246.1931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15560 lossL: tensor(3758.1316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15561 lossL: tensor(3306.2180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15562 lossL: tensor(3102.7446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15563 lossL: tensor(3627.7974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15564 lossL: tensor(3787.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15565 lossL: tensor(3636.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15566 lossL: tensor(3173.9692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15567 lossL: tensor(2956.8284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15568 lossL: tensor(3163.5718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15569 lossL: tensor(3305.4231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15570 lossL: tensor(3308.7559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15571 lossL: tensor(3203.1448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15572 lossL: tensor(3176.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15573 lossL: tensor(3244.8660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15574 lossL: tensor(3334.5432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15575 lossL: tensor(3273.7546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15576 lossL: tensor(2771.6975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15577 lossL: tensor(2817.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15578 lossL: tensor(2869.2119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15579 lossL: tensor(3356.6462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15580 lossL: tensor(2951.9751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15581 lossL: tensor(3121.5674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15582 lossL: tensor(3461.4548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15583 lossL: tensor(3332.0442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15584 lossL: tensor(3100.3606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15585 lossL: tensor(3126.7251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15586 lossL: tensor(2922.1045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15587 lossL: tensor(3298.1365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15588 lossL: tensor(2818.0413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15589 lossL: tensor(3492.3694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15590 lossL: tensor(2814.7126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15591 lossL: tensor(3283.4377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15592 lossL: tensor(3714.8853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15593 lossL: tensor(3620.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15594 lossL: tensor(3074.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15595 lossL: tensor(2804.9622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15596 lossL: tensor(3168.1987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15597 lossL: tensor(3198.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15598 lossL: tensor(3497.0669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15599 lossL: tensor(3531.2195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15600 lossL: tensor(3046.9236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15601 lossL: tensor(3063.4348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15602 lossL: tensor(3676.8308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15603 lossL: tensor(3662.7402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15604 lossL: tensor(3677.3154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15605 lossL: tensor(3821.2603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15606 lossL: tensor(3161.2441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15607 lossL: tensor(3381.2749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15608 lossL: tensor(3085.8057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15609 lossL: tensor(3268.9175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15610 lossL: tensor(3074.7012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15611 lossL: tensor(3110.4075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15612 lossL: tensor(2887.4836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15613 lossL: tensor(3567.0432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15614 lossL: tensor(3425.9253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15615 lossL: tensor(2932.5515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15616 lossL: tensor(3448.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15617 lossL: tensor(3706.5278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15618 lossL: tensor(3189.3188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15619 lossL: tensor(2985.2102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15620 lossL: tensor(3215.1025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15621 lossL: tensor(3527.7075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15622 lossL: tensor(3004.4573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15623 lossL: tensor(3107.6921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15624 lossL: tensor(2753.6060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15625 lossL: tensor(3140.2847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15626 lossL: tensor(3147.5474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15627 lossL: tensor(2779.2795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15628 lossL: tensor(3123.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15629 lossL: tensor(3464.1238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15630 lossL: tensor(2726.2378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "15631 lossL: tensor(2969.9280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15632 lossL: tensor(2939.1628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15633 lossL: tensor(2979.4077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15634 lossL: tensor(3876.4851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15635 lossL: tensor(3218.1248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15636 lossL: tensor(3494.7952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15637 lossL: tensor(3042.4792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15638 lossL: tensor(3267.8499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15639 lossL: tensor(3092.8252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15640 lossL: tensor(3251.3542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15641 lossL: tensor(3026.9316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15642 lossL: tensor(3052.8147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15643 lossL: tensor(3626.0674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15644 lossL: tensor(3297.1575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15645 lossL: tensor(3701.0520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15646 lossL: tensor(3179.3501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15647 lossL: tensor(3257.2261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15648 lossL: tensor(3761.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15649 lossL: tensor(3880.0593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15650 lossL: tensor(3438.4912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15651 lossL: tensor(3942.9573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15652 lossL: tensor(2943.6096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15653 lossL: tensor(3049.2976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15654 lossL: tensor(3198.3452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15655 lossL: tensor(3115.6865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15656 lossL: tensor(3349.5537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15657 lossL: tensor(2950.6514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15658 lossL: tensor(2551.0291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "15659 lossL: tensor(3186.5500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15660 lossL: tensor(3046.7734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15661 lossL: tensor(3222.9680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15662 lossL: tensor(3424.6743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15663 lossL: tensor(2951.3801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15664 lossL: tensor(3257.3621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15665 lossL: tensor(3138.8484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15666 lossL: tensor(2895.5308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15667 lossL: tensor(3220.9365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15668 lossL: tensor(3262.5173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15669 lossL: tensor(3341.0095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15670 lossL: tensor(3145.8464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15671 lossL: tensor(3430.4231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15672 lossL: tensor(3272.1038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15673 lossL: tensor(2994.1082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15674 lossL: tensor(3200.7834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15675 lossL: tensor(2921.3511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15676 lossL: tensor(2787.7141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15677 lossL: tensor(2981.1724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15678 lossL: tensor(2965.0857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15679 lossL: tensor(2974.8015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15680 lossL: tensor(3011.7512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15681 lossL: tensor(3310.1694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15682 lossL: tensor(3508.2649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15683 lossL: tensor(3340.3245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15684 lossL: tensor(3209.3018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15685 lossL: tensor(3116.1340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15686 lossL: tensor(2892.3196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15687 lossL: tensor(3150.5801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15688 lossL: tensor(3269.2339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15689 lossL: tensor(3293.0754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15690 lossL: tensor(3082.8071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15691 lossL: tensor(3103.4753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15692 lossL: tensor(3090.2231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15693 lossL: tensor(2898.3025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15694 lossL: tensor(2889.5193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15695 lossL: tensor(2960.9685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15696 lossL: tensor(2616.4614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15697 lossL: tensor(3255.1545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15698 lossL: tensor(3063.5713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15699 lossL: tensor(2821.7410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15700 lossL: tensor(2953.4646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15701 lossL: tensor(2817.7375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15702 lossL: tensor(3046.3730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15703 lossL: tensor(3309.0830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15704 lossL: tensor(3249.5537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15705 lossL: tensor(3396.7036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15706 lossL: tensor(2938.4988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15707 lossL: tensor(3007.1960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15708 lossL: tensor(3172.9788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15709 lossL: tensor(3086.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15710 lossL: tensor(3319.4912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15711 lossL: tensor(3200.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15712 lossL: tensor(2760.6948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15713 lossL: tensor(3352.3723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15714 lossL: tensor(2693.5879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15715 lossL: tensor(3409.3787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15716 lossL: tensor(3629.0642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15717 lossL: tensor(3086.4656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15718 lossL: tensor(3415.7786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15719 lossL: tensor(3436.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15720 lossL: tensor(3048.2007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15721 lossL: tensor(3331.0225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15722 lossL: tensor(4005.8557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15723 lossL: tensor(2973.7966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15724 lossL: tensor(3292.3552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15725 lossL: tensor(2783.5813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15726 lossL: tensor(3157.8303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15727 lossL: tensor(3068.5527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15728 lossL: tensor(2959.8550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15729 lossL: tensor(3069.3088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15730 lossL: tensor(2993.3833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15731 lossL: tensor(2882.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15732 lossL: tensor(2982.3489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15733 lossL: tensor(3340.5535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15734 lossL: tensor(3042.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15735 lossL: tensor(2797.0972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15736 lossL: tensor(3399.0828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15737 lossL: tensor(3255.4204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15738 lossL: tensor(3077.1184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15739 lossL: tensor(3099.9941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15740 lossL: tensor(3168.0359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15741 lossL: tensor(2878.2395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15742 lossL: tensor(3304.7063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15743 lossL: tensor(3029.5022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15744 lossL: tensor(3434.5234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15745 lossL: tensor(2557.8518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15746 lossL: tensor(3201.0962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15747 lossL: tensor(3225.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15748 lossL: tensor(3490.4509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15749 lossL: tensor(3155.7358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15750 lossL: tensor(2860.4656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15751 lossL: tensor(3257.1943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15752 lossL: tensor(2796.4832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15753 lossL: tensor(3020.7593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15754 lossL: tensor(3059.2993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15755 lossL: tensor(3014.2380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15756 lossL: tensor(3064.8494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15757 lossL: tensor(3305.1450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15758 lossL: tensor(3736.9426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15759 lossL: tensor(2985.5967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15760 lossL: tensor(3050.6489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15761 lossL: tensor(3056.8762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15762 lossL: tensor(3132.5120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15763 lossL: tensor(2822.2434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15764 lossL: tensor(2764.2722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15765 lossL: tensor(3048.4189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15766 lossL: tensor(2821.0974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15767 lossL: tensor(3350.0120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15768 lossL: tensor(3365.4048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15769 lossL: tensor(2557.7917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15770 lossL: tensor(3102.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15771 lossL: tensor(3121.5256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15772 lossL: tensor(3112.4214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15773 lossL: tensor(3560.5671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15774 lossL: tensor(3317.4072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15775 lossL: tensor(3398.6794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15776 lossL: tensor(3041.8848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15777 lossL: tensor(2836.9487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15778 lossL: tensor(3008.6660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15779 lossL: tensor(2996.3584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15780 lossL: tensor(3053.9082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15781 lossL: tensor(3024.6545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15782 lossL: tensor(2495.7078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "15783 lossL: tensor(3005.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15784 lossL: tensor(3003.7529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15785 lossL: tensor(3136.2854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15786 lossL: tensor(3380.2708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15787 lossL: tensor(3104.6614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15788 lossL: tensor(3401.6670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15789 lossL: tensor(2550.3513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15790 lossL: tensor(3143.3113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15791 lossL: tensor(3125.7014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15792 lossL: tensor(2812.4873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15793 lossL: tensor(3157.4365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15794 lossL: tensor(2861.1377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15795 lossL: tensor(2987.4150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15796 lossL: tensor(2852.0078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15797 lossL: tensor(3661.0850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15798 lossL: tensor(3342.7622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15799 lossL: tensor(3330.0134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15800 lossL: tensor(3172.7295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15801 lossL: tensor(3178.0693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15802 lossL: tensor(3322.3589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15803 lossL: tensor(3095.6309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15804 lossL: tensor(3268.1323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15805 lossL: tensor(3113.3162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15806 lossL: tensor(2760.9292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15807 lossL: tensor(3156.2124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15808 lossL: tensor(3354.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15809 lossL: tensor(3171.2932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15810 lossL: tensor(2891.3684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15811 lossL: tensor(3325.3621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15812 lossL: tensor(3310.9792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15813 lossL: tensor(3487.0471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15814 lossL: tensor(2761.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15815 lossL: tensor(2642.3296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15816 lossL: tensor(3350.6997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15817 lossL: tensor(2855.7002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15818 lossL: tensor(3084.7756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15819 lossL: tensor(2704.7822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15820 lossL: tensor(3251.6978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15821 lossL: tensor(3457.2700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15822 lossL: tensor(3113.3977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15823 lossL: tensor(2931.3972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15824 lossL: tensor(3382.2202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15825 lossL: tensor(3189.5029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15826 lossL: tensor(3179.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15827 lossL: tensor(2770.3018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15828 lossL: tensor(3171.2905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15829 lossL: tensor(2943.6123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15830 lossL: tensor(2978.4268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15831 lossL: tensor(2968.3052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15832 lossL: tensor(3088.9160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15833 lossL: tensor(3596.6792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15834 lossL: tensor(2550.5190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15835 lossL: tensor(2971.7822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15836 lossL: tensor(3176.9956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15837 lossL: tensor(3170.2217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15838 lossL: tensor(3199.4221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15839 lossL: tensor(3259.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15840 lossL: tensor(3021.2173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15841 lossL: tensor(3013.3716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15842 lossL: tensor(3394.8005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15843 lossL: tensor(3180.7883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15844 lossL: tensor(2931.8899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15845 lossL: tensor(3228.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15846 lossL: tensor(3533.8530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15847 lossL: tensor(2937.6987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15848 lossL: tensor(3410.6265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15849 lossL: tensor(3168.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15850 lossL: tensor(3880.2805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15851 lossL: tensor(2860.7283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15852 lossL: tensor(3004.0339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15853 lossL: tensor(2976.7913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15854 lossL: tensor(2913.5110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15855 lossL: tensor(3448.1951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15856 lossL: tensor(3358.4822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15857 lossL: tensor(3323.3169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15858 lossL: tensor(3441.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15859 lossL: tensor(3203.7451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15860 lossL: tensor(2897.9104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15861 lossL: tensor(3156.1917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15862 lossL: tensor(3157.0427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15863 lossL: tensor(3087.3728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15864 lossL: tensor(2739.8296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15865 lossL: tensor(3189.2473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15866 lossL: tensor(2888.3604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15867 lossL: tensor(3537.3333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15868 lossL: tensor(2847.5981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15869 lossL: tensor(2670.3394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15870 lossL: tensor(2957.8696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15871 lossL: tensor(3233.6326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15872 lossL: tensor(3391.1592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15873 lossL: tensor(3008.9915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15874 lossL: tensor(3441.9814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15875 lossL: tensor(3141.9919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15876 lossL: tensor(3104.2524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15877 lossL: tensor(3061.0364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15878 lossL: tensor(3055.9700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15879 lossL: tensor(2987.0676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15880 lossL: tensor(3010.7729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15881 lossL: tensor(3149.0518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15882 lossL: tensor(3336.0667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15883 lossL: tensor(3184.9575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15884 lossL: tensor(2982.3347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15885 lossL: tensor(3024.9116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15886 lossL: tensor(2969.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15887 lossL: tensor(2623.6177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15888 lossL: tensor(2865.2136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15889 lossL: tensor(3369.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15890 lossL: tensor(3010.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15891 lossL: tensor(2888.0747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15892 lossL: tensor(2853.3000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15893 lossL: tensor(3018.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15894 lossL: tensor(2823.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15895 lossL: tensor(3202.9443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15896 lossL: tensor(2973.8611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15897 lossL: tensor(2729.3853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15898 lossL: tensor(2792.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15899 lossL: tensor(3164.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15900 lossL: tensor(2868.8738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15901 lossL: tensor(2956.5562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15902 lossL: tensor(2699.9597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15903 lossL: tensor(3210.2681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15904 lossL: tensor(3083.1731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15905 lossL: tensor(3055.0151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15906 lossL: tensor(2812.0562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15907 lossL: tensor(3242.5767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15908 lossL: tensor(2798.2278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15909 lossL: tensor(3202.8352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15910 lossL: tensor(2739.0408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15911 lossL: tensor(2886.3386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15912 lossL: tensor(3026.7124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15913 lossL: tensor(2774.4214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15914 lossL: tensor(2964.0688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15915 lossL: tensor(3298.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15916 lossL: tensor(3307.8467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15917 lossL: tensor(2872.5015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15918 lossL: tensor(2879.2952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15919 lossL: tensor(2768.9548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15920 lossL: tensor(2969.3872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15921 lossL: tensor(3112.8674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15922 lossL: tensor(2941.0229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15923 lossL: tensor(2753.8508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15924 lossL: tensor(3083.9746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15925 lossL: tensor(3320.5659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15926 lossL: tensor(2641.9517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15927 lossL: tensor(3145.9377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15928 lossL: tensor(2547.1045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15929 lossL: tensor(3322.9036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15930 lossL: tensor(3140.4946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15931 lossL: tensor(2992.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15932 lossL: tensor(3456.6372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15933 lossL: tensor(2998.0278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15934 lossL: tensor(2835.9189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15935 lossL: tensor(2959.8989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15936 lossL: tensor(3006.2327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15937 lossL: tensor(3048.2283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15938 lossL: tensor(3112.0752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15939 lossL: tensor(3339.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15940 lossL: tensor(2913.4182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15941 lossL: tensor(2590.9502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15942 lossL: tensor(2786.2488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15943 lossL: tensor(3061.4907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15944 lossL: tensor(2887.8027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15945 lossL: tensor(2882.9575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15946 lossL: tensor(2742.1233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15947 lossL: tensor(3028.9321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15948 lossL: tensor(2960.1003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15949 lossL: tensor(2633.5576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15950 lossL: tensor(2808.5359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15951 lossL: tensor(3144.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15952 lossL: tensor(3257.1248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15953 lossL: tensor(2849.5183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15954 lossL: tensor(3072.1057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15955 lossL: tensor(2656.2717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15956 lossL: tensor(3706.2524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15957 lossL: tensor(2964.5420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15958 lossL: tensor(3048.3591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15959 lossL: tensor(2795.1421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15960 lossL: tensor(2751.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15961 lossL: tensor(2881.0701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15962 lossL: tensor(3025.9602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15963 lossL: tensor(3276.5967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15964 lossL: tensor(3230.6487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15965 lossL: tensor(2676.3394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15966 lossL: tensor(2802.1853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15967 lossL: tensor(2561.4871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15968 lossL: tensor(2655.2412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15969 lossL: tensor(2981.4753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15970 lossL: tensor(2580.1167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15971 lossL: tensor(2911.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15972 lossL: tensor(2876.8677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15973 lossL: tensor(3097.9138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15974 lossL: tensor(2826.6882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15975 lossL: tensor(2650.6616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15976 lossL: tensor(3068.3831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15977 lossL: tensor(3506.4705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15978 lossL: tensor(2929.4839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15979 lossL: tensor(2850.5071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15980 lossL: tensor(2953.5623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15981 lossL: tensor(2938.4192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15982 lossL: tensor(2747.3413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15983 lossL: tensor(3120.8374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15984 lossL: tensor(3140.3235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15985 lossL: tensor(2803.0381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15986 lossL: tensor(2927.8533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15987 lossL: tensor(2734.8762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15988 lossL: tensor(3100.8706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15989 lossL: tensor(2867.9365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15990 lossL: tensor(2652.4902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15991 lossL: tensor(2417.2834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "15992 lossL: tensor(3047.7339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15993 lossL: tensor(3095.9624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15994 lossL: tensor(2913.2371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15995 lossL: tensor(2782.2295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15996 lossL: tensor(3038.8552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15997 lossL: tensor(3097.8354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15998 lossL: tensor(2864.9810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "15999 lossL: tensor(3046.7725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16000 lossL: tensor(3042.0063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16001 lossL: tensor(2896.4089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16002 lossL: tensor(3063.9692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16003 lossL: tensor(2543.4814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16004 lossL: tensor(2635.0671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16005 lossL: tensor(2924.4851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16006 lossL: tensor(2693.2517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16007 lossL: tensor(2826.7395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16008 lossL: tensor(3282.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16009 lossL: tensor(2891.9114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16010 lossL: tensor(2842.9663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16011 lossL: tensor(2791.6665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16012 lossL: tensor(3075.8557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16013 lossL: tensor(2619.2864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16014 lossL: tensor(2773.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16015 lossL: tensor(2603.7935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16016 lossL: tensor(2543.1399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16017 lossL: tensor(3257.7065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16018 lossL: tensor(2348.1431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "16019 lossL: tensor(2868.9724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16020 lossL: tensor(2733.4404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16021 lossL: tensor(3123.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16022 lossL: tensor(2836.2200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16023 lossL: tensor(2920.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16024 lossL: tensor(2843.6843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16025 lossL: tensor(2542.3916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16026 lossL: tensor(3046.1147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16027 lossL: tensor(2774.1008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16028 lossL: tensor(3113.7202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16029 lossL: tensor(2695.8848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16030 lossL: tensor(3111.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16031 lossL: tensor(2871.6194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16032 lossL: tensor(2802.8276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16033 lossL: tensor(2644.3484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16034 lossL: tensor(2787.4421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16035 lossL: tensor(2597.4868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16036 lossL: tensor(2962.5635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16037 lossL: tensor(2711.8528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16038 lossL: tensor(2715.2190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16039 lossL: tensor(2694.3369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16040 lossL: tensor(2606.1812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16041 lossL: tensor(2814.3479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16042 lossL: tensor(2756.4780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16043 lossL: tensor(3341.2251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16044 lossL: tensor(2630.9812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16045 lossL: tensor(2932.4043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16046 lossL: tensor(2544.6536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16047 lossL: tensor(2914.2512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16048 lossL: tensor(2855.4402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16049 lossL: tensor(2844.4863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16050 lossL: tensor(3205.0735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16051 lossL: tensor(2541.5127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16052 lossL: tensor(3284.6880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16053 lossL: tensor(2516.5151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16054 lossL: tensor(2735.5540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16055 lossL: tensor(2488.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16056 lossL: tensor(2929.8289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16057 lossL: tensor(2831.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16058 lossL: tensor(2901.0623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16059 lossL: tensor(2875.9529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16060 lossL: tensor(3011.3074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16061 lossL: tensor(2611.9678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16062 lossL: tensor(2618.0911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16063 lossL: tensor(2976.4973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16064 lossL: tensor(3379.3357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16065 lossL: tensor(2747.9236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16066 lossL: tensor(2638.3179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16067 lossL: tensor(2992.0110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16068 lossL: tensor(2831.2996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16069 lossL: tensor(2986.2131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16070 lossL: tensor(2467.2373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16071 lossL: tensor(3182.5002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16072 lossL: tensor(3186.2043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16073 lossL: tensor(2612.3999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16074 lossL: tensor(2968.7056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16075 lossL: tensor(2721.9583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16076 lossL: tensor(2649.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16077 lossL: tensor(2434.2817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16078 lossL: tensor(2612.8423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16079 lossL: tensor(2602.7800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16080 lossL: tensor(2682.3911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16081 lossL: tensor(2801.7390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16082 lossL: tensor(2656.7961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16083 lossL: tensor(2797.2246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16084 lossL: tensor(2943.1023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16085 lossL: tensor(3091.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16086 lossL: tensor(2939.0669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16087 lossL: tensor(2564.7012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16088 lossL: tensor(2433.5344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16089 lossL: tensor(3177.4717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16090 lossL: tensor(2828.0359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16091 lossL: tensor(3251.8455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16092 lossL: tensor(3012.1304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16093 lossL: tensor(2855.7388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16094 lossL: tensor(2859.7175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16095 lossL: tensor(2770.4883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16096 lossL: tensor(2773.5881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16097 lossL: tensor(2587.4221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16098 lossL: tensor(3531.3186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16099 lossL: tensor(2616.8120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16100 lossL: tensor(3345.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16101 lossL: tensor(2907.9175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16102 lossL: tensor(3304.8062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16103 lossL: tensor(3251.2039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16104 lossL: tensor(3319.8323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16105 lossL: tensor(2986.5842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16106 lossL: tensor(3281.1626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16107 lossL: tensor(3325.6741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16108 lossL: tensor(2853.1541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16109 lossL: tensor(3364.4578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16110 lossL: tensor(2615.9941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16111 lossL: tensor(2999.9224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16112 lossL: tensor(3326.3337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16113 lossL: tensor(3220.8254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16114 lossL: tensor(3325.3923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16115 lossL: tensor(2558.2671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16116 lossL: tensor(3037.2051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16117 lossL: tensor(2848.4585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16118 lossL: tensor(2943.1885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16119 lossL: tensor(2892.4736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16120 lossL: tensor(2793.1099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16121 lossL: tensor(3327.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16122 lossL: tensor(2595.4214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16123 lossL: tensor(3067.0994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16124 lossL: tensor(2839.7834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16125 lossL: tensor(3355.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16126 lossL: tensor(3410.5647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16127 lossL: tensor(2973.4861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16128 lossL: tensor(3264.6013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16129 lossL: tensor(2661.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16130 lossL: tensor(2742.6924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16131 lossL: tensor(2678.4907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16132 lossL: tensor(2778.0728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16133 lossL: tensor(2653.9070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16134 lossL: tensor(2786.7080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16135 lossL: tensor(2709.3328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16136 lossL: tensor(2517.0674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16137 lossL: tensor(2718.2449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16138 lossL: tensor(2758.8997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16139 lossL: tensor(2951.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16140 lossL: tensor(2863.6775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16141 lossL: tensor(2709.7317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16142 lossL: tensor(2677.6455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16143 lossL: tensor(2771.2754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16144 lossL: tensor(2590.9348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16145 lossL: tensor(2394.0542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16146 lossL: tensor(2608.9385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16147 lossL: tensor(2820.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16148 lossL: tensor(2565.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16149 lossL: tensor(2890.3081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16150 lossL: tensor(3006.4248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16151 lossL: tensor(2969.6931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16152 lossL: tensor(3202.8608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16153 lossL: tensor(2690.7764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16154 lossL: tensor(2729.2324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16155 lossL: tensor(2506.3633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16156 lossL: tensor(2538.1077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16157 lossL: tensor(2600.0327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16158 lossL: tensor(2831.3545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16159 lossL: tensor(2648.0513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16160 lossL: tensor(2622.9661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16161 lossL: tensor(2560.7117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16162 lossL: tensor(3011.2639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16163 lossL: tensor(3108.5083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16164 lossL: tensor(2788.6826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16165 lossL: tensor(2774.9363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16166 lossL: tensor(2490.4119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16167 lossL: tensor(2645.0371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16168 lossL: tensor(2910.1208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16169 lossL: tensor(2640.4321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16170 lossL: tensor(2949.2324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16171 lossL: tensor(2621.2502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16172 lossL: tensor(2867.0027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16173 lossL: tensor(2878.2866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16174 lossL: tensor(2581.1685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16175 lossL: tensor(2827.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16176 lossL: tensor(3097.5510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16177 lossL: tensor(2986.7532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16178 lossL: tensor(2609.7297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16179 lossL: tensor(2715.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16180 lossL: tensor(2721.2217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16181 lossL: tensor(2543.6736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16182 lossL: tensor(2983.2161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16183 lossL: tensor(2861.7893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16184 lossL: tensor(3009.9849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16185 lossL: tensor(2661.5732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16186 lossL: tensor(2609.8652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16187 lossL: tensor(2873.6704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16188 lossL: tensor(2616.4165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16189 lossL: tensor(2987.9509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16190 lossL: tensor(2569.2952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16191 lossL: tensor(2507.9404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16192 lossL: tensor(3309.0259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16193 lossL: tensor(2754.2056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16194 lossL: tensor(2539.5908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16195 lossL: tensor(2468.5452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16196 lossL: tensor(2921.0610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16197 lossL: tensor(2464.4875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16198 lossL: tensor(2909.7471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16199 lossL: tensor(2928.5522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16200 lossL: tensor(2619.8213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16201 lossL: tensor(2819.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16202 lossL: tensor(2762.1050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16203 lossL: tensor(2948.3660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16204 lossL: tensor(2412.2139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16205 lossL: tensor(2920.4248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16206 lossL: tensor(2659.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16207 lossL: tensor(2816.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16208 lossL: tensor(2873.4666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16209 lossL: tensor(2567.8889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16210 lossL: tensor(2839.9050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16211 lossL: tensor(2935.1069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16212 lossL: tensor(2820.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16213 lossL: tensor(2890.3418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16214 lossL: tensor(3360.7893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16215 lossL: tensor(2874.0942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16216 lossL: tensor(2596.2190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16217 lossL: tensor(2761.0149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16218 lossL: tensor(2810.5227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16219 lossL: tensor(3376.3735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16220 lossL: tensor(3000.3018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16221 lossL: tensor(2829.3481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16222 lossL: tensor(2845.8726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16223 lossL: tensor(3329.5818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16224 lossL: tensor(2621.2659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16225 lossL: tensor(2849.1965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16226 lossL: tensor(2850.0293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16227 lossL: tensor(3241.6978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16228 lossL: tensor(2777.6499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16229 lossL: tensor(2916.3142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16230 lossL: tensor(3107.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16231 lossL: tensor(2863.3579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16232 lossL: tensor(2746.3193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16233 lossL: tensor(3016.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16234 lossL: tensor(2949.8896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16235 lossL: tensor(2930.8955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16236 lossL: tensor(2895.2371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16237 lossL: tensor(2577.4937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16238 lossL: tensor(3270.4573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16239 lossL: tensor(2640.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16240 lossL: tensor(2843.9985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16241 lossL: tensor(2981.6616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16242 lossL: tensor(3211.6631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16243 lossL: tensor(2568.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16244 lossL: tensor(2508.4424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16245 lossL: tensor(3315.0642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16246 lossL: tensor(2778.2332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16247 lossL: tensor(3030.4028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16248 lossL: tensor(2489.2024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16249 lossL: tensor(3190.7473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16250 lossL: tensor(2907.8076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16251 lossL: tensor(2659.7712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16252 lossL: tensor(3089.2654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16253 lossL: tensor(2453.6011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16254 lossL: tensor(2812.9722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16255 lossL: tensor(2401.0161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16256 lossL: tensor(2615.0435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16257 lossL: tensor(2951.3767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16258 lossL: tensor(2487.9802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16259 lossL: tensor(2497.0347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16260 lossL: tensor(3029.8210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16261 lossL: tensor(2525.2690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16262 lossL: tensor(2650.7095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16263 lossL: tensor(2580.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16264 lossL: tensor(2795.3909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16265 lossL: tensor(2837.9675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16266 lossL: tensor(2838.4126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16267 lossL: tensor(2664.3052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16268 lossL: tensor(2658.2661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16269 lossL: tensor(2647.9690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16270 lossL: tensor(2764.6011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16271 lossL: tensor(3028.3716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16272 lossL: tensor(2646.5264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16273 lossL: tensor(2545.8601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16274 lossL: tensor(3016.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16275 lossL: tensor(2655.8208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16276 lossL: tensor(2726.3599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16277 lossL: tensor(3157.8420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16278 lossL: tensor(2422.4888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16279 lossL: tensor(3135.6553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16280 lossL: tensor(2331.0671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "16281 lossL: tensor(2516.3398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16282 lossL: tensor(2775.4473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16283 lossL: tensor(3041.5920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16284 lossL: tensor(3492.9927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16285 lossL: tensor(2652.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16286 lossL: tensor(3027.1970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16287 lossL: tensor(2736.7944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16288 lossL: tensor(2891.9409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16289 lossL: tensor(2918.4651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16290 lossL: tensor(2489.5146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16291 lossL: tensor(3029.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16292 lossL: tensor(2646.0535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16293 lossL: tensor(2807.4836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16294 lossL: tensor(2702.6780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16295 lossL: tensor(2700.3521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16296 lossL: tensor(2250.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "16297 lossL: tensor(3140.1514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16298 lossL: tensor(2580.1790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16299 lossL: tensor(2876.3547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16300 lossL: tensor(2351.6187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16301 lossL: tensor(2624.8997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16302 lossL: tensor(2627.5955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16303 lossL: tensor(2508.2932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16304 lossL: tensor(2564.6311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16305 lossL: tensor(2718.4128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16306 lossL: tensor(2658.4377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16307 lossL: tensor(2556.7893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16308 lossL: tensor(2327.3875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16309 lossL: tensor(2432.2012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16310 lossL: tensor(2654.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16311 lossL: tensor(2769.3987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16312 lossL: tensor(2659.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16313 lossL: tensor(3030.2078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16314 lossL: tensor(2921.4639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16315 lossL: tensor(2594.1802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16316 lossL: tensor(2856.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16317 lossL: tensor(2503.4958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16318 lossL: tensor(2807.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16319 lossL: tensor(2427.5344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16320 lossL: tensor(2927.5642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16321 lossL: tensor(2826.9233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16322 lossL: tensor(2954.9658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16323 lossL: tensor(2955.9639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16324 lossL: tensor(2605.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16325 lossL: tensor(3022.1504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16326 lossL: tensor(2680.5083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16327 lossL: tensor(2773.7202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16328 lossL: tensor(2368.3784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16329 lossL: tensor(2587.8647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16330 lossL: tensor(3137.9678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16331 lossL: tensor(2610.5237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16332 lossL: tensor(2965.9646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16333 lossL: tensor(2669.4966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16334 lossL: tensor(2596.3030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16335 lossL: tensor(2803.4873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16336 lossL: tensor(2754.1709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16337 lossL: tensor(2839.0369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16338 lossL: tensor(2636.7229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16339 lossL: tensor(2549.7473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16340 lossL: tensor(2697.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16341 lossL: tensor(2362.0532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16342 lossL: tensor(2910.2078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16343 lossL: tensor(2662.3152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16344 lossL: tensor(2761.4695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16345 lossL: tensor(2442.1631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16346 lossL: tensor(2983.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16347 lossL: tensor(2348.4639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16348 lossL: tensor(2569.2058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16349 lossL: tensor(3043.5569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16350 lossL: tensor(2696.9175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16351 lossL: tensor(2445.6641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16352 lossL: tensor(2746.7170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16353 lossL: tensor(2502.2637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16354 lossL: tensor(2683.6318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16355 lossL: tensor(2929.2288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16356 lossL: tensor(2541.2048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16357 lossL: tensor(2603.4036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16358 lossL: tensor(2829.7900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16359 lossL: tensor(2660.1143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16360 lossL: tensor(2613.1978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16361 lossL: tensor(2947.6663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16362 lossL: tensor(2625.4358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16363 lossL: tensor(2591.4324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16364 lossL: tensor(2873.5981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16365 lossL: tensor(2689.1753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16366 lossL: tensor(2675.5400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16367 lossL: tensor(2616.5420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16368 lossL: tensor(2829.9116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16369 lossL: tensor(2541.5996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16370 lossL: tensor(2657.6277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16371 lossL: tensor(2706.6458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16372 lossL: tensor(3045.1538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16373 lossL: tensor(2446.9866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16374 lossL: tensor(2426.3215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16375 lossL: tensor(2792.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16376 lossL: tensor(2552.8347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16377 lossL: tensor(3023.2400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16378 lossL: tensor(2670.4180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16379 lossL: tensor(3018.1353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16380 lossL: tensor(2385.3821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16381 lossL: tensor(2766.6162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16382 lossL: tensor(2559.7036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16383 lossL: tensor(2244.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "16384 lossL: tensor(2327.4673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16385 lossL: tensor(2525.5454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16386 lossL: tensor(2633.2190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16387 lossL: tensor(2288.0088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16388 lossL: tensor(2902.5493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16389 lossL: tensor(2331.1833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16390 lossL: tensor(2794.3005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16391 lossL: tensor(2835.4194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16392 lossL: tensor(2459.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16393 lossL: tensor(2900.6301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16394 lossL: tensor(2712.8486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16395 lossL: tensor(2831.1880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16396 lossL: tensor(2271.4077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16397 lossL: tensor(2587.8647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16398 lossL: tensor(2833.2446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16399 lossL: tensor(2628.8184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16400 lossL: tensor(2685.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16401 lossL: tensor(2526.9287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16402 lossL: tensor(2967.7561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16403 lossL: tensor(2857.8228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16404 lossL: tensor(2863.4023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16405 lossL: tensor(2617.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16406 lossL: tensor(2891.6167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16407 lossL: tensor(2700.8706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16408 lossL: tensor(2787.3801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16409 lossL: tensor(3033.5767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16410 lossL: tensor(2760.5388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16411 lossL: tensor(2908.4336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16412 lossL: tensor(2697.0122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16413 lossL: tensor(2797.2339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16414 lossL: tensor(2752.7361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16415 lossL: tensor(2291.3210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16416 lossL: tensor(3085.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16417 lossL: tensor(2606.7117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16418 lossL: tensor(2750.1755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16419 lossL: tensor(2776.9636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16420 lossL: tensor(2664.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16421 lossL: tensor(2486.8584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16422 lossL: tensor(2271.0161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16423 lossL: tensor(2514.3467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16424 lossL: tensor(2332.9636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16425 lossL: tensor(2474.6458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16426 lossL: tensor(2335.8318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16427 lossL: tensor(2533.2200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16428 lossL: tensor(2558.8088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16429 lossL: tensor(2528.2949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16430 lossL: tensor(2651.6968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16431 lossL: tensor(2125.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "16432 lossL: tensor(2665.1226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16433 lossL: tensor(2551.1667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16434 lossL: tensor(2426.1904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16435 lossL: tensor(2642.8472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16436 lossL: tensor(2999.5071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16437 lossL: tensor(2588.2827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16438 lossL: tensor(2519.1782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16439 lossL: tensor(2688.6841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16440 lossL: tensor(2652.3840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16441 lossL: tensor(2834.6130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16442 lossL: tensor(2474.7280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16443 lossL: tensor(2879.3474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16444 lossL: tensor(2758.5837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16445 lossL: tensor(2801.0161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16446 lossL: tensor(2622.9624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16447 lossL: tensor(2537.3882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16448 lossL: tensor(2699.6323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16449 lossL: tensor(2515.4331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16450 lossL: tensor(2324.3508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16451 lossL: tensor(2679.9485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16452 lossL: tensor(2679.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16453 lossL: tensor(2280.0713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16454 lossL: tensor(2904.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16455 lossL: tensor(2602.8577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16456 lossL: tensor(2794.6104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16457 lossL: tensor(2356.0093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16458 lossL: tensor(2631.1379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16459 lossL: tensor(2494.8162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16460 lossL: tensor(2623.5127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16461 lossL: tensor(2386.5894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16462 lossL: tensor(2553.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16463 lossL: tensor(3029.7688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16464 lossL: tensor(2622.7239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16465 lossL: tensor(2655.9482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16466 lossL: tensor(2341.4854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16467 lossL: tensor(2304.5945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16468 lossL: tensor(2448.9048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16469 lossL: tensor(2488.7366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16470 lossL: tensor(2721.3110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16471 lossL: tensor(2361.9226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16472 lossL: tensor(2418.5684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16473 lossL: tensor(2651.7163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16474 lossL: tensor(2624.7859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16475 lossL: tensor(2648.8062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16476 lossL: tensor(2723.8994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16477 lossL: tensor(2524.5811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16478 lossL: tensor(2756.6030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16479 lossL: tensor(2480.7234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16480 lossL: tensor(3100.6887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16481 lossL: tensor(2639.9229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16482 lossL: tensor(2965.3960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16483 lossL: tensor(2311.6335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16484 lossL: tensor(2467.3264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16485 lossL: tensor(2582.4346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16486 lossL: tensor(2599.9597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16487 lossL: tensor(2439.6523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16488 lossL: tensor(2268.1604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16489 lossL: tensor(2673.9458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16490 lossL: tensor(3179.5769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16491 lossL: tensor(2597.5046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16492 lossL: tensor(2677.0298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16493 lossL: tensor(2687.0957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16494 lossL: tensor(2617.2498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16495 lossL: tensor(3435.2444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16496 lossL: tensor(2865.2717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16497 lossL: tensor(2796.0730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16498 lossL: tensor(2533.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16499 lossL: tensor(2819.7749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16500 lossL: tensor(2364.0979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16501 lossL: tensor(2671.0854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16502 lossL: tensor(2383.6326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16503 lossL: tensor(2850.7668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16504 lossL: tensor(3000.6499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16505 lossL: tensor(2964.0227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16506 lossL: tensor(2478.8132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16507 lossL: tensor(2577.7117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16508 lossL: tensor(3022.5486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16509 lossL: tensor(2565.5835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16510 lossL: tensor(2922.2241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16511 lossL: tensor(2521.8052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16512 lossL: tensor(2513.4678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16513 lossL: tensor(2665.6814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16514 lossL: tensor(2598.8816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16515 lossL: tensor(2784.2739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16516 lossL: tensor(2486.9771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16517 lossL: tensor(2717.6782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16518 lossL: tensor(2540.4241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16519 lossL: tensor(2763.9355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16520 lossL: tensor(2452.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16521 lossL: tensor(2847.3005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16522 lossL: tensor(2856.9663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16523 lossL: tensor(2844.6707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16524 lossL: tensor(2688.6138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16525 lossL: tensor(3302.7878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16526 lossL: tensor(2335.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16527 lossL: tensor(2428.8696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16528 lossL: tensor(2755.7493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16529 lossL: tensor(2596.7063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16530 lossL: tensor(2367.7739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16531 lossL: tensor(2242.1018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16532 lossL: tensor(2824.6306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16533 lossL: tensor(2527.7822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16534 lossL: tensor(2602.3972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16535 lossL: tensor(2846.3462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16536 lossL: tensor(2614.3293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16537 lossL: tensor(2438.4390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16538 lossL: tensor(2370.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16539 lossL: tensor(2722.3181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16540 lossL: tensor(2376.2654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16541 lossL: tensor(2154.1907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16542 lossL: tensor(2425.1050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16543 lossL: tensor(2356.1128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16544 lossL: tensor(2999.6365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16545 lossL: tensor(2271.4131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16546 lossL: tensor(2423.4907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16547 lossL: tensor(2523.7957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16548 lossL: tensor(2515.0525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16549 lossL: tensor(2151.3396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16550 lossL: tensor(2535.2134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16551 lossL: tensor(2732.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16552 lossL: tensor(2549.8208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16553 lossL: tensor(2502.7363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16554 lossL: tensor(2177.1699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16555 lossL: tensor(2243.4919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16556 lossL: tensor(2425.8237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16557 lossL: tensor(2429.9658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16558 lossL: tensor(2518.9343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16559 lossL: tensor(2393.0293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16560 lossL: tensor(2931.2302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16561 lossL: tensor(2443.2961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16562 lossL: tensor(2720.2856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16563 lossL: tensor(2359.9502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16564 lossL: tensor(2657.5361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16565 lossL: tensor(2232.5869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16566 lossL: tensor(2487.2576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16567 lossL: tensor(2598.9539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16568 lossL: tensor(2566.7766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16569 lossL: tensor(2871.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16570 lossL: tensor(2571.2261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16571 lossL: tensor(2645.1155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16572 lossL: tensor(2715.9617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16573 lossL: tensor(2502.6758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16574 lossL: tensor(2548.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16575 lossL: tensor(2318.8528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16576 lossL: tensor(2213.1943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16577 lossL: tensor(2721.9651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16578 lossL: tensor(2467.5369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16579 lossL: tensor(2523.6152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16580 lossL: tensor(2315.4487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16581 lossL: tensor(2335.8132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16582 lossL: tensor(2592.8975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16583 lossL: tensor(2847.6287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16584 lossL: tensor(2388.8276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16585 lossL: tensor(2296.2649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16586 lossL: tensor(2323.4612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16587 lossL: tensor(2727.0745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16588 lossL: tensor(2737.3130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16589 lossL: tensor(2362.9661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16590 lossL: tensor(2676.5432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16591 lossL: tensor(2654.4175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16592 lossL: tensor(2701.0730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16593 lossL: tensor(2685.6047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16594 lossL: tensor(2969.5432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16595 lossL: tensor(2464.2153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16596 lossL: tensor(2551.1270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16597 lossL: tensor(2700.8188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16598 lossL: tensor(2564.4097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16599 lossL: tensor(2836.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16600 lossL: tensor(2716.6504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16601 lossL: tensor(2641.5527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16602 lossL: tensor(2761.3333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16603 lossL: tensor(2283.0786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16604 lossL: tensor(2590.8403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16605 lossL: tensor(2723.9548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16606 lossL: tensor(2739.3589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16607 lossL: tensor(2456.4941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16608 lossL: tensor(2397.5889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16609 lossL: tensor(3093.5945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16610 lossL: tensor(2539.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16611 lossL: tensor(2586.7603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16612 lossL: tensor(2710.4590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16613 lossL: tensor(2274.4907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16614 lossL: tensor(2381.0713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16615 lossL: tensor(2588.0129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16616 lossL: tensor(2541.2896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16617 lossL: tensor(2731.9182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16618 lossL: tensor(2307.8987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16619 lossL: tensor(2458.1587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16620 lossL: tensor(2509.0710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16621 lossL: tensor(2440.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16622 lossL: tensor(2926.6689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16623 lossL: tensor(2601.4976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16624 lossL: tensor(2618.7090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16625 lossL: tensor(2327.2556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16626 lossL: tensor(2507.3215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16627 lossL: tensor(2380.9006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16628 lossL: tensor(2590.4333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16629 lossL: tensor(2541.1548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16630 lossL: tensor(2352.4929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16631 lossL: tensor(2705.1892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16632 lossL: tensor(2265.0613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16633 lossL: tensor(2670.6340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16634 lossL: tensor(2847.1570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16635 lossL: tensor(2373.3130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16636 lossL: tensor(2620.4050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16637 lossL: tensor(2808.9907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16638 lossL: tensor(2203.4724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16639 lossL: tensor(2225.7932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16640 lossL: tensor(2406.0918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16641 lossL: tensor(2249.2561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16642 lossL: tensor(2083.2334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "16643 lossL: tensor(2071.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "16644 lossL: tensor(2410.4001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16645 lossL: tensor(2411.2009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16646 lossL: tensor(2507.3584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16647 lossL: tensor(2821.2046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16648 lossL: tensor(2282.7488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16649 lossL: tensor(2267.1360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16650 lossL: tensor(2464.0725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16651 lossL: tensor(2552.4834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16652 lossL: tensor(2119.6628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16653 lossL: tensor(2571.0369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16654 lossL: tensor(2305.2593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16655 lossL: tensor(2586.8716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16656 lossL: tensor(2432.1794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16657 lossL: tensor(2489.4045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16658 lossL: tensor(2679.6284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16659 lossL: tensor(2746.7788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16660 lossL: tensor(2474.2939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16661 lossL: tensor(2297.3235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16662 lossL: tensor(2293.0891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16663 lossL: tensor(2659.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16664 lossL: tensor(2422.0457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16665 lossL: tensor(2798.3757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16666 lossL: tensor(2305.7751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16667 lossL: tensor(2223.5872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16668 lossL: tensor(2167.4058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16669 lossL: tensor(2607.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16670 lossL: tensor(2706.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16671 lossL: tensor(2321.2915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16672 lossL: tensor(2762.3708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16673 lossL: tensor(2479.1646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16674 lossL: tensor(2682.8894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16675 lossL: tensor(2313.5867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16676 lossL: tensor(2384.8657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16677 lossL: tensor(2659.1921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16678 lossL: tensor(2422.1868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16679 lossL: tensor(2585.2515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16680 lossL: tensor(2835.8669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16681 lossL: tensor(2742.2642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16682 lossL: tensor(2506.5945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16683 lossL: tensor(2368.8220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16684 lossL: tensor(2258.3875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16685 lossL: tensor(2681.9639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16686 lossL: tensor(2378.5737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16687 lossL: tensor(2153.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16688 lossL: tensor(2266.1621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16689 lossL: tensor(2910.8201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16690 lossL: tensor(2275.6638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16691 lossL: tensor(2558.7849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16692 lossL: tensor(2476.5044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16693 lossL: tensor(2544.4370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16694 lossL: tensor(2200.5293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16695 lossL: tensor(2594.1079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16696 lossL: tensor(2132.2417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16697 lossL: tensor(2542.3284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16698 lossL: tensor(2463.5266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16699 lossL: tensor(2887.5073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16700 lossL: tensor(2294.4746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16701 lossL: tensor(2565.0693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16702 lossL: tensor(2182.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16703 lossL: tensor(2247.4199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16704 lossL: tensor(2612.4722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16705 lossL: tensor(2469.4138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16706 lossL: tensor(2224.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16707 lossL: tensor(2363.5752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16708 lossL: tensor(2760.5381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16709 lossL: tensor(2626.0779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16710 lossL: tensor(2402.2566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16711 lossL: tensor(2546.5164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16712 lossL: tensor(2325.6870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16713 lossL: tensor(2617.1335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16714 lossL: tensor(2091.4536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16715 lossL: tensor(2608.5374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16716 lossL: tensor(2321.0867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16717 lossL: tensor(2721.3018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16718 lossL: tensor(2790.7732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16719 lossL: tensor(2500.7278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16720 lossL: tensor(2333.5349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16721 lossL: tensor(2591.6514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16722 lossL: tensor(2591.8364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16723 lossL: tensor(2259.4497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16724 lossL: tensor(2390.4673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16725 lossL: tensor(2265.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16726 lossL: tensor(2628.2092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16727 lossL: tensor(2535.1267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16728 lossL: tensor(2365.0366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16729 lossL: tensor(2460.3987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16730 lossL: tensor(2444.4907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16731 lossL: tensor(2405.8123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16732 lossL: tensor(2322.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16733 lossL: tensor(2595.4143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16734 lossL: tensor(2342.8018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16735 lossL: tensor(2518.6904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16736 lossL: tensor(2546.9395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16737 lossL: tensor(2363.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16738 lossL: tensor(2484.2139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16739 lossL: tensor(2387.4539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16740 lossL: tensor(2534.0283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16741 lossL: tensor(2764.8572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16742 lossL: tensor(2370.1277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16743 lossL: tensor(2683.7385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16744 lossL: tensor(2315.7959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16745 lossL: tensor(2432.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16746 lossL: tensor(2449.3149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16747 lossL: tensor(2179.8289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16748 lossL: tensor(2512.1057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16749 lossL: tensor(2470.5579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16750 lossL: tensor(2726.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16751 lossL: tensor(2508.1426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16752 lossL: tensor(2175.8767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16753 lossL: tensor(2331.0725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16754 lossL: tensor(2469.1028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16755 lossL: tensor(2189.4470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16756 lossL: tensor(2530.8904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16757 lossL: tensor(2706.3530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16758 lossL: tensor(2288.0083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16759 lossL: tensor(2237.4873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16760 lossL: tensor(2202.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16761 lossL: tensor(2463.0791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16762 lossL: tensor(2549.5837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16763 lossL: tensor(2520.0681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16764 lossL: tensor(2419.9612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16765 lossL: tensor(2143.5864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16766 lossL: tensor(2373.7300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16767 lossL: tensor(2427.6069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16768 lossL: tensor(2523.2817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16769 lossL: tensor(2294.8916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16770 lossL: tensor(2424.9771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16771 lossL: tensor(2254.2625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16772 lossL: tensor(2484.4243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16773 lossL: tensor(2547.4617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16774 lossL: tensor(2315.4553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16775 lossL: tensor(2402.9636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16776 lossL: tensor(2675.2822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16777 lossL: tensor(2280.7124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16778 lossL: tensor(2363.3965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16779 lossL: tensor(2179.3977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16780 lossL: tensor(2456.9016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16781 lossL: tensor(2215.3521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16782 lossL: tensor(2562.5251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16783 lossL: tensor(2419.8220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16784 lossL: tensor(2640.6743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16785 lossL: tensor(2441.4924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16786 lossL: tensor(2485.2395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16787 lossL: tensor(2549.0703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16788 lossL: tensor(2369.4302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16789 lossL: tensor(2305.1306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16790 lossL: tensor(2307.3228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16791 lossL: tensor(2407.8540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16792 lossL: tensor(2749.3328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16793 lossL: tensor(2457.9583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16794 lossL: tensor(2725.2029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16795 lossL: tensor(2477.2180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16796 lossL: tensor(2491.0376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16797 lossL: tensor(2151.4363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16798 lossL: tensor(2571.3088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16799 lossL: tensor(2855.8201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16800 lossL: tensor(2894.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16801 lossL: tensor(2391.4912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16802 lossL: tensor(2798.0095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16803 lossL: tensor(2378.7632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16804 lossL: tensor(2566.3901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16805 lossL: tensor(2507.4714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16806 lossL: tensor(2196.8013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16807 lossL: tensor(2563.8833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16808 lossL: tensor(2474.6748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16809 lossL: tensor(2674.2034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16810 lossL: tensor(2549.1506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16811 lossL: tensor(2947.5369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16812 lossL: tensor(2162.5603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16813 lossL: tensor(2540.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16814 lossL: tensor(2231.3728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16815 lossL: tensor(2421.6721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16816 lossL: tensor(2418.1697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16817 lossL: tensor(3299.1335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16818 lossL: tensor(2677.5576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16819 lossL: tensor(2358.4116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16820 lossL: tensor(2556.7920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16821 lossL: tensor(2139.8464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16822 lossL: tensor(2527.6204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16823 lossL: tensor(2464.7102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16824 lossL: tensor(2297.2375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16825 lossL: tensor(2336.1780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16826 lossL: tensor(2590.5330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16827 lossL: tensor(3150.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16828 lossL: tensor(2512.6753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16829 lossL: tensor(2541.7646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16830 lossL: tensor(2413.6257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16831 lossL: tensor(2499.9189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16832 lossL: tensor(2571.8818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16833 lossL: tensor(2355.4893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16834 lossL: tensor(2605.1257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16835 lossL: tensor(2417.8418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16836 lossL: tensor(2734.1631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16837 lossL: tensor(2378.8259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16838 lossL: tensor(2262.9553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16839 lossL: tensor(2664.1138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16840 lossL: tensor(2191.6936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16841 lossL: tensor(2403.8425, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16842 lossL: tensor(2414.3281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16843 lossL: tensor(2542.5203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16844 lossL: tensor(2521.5840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16845 lossL: tensor(2376.4888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16846 lossL: tensor(2186.8328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16847 lossL: tensor(2286.0305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16848 lossL: tensor(2159.1509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16849 lossL: tensor(2334.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16850 lossL: tensor(2324.9761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16851 lossL: tensor(2420.1653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16852 lossL: tensor(2389.0896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16853 lossL: tensor(2106.4163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16854 lossL: tensor(2455.4209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16855 lossL: tensor(2239.9929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16856 lossL: tensor(2380.6072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16857 lossL: tensor(2213.0881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16858 lossL: tensor(2531.3335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16859 lossL: tensor(2443.9597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16860 lossL: tensor(2232.1628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16861 lossL: tensor(2482.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16862 lossL: tensor(2297.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16863 lossL: tensor(2239.1912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16864 lossL: tensor(2395.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16865 lossL: tensor(2140.5161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16866 lossL: tensor(2242.1079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16867 lossL: tensor(2442.4785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16868 lossL: tensor(2080.1328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16869 lossL: tensor(2134.3591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16870 lossL: tensor(2568.3962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16871 lossL: tensor(2166.8501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16872 lossL: tensor(2153.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16873 lossL: tensor(2447.6306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16874 lossL: tensor(2371.2192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16875 lossL: tensor(2503.0610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16876 lossL: tensor(2321.8892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16877 lossL: tensor(2534.5757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16878 lossL: tensor(2246.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16879 lossL: tensor(2796.8665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16880 lossL: tensor(2237.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16881 lossL: tensor(2267.4294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16882 lossL: tensor(2461.2393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16883 lossL: tensor(2411.1763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16884 lossL: tensor(2241.3699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16885 lossL: tensor(2418.6301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16886 lossL: tensor(2461.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16887 lossL: tensor(2330.6631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16888 lossL: tensor(2488.3882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16889 lossL: tensor(2429.5803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16890 lossL: tensor(2135.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16891 lossL: tensor(2368.1611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16892 lossL: tensor(2456.1357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16893 lossL: tensor(2423.5217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16894 lossL: tensor(2607.7146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16895 lossL: tensor(2408.3472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16896 lossL: tensor(2417.4155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16897 lossL: tensor(2292.8083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16898 lossL: tensor(2620.6814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16899 lossL: tensor(2360.5164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16900 lossL: tensor(2696.3418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16901 lossL: tensor(2276.8818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16902 lossL: tensor(2497.9312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16903 lossL: tensor(2128.7585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16904 lossL: tensor(2447.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16905 lossL: tensor(2324.4441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16906 lossL: tensor(2471.5430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16907 lossL: tensor(2428.1021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16908 lossL: tensor(2331.3037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16909 lossL: tensor(2721.5164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16910 lossL: tensor(2279.3142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16911 lossL: tensor(2720.6633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16912 lossL: tensor(2765.2502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16913 lossL: tensor(2773.7368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16914 lossL: tensor(2744.7690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16915 lossL: tensor(3000.0403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16916 lossL: tensor(2182.8108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16917 lossL: tensor(2638.3606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16918 lossL: tensor(2175.0947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16919 lossL: tensor(2273.0808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16920 lossL: tensor(2534.1104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16921 lossL: tensor(2194.7041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16922 lossL: tensor(2258.7112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16923 lossL: tensor(2457.9661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16924 lossL: tensor(2473.6121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16925 lossL: tensor(2224.6277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16926 lossL: tensor(2538.2112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16927 lossL: tensor(2629.3972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16928 lossL: tensor(2364.3379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16929 lossL: tensor(2304.9646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16930 lossL: tensor(2386.7136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16931 lossL: tensor(2415.6541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16932 lossL: tensor(2182.8740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16933 lossL: tensor(2224.0442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16934 lossL: tensor(2455.5320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16935 lossL: tensor(2393.9993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16936 lossL: tensor(2301.3528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16937 lossL: tensor(2519.1724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16938 lossL: tensor(2501.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16939 lossL: tensor(2467.8660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16940 lossL: tensor(2273.1819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16941 lossL: tensor(2146.5535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16942 lossL: tensor(2348.3188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16943 lossL: tensor(2120.5386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16944 lossL: tensor(2282.2649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16945 lossL: tensor(2314.5483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16946 lossL: tensor(2128.2290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16947 lossL: tensor(2315.6475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16948 lossL: tensor(2228.3381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16949 lossL: tensor(2212.0107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16950 lossL: tensor(2211.7236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16951 lossL: tensor(2065.7185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "16952 lossL: tensor(2516.7993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16953 lossL: tensor(2724.4878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16954 lossL: tensor(2293.6670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16955 lossL: tensor(2037.0739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "16956 lossL: tensor(2105.3904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16957 lossL: tensor(2230.2798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16958 lossL: tensor(2225.5442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16959 lossL: tensor(2260.0522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16960 lossL: tensor(2643.8704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16961 lossL: tensor(2521.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16962 lossL: tensor(2192.6477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16963 lossL: tensor(2213.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16964 lossL: tensor(1873.2670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "16965 lossL: tensor(2296.4558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16966 lossL: tensor(2159.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16967 lossL: tensor(2913.7236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16968 lossL: tensor(2241.5127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16969 lossL: tensor(2399.4546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16970 lossL: tensor(2144.5081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16971 lossL: tensor(2234.4270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16972 lossL: tensor(2253.4629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16973 lossL: tensor(2310.7742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16974 lossL: tensor(2389.2678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16975 lossL: tensor(2365.0383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16976 lossL: tensor(2668.7249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16977 lossL: tensor(2378.2361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16978 lossL: tensor(2370.0996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16979 lossL: tensor(2331.6821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16980 lossL: tensor(2375.5991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16981 lossL: tensor(2357.1904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16982 lossL: tensor(2509.6382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16983 lossL: tensor(2050.9355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16984 lossL: tensor(2431.5896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16985 lossL: tensor(2033.0593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16986 lossL: tensor(2480.5583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16987 lossL: tensor(2430.5166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16988 lossL: tensor(2051.0818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16989 lossL: tensor(2397.1973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16990 lossL: tensor(2380.1514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16991 lossL: tensor(2367.5090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16992 lossL: tensor(2152.5376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16993 lossL: tensor(2379.4014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16994 lossL: tensor(2362.0320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16995 lossL: tensor(2303.6440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16996 lossL: tensor(2379.2710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16997 lossL: tensor(2414.8198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16998 lossL: tensor(2330.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "16999 lossL: tensor(2433.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17000 lossL: tensor(2367.6042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17001 lossL: tensor(2368.5220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17002 lossL: tensor(2147.9644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17003 lossL: tensor(2378.0828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17004 lossL: tensor(2238.6968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17005 lossL: tensor(2263.0825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17006 lossL: tensor(2456.9026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17007 lossL: tensor(2718.9614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17008 lossL: tensor(2347.5291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17009 lossL: tensor(2527.2485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17010 lossL: tensor(2167.5073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17011 lossL: tensor(2447.2163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17012 lossL: tensor(2215.4961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17013 lossL: tensor(2312.6316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17014 lossL: tensor(2421.9622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17015 lossL: tensor(2430.9929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17016 lossL: tensor(2395.6440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17017 lossL: tensor(2363.7136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17018 lossL: tensor(2359.0833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17019 lossL: tensor(2128.6052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17020 lossL: tensor(2931.3875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17021 lossL: tensor(2055.2217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17022 lossL: tensor(2159.5093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17023 lossL: tensor(2213.4504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17024 lossL: tensor(2303.0813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17025 lossL: tensor(2238.4924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17026 lossL: tensor(2465.2358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17027 lossL: tensor(2259.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17028 lossL: tensor(2371.3965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17029 lossL: tensor(2137.5889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17030 lossL: tensor(2265.2756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17031 lossL: tensor(2288.9841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17032 lossL: tensor(2306.0271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17033 lossL: tensor(2412.3872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17034 lossL: tensor(2650.9602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17035 lossL: tensor(2270.9954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17036 lossL: tensor(2706.1748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17037 lossL: tensor(2335.3306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17038 lossL: tensor(2217.4934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17039 lossL: tensor(2321.8413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17040 lossL: tensor(2228.5857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17041 lossL: tensor(2429.4436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17042 lossL: tensor(1960.4174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17043 lossL: tensor(2380.2134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17044 lossL: tensor(2486.6687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17045 lossL: tensor(2386.1023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17046 lossL: tensor(2667.5798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17047 lossL: tensor(1953.9279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17048 lossL: tensor(2817.2900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17049 lossL: tensor(2109.4666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17050 lossL: tensor(2261.6770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17051 lossL: tensor(2286.5527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17052 lossL: tensor(2219.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17053 lossL: tensor(2285.1619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17054 lossL: tensor(2082.9038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17055 lossL: tensor(2645.9495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17056 lossL: tensor(2109.9412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17057 lossL: tensor(2154.5220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17058 lossL: tensor(2219.5120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17059 lossL: tensor(2160.1343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17060 lossL: tensor(2214.4956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17061 lossL: tensor(2108.8811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17062 lossL: tensor(2220.2002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17063 lossL: tensor(2136.4321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17064 lossL: tensor(2169.4951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17065 lossL: tensor(2098.3391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17066 lossL: tensor(2562.4446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17067 lossL: tensor(2537.3931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17068 lossL: tensor(2134.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17069 lossL: tensor(2179.2725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17070 lossL: tensor(2296.6973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17071 lossL: tensor(2149.3044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17072 lossL: tensor(2067.6724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17073 lossL: tensor(2256.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17074 lossL: tensor(2344.9092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17075 lossL: tensor(2739.2107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17076 lossL: tensor(2162.4697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17077 lossL: tensor(2464.3113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17078 lossL: tensor(2542.2324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17079 lossL: tensor(2228.6118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17080 lossL: tensor(2408.8503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17081 lossL: tensor(2437.7170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17082 lossL: tensor(2581.0298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17083 lossL: tensor(2340.2520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17084 lossL: tensor(2274.2896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17085 lossL: tensor(2429.4734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17086 lossL: tensor(2163.2505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17087 lossL: tensor(2094.1035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17088 lossL: tensor(2245.0349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17089 lossL: tensor(2207.2437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17090 lossL: tensor(2294.0144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17091 lossL: tensor(2108.6387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17092 lossL: tensor(1947.2823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17093 lossL: tensor(2533.4539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17094 lossL: tensor(2283.0227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17095 lossL: tensor(2313.7581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17096 lossL: tensor(2424.0288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17097 lossL: tensor(2360.6809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17098 lossL: tensor(2241.0444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17099 lossL: tensor(2251.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17100 lossL: tensor(1968.3049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17101 lossL: tensor(2244.6072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17102 lossL: tensor(2410.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17103 lossL: tensor(2520.8235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17104 lossL: tensor(2217.7258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17105 lossL: tensor(2254.1189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17106 lossL: tensor(2240.0032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17107 lossL: tensor(2450.2158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17108 lossL: tensor(2295.0706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17109 lossL: tensor(2378.2202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17110 lossL: tensor(2193.7046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17111 lossL: tensor(2304.2329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17112 lossL: tensor(2197.0676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17113 lossL: tensor(2622.5640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17114 lossL: tensor(2308.7991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17115 lossL: tensor(2515.8755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17116 lossL: tensor(2141.4382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17117 lossL: tensor(2287.4312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17118 lossL: tensor(2250.9756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17119 lossL: tensor(1987.4714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17120 lossL: tensor(2323.3171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17121 lossL: tensor(2142.9143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17122 lossL: tensor(2105.5984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17123 lossL: tensor(2206.0691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17124 lossL: tensor(2204.5269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17125 lossL: tensor(2101.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17126 lossL: tensor(2276.4817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17127 lossL: tensor(2107.2495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17128 lossL: tensor(1968.6858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17129 lossL: tensor(2416.2568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17130 lossL: tensor(2033.1881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17131 lossL: tensor(2232.5288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17132 lossL: tensor(2349.2393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17133 lossL: tensor(2338.5579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17134 lossL: tensor(2067.1182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17135 lossL: tensor(2238.8782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17136 lossL: tensor(2108.2273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17137 lossL: tensor(2184.9812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17138 lossL: tensor(2017.2085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17139 lossL: tensor(2422.8860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17140 lossL: tensor(2114.1741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17141 lossL: tensor(2228.6292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17142 lossL: tensor(2189.9390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17143 lossL: tensor(2219.9683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17144 lossL: tensor(2092.9434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17145 lossL: tensor(2143.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17146 lossL: tensor(1822.4578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "17147 lossL: tensor(2459.8579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17148 lossL: tensor(2046.3386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17149 lossL: tensor(2314.5063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17150 lossL: tensor(2196.6223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17151 lossL: tensor(2362.2747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17152 lossL: tensor(1921.1621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17153 lossL: tensor(2322.1626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17154 lossL: tensor(2219.2446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17155 lossL: tensor(2105.1377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17156 lossL: tensor(2339.0691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17157 lossL: tensor(2174.6418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17158 lossL: tensor(1944.6105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17159 lossL: tensor(1979.4189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17160 lossL: tensor(2450.2795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17161 lossL: tensor(2291.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17162 lossL: tensor(2302.6875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17163 lossL: tensor(2471.8101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17164 lossL: tensor(2165.9270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17165 lossL: tensor(1905.4138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17166 lossL: tensor(2106.7273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17167 lossL: tensor(2463.6824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17168 lossL: tensor(2458.5383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17169 lossL: tensor(1889.4441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17170 lossL: tensor(2152.6753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17171 lossL: tensor(2368.4944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17172 lossL: tensor(2400.5532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17173 lossL: tensor(2124.2166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17174 lossL: tensor(2241.5271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17175 lossL: tensor(2154.4470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17176 lossL: tensor(2077.5088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17177 lossL: tensor(2077.5955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17178 lossL: tensor(2226.6504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17179 lossL: tensor(2355.2568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17180 lossL: tensor(2463.5322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17181 lossL: tensor(2162.8572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17182 lossL: tensor(2289.4985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17183 lossL: tensor(2373.7102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17184 lossL: tensor(2473.6362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17185 lossL: tensor(2362.3726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17186 lossL: tensor(2415.2795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17187 lossL: tensor(2039.2704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17188 lossL: tensor(2678.5786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17189 lossL: tensor(2325.3198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17190 lossL: tensor(2525.8218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17191 lossL: tensor(2426.8743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17192 lossL: tensor(2274.2666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17193 lossL: tensor(2111.8269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17194 lossL: tensor(2705.1707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17195 lossL: tensor(2099.8389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17196 lossL: tensor(2577.1946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17197 lossL: tensor(2179.4722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17198 lossL: tensor(2321.1907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17199 lossL: tensor(2356.5107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17200 lossL: tensor(2524.4307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17201 lossL: tensor(2255.1575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17202 lossL: tensor(2265.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17203 lossL: tensor(2195.8149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17204 lossL: tensor(2112.6208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17205 lossL: tensor(1999.4043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17206 lossL: tensor(2256.1658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17207 lossL: tensor(2539.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17208 lossL: tensor(2563.4268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17209 lossL: tensor(2361.3391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17210 lossL: tensor(2493.5669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17211 lossL: tensor(2071.6335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17212 lossL: tensor(2210.2075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17213 lossL: tensor(2312.9202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17214 lossL: tensor(2274.8916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17215 lossL: tensor(2310.8066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17216 lossL: tensor(2019.0646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17217 lossL: tensor(2314.2002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17218 lossL: tensor(2244.8352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17219 lossL: tensor(2242.8694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17220 lossL: tensor(2047.2278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17221 lossL: tensor(2556.3901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17222 lossL: tensor(2173.4209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17223 lossL: tensor(2180.8428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17224 lossL: tensor(1903.4009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17225 lossL: tensor(2282.1509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17226 lossL: tensor(2095.0269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17227 lossL: tensor(2095.3784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17228 lossL: tensor(2369.9636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17229 lossL: tensor(2284.4185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17230 lossL: tensor(2138.1201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17231 lossL: tensor(2215.6831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17232 lossL: tensor(2290.6616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17233 lossL: tensor(1991.6663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17234 lossL: tensor(2051.3181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17235 lossL: tensor(2099.1799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17236 lossL: tensor(1989.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17237 lossL: tensor(2345.8469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17238 lossL: tensor(2415.1194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17239 lossL: tensor(2170.2844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17240 lossL: tensor(2145.6614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17241 lossL: tensor(2286.7537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17242 lossL: tensor(2011.8833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17243 lossL: tensor(2094.7815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17244 lossL: tensor(2246.1084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17245 lossL: tensor(2305.5066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17246 lossL: tensor(2026.3687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17247 lossL: tensor(2070.7073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17248 lossL: tensor(2357.4380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17249 lossL: tensor(2075.5874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17250 lossL: tensor(2133.4988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17251 lossL: tensor(1961.7021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17252 lossL: tensor(2597.8247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17253 lossL: tensor(2044.2559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17254 lossL: tensor(2219.8474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17255 lossL: tensor(2165.7820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17256 lossL: tensor(2160.8657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17257 lossL: tensor(2364.1648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17258 lossL: tensor(2322.2991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17259 lossL: tensor(2410.2622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17260 lossL: tensor(2347.2866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17261 lossL: tensor(2398.1863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17262 lossL: tensor(1994.1808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17263 lossL: tensor(2217.3318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17264 lossL: tensor(2060.6619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17265 lossL: tensor(2066.9341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17266 lossL: tensor(2009.9230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17267 lossL: tensor(2268.0681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17268 lossL: tensor(2150.7034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17269 lossL: tensor(2254.0693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17270 lossL: tensor(2038.1448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17271 lossL: tensor(2006.6470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17272 lossL: tensor(1903.3994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17273 lossL: tensor(2367.2322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17274 lossL: tensor(2188.9917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17275 lossL: tensor(1970.3279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17276 lossL: tensor(2204.3054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17277 lossL: tensor(2047.7119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17278 lossL: tensor(2357.2661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17279 lossL: tensor(1938.4039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17280 lossL: tensor(2214.2512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17281 lossL: tensor(2154.6099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17282 lossL: tensor(2213.8965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17283 lossL: tensor(2169.5032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17284 lossL: tensor(2327.4453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17285 lossL: tensor(2088.4651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17286 lossL: tensor(2395.6040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17287 lossL: tensor(2396.5283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17288 lossL: tensor(2126.7988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17289 lossL: tensor(2331.6907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17290 lossL: tensor(1949.2909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17291 lossL: tensor(2106.1260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17292 lossL: tensor(2172.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17293 lossL: tensor(2175.3853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17294 lossL: tensor(2512.0913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17295 lossL: tensor(2478.8796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17296 lossL: tensor(2339.9429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17297 lossL: tensor(2307.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17298 lossL: tensor(2248.7258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17299 lossL: tensor(2483.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17300 lossL: tensor(2393.4563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17301 lossL: tensor(2340.5371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17302 lossL: tensor(2380.4036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17303 lossL: tensor(2227.9783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17304 lossL: tensor(2182.5264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17305 lossL: tensor(2392.3860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17306 lossL: tensor(2352.5208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17307 lossL: tensor(2079.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17308 lossL: tensor(2309.1582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17309 lossL: tensor(2425.4595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17310 lossL: tensor(2198.9067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17311 lossL: tensor(2144.1069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17312 lossL: tensor(2370.8342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17313 lossL: tensor(1930.1266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17314 lossL: tensor(2171.3088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17315 lossL: tensor(2088.0515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17316 lossL: tensor(2154.0154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17317 lossL: tensor(2269.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17318 lossL: tensor(2181.7871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17319 lossL: tensor(2241.4795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17320 lossL: tensor(2051.4155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17321 lossL: tensor(2239.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17322 lossL: tensor(2446.4927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17323 lossL: tensor(1990.6447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17324 lossL: tensor(1994.3990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17325 lossL: tensor(2211.1719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17326 lossL: tensor(1970.2551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17327 lossL: tensor(2162.7910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17328 lossL: tensor(2180.4094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17329 lossL: tensor(2394.6375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17330 lossL: tensor(2140.3440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17331 lossL: tensor(2290.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17332 lossL: tensor(1829.4169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17333 lossL: tensor(1862.6151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17334 lossL: tensor(2299.4072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17335 lossL: tensor(2113.7290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17336 lossL: tensor(2288.8779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17337 lossL: tensor(2090.7874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17338 lossL: tensor(2454.4197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17339 lossL: tensor(2058.9429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17340 lossL: tensor(2306.5684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17341 lossL: tensor(2230.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17342 lossL: tensor(2046.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17343 lossL: tensor(2264.1565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17344 lossL: tensor(2171.7439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17345 lossL: tensor(2160.3743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17346 lossL: tensor(2638.3162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17347 lossL: tensor(2311.7822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17348 lossL: tensor(2144.1482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17349 lossL: tensor(2321.6204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17350 lossL: tensor(2070.3298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17351 lossL: tensor(1995.7080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17352 lossL: tensor(2315.5669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17353 lossL: tensor(2077.5684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17354 lossL: tensor(2459.4031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17355 lossL: tensor(2019.9115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17356 lossL: tensor(2052.3914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17357 lossL: tensor(2043.9960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17358 lossL: tensor(2079.1831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17359 lossL: tensor(1852.8962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17360 lossL: tensor(2122.2512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17361 lossL: tensor(2320.1833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17362 lossL: tensor(2433.3269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17363 lossL: tensor(2136.8640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17364 lossL: tensor(2455.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17365 lossL: tensor(2325.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17366 lossL: tensor(1908.5364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17367 lossL: tensor(2126.3479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17368 lossL: tensor(2061.8745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17369 lossL: tensor(2072.1638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17370 lossL: tensor(2142.8430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17371 lossL: tensor(2328.7751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17372 lossL: tensor(2086.4824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17373 lossL: tensor(1909.8661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17374 lossL: tensor(2424.0876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17375 lossL: tensor(2317.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17376 lossL: tensor(2225.7363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17377 lossL: tensor(1992.9362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17378 lossL: tensor(2121.0876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17379 lossL: tensor(2139.2432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17380 lossL: tensor(2109.8445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17381 lossL: tensor(2071.5198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17382 lossL: tensor(2226.5713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17383 lossL: tensor(2224.1704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17384 lossL: tensor(2136.3157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17385 lossL: tensor(2077.8743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17386 lossL: tensor(2425.5911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17387 lossL: tensor(2292.1697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17388 lossL: tensor(2346.2407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17389 lossL: tensor(1962.0549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17390 lossL: tensor(2438.0957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17391 lossL: tensor(2182.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17392 lossL: tensor(2022.9611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17393 lossL: tensor(2307.4202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17394 lossL: tensor(1962.4446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17395 lossL: tensor(2130.7747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17396 lossL: tensor(2092.4426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17397 lossL: tensor(2306.9392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17398 lossL: tensor(1998.7756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17399 lossL: tensor(2282.9744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17400 lossL: tensor(2247.0491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17401 lossL: tensor(1947.2045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17402 lossL: tensor(2077.4856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17403 lossL: tensor(1856.9117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17404 lossL: tensor(2370.8215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17405 lossL: tensor(1948.8445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17406 lossL: tensor(2154.3037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17407 lossL: tensor(2002.6355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17408 lossL: tensor(2266.4543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17409 lossL: tensor(2168.8958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17410 lossL: tensor(2082.4189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17411 lossL: tensor(2425.4795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17412 lossL: tensor(2052.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17413 lossL: tensor(2026.7714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17414 lossL: tensor(2139.8035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17415 lossL: tensor(2013.2627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17416 lossL: tensor(2166.4724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17417 lossL: tensor(1816.4963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "17418 lossL: tensor(2215.8511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17419 lossL: tensor(1940.9586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17420 lossL: tensor(2145.7520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17421 lossL: tensor(1922.1527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17422 lossL: tensor(2076.2781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17423 lossL: tensor(2255.3000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17424 lossL: tensor(2156.8704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17425 lossL: tensor(1731.8531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "17426 lossL: tensor(2255.0415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17427 lossL: tensor(2299.9270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17428 lossL: tensor(2269.2808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17429 lossL: tensor(1871.3319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17430 lossL: tensor(2263.5967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17431 lossL: tensor(2368.1548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17432 lossL: tensor(2343.1824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17433 lossL: tensor(2143.6038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17434 lossL: tensor(2379.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17435 lossL: tensor(2244.9099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17436 lossL: tensor(2267.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17437 lossL: tensor(2433.5303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17438 lossL: tensor(1936.4526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17439 lossL: tensor(2263.4470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17440 lossL: tensor(1993.8868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17441 lossL: tensor(2118.8386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17442 lossL: tensor(2296.1631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17443 lossL: tensor(2213.4248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17444 lossL: tensor(1828.4557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17445 lossL: tensor(2249.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17446 lossL: tensor(2276.4155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17447 lossL: tensor(2292.6521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17448 lossL: tensor(2170.8525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17449 lossL: tensor(2053.1045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17450 lossL: tensor(2585.3723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17451 lossL: tensor(2427.4932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17452 lossL: tensor(2195.0298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17453 lossL: tensor(2255.2954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17454 lossL: tensor(2424.2327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17455 lossL: tensor(2065.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17456 lossL: tensor(2323.2710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17457 lossL: tensor(2278.6592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17458 lossL: tensor(2416.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17459 lossL: tensor(2072.3057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17460 lossL: tensor(2594.4346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17461 lossL: tensor(2086.6230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17462 lossL: tensor(2462.3625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17463 lossL: tensor(2572.7979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17464 lossL: tensor(2038.9919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17465 lossL: tensor(2825.1357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17466 lossL: tensor(2173.6321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17467 lossL: tensor(2356.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17468 lossL: tensor(2015.5488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17469 lossL: tensor(2774.9216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17470 lossL: tensor(2229.2754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17471 lossL: tensor(2008.7144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17472 lossL: tensor(2069.7012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17473 lossL: tensor(2496.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17474 lossL: tensor(2337.3843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17475 lossL: tensor(2324.8169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17476 lossL: tensor(2036.0269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17477 lossL: tensor(2200.6990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17478 lossL: tensor(2159.5645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17479 lossL: tensor(2086.7017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17480 lossL: tensor(2406.9480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17481 lossL: tensor(1971.5034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17482 lossL: tensor(2295.5869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17483 lossL: tensor(2313.5371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17484 lossL: tensor(2324.2744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17485 lossL: tensor(2166.5627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17486 lossL: tensor(1981.0828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17487 lossL: tensor(1937.7321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17488 lossL: tensor(1965.9937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17489 lossL: tensor(2436.0476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17490 lossL: tensor(2103.9036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17491 lossL: tensor(2328.7317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17492 lossL: tensor(1989.0289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17493 lossL: tensor(2159.5027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17494 lossL: tensor(2158.8401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17495 lossL: tensor(1997.6412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17496 lossL: tensor(2265.9241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17497 lossL: tensor(2120.0398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17498 lossL: tensor(1938.9128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17499 lossL: tensor(1751.0392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17500 lossL: tensor(2330.4607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17501 lossL: tensor(2185.7988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17502 lossL: tensor(2377.9900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17503 lossL: tensor(2154.7009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17504 lossL: tensor(1899.0317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17505 lossL: tensor(2315.1458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17506 lossL: tensor(2151.2771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17507 lossL: tensor(1986.3740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17508 lossL: tensor(2150.0620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17509 lossL: tensor(2229.4688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17510 lossL: tensor(2195.6074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17511 lossL: tensor(2065.6201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17512 lossL: tensor(1836.7919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17513 lossL: tensor(2427.7510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17514 lossL: tensor(2053.4897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17515 lossL: tensor(2196.5146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17516 lossL: tensor(2042.0271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17517 lossL: tensor(2026.0756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17518 lossL: tensor(2129.4363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17519 lossL: tensor(2097.4282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17520 lossL: tensor(2240.8279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17521 lossL: tensor(1983.2242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17522 lossL: tensor(2073.2339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17523 lossL: tensor(2056.3860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17524 lossL: tensor(2054.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17525 lossL: tensor(2212.7197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17526 lossL: tensor(2018.6416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17527 lossL: tensor(1989.0999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17528 lossL: tensor(2241.8333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17529 lossL: tensor(2254.5801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17530 lossL: tensor(2163.4790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17531 lossL: tensor(2022.9235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17532 lossL: tensor(1758.8972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17533 lossL: tensor(2112.6465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17534 lossL: tensor(2053.1304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17535 lossL: tensor(1838.1643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17536 lossL: tensor(2002.4513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17537 lossL: tensor(1913.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17538 lossL: tensor(2222.9553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17539 lossL: tensor(2071.9255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17540 lossL: tensor(2202.2629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17541 lossL: tensor(2056.1143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17542 lossL: tensor(2309.1277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17543 lossL: tensor(2233.0288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17544 lossL: tensor(2340.1477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17545 lossL: tensor(1857.1729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17546 lossL: tensor(2136.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17547 lossL: tensor(1796.4944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17548 lossL: tensor(2248.5898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17549 lossL: tensor(1951.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17550 lossL: tensor(2150.0303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17551 lossL: tensor(2021.3094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17552 lossL: tensor(1938.7722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17553 lossL: tensor(2087.9221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17554 lossL: tensor(1953.0464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17555 lossL: tensor(2213.6892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17556 lossL: tensor(2159.2590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17557 lossL: tensor(2010.6896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17558 lossL: tensor(2226.1282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17559 lossL: tensor(2157.7197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17560 lossL: tensor(2196.5051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17561 lossL: tensor(1882.0375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17562 lossL: tensor(2259.6973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17563 lossL: tensor(1930.3785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17564 lossL: tensor(2167.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17565 lossL: tensor(1728.7378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "17566 lossL: tensor(1935.3175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17567 lossL: tensor(1887.5452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17568 lossL: tensor(2075.3699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17569 lossL: tensor(1894.9303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17570 lossL: tensor(2083.6003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17571 lossL: tensor(2075.5012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17572 lossL: tensor(2255.9524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17573 lossL: tensor(1884.1692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17574 lossL: tensor(2026.7253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17575 lossL: tensor(2021.5437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17576 lossL: tensor(2136.8896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17577 lossL: tensor(2060.3015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17578 lossL: tensor(2232.2542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17579 lossL: tensor(1898.7239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17580 lossL: tensor(2262.7026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17581 lossL: tensor(1864.3428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17582 lossL: tensor(1951.4606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17583 lossL: tensor(1773.0667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17584 lossL: tensor(2096.3345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17585 lossL: tensor(1983.2034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17586 lossL: tensor(2004.4136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17587 lossL: tensor(2346.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17588 lossL: tensor(1976.2570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17589 lossL: tensor(2333.9690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17590 lossL: tensor(2025.1699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17591 lossL: tensor(2734.4785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17592 lossL: tensor(1887.0648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17593 lossL: tensor(2301.4243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17594 lossL: tensor(1928.7147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17595 lossL: tensor(2249.0459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17596 lossL: tensor(2157.1233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17597 lossL: tensor(2417.4065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17598 lossL: tensor(1878.9905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17599 lossL: tensor(2200.8560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17600 lossL: tensor(2134.5896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17601 lossL: tensor(2259.6941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17602 lossL: tensor(2211.1216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17603 lossL: tensor(2154.4924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17604 lossL: tensor(2294.7961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17605 lossL: tensor(2227.5886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17606 lossL: tensor(2259.4385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17607 lossL: tensor(2117.6440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17608 lossL: tensor(1925.6659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17609 lossL: tensor(2197.8535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17610 lossL: tensor(2013.6063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17611 lossL: tensor(2348.1941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17612 lossL: tensor(1926.6814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17613 lossL: tensor(2455.7290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17614 lossL: tensor(2164.1082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17615 lossL: tensor(2341.5991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17616 lossL: tensor(2029.9006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17617 lossL: tensor(2281.5588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17618 lossL: tensor(1981.5714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17619 lossL: tensor(2383.6570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17620 lossL: tensor(1906.0767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17621 lossL: tensor(2283.6082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17622 lossL: tensor(1889.0343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17623 lossL: tensor(2262.0256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17624 lossL: tensor(1872.8523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17625 lossL: tensor(2265.5112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17626 lossL: tensor(1950.4890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17627 lossL: tensor(2213.1907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17628 lossL: tensor(1933.6392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17629 lossL: tensor(2338.6433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17630 lossL: tensor(2017.3169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17631 lossL: tensor(2144.3931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17632 lossL: tensor(2198.3064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17633 lossL: tensor(2023.1180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17634 lossL: tensor(1750.8798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17635 lossL: tensor(1887.0576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17636 lossL: tensor(1919.4760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17637 lossL: tensor(2214.5688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17638 lossL: tensor(2082.8518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17639 lossL: tensor(2024.7986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17640 lossL: tensor(2006.5648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17641 lossL: tensor(1956.2756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17642 lossL: tensor(2032.7792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17643 lossL: tensor(1967.5446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17644 lossL: tensor(1907.9094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17645 lossL: tensor(2030.1940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17646 lossL: tensor(1858.4130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17647 lossL: tensor(1814.9071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17648 lossL: tensor(2118.0928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17649 lossL: tensor(2196.6946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17650 lossL: tensor(1960.2335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17651 lossL: tensor(1987.4885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17652 lossL: tensor(2121.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17653 lossL: tensor(2198.6467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17654 lossL: tensor(2100.2168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17655 lossL: tensor(2223.1057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17656 lossL: tensor(1813.8455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17657 lossL: tensor(2005.5334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17658 lossL: tensor(1890.8505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17659 lossL: tensor(1731.2980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17660 lossL: tensor(1865.0149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17661 lossL: tensor(1892.2711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17662 lossL: tensor(1951.8712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17663 lossL: tensor(2041.1656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17664 lossL: tensor(2107.4834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17665 lossL: tensor(1878.6656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17666 lossL: tensor(1874.2427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17667 lossL: tensor(1965.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17668 lossL: tensor(1943.7126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17669 lossL: tensor(1919.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17670 lossL: tensor(2059.4263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17671 lossL: tensor(1878.5370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17672 lossL: tensor(2040.1904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17673 lossL: tensor(2013.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17674 lossL: tensor(2222.5618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17675 lossL: tensor(2096.0381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17676 lossL: tensor(2238.9399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17677 lossL: tensor(2258.3813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17678 lossL: tensor(2023.3446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17679 lossL: tensor(2104.4993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17680 lossL: tensor(2329.5962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17681 lossL: tensor(2164.8003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17682 lossL: tensor(2006.2885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17683 lossL: tensor(2353.4216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17684 lossL: tensor(2279.2727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17685 lossL: tensor(1896.7808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17686 lossL: tensor(2215.4622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17687 lossL: tensor(2055.3042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17688 lossL: tensor(2109.8899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17689 lossL: tensor(1954.6312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17690 lossL: tensor(2063.5637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17691 lossL: tensor(1861.8032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17692 lossL: tensor(2012.2657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17693 lossL: tensor(1988.9674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17694 lossL: tensor(2084.7913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17695 lossL: tensor(1759.6896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17696 lossL: tensor(1991.6779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17697 lossL: tensor(2204.9392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17698 lossL: tensor(2293.7603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17699 lossL: tensor(1942.6986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17700 lossL: tensor(1895.1708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17701 lossL: tensor(1809.5967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17702 lossL: tensor(2098.1416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17703 lossL: tensor(2120.6011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17704 lossL: tensor(2100.4263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17705 lossL: tensor(2202.2537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17706 lossL: tensor(2057.3132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17707 lossL: tensor(2179.2375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17708 lossL: tensor(1846.0546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17709 lossL: tensor(1885.9047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17710 lossL: tensor(2129.6521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17711 lossL: tensor(1926.2048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17712 lossL: tensor(2009.0403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17713 lossL: tensor(1974.0929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17714 lossL: tensor(1941.8306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17715 lossL: tensor(1886.4521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17716 lossL: tensor(2079.7478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17717 lossL: tensor(1933.5284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17718 lossL: tensor(1924.0250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17719 lossL: tensor(2318.8269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17720 lossL: tensor(2135.5925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17721 lossL: tensor(1927.0149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17722 lossL: tensor(1972.4604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17723 lossL: tensor(2110.7166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17724 lossL: tensor(2069.9558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17725 lossL: tensor(1959.6615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17726 lossL: tensor(1987.5208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17727 lossL: tensor(1865.3901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17728 lossL: tensor(1920.5062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17729 lossL: tensor(1935.8149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17730 lossL: tensor(1947.2371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17731 lossL: tensor(2166.7415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17732 lossL: tensor(1962.0262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17733 lossL: tensor(2046.4945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17734 lossL: tensor(1909.7422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17735 lossL: tensor(1940.1962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17736 lossL: tensor(1844.6434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17737 lossL: tensor(2024.6844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17738 lossL: tensor(1883.6180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17739 lossL: tensor(1895.2529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17740 lossL: tensor(2298.7690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17741 lossL: tensor(2111.0288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17742 lossL: tensor(2138.1858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17743 lossL: tensor(1972.4663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17744 lossL: tensor(2053.4509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17745 lossL: tensor(1908.1354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17746 lossL: tensor(1990.8206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17747 lossL: tensor(2041.0131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17748 lossL: tensor(2053.8347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17749 lossL: tensor(1717.0950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "17750 lossL: tensor(2013.3843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17751 lossL: tensor(1678.7147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "17752 lossL: tensor(1880.3866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17753 lossL: tensor(1987.6544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17754 lossL: tensor(2016.9274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17755 lossL: tensor(1973.0579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17756 lossL: tensor(2057.3650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17757 lossL: tensor(2064.7483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17758 lossL: tensor(1828.1121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17759 lossL: tensor(2018.2399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17760 lossL: tensor(1955.2810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17761 lossL: tensor(2003.4561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17762 lossL: tensor(1974.0704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17763 lossL: tensor(1927.3604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17764 lossL: tensor(1980.4656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17765 lossL: tensor(1862.4814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17766 lossL: tensor(1846.7863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17767 lossL: tensor(1998.3940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17768 lossL: tensor(2057.7117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17769 lossL: tensor(2079.2993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17770 lossL: tensor(1998.8184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17771 lossL: tensor(1922.7876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17772 lossL: tensor(2302.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17773 lossL: tensor(2139.2568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17774 lossL: tensor(2287.8691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17775 lossL: tensor(1929.3732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17776 lossL: tensor(2336.4705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17777 lossL: tensor(2059.9556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17778 lossL: tensor(2059.2556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17779 lossL: tensor(1906.4867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17780 lossL: tensor(2508.1147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17781 lossL: tensor(2173.5764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17782 lossL: tensor(2702.1350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17783 lossL: tensor(1843.8124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17784 lossL: tensor(2384.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17785 lossL: tensor(1757.8510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17786 lossL: tensor(2190.8071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17787 lossL: tensor(2104.4067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17788 lossL: tensor(1985.0010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17789 lossL: tensor(1909.5123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17790 lossL: tensor(2003.3134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17791 lossL: tensor(2033.0837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17792 lossL: tensor(2079.9124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17793 lossL: tensor(1864.1753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17794 lossL: tensor(1934.5465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17795 lossL: tensor(1950.1129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17796 lossL: tensor(1975.5719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17797 lossL: tensor(1881.2631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17798 lossL: tensor(1882.8732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17799 lossL: tensor(1858.7875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17800 lossL: tensor(2000.7208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17801 lossL: tensor(1909.2836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17802 lossL: tensor(1679.5673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17803 lossL: tensor(2048.8953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17804 lossL: tensor(1940.1007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17805 lossL: tensor(1959.5857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17806 lossL: tensor(2002.9950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17807 lossL: tensor(1862.9362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17808 lossL: tensor(2041.3534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17809 lossL: tensor(2064.8611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17810 lossL: tensor(1824.7009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17811 lossL: tensor(1761.3167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17812 lossL: tensor(2023.4681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17813 lossL: tensor(1872.9413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17814 lossL: tensor(2124.8501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17815 lossL: tensor(2068.6326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17816 lossL: tensor(1843.7521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17817 lossL: tensor(1978.4276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17818 lossL: tensor(1997.0045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17819 lossL: tensor(2120.9614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17820 lossL: tensor(1794.5927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17821 lossL: tensor(2269.0532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17822 lossL: tensor(2237.4851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17823 lossL: tensor(2272.8188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17824 lossL: tensor(2009.3651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17825 lossL: tensor(1999.8446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17826 lossL: tensor(2262.5400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17827 lossL: tensor(1910.8542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17828 lossL: tensor(2084.8684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17829 lossL: tensor(2120.6138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17830 lossL: tensor(1947.2252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17831 lossL: tensor(1988.9081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17832 lossL: tensor(1980.5917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17833 lossL: tensor(1944.0105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17834 lossL: tensor(2090.1108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17835 lossL: tensor(1937.5691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17836 lossL: tensor(1981.9934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17837 lossL: tensor(1800.2825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17838 lossL: tensor(1888.2987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17839 lossL: tensor(1951.8193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17840 lossL: tensor(2149.8254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17841 lossL: tensor(1846.1786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17842 lossL: tensor(2124.9888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17843 lossL: tensor(1754.4718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17844 lossL: tensor(1888.5669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17845 lossL: tensor(1803.6150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17846 lossL: tensor(1759.3389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17847 lossL: tensor(2030.2729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17848 lossL: tensor(2040.7174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17849 lossL: tensor(1928.9128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17850 lossL: tensor(1992.0167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17851 lossL: tensor(2012.6283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17852 lossL: tensor(1979.2257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17853 lossL: tensor(1938.3973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17854 lossL: tensor(2003.4458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17855 lossL: tensor(1944.7452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17856 lossL: tensor(2318.4412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17857 lossL: tensor(1856.2828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17858 lossL: tensor(1898.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17859 lossL: tensor(2061.0295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17860 lossL: tensor(1854.1880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17861 lossL: tensor(2038.0809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17862 lossL: tensor(2169.6379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17863 lossL: tensor(2073.9355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17864 lossL: tensor(1905.7327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17865 lossL: tensor(2048.3599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17866 lossL: tensor(2068.9802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17867 lossL: tensor(2019.7200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17868 lossL: tensor(1855.0646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17869 lossL: tensor(1831.1217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17870 lossL: tensor(1787.6908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17871 lossL: tensor(1931.0145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17872 lossL: tensor(2052.7510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17873 lossL: tensor(1759.1399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17874 lossL: tensor(1847.0549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17875 lossL: tensor(1967.5980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17876 lossL: tensor(1781.6160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17877 lossL: tensor(1928.0671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17878 lossL: tensor(2160.9768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17879 lossL: tensor(1702.5267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17880 lossL: tensor(1927.4517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17881 lossL: tensor(1878.3090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17882 lossL: tensor(1959.7723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17883 lossL: tensor(1941.2549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17884 lossL: tensor(1884.3053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17885 lossL: tensor(1802.1216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17886 lossL: tensor(2499.1414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17887 lossL: tensor(1861.6381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17888 lossL: tensor(2241.8325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17889 lossL: tensor(1942.5394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17890 lossL: tensor(1634.1663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "17891 lossL: tensor(2763.1794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17892 lossL: tensor(2085.8115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17893 lossL: tensor(2165.7004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17894 lossL: tensor(1950.2075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17895 lossL: tensor(2150.8252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17896 lossL: tensor(1777.8131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17897 lossL: tensor(2064.5920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17898 lossL: tensor(1809.4004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17899 lossL: tensor(2019.6709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17900 lossL: tensor(1895.0969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17901 lossL: tensor(1902.8654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17902 lossL: tensor(1531.2502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "17903 lossL: tensor(1966.1636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17904 lossL: tensor(1912.1592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17905 lossL: tensor(1979.8357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17906 lossL: tensor(2037.4871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17907 lossL: tensor(2084.3870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17908 lossL: tensor(1813.6783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17909 lossL: tensor(2108.7944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17910 lossL: tensor(2168.7830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17911 lossL: tensor(1987.1816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17912 lossL: tensor(1805.4384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17913 lossL: tensor(2163.1782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17914 lossL: tensor(2158.3796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17915 lossL: tensor(2179.5110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17916 lossL: tensor(2217.7380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17917 lossL: tensor(2164.0698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17918 lossL: tensor(2004.1488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17919 lossL: tensor(2162.6555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17920 lossL: tensor(1838.7057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17921 lossL: tensor(2192.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17922 lossL: tensor(2111.3252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17923 lossL: tensor(2044.9875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17924 lossL: tensor(1951.5753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17925 lossL: tensor(2059.2876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17926 lossL: tensor(1760.6876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17927 lossL: tensor(1823.2844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17928 lossL: tensor(1927.5828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17929 lossL: tensor(1880.5974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17930 lossL: tensor(1975.1532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17931 lossL: tensor(2142.5874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17932 lossL: tensor(2035.7684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17933 lossL: tensor(2022.7543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17934 lossL: tensor(1967.2823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17935 lossL: tensor(2027.5164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17936 lossL: tensor(1910.2211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17937 lossL: tensor(2257.5710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17938 lossL: tensor(1901.4333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17939 lossL: tensor(2415.4714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17940 lossL: tensor(1804.3082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17941 lossL: tensor(2208.8967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17942 lossL: tensor(1584.4462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17943 lossL: tensor(2032.7866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17944 lossL: tensor(1833.2513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17945 lossL: tensor(2252.2075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17946 lossL: tensor(1891.2487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17947 lossL: tensor(1858.4432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17948 lossL: tensor(2056.3926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17949 lossL: tensor(1759.7982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17950 lossL: tensor(1821.5693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17951 lossL: tensor(1943.2955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17952 lossL: tensor(2015.4978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17953 lossL: tensor(1896.7117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17954 lossL: tensor(2236.4929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17955 lossL: tensor(1993.5759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17956 lossL: tensor(2167.1443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17957 lossL: tensor(2097.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17958 lossL: tensor(1824.1862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17959 lossL: tensor(2030.3483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17960 lossL: tensor(1965.3914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17961 lossL: tensor(1698.1852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17962 lossL: tensor(2102.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17963 lossL: tensor(2060.0410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17964 lossL: tensor(2110.0940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17965 lossL: tensor(2021.5033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17966 lossL: tensor(1980.7032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17967 lossL: tensor(1966.6628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17968 lossL: tensor(2059.9458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17969 lossL: tensor(2035.0648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17970 lossL: tensor(2011.9944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17971 lossL: tensor(1700.3801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17972 lossL: tensor(1981.6714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17973 lossL: tensor(1980.1371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17974 lossL: tensor(1870.6851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17975 lossL: tensor(1847.9174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17976 lossL: tensor(1965.4254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17977 lossL: tensor(1918.1249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17978 lossL: tensor(2019.0490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17979 lossL: tensor(2073.5447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17980 lossL: tensor(2102.0945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17981 lossL: tensor(2025.6611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17982 lossL: tensor(1665.6963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17983 lossL: tensor(1924.0717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17984 lossL: tensor(1829.2189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17985 lossL: tensor(1950.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17986 lossL: tensor(1704.9388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17987 lossL: tensor(2200.1199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17988 lossL: tensor(1940.9027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17989 lossL: tensor(1966.8983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17990 lossL: tensor(1813.3593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17991 lossL: tensor(1978.7520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17992 lossL: tensor(2037.3761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17993 lossL: tensor(2052.3567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17994 lossL: tensor(1658.3030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17995 lossL: tensor(1892.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17996 lossL: tensor(1774.6781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17997 lossL: tensor(1985.9614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17998 lossL: tensor(2048.8032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "17999 lossL: tensor(1943.6053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18000 lossL: tensor(1864.7185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18001 lossL: tensor(1792.2180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18002 lossL: tensor(1703.5674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18003 lossL: tensor(1866.9474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18004 lossL: tensor(1803.3087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18005 lossL: tensor(1831.3766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18006 lossL: tensor(1833.2029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18007 lossL: tensor(1717.7416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18008 lossL: tensor(1864.6693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18009 lossL: tensor(1848.1118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18010 lossL: tensor(2079.6829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18011 lossL: tensor(1777.6649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18012 lossL: tensor(1800.6383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18013 lossL: tensor(2127.3364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18014 lossL: tensor(2180.4053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18015 lossL: tensor(2055.3772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18016 lossL: tensor(1909.7236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18017 lossL: tensor(2024.5374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18018 lossL: tensor(2066.0283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18019 lossL: tensor(1981.5239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18020 lossL: tensor(1740.6443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18021 lossL: tensor(1909.2412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18022 lossL: tensor(1821.8940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18023 lossL: tensor(1843.1671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18024 lossL: tensor(1769.1451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18025 lossL: tensor(2089.7324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18026 lossL: tensor(1741.7928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18027 lossL: tensor(1949.6799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18028 lossL: tensor(1949.7896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18029 lossL: tensor(1841.5869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18030 lossL: tensor(1965.0277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18031 lossL: tensor(2086.5527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18032 lossL: tensor(1831.1224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18033 lossL: tensor(1601.2277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18034 lossL: tensor(1885.0985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18035 lossL: tensor(1873.4478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18036 lossL: tensor(1963.4424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18037 lossL: tensor(1708.4684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18038 lossL: tensor(1804.6584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18039 lossL: tensor(1947.0337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18040 lossL: tensor(1906.1440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18041 lossL: tensor(2037.4148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18042 lossL: tensor(2165.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18043 lossL: tensor(1992.5844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18044 lossL: tensor(1849.7467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18045 lossL: tensor(2115.6284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18046 lossL: tensor(1788.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18047 lossL: tensor(1926.1359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18048 lossL: tensor(2051.3704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18049 lossL: tensor(2010.9263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18050 lossL: tensor(1833.7815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18051 lossL: tensor(1842.6593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18052 lossL: tensor(1998.6451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18053 lossL: tensor(2039.3134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18054 lossL: tensor(1904.7664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18055 lossL: tensor(2058.7349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18056 lossL: tensor(2095.7458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18057 lossL: tensor(1826.5841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18058 lossL: tensor(1894.3439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18059 lossL: tensor(1903.6204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18060 lossL: tensor(2009.2620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18061 lossL: tensor(2075.8857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18062 lossL: tensor(1938.6083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18063 lossL: tensor(1709.8481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18064 lossL: tensor(1821.5112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18065 lossL: tensor(1884.8746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18066 lossL: tensor(1830.7035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18067 lossL: tensor(1930.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18068 lossL: tensor(2002.9540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18069 lossL: tensor(1805.1553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18070 lossL: tensor(1680.7360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18071 lossL: tensor(1872.0496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18072 lossL: tensor(2031.9440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18073 lossL: tensor(2002.5348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18074 lossL: tensor(1833.8453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18075 lossL: tensor(1805.4633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18076 lossL: tensor(1874.9586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18077 lossL: tensor(1833.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18078 lossL: tensor(1690.2067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18079 lossL: tensor(1864.4607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18080 lossL: tensor(2217.7053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18081 lossL: tensor(2069.0576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18082 lossL: tensor(1919.1224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18083 lossL: tensor(2273.8882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18084 lossL: tensor(1773.7513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18085 lossL: tensor(1774.0083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18086 lossL: tensor(1767.5642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18087 lossL: tensor(2073.3740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18088 lossL: tensor(1872.6440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18089 lossL: tensor(2137.5625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18090 lossL: tensor(1924.5096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18091 lossL: tensor(1874.6791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18092 lossL: tensor(1936.8940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18093 lossL: tensor(1916.8002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18094 lossL: tensor(1607.7878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18095 lossL: tensor(1731.5103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18096 lossL: tensor(1684.8813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18097 lossL: tensor(1986.6580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18098 lossL: tensor(1755.3347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18099 lossL: tensor(1753.3291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18100 lossL: tensor(1694.5397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18101 lossL: tensor(1725.0559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18102 lossL: tensor(1956.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18103 lossL: tensor(1863.2103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18104 lossL: tensor(1979.6176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18105 lossL: tensor(1863.2489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18106 lossL: tensor(2085.2493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18107 lossL: tensor(1750.8395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18108 lossL: tensor(2141.1707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18109 lossL: tensor(1830.5740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18110 lossL: tensor(1738.7955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18111 lossL: tensor(1790.8645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18112 lossL: tensor(1940.2435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18113 lossL: tensor(1983.8450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18114 lossL: tensor(1757.5905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18115 lossL: tensor(2118.4211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18116 lossL: tensor(2024.2980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18117 lossL: tensor(1865.0599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18118 lossL: tensor(1710.9734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18119 lossL: tensor(2071.0818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18120 lossL: tensor(1947.1019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18121 lossL: tensor(1880.6884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18122 lossL: tensor(1855.0887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18123 lossL: tensor(2040.5265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18124 lossL: tensor(1847.1270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18125 lossL: tensor(2250.8254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18126 lossL: tensor(1851.6001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18127 lossL: tensor(1772.1508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18128 lossL: tensor(1782.1746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18129 lossL: tensor(2049.7576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18130 lossL: tensor(1935.1157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18131 lossL: tensor(1632.0745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18132 lossL: tensor(2027.4932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18133 lossL: tensor(1963.1428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18134 lossL: tensor(2051.4365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18135 lossL: tensor(1925.8225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18136 lossL: tensor(1616.6721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18137 lossL: tensor(1734.5592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18138 lossL: tensor(1874.2980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18139 lossL: tensor(1771.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18140 lossL: tensor(1786.0579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18141 lossL: tensor(1833.7980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18142 lossL: tensor(1853.5835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18143 lossL: tensor(1877.6757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18144 lossL: tensor(1778.2188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18145 lossL: tensor(1910.3556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18146 lossL: tensor(1981.8521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18147 lossL: tensor(1836.8724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18148 lossL: tensor(1888.7657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18149 lossL: tensor(1698.7716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18150 lossL: tensor(1890.1340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18151 lossL: tensor(1741.6560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18152 lossL: tensor(2009.5845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18153 lossL: tensor(1787.1259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18154 lossL: tensor(1817.5059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18155 lossL: tensor(2079.9915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18156 lossL: tensor(1919.2324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18157 lossL: tensor(1832.6040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18158 lossL: tensor(1881.7269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18159 lossL: tensor(1681.7988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18160 lossL: tensor(1718.2444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18161 lossL: tensor(1830.0459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18162 lossL: tensor(1765.5946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18163 lossL: tensor(2191.4119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18164 lossL: tensor(1862.6151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18165 lossL: tensor(1800.9745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18166 lossL: tensor(1814.5544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18167 lossL: tensor(1948.5454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18168 lossL: tensor(1890.9520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18169 lossL: tensor(1882.2124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18170 lossL: tensor(1779.7314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18171 lossL: tensor(2119.8274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18172 lossL: tensor(1884.2010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18173 lossL: tensor(2209.9561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18174 lossL: tensor(1691.5557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18175 lossL: tensor(1951.8002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18176 lossL: tensor(1776.3855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18177 lossL: tensor(1807.9706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18178 lossL: tensor(2045.6863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18179 lossL: tensor(1760.3262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18180 lossL: tensor(1871.0460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18181 lossL: tensor(1873.3607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18182 lossL: tensor(1867.6112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18183 lossL: tensor(2164.9653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18184 lossL: tensor(1966.1252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18185 lossL: tensor(1950.6506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18186 lossL: tensor(1851.4669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18187 lossL: tensor(1957.5687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18188 lossL: tensor(1894.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18189 lossL: tensor(1513.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "18190 lossL: tensor(1738.0652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18191 lossL: tensor(1872.5940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18192 lossL: tensor(1808.9403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18193 lossL: tensor(1872.1661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18194 lossL: tensor(1830.0165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18195 lossL: tensor(1857.2003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18196 lossL: tensor(1834.5811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18197 lossL: tensor(1947.6338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18198 lossL: tensor(1619.6566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18199 lossL: tensor(1957.7629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18200 lossL: tensor(1843.0436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18201 lossL: tensor(2010.9376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18202 lossL: tensor(1821.9972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18203 lossL: tensor(2025.4427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18204 lossL: tensor(1801.4547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18205 lossL: tensor(1837.2780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18206 lossL: tensor(1813.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18207 lossL: tensor(2117.7197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18208 lossL: tensor(1625.3374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18209 lossL: tensor(1891.8740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18210 lossL: tensor(1765.1835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18211 lossL: tensor(1816.7964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18212 lossL: tensor(1853.0752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18213 lossL: tensor(1807.0809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18214 lossL: tensor(1770.0643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18215 lossL: tensor(2293.7671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18216 lossL: tensor(2227.8601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18217 lossL: tensor(1900.8420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18218 lossL: tensor(2018.6711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18219 lossL: tensor(1883.9576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18220 lossL: tensor(1986.2542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18221 lossL: tensor(2054.1714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18222 lossL: tensor(1902.4978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18223 lossL: tensor(2077.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18224 lossL: tensor(1992.7509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18225 lossL: tensor(1924.7151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18226 lossL: tensor(2072.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18227 lossL: tensor(1789.5394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18228 lossL: tensor(1963.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18229 lossL: tensor(1779.4045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18230 lossL: tensor(1675.4418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18231 lossL: tensor(1831.3564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18232 lossL: tensor(2156.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18233 lossL: tensor(1975.6594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18234 lossL: tensor(1698.4711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18235 lossL: tensor(1805.0165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18236 lossL: tensor(1872.0482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18237 lossL: tensor(1797.3436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18238 lossL: tensor(2125.9661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18239 lossL: tensor(1864.6549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18240 lossL: tensor(1870.6692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18241 lossL: tensor(1866.7407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18242 lossL: tensor(1842.9135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18243 lossL: tensor(1670.2720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18244 lossL: tensor(1733.2847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18245 lossL: tensor(1771.4392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18246 lossL: tensor(1792.5383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18247 lossL: tensor(2066.8579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18248 lossL: tensor(1733.3634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18249 lossL: tensor(1791.9069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18250 lossL: tensor(1959.6766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18251 lossL: tensor(1999.6189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18252 lossL: tensor(1714.9767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18253 lossL: tensor(1810.7793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18254 lossL: tensor(1747.4915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18255 lossL: tensor(1720.2664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18256 lossL: tensor(1878.4266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18257 lossL: tensor(1828.0725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18258 lossL: tensor(1934.4609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18259 lossL: tensor(1824.4006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18260 lossL: tensor(1835.9612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18261 lossL: tensor(1957.0322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18262 lossL: tensor(1977.7952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18263 lossL: tensor(1772.7551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18264 lossL: tensor(1811.7550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18265 lossL: tensor(1715.1890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18266 lossL: tensor(1923.2667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18267 lossL: tensor(1672.7820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18268 lossL: tensor(1691.2416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18269 lossL: tensor(1733.6589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18270 lossL: tensor(1619.5928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18271 lossL: tensor(1839.1062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18272 lossL: tensor(1773.9049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18273 lossL: tensor(1640.5187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18274 lossL: tensor(1828.5791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18275 lossL: tensor(1724.4031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18276 lossL: tensor(1647.3236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18277 lossL: tensor(1736.3960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18278 lossL: tensor(1959.7521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18279 lossL: tensor(1676.3077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18280 lossL: tensor(1754.2156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18281 lossL: tensor(1672.0691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18282 lossL: tensor(1942.0006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18283 lossL: tensor(1743.2762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18284 lossL: tensor(1831.1123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18285 lossL: tensor(1979.0537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18286 lossL: tensor(1860.5142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18287 lossL: tensor(1690.6151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18288 lossL: tensor(1806.7399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18289 lossL: tensor(2075.0667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18290 lossL: tensor(1792.9050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18291 lossL: tensor(2014.1958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18292 lossL: tensor(1705.3625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18293 lossL: tensor(1761.3229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18294 lossL: tensor(1909.4651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18295 lossL: tensor(1763.2258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18296 lossL: tensor(1668.3397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18297 lossL: tensor(1759.8171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18298 lossL: tensor(2021.0997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18299 lossL: tensor(1792.4075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18300 lossL: tensor(1754.3741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18301 lossL: tensor(2064.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18302 lossL: tensor(1998.1033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18303 lossL: tensor(1815.2037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18304 lossL: tensor(1574.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18305 lossL: tensor(1982.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18306 lossL: tensor(1829.0780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18307 lossL: tensor(1905.5770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18308 lossL: tensor(1879.0288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18309 lossL: tensor(1890.5093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18310 lossL: tensor(1693.7454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18311 lossL: tensor(1815.0879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18312 lossL: tensor(1749.9301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18313 lossL: tensor(1755.7709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18314 lossL: tensor(1834.0723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18315 lossL: tensor(1916.5533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18316 lossL: tensor(1657.8826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18317 lossL: tensor(1723.3171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18318 lossL: tensor(1682.7844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18319 lossL: tensor(1891.8384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18320 lossL: tensor(1939.9525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18321 lossL: tensor(1693.9045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18322 lossL: tensor(1951.5985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18323 lossL: tensor(1711.6534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18324 lossL: tensor(2022.7502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18325 lossL: tensor(1786.4786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18326 lossL: tensor(1696.2959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18327 lossL: tensor(1808.4442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18328 lossL: tensor(1902.8754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18329 lossL: tensor(1648.5704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18330 lossL: tensor(1843.2821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18331 lossL: tensor(1885.2556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18332 lossL: tensor(1708.2181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18333 lossL: tensor(1802.6808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18334 lossL: tensor(1795.4882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18335 lossL: tensor(1587.1752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18336 lossL: tensor(1619.8588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18337 lossL: tensor(1599.5194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18338 lossL: tensor(1898.8367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18339 lossL: tensor(1938.6431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18340 lossL: tensor(1774.3207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18341 lossL: tensor(1762.0590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18342 lossL: tensor(1821.9591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18343 lossL: tensor(2068.9653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18344 lossL: tensor(1783.5880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18345 lossL: tensor(1882.6422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18346 lossL: tensor(1678.4620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18347 lossL: tensor(1701.9795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18348 lossL: tensor(1737.0082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18349 lossL: tensor(1672.2971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18350 lossL: tensor(2083.5825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18351 lossL: tensor(1810.9385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18352 lossL: tensor(1844.9000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18353 lossL: tensor(2003.1154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18354 lossL: tensor(1772.8749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18355 lossL: tensor(1884.3259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18356 lossL: tensor(1709.0984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18357 lossL: tensor(1797.2281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18358 lossL: tensor(1792.1096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18359 lossL: tensor(1948.2628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18360 lossL: tensor(1763.5588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18361 lossL: tensor(1678.6008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18362 lossL: tensor(1809.2855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18363 lossL: tensor(1662.0200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18364 lossL: tensor(1783.8462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18365 lossL: tensor(1915.2524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18366 lossL: tensor(1851.1206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18367 lossL: tensor(1899.4518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18368 lossL: tensor(1749.5710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18369 lossL: tensor(1825.3718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18370 lossL: tensor(1762.4941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18371 lossL: tensor(1959.1526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18372 lossL: tensor(1722.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18373 lossL: tensor(1970.9915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18374 lossL: tensor(2011.0114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18375 lossL: tensor(1887.9213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18376 lossL: tensor(1848.4884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18377 lossL: tensor(1852.7245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18378 lossL: tensor(1932.7513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18379 lossL: tensor(1707.4951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18380 lossL: tensor(1783.7389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18381 lossL: tensor(1692.0291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18382 lossL: tensor(1734.1981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18383 lossL: tensor(1837.6945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18384 lossL: tensor(1896.8286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18385 lossL: tensor(1990.2933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18386 lossL: tensor(1802.6089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18387 lossL: tensor(1526.1924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18388 lossL: tensor(1828.4913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18389 lossL: tensor(2034.1604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18390 lossL: tensor(1807.2200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18391 lossL: tensor(1840.0659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18392 lossL: tensor(1921.7583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18393 lossL: tensor(1709.6251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18394 lossL: tensor(1688.2815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18395 lossL: tensor(1821.8162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18396 lossL: tensor(1761.6768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18397 lossL: tensor(1816.8732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18398 lossL: tensor(1908.7494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18399 lossL: tensor(1720.1041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18400 lossL: tensor(2027.6740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18401 lossL: tensor(1772.4985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18402 lossL: tensor(1771.3702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18403 lossL: tensor(1767.3673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18404 lossL: tensor(1908.2550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18405 lossL: tensor(1837.7820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18406 lossL: tensor(1745.0194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18407 lossL: tensor(1966.6830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18408 lossL: tensor(1817.1392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18409 lossL: tensor(1770.7228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18410 lossL: tensor(2189.7371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18411 lossL: tensor(1854.0062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18412 lossL: tensor(1914.6216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18413 lossL: tensor(1798.0114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18414 lossL: tensor(1650.9144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18415 lossL: tensor(2032.0497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18416 lossL: tensor(1803.0502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18417 lossL: tensor(1866.4664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18418 lossL: tensor(1488.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "18419 lossL: tensor(1877.2842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18420 lossL: tensor(1895.8877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18421 lossL: tensor(1798.4857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18422 lossL: tensor(1822.2107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18423 lossL: tensor(1750.4537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18424 lossL: tensor(1841.4014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18425 lossL: tensor(1950.1035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18426 lossL: tensor(1736.3588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18427 lossL: tensor(1653.0602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18428 lossL: tensor(1651.1461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18429 lossL: tensor(1940.0090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18430 lossL: tensor(1721.1257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18431 lossL: tensor(1608.3616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18432 lossL: tensor(1955.8118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18433 lossL: tensor(1802.7191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18434 lossL: tensor(1735.9487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18435 lossL: tensor(1667.6967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18436 lossL: tensor(1678.9064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18437 lossL: tensor(1810.7355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18438 lossL: tensor(1805.0042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18439 lossL: tensor(1780.1045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18440 lossL: tensor(1692.3776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18441 lossL: tensor(1864.3684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18442 lossL: tensor(1741.5535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18443 lossL: tensor(1740.7046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18444 lossL: tensor(1670.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18445 lossL: tensor(1721.6322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18446 lossL: tensor(1875.5172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18447 lossL: tensor(1708.7397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18448 lossL: tensor(1758.5468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18449 lossL: tensor(1758.2960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18450 lossL: tensor(1720.9294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18451 lossL: tensor(1712.5271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18452 lossL: tensor(1652.6786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18453 lossL: tensor(1634.9977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18454 lossL: tensor(1836.7511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18455 lossL: tensor(1972.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18456 lossL: tensor(2137.4302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18457 lossL: tensor(1764.1858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18458 lossL: tensor(1650.9974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18459 lossL: tensor(1766.8889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18460 lossL: tensor(1729.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18461 lossL: tensor(1617.5908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18462 lossL: tensor(1753.4980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18463 lossL: tensor(1534.1733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18464 lossL: tensor(1699.1903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18465 lossL: tensor(1975.7529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18466 lossL: tensor(1827.1287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18467 lossL: tensor(1820.6440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18468 lossL: tensor(1610.6522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18469 lossL: tensor(1710.4703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18470 lossL: tensor(1697.8318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18471 lossL: tensor(1858.8099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18472 lossL: tensor(1642.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18473 lossL: tensor(1733.0757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18474 lossL: tensor(1794.0903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18475 lossL: tensor(1668.2236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18476 lossL: tensor(1742.8815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18477 lossL: tensor(1767.5081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18478 lossL: tensor(1825.0433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18479 lossL: tensor(1692.1476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18480 lossL: tensor(1646.3971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18481 lossL: tensor(1844.2115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18482 lossL: tensor(1795.7394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18483 lossL: tensor(1820.9601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18484 lossL: tensor(1684.5728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18485 lossL: tensor(1634.3074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18486 lossL: tensor(1517.3060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18487 lossL: tensor(1710.4528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18488 lossL: tensor(1826.8082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18489 lossL: tensor(1762.6909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18490 lossL: tensor(1802.9775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18491 lossL: tensor(1879.6791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18492 lossL: tensor(1780.6321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18493 lossL: tensor(1820.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18494 lossL: tensor(1698.0490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18495 lossL: tensor(1827.2156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18496 lossL: tensor(1705.1301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18497 lossL: tensor(1765.4728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18498 lossL: tensor(1635.0996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18499 lossL: tensor(1804.7811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18500 lossL: tensor(1906.5496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18501 lossL: tensor(1719.4834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18502 lossL: tensor(1630.9388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18503 lossL: tensor(1815.0706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18504 lossL: tensor(2017.9243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18505 lossL: tensor(1856.1023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18506 lossL: tensor(1720.4196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18507 lossL: tensor(2203.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18508 lossL: tensor(1839.4020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18509 lossL: tensor(1940.8928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18510 lossL: tensor(1924.2056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18511 lossL: tensor(1667.0131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18512 lossL: tensor(1872.2455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18513 lossL: tensor(1735.3124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18514 lossL: tensor(1615.6111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18515 lossL: tensor(1882.8179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18516 lossL: tensor(1724.7145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18517 lossL: tensor(1691.9521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18518 lossL: tensor(1625.5249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18519 lossL: tensor(1743.9285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18520 lossL: tensor(1878.0997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18521 lossL: tensor(1988.9591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18522 lossL: tensor(1699.3383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18523 lossL: tensor(2030.2269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18524 lossL: tensor(1515.3301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18525 lossL: tensor(1764.4495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18526 lossL: tensor(1674.4230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18527 lossL: tensor(1974.5559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18528 lossL: tensor(1800.4521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18529 lossL: tensor(1821.7086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18530 lossL: tensor(1779.1982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18531 lossL: tensor(1721.0038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18532 lossL: tensor(1856.3894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18533 lossL: tensor(1919.2819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18534 lossL: tensor(1685.4684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18535 lossL: tensor(1792.6837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18536 lossL: tensor(1604.3754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18537 lossL: tensor(1671.7866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18538 lossL: tensor(1696.3221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18539 lossL: tensor(1745.2225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18540 lossL: tensor(1559.5917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18541 lossL: tensor(1791.4595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18542 lossL: tensor(1753.3390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18543 lossL: tensor(1698.2255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18544 lossL: tensor(1885.1281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18545 lossL: tensor(1661.6444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18546 lossL: tensor(1735.6000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18547 lossL: tensor(1576.7203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18548 lossL: tensor(1645.9421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18549 lossL: tensor(1650.9489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18550 lossL: tensor(1866.0941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18551 lossL: tensor(1961.8173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18552 lossL: tensor(1931.5389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18553 lossL: tensor(1573.0786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18554 lossL: tensor(1802.6149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18555 lossL: tensor(1657.9626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18556 lossL: tensor(1784.8807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18557 lossL: tensor(1580.1354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18558 lossL: tensor(1802.5009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18559 lossL: tensor(1835.5472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18560 lossL: tensor(1875.9095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18561 lossL: tensor(1640.7064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18562 lossL: tensor(1711.4775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18563 lossL: tensor(1629.2030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18564 lossL: tensor(1825.5360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18565 lossL: tensor(1552.2183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18566 lossL: tensor(1724.7908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18567 lossL: tensor(1795.2057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18568 lossL: tensor(1852.3191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18569 lossL: tensor(1830.6702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18570 lossL: tensor(1739.0087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18571 lossL: tensor(1643.1984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18572 lossL: tensor(1669.6790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18573 lossL: tensor(1601.2772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18574 lossL: tensor(1632.7670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18575 lossL: tensor(1692.2809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18576 lossL: tensor(1861.4259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18577 lossL: tensor(1591.4170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18578 lossL: tensor(1968.2166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18579 lossL: tensor(1697.5796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18580 lossL: tensor(1846.8872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18581 lossL: tensor(1649.1321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18582 lossL: tensor(1518.7609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18583 lossL: tensor(1678.7275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18584 lossL: tensor(1762.2295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18585 lossL: tensor(1537.5428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18586 lossL: tensor(1662.3949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18587 lossL: tensor(1702.7064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18588 lossL: tensor(1669.0232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18589 lossL: tensor(1601.5463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18590 lossL: tensor(1771.7418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18591 lossL: tensor(1558.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18592 lossL: tensor(1877.3612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18593 lossL: tensor(1882.2859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18594 lossL: tensor(1862.1566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18595 lossL: tensor(1681.9471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18596 lossL: tensor(1747.3788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18597 lossL: tensor(1776.6942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18598 lossL: tensor(1615.0758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18599 lossL: tensor(1753.5574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18600 lossL: tensor(1662.6793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18601 lossL: tensor(1490.8525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18602 lossL: tensor(1666.1454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18603 lossL: tensor(1476.9879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "18604 lossL: tensor(1499.4412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18605 lossL: tensor(1688.6788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18606 lossL: tensor(1659.4045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18607 lossL: tensor(1825.0942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18608 lossL: tensor(1598.6543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18609 lossL: tensor(1782.1176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18610 lossL: tensor(1943.0276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18611 lossL: tensor(1741.1044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18612 lossL: tensor(1606.6687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18613 lossL: tensor(1667.2513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18614 lossL: tensor(1756.7760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18615 lossL: tensor(1661.8273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18616 lossL: tensor(1818.8151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18617 lossL: tensor(1822.5427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18618 lossL: tensor(1817.8621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18619 lossL: tensor(1623.4255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18620 lossL: tensor(1905.2711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18621 lossL: tensor(1653.3358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18622 lossL: tensor(1634.6918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18623 lossL: tensor(1569.1061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18624 lossL: tensor(1760.5510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18625 lossL: tensor(1703.0485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18626 lossL: tensor(1765.2601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18627 lossL: tensor(1526.6345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18628 lossL: tensor(1759.1436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18629 lossL: tensor(1692.1614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18630 lossL: tensor(1667.8346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18631 lossL: tensor(1699.8103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18632 lossL: tensor(1611.1765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18633 lossL: tensor(1687.8419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18634 lossL: tensor(1650.5436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18635 lossL: tensor(1745.3976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18636 lossL: tensor(1948.6893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18637 lossL: tensor(1786.4841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18638 lossL: tensor(1574.1930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18639 lossL: tensor(1611.8116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18640 lossL: tensor(1798.9323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18641 lossL: tensor(1751.4067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18642 lossL: tensor(1920.2250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18643 lossL: tensor(1633.7959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18644 lossL: tensor(1609.9207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18645 lossL: tensor(1658.9281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18646 lossL: tensor(1535.9391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18647 lossL: tensor(1594.5151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18648 lossL: tensor(1624.5403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18649 lossL: tensor(1668.9880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18650 lossL: tensor(1631.8932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18651 lossL: tensor(1796.6018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18652 lossL: tensor(1695.8234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18653 lossL: tensor(1944.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18654 lossL: tensor(1720.4836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18655 lossL: tensor(1641.0278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18656 lossL: tensor(1758.8749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18657 lossL: tensor(1915.4763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18658 lossL: tensor(1527.6780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18659 lossL: tensor(1638.8923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18660 lossL: tensor(1768.9637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18661 lossL: tensor(1643.4276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18662 lossL: tensor(1683.7223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18663 lossL: tensor(1728.2538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18664 lossL: tensor(1656.9655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18665 lossL: tensor(1679.4105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18666 lossL: tensor(1886.1807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18667 lossL: tensor(1635.2739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18668 lossL: tensor(1645.6937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18669 lossL: tensor(1964.7382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18670 lossL: tensor(1741.7567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18671 lossL: tensor(1721.6569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18672 lossL: tensor(1712.6337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18673 lossL: tensor(1638.8539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18674 lossL: tensor(1817.5287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18675 lossL: tensor(1869.3284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18676 lossL: tensor(1622.0679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18677 lossL: tensor(1604.4866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18678 lossL: tensor(1589.3271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18679 lossL: tensor(1631.4104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18680 lossL: tensor(1640.9448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18681 lossL: tensor(1691.4886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18682 lossL: tensor(1713.6642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18683 lossL: tensor(1711.5497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18684 lossL: tensor(1539.8805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18685 lossL: tensor(1602.4958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18686 lossL: tensor(1571.4532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18687 lossL: tensor(1488.4325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18688 lossL: tensor(1548.2949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18689 lossL: tensor(1630.6130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18690 lossL: tensor(1735.6711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18691 lossL: tensor(1819.9117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18692 lossL: tensor(1720.9813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18693 lossL: tensor(1646.5271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18694 lossL: tensor(1598.4955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18695 lossL: tensor(1742.9948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18696 lossL: tensor(1859.5254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18697 lossL: tensor(1728.0115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18698 lossL: tensor(1644.0044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18699 lossL: tensor(1543.1117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18700 lossL: tensor(1862.7568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18701 lossL: tensor(1763.3262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18702 lossL: tensor(1699.6971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18703 lossL: tensor(1552.6841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18704 lossL: tensor(1610.0649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18705 lossL: tensor(1542.1440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18706 lossL: tensor(1503.9683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18707 lossL: tensor(1587.3754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18708 lossL: tensor(1889.8840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18709 lossL: tensor(1752.3663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18710 lossL: tensor(1510.7034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18711 lossL: tensor(1782.3640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18712 lossL: tensor(1682.6763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18713 lossL: tensor(1708.0808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18714 lossL: tensor(1947.2698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18715 lossL: tensor(1683.7162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18716 lossL: tensor(1728.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18717 lossL: tensor(1619.2815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18718 lossL: tensor(1692.6622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18719 lossL: tensor(1711.6519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18720 lossL: tensor(1616.8806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18721 lossL: tensor(1532.4502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18722 lossL: tensor(1644.6353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18723 lossL: tensor(1638.3024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18724 lossL: tensor(1635.1906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18725 lossL: tensor(1638.5688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18726 lossL: tensor(1507.5151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18727 lossL: tensor(1408.8859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "18728 lossL: tensor(1580.5712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18729 lossL: tensor(1619.1929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18730 lossL: tensor(1539.6670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18731 lossL: tensor(1641.0499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18732 lossL: tensor(1733.0217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18733 lossL: tensor(1701.8871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18734 lossL: tensor(1725.8381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18735 lossL: tensor(1580.0300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18736 lossL: tensor(1589.2024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18737 lossL: tensor(1561.1427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18738 lossL: tensor(1780.0031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18739 lossL: tensor(1677.2079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18740 lossL: tensor(1761.7034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18741 lossL: tensor(1572.9573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18742 lossL: tensor(1622.0242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18743 lossL: tensor(1619.8813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18744 lossL: tensor(1659.8718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18745 lossL: tensor(1501.2159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18746 lossL: tensor(1501.2512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18747 lossL: tensor(1819.4037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18748 lossL: tensor(1618.8804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18749 lossL: tensor(1568.6694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18750 lossL: tensor(1693.0911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18751 lossL: tensor(1695.0876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18752 lossL: tensor(1834.8256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18753 lossL: tensor(1647.0083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18754 lossL: tensor(1855.3820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18755 lossL: tensor(1628.0287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18756 lossL: tensor(1575.6515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18757 lossL: tensor(1646.4767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18758 lossL: tensor(1620.6677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18759 lossL: tensor(1547.9983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18760 lossL: tensor(1818.8020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18761 lossL: tensor(1614.6199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18762 lossL: tensor(1583.2640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18763 lossL: tensor(1630.3868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18764 lossL: tensor(1622.5812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18765 lossL: tensor(1628.4049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18766 lossL: tensor(1841.4335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18767 lossL: tensor(1695.7972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18768 lossL: tensor(1662.3250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18769 lossL: tensor(1848.4225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18770 lossL: tensor(1562.5233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18771 lossL: tensor(1827.1562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18772 lossL: tensor(1647.4418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18773 lossL: tensor(1713.2679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18774 lossL: tensor(1490.1339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18775 lossL: tensor(1821.2202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18776 lossL: tensor(1576.7306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18777 lossL: tensor(1603.0161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18778 lossL: tensor(1712.0161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18779 lossL: tensor(1916.6749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18780 lossL: tensor(1590.9332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18781 lossL: tensor(1634.6526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18782 lossL: tensor(1565.0242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18783 lossL: tensor(1634.1321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18784 lossL: tensor(1676.6001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18785 lossL: tensor(1693.8210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18786 lossL: tensor(1661.1431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18787 lossL: tensor(1831.5392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18788 lossL: tensor(1591.5072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18789 lossL: tensor(1691.2759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18790 lossL: tensor(1754.9905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18791 lossL: tensor(1593.0114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18792 lossL: tensor(1815.4260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18793 lossL: tensor(1496.0281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18794 lossL: tensor(1824.2502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18795 lossL: tensor(1638.9368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18796 lossL: tensor(1687.0573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18797 lossL: tensor(1516.8267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18798 lossL: tensor(1522.5695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18799 lossL: tensor(1584.3286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18800 lossL: tensor(1734.3564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18801 lossL: tensor(1584.7932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18802 lossL: tensor(1536.1943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18803 lossL: tensor(1494.1472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18804 lossL: tensor(1655.1042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18805 lossL: tensor(1758.7267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18806 lossL: tensor(1683.0342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18807 lossL: tensor(1611.9167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18808 lossL: tensor(1674.1243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18809 lossL: tensor(1659.0125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18810 lossL: tensor(1578.6686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18811 lossL: tensor(1521.8031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18812 lossL: tensor(1753.5557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18813 lossL: tensor(1849.1638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18814 lossL: tensor(1709.9796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18815 lossL: tensor(1494.4004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18816 lossL: tensor(1778.1349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18817 lossL: tensor(1885.9037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18818 lossL: tensor(1720.0367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18819 lossL: tensor(1557.9714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18820 lossL: tensor(1748.9006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18821 lossL: tensor(1664.6250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18822 lossL: tensor(1631.8936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18823 lossL: tensor(1994.3273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18824 lossL: tensor(1728.3975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18825 lossL: tensor(2041.9213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18826 lossL: tensor(1749.2181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18827 lossL: tensor(1808.4716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18828 lossL: tensor(1543.7126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18829 lossL: tensor(1747.2382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18830 lossL: tensor(1611.8701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18831 lossL: tensor(1695.8647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18832 lossL: tensor(1558.1517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18833 lossL: tensor(1599.7802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18834 lossL: tensor(1496.9736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18835 lossL: tensor(1726.0774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18836 lossL: tensor(1670.7994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18837 lossL: tensor(1769.9396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18838 lossL: tensor(1600.2366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18839 lossL: tensor(1573.7322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18840 lossL: tensor(1624.7589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18841 lossL: tensor(1764.1893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18842 lossL: tensor(1562.3380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18843 lossL: tensor(1885.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18844 lossL: tensor(1675.9413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18845 lossL: tensor(1758.0867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18846 lossL: tensor(1642.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18847 lossL: tensor(1720.5878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18848 lossL: tensor(1755.5182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18849 lossL: tensor(1692.9977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18850 lossL: tensor(1655.2617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18851 lossL: tensor(1863.1598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18852 lossL: tensor(1742.2417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18853 lossL: tensor(1500.1774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18854 lossL: tensor(1646.7025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18855 lossL: tensor(1636.3250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18856 lossL: tensor(1656.8833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18857 lossL: tensor(1727.3500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18858 lossL: tensor(1749.9095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18859 lossL: tensor(1596.9580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18860 lossL: tensor(1535.7096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18861 lossL: tensor(1729.8036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18862 lossL: tensor(1454.8239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18863 lossL: tensor(1600.8721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18864 lossL: tensor(1694.1578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18865 lossL: tensor(1472.5577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18866 lossL: tensor(1532.0671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18867 lossL: tensor(1538.7711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18868 lossL: tensor(1706.4752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18869 lossL: tensor(1799.6736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18870 lossL: tensor(1808.6141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18871 lossL: tensor(1807.2644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18872 lossL: tensor(1555.4622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18873 lossL: tensor(1560.3604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18874 lossL: tensor(1630.8933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18875 lossL: tensor(1533.7904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18876 lossL: tensor(1831.8257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18877 lossL: tensor(1616.2218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18878 lossL: tensor(1719.5660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18879 lossL: tensor(1591.7770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18880 lossL: tensor(1458.2441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18881 lossL: tensor(1692.3314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18882 lossL: tensor(1584.5052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18883 lossL: tensor(1594.8882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18884 lossL: tensor(1832.7413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18885 lossL: tensor(1403.7795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "18886 lossL: tensor(1444.0765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18887 lossL: tensor(1741.1929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18888 lossL: tensor(1874.1239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18889 lossL: tensor(1551.1149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18890 lossL: tensor(1662.9116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18891 lossL: tensor(1620.7170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18892 lossL: tensor(1666.0490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18893 lossL: tensor(1502.7183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18894 lossL: tensor(1496.2264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18895 lossL: tensor(1631.2786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18896 lossL: tensor(1618.0253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18897 lossL: tensor(1744.6047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18898 lossL: tensor(1809.8413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18899 lossL: tensor(1698.9592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18900 lossL: tensor(1753.0278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18901 lossL: tensor(1585.5962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18902 lossL: tensor(1671.2286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18903 lossL: tensor(1540.5343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18904 lossL: tensor(1773.1205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18905 lossL: tensor(2047.5491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18906 lossL: tensor(1519.7205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18907 lossL: tensor(1729.3978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18908 lossL: tensor(1636.8939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18909 lossL: tensor(1601.4319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18910 lossL: tensor(1695.2750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18911 lossL: tensor(1739.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18912 lossL: tensor(1911.1842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18913 lossL: tensor(1576.2646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18914 lossL: tensor(1799.3984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18915 lossL: tensor(1743.7643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18916 lossL: tensor(2034.6626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18917 lossL: tensor(1444.1187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18918 lossL: tensor(2356.0759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18919 lossL: tensor(1650.7261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18920 lossL: tensor(2074.1394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18921 lossL: tensor(1792.5822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18922 lossL: tensor(1820.2509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18923 lossL: tensor(1567.9032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18924 lossL: tensor(1610.0850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18925 lossL: tensor(1801.6921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18926 lossL: tensor(1841.8464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18927 lossL: tensor(1717.6088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18928 lossL: tensor(1448.1099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18929 lossL: tensor(1691.3556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18930 lossL: tensor(1588.2659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18931 lossL: tensor(1743.2666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18932 lossL: tensor(1556.7722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18933 lossL: tensor(1770.3387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18934 lossL: tensor(1843.5775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18935 lossL: tensor(1751.1011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18936 lossL: tensor(1439.7438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18937 lossL: tensor(1910.4302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18938 lossL: tensor(1682.6841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18939 lossL: tensor(1633.6377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18940 lossL: tensor(1440.2955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18941 lossL: tensor(1423.5114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18942 lossL: tensor(1642.7529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18943 lossL: tensor(1552.1709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18944 lossL: tensor(1708.4633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18945 lossL: tensor(1740.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18946 lossL: tensor(1527.3226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18947 lossL: tensor(1647.3127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18948 lossL: tensor(1517.9015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18949 lossL: tensor(1740.4119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18950 lossL: tensor(1611.3058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18951 lossL: tensor(1727.3940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18952 lossL: tensor(1494.5472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18953 lossL: tensor(1692.8838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18954 lossL: tensor(1606.9622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18955 lossL: tensor(1803.6550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18956 lossL: tensor(1737.1095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18957 lossL: tensor(1413.2229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18958 lossL: tensor(1469.0487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18959 lossL: tensor(1561., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18960 lossL: tensor(1439.5803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18961 lossL: tensor(1772.9526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18962 lossL: tensor(1629.5939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18963 lossL: tensor(1615.5803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18964 lossL: tensor(1430.3123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18965 lossL: tensor(1722.8618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18966 lossL: tensor(1473.4249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18967 lossL: tensor(1597.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18968 lossL: tensor(1628.1219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18969 lossL: tensor(1561.5227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18970 lossL: tensor(1712.3849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18971 lossL: tensor(1531.2623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18972 lossL: tensor(1533.9073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18973 lossL: tensor(1570.4083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18974 lossL: tensor(1502.1360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18975 lossL: tensor(1720.7284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18976 lossL: tensor(1563.0946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18977 lossL: tensor(1562.0239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18978 lossL: tensor(1527.5504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18979 lossL: tensor(1632.9174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18980 lossL: tensor(1461.1776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18981 lossL: tensor(1738.4515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18982 lossL: tensor(1719.2280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18983 lossL: tensor(1751.9027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18984 lossL: tensor(1594.5918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18985 lossL: tensor(1723.4395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18986 lossL: tensor(1609.2277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18987 lossL: tensor(1666.1658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18988 lossL: tensor(1524.6316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18989 lossL: tensor(1614.5244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18990 lossL: tensor(1574.9332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18991 lossL: tensor(1608.8346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18992 lossL: tensor(1414.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18993 lossL: tensor(1658.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18994 lossL: tensor(1390.5406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "18995 lossL: tensor(1594.7654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18996 lossL: tensor(1780.5546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18997 lossL: tensor(1639.4133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18998 lossL: tensor(1685.7686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "18999 lossL: tensor(1491.4888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19000 lossL: tensor(1523.4385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19001 lossL: tensor(1480.9558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19002 lossL: tensor(1697.3135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19003 lossL: tensor(1540.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19004 lossL: tensor(1739.1432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19005 lossL: tensor(1560.8453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19006 lossL: tensor(1719.8716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19007 lossL: tensor(1498.9666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19008 lossL: tensor(1474.6796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19009 lossL: tensor(1441.5049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19010 lossL: tensor(1636.9827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19011 lossL: tensor(1571.5531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19012 lossL: tensor(1522.8148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19013 lossL: tensor(1494.7802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19014 lossL: tensor(1718.2200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19015 lossL: tensor(1755.8657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19016 lossL: tensor(1673.9594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19017 lossL: tensor(1606.5841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19018 lossL: tensor(1335.8497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "19019 lossL: tensor(1879.2822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19020 lossL: tensor(1593.9879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19021 lossL: tensor(1591.2698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19022 lossL: tensor(1758.3998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19023 lossL: tensor(1500.9218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19024 lossL: tensor(1638.4700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19025 lossL: tensor(1416.8489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19026 lossL: tensor(1555.8567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19027 lossL: tensor(1593.8894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19028 lossL: tensor(1486.6604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19029 lossL: tensor(1736.9933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19030 lossL: tensor(1454.7517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19031 lossL: tensor(1599.9911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19032 lossL: tensor(1504.9302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19033 lossL: tensor(1668.0366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19034 lossL: tensor(1441.6068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19035 lossL: tensor(1399.7542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19036 lossL: tensor(1685.6818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19037 lossL: tensor(1589.6943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19038 lossL: tensor(1845.6350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19039 lossL: tensor(1672.8057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19040 lossL: tensor(1539.6072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19041 lossL: tensor(1541.2041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19042 lossL: tensor(1581.1621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19043 lossL: tensor(1578.3533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19044 lossL: tensor(1781.2072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19045 lossL: tensor(1521.3282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19046 lossL: tensor(1663.1232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19047 lossL: tensor(1439.3553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19048 lossL: tensor(1656.9985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19049 lossL: tensor(1494.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19050 lossL: tensor(1499.9974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19051 lossL: tensor(1433.4164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19052 lossL: tensor(1745.6720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19053 lossL: tensor(1550.2039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19054 lossL: tensor(1666.1465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19055 lossL: tensor(1571.2365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19056 lossL: tensor(1576.9930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19057 lossL: tensor(1565.1038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19058 lossL: tensor(1460.5475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19059 lossL: tensor(1410.2367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19060 lossL: tensor(1464.8842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19061 lossL: tensor(1496.2323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19062 lossL: tensor(1548.3423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19063 lossL: tensor(1516.9095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19064 lossL: tensor(1607.5106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19065 lossL: tensor(1548.9363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19066 lossL: tensor(1472.0806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19067 lossL: tensor(1712.6145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19068 lossL: tensor(1416.4133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19069 lossL: tensor(1487.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19070 lossL: tensor(1394.7297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19071 lossL: tensor(1702.1616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19072 lossL: tensor(1482.2278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19073 lossL: tensor(1591.0861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19074 lossL: tensor(1474.7927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19075 lossL: tensor(1671.8303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19076 lossL: tensor(1503.4414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19077 lossL: tensor(1516.9363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19078 lossL: tensor(1536.0414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19079 lossL: tensor(1334.1699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "19080 lossL: tensor(1545.3658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19081 lossL: tensor(1519.4290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19082 lossL: tensor(1561.8602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19083 lossL: tensor(1550.8147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19084 lossL: tensor(1625.9371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19085 lossL: tensor(1812.8441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19086 lossL: tensor(1889.4821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19087 lossL: tensor(1549.0303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19088 lossL: tensor(1702.9099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19089 lossL: tensor(1570.1317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19090 lossL: tensor(1678.9045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19091 lossL: tensor(1664.9646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19092 lossL: tensor(1553.2871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19093 lossL: tensor(1493.0769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19094 lossL: tensor(1606.1361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19095 lossL: tensor(1499.1661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19096 lossL: tensor(1633.4204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19097 lossL: tensor(1356.6152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19098 lossL: tensor(1427.0889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19099 lossL: tensor(1876.7047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19100 lossL: tensor(1695.6486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19101 lossL: tensor(1585.8882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19102 lossL: tensor(1555.4797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19103 lossL: tensor(1564.5214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19104 lossL: tensor(1450.4543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19105 lossL: tensor(1453.0363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19106 lossL: tensor(1629.7966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19107 lossL: tensor(1598.1831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19108 lossL: tensor(1678.0491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19109 lossL: tensor(1545.6064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19110 lossL: tensor(1748.1899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19111 lossL: tensor(1650.3932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19112 lossL: tensor(1831.1046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19113 lossL: tensor(1509.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19114 lossL: tensor(1556.2496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19115 lossL: tensor(1700.3300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19116 lossL: tensor(1690.6083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19117 lossL: tensor(1635.8346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19118 lossL: tensor(1644.2655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19119 lossL: tensor(1535.0437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19120 lossL: tensor(1764.3622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19121 lossL: tensor(1566.7003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19122 lossL: tensor(1570.5739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19123 lossL: tensor(1491.4757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19124 lossL: tensor(1602.1697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19125 lossL: tensor(1590.0691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19126 lossL: tensor(1470.8408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19127 lossL: tensor(1471.0424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19128 lossL: tensor(1675.3687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19129 lossL: tensor(1563.5298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19130 lossL: tensor(1607.1364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19131 lossL: tensor(1547.6710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19132 lossL: tensor(1497.4219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19133 lossL: tensor(1872.0289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19134 lossL: tensor(1464.0770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19135 lossL: tensor(1589.5349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19136 lossL: tensor(1636.9813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19137 lossL: tensor(1516.4154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19138 lossL: tensor(1456.0529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19139 lossL: tensor(1541.9543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19140 lossL: tensor(1512.5193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19141 lossL: tensor(1602.7605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19142 lossL: tensor(1553.6891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19143 lossL: tensor(1614.3754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19144 lossL: tensor(1492.0466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19145 lossL: tensor(1493.2932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19146 lossL: tensor(1669.6766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19147 lossL: tensor(1622.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19148 lossL: tensor(1630.2544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19149 lossL: tensor(1522.0385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19150 lossL: tensor(1609.5803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19151 lossL: tensor(1522.7104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19152 lossL: tensor(1559.9626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19153 lossL: tensor(1439.9658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19154 lossL: tensor(1628.6893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19155 lossL: tensor(1588.7395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19156 lossL: tensor(1623.4287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19157 lossL: tensor(1505.3536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19158 lossL: tensor(1506.0101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19159 lossL: tensor(1608.5120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19160 lossL: tensor(1664.6458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19161 lossL: tensor(1402.8583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19162 lossL: tensor(1490.2175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19163 lossL: tensor(1624.9437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19164 lossL: tensor(1620.2273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19165 lossL: tensor(1446.7043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19166 lossL: tensor(1590.3748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19167 lossL: tensor(1590.4182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19168 lossL: tensor(1620.6711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19169 lossL: tensor(1621.5699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19170 lossL: tensor(1739.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19171 lossL: tensor(1570.7156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19172 lossL: tensor(1650.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19173 lossL: tensor(1549.1042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19174 lossL: tensor(1511.6810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19175 lossL: tensor(1504.7810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19176 lossL: tensor(1456.8058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19177 lossL: tensor(1515.1709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19178 lossL: tensor(1509.8296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19179 lossL: tensor(1563.1011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19180 lossL: tensor(1680.9530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19181 lossL: tensor(1492.4866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19182 lossL: tensor(1378.7435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19183 lossL: tensor(1587.4020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19184 lossL: tensor(1500.5922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19185 lossL: tensor(1670.8998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19186 lossL: tensor(1385.1176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19187 lossL: tensor(1495.9954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19188 lossL: tensor(1478.4592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19189 lossL: tensor(1496.5693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19190 lossL: tensor(1591.8191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19191 lossL: tensor(1464.5685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19192 lossL: tensor(1431.6733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19193 lossL: tensor(1559.8716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19194 lossL: tensor(1542.8472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19195 lossL: tensor(1549.4591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19196 lossL: tensor(1372.0404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19197 lossL: tensor(1406.3428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19198 lossL: tensor(1454.0969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19199 lossL: tensor(1388.2937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19200 lossL: tensor(1616.3458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19201 lossL: tensor(1565.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19202 lossL: tensor(1573.5023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19203 lossL: tensor(1495.1381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19204 lossL: tensor(1529.1415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19205 lossL: tensor(1819.5382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19206 lossL: tensor(1452.1467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19207 lossL: tensor(1573.4690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19208 lossL: tensor(1393.2913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19209 lossL: tensor(1500.1871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19210 lossL: tensor(1586.4142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19211 lossL: tensor(1719.8209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19212 lossL: tensor(1528.2267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19213 lossL: tensor(1460.2260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19214 lossL: tensor(1656.9742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19215 lossL: tensor(1489.7324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19216 lossL: tensor(1456.6230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19217 lossL: tensor(1337.9470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19218 lossL: tensor(1394.5278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19219 lossL: tensor(1422.6487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19220 lossL: tensor(1523.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19221 lossL: tensor(1580.9041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19222 lossL: tensor(1355.0513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19223 lossL: tensor(1645.1575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19224 lossL: tensor(1713.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19225 lossL: tensor(1429.1272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19226 lossL: tensor(1482.1794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19227 lossL: tensor(1456.1443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19228 lossL: tensor(1495.2523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19229 lossL: tensor(1714.1139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19230 lossL: tensor(1583.8304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19231 lossL: tensor(1399.1721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19232 lossL: tensor(1444.6532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19233 lossL: tensor(1713.1010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19234 lossL: tensor(1465.7981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19235 lossL: tensor(1796.9265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19236 lossL: tensor(1654.3424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19237 lossL: tensor(1398.8352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19238 lossL: tensor(1432.4369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19239 lossL: tensor(1367.1321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19240 lossL: tensor(1574.0182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19241 lossL: tensor(1562.0411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19242 lossL: tensor(1694.9155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19243 lossL: tensor(1525.5675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19244 lossL: tensor(1368.0475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19245 lossL: tensor(1541.1587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19246 lossL: tensor(1334.7064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19247 lossL: tensor(1466.8308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19248 lossL: tensor(1418.8951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19249 lossL: tensor(1596.8643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19250 lossL: tensor(1408.0524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19251 lossL: tensor(1656.5283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19252 lossL: tensor(1541.4907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19253 lossL: tensor(1745.9436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19254 lossL: tensor(1775.0593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19255 lossL: tensor(1489.9194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19256 lossL: tensor(1449.9821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19257 lossL: tensor(1704.0283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19258 lossL: tensor(1666.7469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19259 lossL: tensor(1520.3661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19260 lossL: tensor(1715.6008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19261 lossL: tensor(1505.8831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19262 lossL: tensor(1543.7682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19263 lossL: tensor(1429.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19264 lossL: tensor(1679.7939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19265 lossL: tensor(1426.1106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19266 lossL: tensor(1602.8975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19267 lossL: tensor(1269.6472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "19268 lossL: tensor(1545.2523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19269 lossL: tensor(1402.0192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19270 lossL: tensor(1467.6786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19271 lossL: tensor(1555.1726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19272 lossL: tensor(1543.4441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19273 lossL: tensor(1472.3374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19274 lossL: tensor(1501.7673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19275 lossL: tensor(1404.0791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19276 lossL: tensor(1497.0067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19277 lossL: tensor(1439.1697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19278 lossL: tensor(1497.9004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19279 lossL: tensor(1587.7292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19280 lossL: tensor(1465.4985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19281 lossL: tensor(1806.2429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19282 lossL: tensor(1593.6239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19283 lossL: tensor(1535.3208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19284 lossL: tensor(1519.8119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19285 lossL: tensor(1434.2760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19286 lossL: tensor(1555.1038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19287 lossL: tensor(1432.4750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19288 lossL: tensor(1498.8163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19289 lossL: tensor(1594.5129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19290 lossL: tensor(1555.0109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19291 lossL: tensor(1466.6763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19292 lossL: tensor(1510.0634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19293 lossL: tensor(1512.5393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19294 lossL: tensor(1666.6965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19295 lossL: tensor(1421.6396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19296 lossL: tensor(1868.8982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19297 lossL: tensor(1536.5387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19298 lossL: tensor(1517.8712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19299 lossL: tensor(1520.2397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19300 lossL: tensor(1354.3988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19301 lossL: tensor(1587.2043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19302 lossL: tensor(1535.0410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19303 lossL: tensor(1361.4738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19304 lossL: tensor(1661.6184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19305 lossL: tensor(1535.5653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19306 lossL: tensor(1547.5238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19307 lossL: tensor(1486.4307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19308 lossL: tensor(1474.4575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19309 lossL: tensor(1519.0195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19310 lossL: tensor(1543.0613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19311 lossL: tensor(1471.6505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19312 lossL: tensor(1482.7291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19313 lossL: tensor(1601.8834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19314 lossL: tensor(1495.0083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19315 lossL: tensor(1544.6233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19316 lossL: tensor(1518.4938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19317 lossL: tensor(1429.4124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19318 lossL: tensor(1572.8146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19319 lossL: tensor(1542.9225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19320 lossL: tensor(1385.7535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19321 lossL: tensor(1723.4412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19322 lossL: tensor(1480.8397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19323 lossL: tensor(1564.6823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19324 lossL: tensor(1535.6177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19325 lossL: tensor(1553.7390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19326 lossL: tensor(1430.5392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19327 lossL: tensor(1551.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19328 lossL: tensor(1367.8625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19329 lossL: tensor(1433.9341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19330 lossL: tensor(1380.9102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19331 lossL: tensor(1654.5728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19332 lossL: tensor(1424.4204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19333 lossL: tensor(1469.8391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19334 lossL: tensor(1521.6759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19335 lossL: tensor(1504.4121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19336 lossL: tensor(1596.3682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19337 lossL: tensor(1496.5723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19338 lossL: tensor(1323.3440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19339 lossL: tensor(1467.7916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19340 lossL: tensor(1553.3485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19341 lossL: tensor(1548.4248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19342 lossL: tensor(1430.6031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19343 lossL: tensor(1377.8551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19344 lossL: tensor(1425.1687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19345 lossL: tensor(1350.0277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19346 lossL: tensor(1488.0631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19347 lossL: tensor(1533.9637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19348 lossL: tensor(1577.6395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19349 lossL: tensor(1481.4198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19350 lossL: tensor(1546.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19351 lossL: tensor(1480.0339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19352 lossL: tensor(1559.6442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19353 lossL: tensor(1579.1998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19354 lossL: tensor(1535.8677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19355 lossL: tensor(1416.6945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19356 lossL: tensor(1522.6586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19357 lossL: tensor(1530.4380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19358 lossL: tensor(1510.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19359 lossL: tensor(1453.0858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19360 lossL: tensor(1496.5592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19361 lossL: tensor(1511.6136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19362 lossL: tensor(1461.0475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19363 lossL: tensor(1540.8911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19364 lossL: tensor(1591.1099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19365 lossL: tensor(1427.1029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19366 lossL: tensor(1440.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19367 lossL: tensor(1459.0773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19368 lossL: tensor(1569.0800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19369 lossL: tensor(1567.9680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19370 lossL: tensor(1457.8608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19371 lossL: tensor(1542.2664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19372 lossL: tensor(1514.3928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19373 lossL: tensor(1628.2522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19374 lossL: tensor(1644.2529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19375 lossL: tensor(1544.8004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19376 lossL: tensor(1607.1083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19377 lossL: tensor(1504.1714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19378 lossL: tensor(1554.5129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19379 lossL: tensor(1672.4673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19380 lossL: tensor(1596.6272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19381 lossL: tensor(1409.8917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19382 lossL: tensor(1589.9426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19383 lossL: tensor(1630.3743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19384 lossL: tensor(1626.3169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19385 lossL: tensor(1393.7456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19386 lossL: tensor(1423.5024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19387 lossL: tensor(1628.7500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19388 lossL: tensor(1449.2843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19389 lossL: tensor(1523.5372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19390 lossL: tensor(1472.8330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19391 lossL: tensor(1643.0675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19392 lossL: tensor(1484.0891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19393 lossL: tensor(1479.5283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19394 lossL: tensor(1483.2585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19395 lossL: tensor(1447.6178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19396 lossL: tensor(1566.1908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19397 lossL: tensor(1586.1991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19398 lossL: tensor(1462.2837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19399 lossL: tensor(1376.1752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19400 lossL: tensor(1441.5573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19401 lossL: tensor(1515.6589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19402 lossL: tensor(1418.9419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19403 lossL: tensor(1382.8564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19404 lossL: tensor(1378.0374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19405 lossL: tensor(1469.1294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19406 lossL: tensor(1532.2509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19407 lossL: tensor(1375.8467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19408 lossL: tensor(1405.1001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19409 lossL: tensor(1361.3000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19410 lossL: tensor(1418.6987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19411 lossL: tensor(1340.4337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19412 lossL: tensor(1439.1042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19413 lossL: tensor(1469.4984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19414 lossL: tensor(1315.5764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19415 lossL: tensor(1413.1102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19416 lossL: tensor(1456.2732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19417 lossL: tensor(1538.9015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19418 lossL: tensor(1438.8154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19419 lossL: tensor(1444.7926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19420 lossL: tensor(1351.6422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19421 lossL: tensor(1439.2457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19422 lossL: tensor(1365.4962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19423 lossL: tensor(1625.5475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19424 lossL: tensor(1540.1217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19425 lossL: tensor(1277.5671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19426 lossL: tensor(1368.9594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19427 lossL: tensor(1398.7811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19428 lossL: tensor(1493.9985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19429 lossL: tensor(1464.2949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19430 lossL: tensor(1588.4633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19431 lossL: tensor(1541.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19432 lossL: tensor(1361.1826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19433 lossL: tensor(1476.6199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19434 lossL: tensor(1381.2444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19435 lossL: tensor(1398.6500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19436 lossL: tensor(1470.6370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19437 lossL: tensor(1484.0297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19438 lossL: tensor(1453.5131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19439 lossL: tensor(1509.0978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19440 lossL: tensor(1361.8965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19441 lossL: tensor(1538.7327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19442 lossL: tensor(1459.0751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19443 lossL: tensor(1397.6957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19444 lossL: tensor(1415.0651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19445 lossL: tensor(1684.1731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19446 lossL: tensor(1538.9905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19447 lossL: tensor(1487.9087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19448 lossL: tensor(1673.6722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19449 lossL: tensor(1517.6177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19450 lossL: tensor(1314.2036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19451 lossL: tensor(1518.0214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19452 lossL: tensor(1467.0725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19453 lossL: tensor(1572.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19454 lossL: tensor(1694.7611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19455 lossL: tensor(1443.2714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19456 lossL: tensor(1501.7472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19457 lossL: tensor(1385.5027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19458 lossL: tensor(1275.3994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19459 lossL: tensor(1375.2733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19460 lossL: tensor(1459.0627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19461 lossL: tensor(1602.0795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19462 lossL: tensor(1354.4958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19463 lossL: tensor(1361.3092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19464 lossL: tensor(1354.6002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19465 lossL: tensor(1512.0118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19466 lossL: tensor(1602.3947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19467 lossL: tensor(1627.5157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19468 lossL: tensor(1675.9319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19469 lossL: tensor(1635.3607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19470 lossL: tensor(1562.1965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19471 lossL: tensor(1712.0297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19472 lossL: tensor(1346.3186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19473 lossL: tensor(1714.6637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19474 lossL: tensor(1445.3058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19475 lossL: tensor(1783.5857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19476 lossL: tensor(1536.2744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19477 lossL: tensor(1722.1017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19478 lossL: tensor(1463.0999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19479 lossL: tensor(1554.1116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19480 lossL: tensor(1408.6637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19481 lossL: tensor(1513.4030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19482 lossL: tensor(1528.6812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19483 lossL: tensor(1593.5564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19484 lossL: tensor(1648.2408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19485 lossL: tensor(1477.1702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19486 lossL: tensor(1601.0814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19487 lossL: tensor(1453.6421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19488 lossL: tensor(1517.8975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19489 lossL: tensor(1454.6882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19490 lossL: tensor(1679.8059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19491 lossL: tensor(1408.4669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19492 lossL: tensor(1405.7504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19493 lossL: tensor(1522.6779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19494 lossL: tensor(1567.5548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19495 lossL: tensor(1508.2146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19496 lossL: tensor(1413.0088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19497 lossL: tensor(1591.1803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19498 lossL: tensor(1498.1667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19499 lossL: tensor(1459.5222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19500 lossL: tensor(1545.2620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19501 lossL: tensor(1449.3823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19502 lossL: tensor(1521.9260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19503 lossL: tensor(1578.4421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19504 lossL: tensor(1346.6642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19505 lossL: tensor(1458.6573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19506 lossL: tensor(1349.9073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19507 lossL: tensor(1410.2017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19508 lossL: tensor(1496.7571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19509 lossL: tensor(1243.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "19510 lossL: tensor(1254.8920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19511 lossL: tensor(1525.3459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19512 lossL: tensor(1407.9650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19513 lossL: tensor(1576.4083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19514 lossL: tensor(1457.2944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19515 lossL: tensor(1480.6504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19516 lossL: tensor(1521.3206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19517 lossL: tensor(1633.9352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19518 lossL: tensor(1407.9073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19519 lossL: tensor(1435.3384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19520 lossL: tensor(1434.9584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19521 lossL: tensor(1257.5488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19522 lossL: tensor(1560.3271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19523 lossL: tensor(1438.8673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19524 lossL: tensor(1369.1388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19525 lossL: tensor(1357.2751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19526 lossL: tensor(1444.9965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19527 lossL: tensor(1515.2036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19528 lossL: tensor(1522.0435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19529 lossL: tensor(1361.1614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19530 lossL: tensor(1432.8625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19531 lossL: tensor(1427.4690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19532 lossL: tensor(1389.5797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19533 lossL: tensor(1444.3553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19534 lossL: tensor(1430.6593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19535 lossL: tensor(1576.9675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19536 lossL: tensor(1382.1965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19537 lossL: tensor(1605.4449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19538 lossL: tensor(1368.6898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19539 lossL: tensor(1446.3854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19540 lossL: tensor(1235.0981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "19541 lossL: tensor(1462.7844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19542 lossL: tensor(1431.3247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19543 lossL: tensor(1501.3445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19544 lossL: tensor(1372.8854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19545 lossL: tensor(1427.5397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19546 lossL: tensor(1532.3866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19547 lossL: tensor(1569.9186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19548 lossL: tensor(1399.4034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19549 lossL: tensor(1452.6918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19550 lossL: tensor(1310.9059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19551 lossL: tensor(1487.5691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19552 lossL: tensor(1418.2457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19553 lossL: tensor(1454.9840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19554 lossL: tensor(1430.3379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19555 lossL: tensor(1348.6779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19556 lossL: tensor(1471.1331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19557 lossL: tensor(1510.0570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19558 lossL: tensor(1361.9535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19559 lossL: tensor(1418.1761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19560 lossL: tensor(1376.7017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19561 lossL: tensor(1256.2670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19562 lossL: tensor(1490.2491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19563 lossL: tensor(1585.3363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19564 lossL: tensor(1399.3599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19565 lossL: tensor(1467.5935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19566 lossL: tensor(1253.3812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19567 lossL: tensor(1431.4128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19568 lossL: tensor(1316.1329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19569 lossL: tensor(1421.9539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19570 lossL: tensor(1351.1464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19571 lossL: tensor(1403.2069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19572 lossL: tensor(1483.0848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19573 lossL: tensor(1462.3787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19574 lossL: tensor(1433.1737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19575 lossL: tensor(1532.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19576 lossL: tensor(1361.3451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19577 lossL: tensor(1419.8220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19578 lossL: tensor(1415.8285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19579 lossL: tensor(1552.7136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19580 lossL: tensor(1314.3864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19581 lossL: tensor(1299.0917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19582 lossL: tensor(1373.1351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19583 lossL: tensor(1543.6262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19584 lossL: tensor(1622.4408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19585 lossL: tensor(1485.9700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19586 lossL: tensor(1423.1417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19587 lossL: tensor(1370.9238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19588 lossL: tensor(1521.7297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19589 lossL: tensor(1391.2704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19590 lossL: tensor(1362.7056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19591 lossL: tensor(1387.6178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19592 lossL: tensor(1363.0895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19593 lossL: tensor(1419.4130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19594 lossL: tensor(1349.0226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19595 lossL: tensor(1425.0737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19596 lossL: tensor(1399.1200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19597 lossL: tensor(1458.2855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19598 lossL: tensor(1251.1458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19599 lossL: tensor(1433.8407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19600 lossL: tensor(1232.1428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "19601 lossL: tensor(1251.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19602 lossL: tensor(1523.2118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19603 lossL: tensor(1556.3207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19604 lossL: tensor(1333.6089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19605 lossL: tensor(1641.7119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19606 lossL: tensor(1366.4818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19607 lossL: tensor(1371.7263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19608 lossL: tensor(1691.4977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19609 lossL: tensor(1384.0483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19610 lossL: tensor(1544.7015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19611 lossL: tensor(1362.9818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19612 lossL: tensor(1672.8411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19613 lossL: tensor(1463.0380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19614 lossL: tensor(1627.1686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19615 lossL: tensor(1338.7767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19616 lossL: tensor(1714.2430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19617 lossL: tensor(1391.5996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19618 lossL: tensor(1582.2555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19619 lossL: tensor(1248.5315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19620 lossL: tensor(1471.8943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19621 lossL: tensor(1449.6793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19622 lossL: tensor(1343.1124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19623 lossL: tensor(1540.1948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19624 lossL: tensor(1432.4775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19625 lossL: tensor(1510.8787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19626 lossL: tensor(1449.9836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19627 lossL: tensor(1247.9713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19628 lossL: tensor(1430.8976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19629 lossL: tensor(1414.4987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19630 lossL: tensor(1569.6672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19631 lossL: tensor(1667.3280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19632 lossL: tensor(1423.4167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19633 lossL: tensor(1461.8044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19634 lossL: tensor(1373.4980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19635 lossL: tensor(1489.0575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19636 lossL: tensor(1263.1038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19637 lossL: tensor(1362.2534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19638 lossL: tensor(1445.2067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19639 lossL: tensor(1365.4619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19640 lossL: tensor(1498.1075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19641 lossL: tensor(1481.0133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19642 lossL: tensor(1487.8992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19643 lossL: tensor(1431.3615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19644 lossL: tensor(1393.1639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19645 lossL: tensor(1362.7704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19646 lossL: tensor(1373.0641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19647 lossL: tensor(1385.4446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19648 lossL: tensor(1431.0447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19649 lossL: tensor(1476.8936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19650 lossL: tensor(1370.8198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19651 lossL: tensor(1306.5453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19652 lossL: tensor(1490.9403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19653 lossL: tensor(1365.7604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19654 lossL: tensor(1280.9238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19655 lossL: tensor(1389.3544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19656 lossL: tensor(1481.4304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19657 lossL: tensor(1402.5565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19658 lossL: tensor(1266.3328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19659 lossL: tensor(1325.5133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19660 lossL: tensor(1449.7382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19661 lossL: tensor(1317.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19662 lossL: tensor(1362.7224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19663 lossL: tensor(1337.1799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19664 lossL: tensor(1460.3673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19665 lossL: tensor(1384.7699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19666 lossL: tensor(1293.0332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19667 lossL: tensor(1534.7959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19668 lossL: tensor(1355.2935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19669 lossL: tensor(1411.2736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19670 lossL: tensor(1385.2286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19671 lossL: tensor(1348.5208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19672 lossL: tensor(1474.1755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19673 lossL: tensor(1424.1503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19674 lossL: tensor(1207.7058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "19675 lossL: tensor(1383.5922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19676 lossL: tensor(1408.8389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19677 lossL: tensor(1448.2679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19678 lossL: tensor(1605.9747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19679 lossL: tensor(1554.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19680 lossL: tensor(1610.1409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19681 lossL: tensor(1439.6626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19682 lossL: tensor(1660.2767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19683 lossL: tensor(1420.5936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19684 lossL: tensor(1703.8904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19685 lossL: tensor(1624.0389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19686 lossL: tensor(1458.6079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19687 lossL: tensor(1400.5675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19688 lossL: tensor(1304.6730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19689 lossL: tensor(1364.1890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19690 lossL: tensor(1404.4419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19691 lossL: tensor(1423.4271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19692 lossL: tensor(1242.2861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19693 lossL: tensor(1539.7228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19694 lossL: tensor(1462.2734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19695 lossL: tensor(1586.5271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19696 lossL: tensor(1365.1304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19697 lossL: tensor(1568.7937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19698 lossL: tensor(1435.7395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19699 lossL: tensor(1499.4713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19700 lossL: tensor(1466.0593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19701 lossL: tensor(1374.6169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19702 lossL: tensor(1342.9482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19703 lossL: tensor(1532.6185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19704 lossL: tensor(1664.8931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19705 lossL: tensor(1341.4490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19706 lossL: tensor(1489.5839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19707 lossL: tensor(1480.9087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19708 lossL: tensor(1493.0907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19709 lossL: tensor(1363.5697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19710 lossL: tensor(1532.4508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19711 lossL: tensor(1546.7745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19712 lossL: tensor(1383.1091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19713 lossL: tensor(1279.4567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19714 lossL: tensor(1307.1531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19715 lossL: tensor(1363.9528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19716 lossL: tensor(1380.0071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19717 lossL: tensor(1427.7885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19718 lossL: tensor(1486.4681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19719 lossL: tensor(1544.5782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19720 lossL: tensor(1561.8313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19721 lossL: tensor(1734.8492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19722 lossL: tensor(1418.4446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19723 lossL: tensor(1833.9183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19724 lossL: tensor(1662.0879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19725 lossL: tensor(1517.3412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19726 lossL: tensor(1743.8864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19727 lossL: tensor(1480.6862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19728 lossL: tensor(1893.5530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19729 lossL: tensor(1443.6722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19730 lossL: tensor(1546.4426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19731 lossL: tensor(1390.5654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19732 lossL: tensor(1614.3506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19733 lossL: tensor(1368.3418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19734 lossL: tensor(1768.1285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19735 lossL: tensor(1294.7761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19736 lossL: tensor(1491.1544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19737 lossL: tensor(1656.2114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19738 lossL: tensor(1389.9504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19739 lossL: tensor(1320.9390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19740 lossL: tensor(1352.1624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19741 lossL: tensor(1392.2295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19742 lossL: tensor(1396.2190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19743 lossL: tensor(1419.1631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19744 lossL: tensor(1346.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19745 lossL: tensor(1442.2545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19746 lossL: tensor(1426.6957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19747 lossL: tensor(1463.4503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19748 lossL: tensor(1854.9172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19749 lossL: tensor(1355.7163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19750 lossL: tensor(1667.0293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19751 lossL: tensor(1452.3279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19752 lossL: tensor(1625.1260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19753 lossL: tensor(1564.2402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19754 lossL: tensor(1439.9639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19755 lossL: tensor(1375.0787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19756 lossL: tensor(1271.6206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19757 lossL: tensor(1538.3053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19758 lossL: tensor(1371.2261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19759 lossL: tensor(1455.0673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19760 lossL: tensor(1535.9258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19761 lossL: tensor(1421.4224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19762 lossL: tensor(1330.7412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19763 lossL: tensor(1490.1794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19764 lossL: tensor(1423.1871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19765 lossL: tensor(1281.2427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19766 lossL: tensor(1324.8892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19767 lossL: tensor(1526.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19768 lossL: tensor(1490.8455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19769 lossL: tensor(1498.9280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19770 lossL: tensor(1582.7758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19771 lossL: tensor(1433.6327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19772 lossL: tensor(1453.8912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19773 lossL: tensor(1334.9709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19774 lossL: tensor(1440.2596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19775 lossL: tensor(1437.4913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19776 lossL: tensor(1314.2585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19777 lossL: tensor(1351.8154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19778 lossL: tensor(1467.7766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19779 lossL: tensor(1348.6201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19780 lossL: tensor(1314.4976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19781 lossL: tensor(1325.3569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19782 lossL: tensor(1403.7192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19783 lossL: tensor(1310.6318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19784 lossL: tensor(1379.6837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19785 lossL: tensor(1438.0881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19786 lossL: tensor(1371.3262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19787 lossL: tensor(1518.3899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19788 lossL: tensor(1375.6572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19789 lossL: tensor(1487.2609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19790 lossL: tensor(1408.8552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19791 lossL: tensor(1393.3586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19792 lossL: tensor(1396.9653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19793 lossL: tensor(1287.6783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19794 lossL: tensor(1410.0820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19795 lossL: tensor(1598.1282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19796 lossL: tensor(1328.2462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19797 lossL: tensor(1538.7393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19798 lossL: tensor(1371.6376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19799 lossL: tensor(1394.2258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19800 lossL: tensor(1448.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19801 lossL: tensor(1379.7837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19802 lossL: tensor(1313.0775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19803 lossL: tensor(1334.7184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19804 lossL: tensor(1378.5691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19805 lossL: tensor(1341.6115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19806 lossL: tensor(1529.6403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19807 lossL: tensor(1515.6616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19808 lossL: tensor(1236.3696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19809 lossL: tensor(1396.5063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19810 lossL: tensor(1483.1318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19811 lossL: tensor(1507.6117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19812 lossL: tensor(1374.8107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19813 lossL: tensor(1498.0944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19814 lossL: tensor(1335.1262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19815 lossL: tensor(1558.2344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19816 lossL: tensor(1426.2920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19817 lossL: tensor(1525.7135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19818 lossL: tensor(1276.8418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19819 lossL: tensor(1581.2181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19820 lossL: tensor(1434.4204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19821 lossL: tensor(1407.8365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19822 lossL: tensor(1562.6915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19823 lossL: tensor(1356.1694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19824 lossL: tensor(1390.2224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19825 lossL: tensor(1275.7400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19826 lossL: tensor(1277.5226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19827 lossL: tensor(1320.6331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19828 lossL: tensor(1274.2532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19829 lossL: tensor(1247.5487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19830 lossL: tensor(1505.4683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19831 lossL: tensor(1309.2023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19832 lossL: tensor(1353.0071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19833 lossL: tensor(1335.8817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19834 lossL: tensor(1475.3192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19835 lossL: tensor(1250.4827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19836 lossL: tensor(1385.6996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19837 lossL: tensor(1371.1379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19838 lossL: tensor(1463.9413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19839 lossL: tensor(1473.6071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19840 lossL: tensor(1301.8329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19841 lossL: tensor(1396.4995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19842 lossL: tensor(1378.2042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19843 lossL: tensor(1492.2627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19844 lossL: tensor(1280.9417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19845 lossL: tensor(1301.9731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19846 lossL: tensor(1370.9471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19847 lossL: tensor(1221.2164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19848 lossL: tensor(1288.2212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19849 lossL: tensor(1362.7135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19850 lossL: tensor(1342.2195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19851 lossL: tensor(1405.5919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19852 lossL: tensor(1432.6227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19853 lossL: tensor(1394.7645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19854 lossL: tensor(1385.3944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19855 lossL: tensor(1420.2732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19856 lossL: tensor(1319.2115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19857 lossL: tensor(1560.9672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19858 lossL: tensor(1356.2701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19859 lossL: tensor(1385.8823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19860 lossL: tensor(1415.4788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19861 lossL: tensor(1455.3839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19862 lossL: tensor(1449.4347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19863 lossL: tensor(1404.6571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19864 lossL: tensor(1469.4780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19865 lossL: tensor(1311.7124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19866 lossL: tensor(1287.5415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19867 lossL: tensor(1426.3024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19868 lossL: tensor(1297.9420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19869 lossL: tensor(1384.3698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19870 lossL: tensor(1303.5826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19871 lossL: tensor(1206.9109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "19872 lossL: tensor(1314.3428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19873 lossL: tensor(1392.0248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19874 lossL: tensor(1251.6073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19875 lossL: tensor(1494.7963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19876 lossL: tensor(1642.3839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19877 lossL: tensor(1328.3020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19878 lossL: tensor(1348.6394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19879 lossL: tensor(1393.4419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19880 lossL: tensor(1300.7909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19881 lossL: tensor(1384.9327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19882 lossL: tensor(1268.7377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19883 lossL: tensor(1481.4744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19884 lossL: tensor(1430.0763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19885 lossL: tensor(1332.7135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19886 lossL: tensor(1400.4191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19887 lossL: tensor(1437.1675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19888 lossL: tensor(1387.7200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19889 lossL: tensor(1252.7721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19890 lossL: tensor(1346.0094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19891 lossL: tensor(1458.0601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19892 lossL: tensor(1412.1711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19893 lossL: tensor(1430.3219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19894 lossL: tensor(1235.7476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19895 lossL: tensor(1379.1614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19896 lossL: tensor(1294.8964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19897 lossL: tensor(1262.4249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19898 lossL: tensor(1301.6533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19899 lossL: tensor(1387.2883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19900 lossL: tensor(1359.3578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19901 lossL: tensor(1376.2883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19902 lossL: tensor(1564.4283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19903 lossL: tensor(1299.2781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19904 lossL: tensor(1409.1785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19905 lossL: tensor(1364.3806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19906 lossL: tensor(1336.8236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19907 lossL: tensor(1326.5197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19908 lossL: tensor(1372.8547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19909 lossL: tensor(1324.8065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19910 lossL: tensor(1376.2850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19911 lossL: tensor(1318.8762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19912 lossL: tensor(1403.8706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19913 lossL: tensor(1494.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19914 lossL: tensor(1374.9001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19915 lossL: tensor(1323.8838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19916 lossL: tensor(1270.7361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19917 lossL: tensor(1391.8429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19918 lossL: tensor(1512.4685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19919 lossL: tensor(1340.8740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19920 lossL: tensor(1416.2426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19921 lossL: tensor(1472.2629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19922 lossL: tensor(1510.6489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19923 lossL: tensor(1384.8820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19924 lossL: tensor(1588.6525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19925 lossL: tensor(1321.7623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19926 lossL: tensor(1381.7803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19927 lossL: tensor(1532.4755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19928 lossL: tensor(1434.9169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19929 lossL: tensor(1423.5057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19930 lossL: tensor(1572.3395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19931 lossL: tensor(1360.4280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19932 lossL: tensor(1570.2854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19933 lossL: tensor(1412.8873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19934 lossL: tensor(1636.4351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19935 lossL: tensor(1396.1155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19936 lossL: tensor(1622.4658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19937 lossL: tensor(1593.4005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19938 lossL: tensor(1653.3595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19939 lossL: tensor(1358.2916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19940 lossL: tensor(1698.5658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19941 lossL: tensor(1480.7811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19942 lossL: tensor(1540.3542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19943 lossL: tensor(1516.5387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19944 lossL: tensor(1357.3118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19945 lossL: tensor(1674.1667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19946 lossL: tensor(1472.1980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19947 lossL: tensor(1506.2413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19948 lossL: tensor(1343.3386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19949 lossL: tensor(1341.2725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19950 lossL: tensor(1349.0438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19951 lossL: tensor(1272.9122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19952 lossL: tensor(1438.0637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19953 lossL: tensor(1394.3049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19954 lossL: tensor(1352.1530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19955 lossL: tensor(1448.2549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19956 lossL: tensor(1388.2146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19957 lossL: tensor(1533.3329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19958 lossL: tensor(1323.4381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19959 lossL: tensor(1345.4460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19960 lossL: tensor(1358.7273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19961 lossL: tensor(1371.6492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19962 lossL: tensor(1541.9530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19963 lossL: tensor(1290.7957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19964 lossL: tensor(1367.0785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19965 lossL: tensor(1265.5128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19966 lossL: tensor(1437.7396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19967 lossL: tensor(1273.5966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19968 lossL: tensor(1261.3529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19969 lossL: tensor(1438.2946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19970 lossL: tensor(1208.9155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19971 lossL: tensor(1330.2876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19972 lossL: tensor(1456.3407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19973 lossL: tensor(1428.0162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19974 lossL: tensor(1317.3115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19975 lossL: tensor(1374.1464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19976 lossL: tensor(1368.5742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19977 lossL: tensor(1355.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19978 lossL: tensor(1401.2839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19979 lossL: tensor(1195.4540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "19980 lossL: tensor(1400.2798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19981 lossL: tensor(1452.7094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19982 lossL: tensor(1241.3235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19983 lossL: tensor(1529.4011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19984 lossL: tensor(1303.6715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19985 lossL: tensor(1448.0198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19986 lossL: tensor(1414.6454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19987 lossL: tensor(1501.3142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19988 lossL: tensor(1405.5956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19989 lossL: tensor(1332.3419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19990 lossL: tensor(1366.0973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19991 lossL: tensor(1296.3921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19992 lossL: tensor(1214.7404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19993 lossL: tensor(1385.4900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19994 lossL: tensor(1331.6917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19995 lossL: tensor(1309.9020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19996 lossL: tensor(1395.6218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19997 lossL: tensor(1373.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19998 lossL: tensor(1384.3888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "19999 lossL: tensor(1407.9777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20000 lossL: tensor(1541.5522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20001 lossL: tensor(1395.9143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20002 lossL: tensor(1494.1985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20003 lossL: tensor(1303.5553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20004 lossL: tensor(1255.1284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20005 lossL: tensor(1442.6794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20006 lossL: tensor(1382.2795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20007 lossL: tensor(1386.2073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20008 lossL: tensor(1290.0978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20009 lossL: tensor(1314.7587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20010 lossL: tensor(1554.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20011 lossL: tensor(1482.9451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20012 lossL: tensor(1497.1648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20013 lossL: tensor(1372.4814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20014 lossL: tensor(1277.5249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20015 lossL: tensor(1307.1315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20016 lossL: tensor(1284.0305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20017 lossL: tensor(1327.5441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20018 lossL: tensor(1218.1014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20019 lossL: tensor(1324.4598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20020 lossL: tensor(1267.2648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20021 lossL: tensor(1351.2522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20022 lossL: tensor(1322.3480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20023 lossL: tensor(1276.0332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20024 lossL: tensor(1437.4727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20025 lossL: tensor(1305.0248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20026 lossL: tensor(1364.2965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20027 lossL: tensor(1271.1198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20028 lossL: tensor(1316.8916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20029 lossL: tensor(1344.8156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20030 lossL: tensor(1378.5277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20031 lossL: tensor(1438.6417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20032 lossL: tensor(1242.9243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20033 lossL: tensor(1343.4266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20034 lossL: tensor(1494.7462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20035 lossL: tensor(1421.9636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20036 lossL: tensor(1320.8361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20037 lossL: tensor(1335.5925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20038 lossL: tensor(1402.5090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20039 lossL: tensor(1367.6699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20040 lossL: tensor(1289.6747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20041 lossL: tensor(1538.3367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20042 lossL: tensor(1316.0917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20043 lossL: tensor(1291.2633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20044 lossL: tensor(1274.6718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20045 lossL: tensor(1532.4528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20046 lossL: tensor(1280.3376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20047 lossL: tensor(1372.9196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20048 lossL: tensor(1355.3507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20049 lossL: tensor(1121.3130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "20050 lossL: tensor(1389.4548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20051 lossL: tensor(1451.0118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20052 lossL: tensor(1372.8479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20053 lossL: tensor(1301.1302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20054 lossL: tensor(1293.2745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20055 lossL: tensor(1311.6912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20056 lossL: tensor(1451.7096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20057 lossL: tensor(1272.7925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20058 lossL: tensor(1322.8326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20059 lossL: tensor(1349.1886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20060 lossL: tensor(1268.1584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20061 lossL: tensor(1435.9476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20062 lossL: tensor(1523.6580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20063 lossL: tensor(1331.6198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20064 lossL: tensor(1267.8195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20065 lossL: tensor(1210.9008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20066 lossL: tensor(1367.4888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20067 lossL: tensor(1332.2537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20068 lossL: tensor(1349.4503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20069 lossL: tensor(1271.5431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20070 lossL: tensor(1431.2887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20071 lossL: tensor(1325.9817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20072 lossL: tensor(1287.5746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20073 lossL: tensor(1278.1714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20074 lossL: tensor(1400.9678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20075 lossL: tensor(1431.5077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20076 lossL: tensor(1239.3491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20077 lossL: tensor(1288.2407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20078 lossL: tensor(1444.1930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20079 lossL: tensor(1334.2679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20080 lossL: tensor(1296.8743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20081 lossL: tensor(1391.9980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20082 lossL: tensor(1459.6233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20083 lossL: tensor(1256.0062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20084 lossL: tensor(1295.4380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20085 lossL: tensor(1294.0200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20086 lossL: tensor(1377.3412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20087 lossL: tensor(1288.5837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20088 lossL: tensor(1398.6528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20089 lossL: tensor(1310.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20090 lossL: tensor(1379.1820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20091 lossL: tensor(1469.5110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20092 lossL: tensor(1236.6536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20093 lossL: tensor(1412.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20094 lossL: tensor(1250.2236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20095 lossL: tensor(1413.9840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20096 lossL: tensor(1494.9264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20097 lossL: tensor(1413.2002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20098 lossL: tensor(1445.2859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20099 lossL: tensor(1305.1844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20100 lossL: tensor(1533.8760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20101 lossL: tensor(1323.0608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20102 lossL: tensor(1303.9600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20103 lossL: tensor(1275.9908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20104 lossL: tensor(1225.9832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20105 lossL: tensor(1365.5913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20106 lossL: tensor(1177.6176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20107 lossL: tensor(1330.6589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20108 lossL: tensor(1259.7819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20109 lossL: tensor(1512.9174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20110 lossL: tensor(1242.8495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20111 lossL: tensor(1320.3785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20112 lossL: tensor(1400.5621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20113 lossL: tensor(1289.1528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20114 lossL: tensor(1223.5775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20115 lossL: tensor(1367.3569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20116 lossL: tensor(1324.4778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20117 lossL: tensor(1378.1799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20118 lossL: tensor(1461.4619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20119 lossL: tensor(1386.0603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20120 lossL: tensor(1299.3768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20121 lossL: tensor(1289.7302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20122 lossL: tensor(1266.1873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20123 lossL: tensor(1210.4298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20124 lossL: tensor(1332.8478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20125 lossL: tensor(1284.0956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20126 lossL: tensor(1267.1366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20127 lossL: tensor(1190.3344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20128 lossL: tensor(1315.6886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20129 lossL: tensor(1405.7208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20130 lossL: tensor(1321.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20131 lossL: tensor(1235.8934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20132 lossL: tensor(1521.9010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20133 lossL: tensor(1460.7599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20134 lossL: tensor(1327.9596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20135 lossL: tensor(1428.6637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20136 lossL: tensor(1358.5701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20137 lossL: tensor(1434.8464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20138 lossL: tensor(1422.7184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20139 lossL: tensor(1323.5288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20140 lossL: tensor(1291.0822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20141 lossL: tensor(1385.0779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20142 lossL: tensor(1413.2552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20143 lossL: tensor(1374.9048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20144 lossL: tensor(1345.0808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20145 lossL: tensor(1314.3564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20146 lossL: tensor(1306.3257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20147 lossL: tensor(1394.2845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20148 lossL: tensor(1233.0237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20149 lossL: tensor(1248.3912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20150 lossL: tensor(1378.1863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20151 lossL: tensor(1345.8250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20152 lossL: tensor(1169.3251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20153 lossL: tensor(1358.7379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20154 lossL: tensor(1265.1641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20155 lossL: tensor(1365.8015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20156 lossL: tensor(1281.4464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20157 lossL: tensor(1317.9233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20158 lossL: tensor(1283.7787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20159 lossL: tensor(1332.9110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20160 lossL: tensor(1355.8453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20161 lossL: tensor(1245.1107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20162 lossL: tensor(1196.0052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20163 lossL: tensor(1279.5050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20164 lossL: tensor(1286.9432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20165 lossL: tensor(1245.6401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20166 lossL: tensor(1422.6687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20167 lossL: tensor(1350.0779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20168 lossL: tensor(1421.1559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20169 lossL: tensor(1336.9182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20170 lossL: tensor(1251.4893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20171 lossL: tensor(1242.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20172 lossL: tensor(1207.6296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20173 lossL: tensor(1423.7689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20174 lossL: tensor(1329.7405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20175 lossL: tensor(1221.8020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20176 lossL: tensor(1317.6332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20177 lossL: tensor(1461.2793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20178 lossL: tensor(1354.5099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20179 lossL: tensor(1388.4709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20180 lossL: tensor(1254.9808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20181 lossL: tensor(1337.2834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20182 lossL: tensor(1389.6158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20183 lossL: tensor(1234.5571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20184 lossL: tensor(1254.4788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20185 lossL: tensor(1322.3810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20186 lossL: tensor(1494.8521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20187 lossL: tensor(1202.5420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20188 lossL: tensor(1307.6831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20189 lossL: tensor(1192.3167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20190 lossL: tensor(1263.9008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20191 lossL: tensor(1383.0684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20192 lossL: tensor(1361.6671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20193 lossL: tensor(1314.0231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20194 lossL: tensor(1325.8734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20195 lossL: tensor(1370.8439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20196 lossL: tensor(1206.6162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20197 lossL: tensor(1333.5273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20198 lossL: tensor(1279.3792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20199 lossL: tensor(1335.7560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20200 lossL: tensor(1229.3053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20201 lossL: tensor(1504.8069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20202 lossL: tensor(1225.4292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20203 lossL: tensor(1273.9999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20204 lossL: tensor(1386.5212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20205 lossL: tensor(1335.6304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20206 lossL: tensor(1503.1853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20207 lossL: tensor(1548.9110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20208 lossL: tensor(1383.3966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20209 lossL: tensor(1348.4410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20210 lossL: tensor(1277.6506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20211 lossL: tensor(1242.4847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20212 lossL: tensor(1314.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20213 lossL: tensor(1331.8131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20214 lossL: tensor(1390.2726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20215 lossL: tensor(1320.2257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20216 lossL: tensor(1375.2548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20217 lossL: tensor(1283.9923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20218 lossL: tensor(1282.4203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20219 lossL: tensor(1445.9712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20220 lossL: tensor(1396.0231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20221 lossL: tensor(1347.7078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20222 lossL: tensor(1402.6410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20223 lossL: tensor(1228.6023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20224 lossL: tensor(1352.3663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20225 lossL: tensor(1296.4049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20226 lossL: tensor(1291.1167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20227 lossL: tensor(1266.2476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20228 lossL: tensor(1184.3260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20229 lossL: tensor(1405.8011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20230 lossL: tensor(1327.5309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20231 lossL: tensor(1363.9041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20232 lossL: tensor(1356.3831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20233 lossL: tensor(1302.7590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20234 lossL: tensor(1242.8848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20235 lossL: tensor(1304.6323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20236 lossL: tensor(1242.1477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20237 lossL: tensor(1181.7217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20238 lossL: tensor(1335.4430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20239 lossL: tensor(1203.1351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20240 lossL: tensor(1284.9857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20241 lossL: tensor(1476.4094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20242 lossL: tensor(1256.9728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20243 lossL: tensor(1297.5330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20244 lossL: tensor(1110.8292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "20245 lossL: tensor(1355.6182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20246 lossL: tensor(1448.6370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20247 lossL: tensor(1182.2036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20248 lossL: tensor(1120.4243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20249 lossL: tensor(1444.0593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20250 lossL: tensor(1367.1819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20251 lossL: tensor(1197.7848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20252 lossL: tensor(1287.8522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20253 lossL: tensor(1306.9819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20254 lossL: tensor(1360.3516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20255 lossL: tensor(1404.7397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20256 lossL: tensor(1356.5903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20257 lossL: tensor(1287.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20258 lossL: tensor(1360.6766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20259 lossL: tensor(1386.6047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20260 lossL: tensor(1454.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20261 lossL: tensor(1356.3740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20262 lossL: tensor(1362.1899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20263 lossL: tensor(1292.1104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20264 lossL: tensor(1291.7163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20265 lossL: tensor(1560.0424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20266 lossL: tensor(1262.9437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20267 lossL: tensor(1435.0594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20268 lossL: tensor(1446.2723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20269 lossL: tensor(1442.2756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20270 lossL: tensor(1358.0414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20271 lossL: tensor(1377.0663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20272 lossL: tensor(1379.8521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20273 lossL: tensor(1311.1982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20274 lossL: tensor(1226.2117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20275 lossL: tensor(1181.5024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20276 lossL: tensor(1332.9969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20277 lossL: tensor(1341.7181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20278 lossL: tensor(1337.4177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20279 lossL: tensor(1189.7892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20280 lossL: tensor(1286.4585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20281 lossL: tensor(1201.6130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20282 lossL: tensor(1422.4152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20283 lossL: tensor(1249.4507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20284 lossL: tensor(1459.9921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20285 lossL: tensor(1322.7909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20286 lossL: tensor(1280.0690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20287 lossL: tensor(1374.6572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20288 lossL: tensor(1367.9594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20289 lossL: tensor(1333.6420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20290 lossL: tensor(1284.9668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20291 lossL: tensor(1224.9542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20292 lossL: tensor(1305.0403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20293 lossL: tensor(1329.8993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20294 lossL: tensor(1323.8502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20295 lossL: tensor(1454.1249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20296 lossL: tensor(1734.1195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20297 lossL: tensor(1389.8591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20298 lossL: tensor(1954.5927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20299 lossL: tensor(1246.2394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20300 lossL: tensor(1713.8843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20301 lossL: tensor(1412.2306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20302 lossL: tensor(1454.6743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20303 lossL: tensor(1602.9326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20304 lossL: tensor(1455.4696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20305 lossL: tensor(1634.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20306 lossL: tensor(1238.3523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20307 lossL: tensor(1499.5145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20308 lossL: tensor(1307.1775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20309 lossL: tensor(1413.4369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20310 lossL: tensor(1337.7527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20311 lossL: tensor(1570.6204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20312 lossL: tensor(1197.8802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20313 lossL: tensor(1495.9900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20314 lossL: tensor(1325.4413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20315 lossL: tensor(1452.7366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20316 lossL: tensor(1298.5354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20317 lossL: tensor(1583.4121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20318 lossL: tensor(1220.3502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20319 lossL: tensor(1346.2548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20320 lossL: tensor(1333.9652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20321 lossL: tensor(1386.2080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20322 lossL: tensor(1230.1089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20323 lossL: tensor(1366.7286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20324 lossL: tensor(1352.7448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20325 lossL: tensor(1276.4133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20326 lossL: tensor(1333.4087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20327 lossL: tensor(1472.8444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20328 lossL: tensor(1535.5619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20329 lossL: tensor(1260.1569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20330 lossL: tensor(1338.7483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20331 lossL: tensor(1251.0399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20332 lossL: tensor(1264.2594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20333 lossL: tensor(1288.9091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20334 lossL: tensor(1219.6974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20335 lossL: tensor(1302.5138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20336 lossL: tensor(1323.7139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20337 lossL: tensor(1271.1609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20338 lossL: tensor(1362.2646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20339 lossL: tensor(1443.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20340 lossL: tensor(1232.8625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20341 lossL: tensor(1226.2253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20342 lossL: tensor(1228.7070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20343 lossL: tensor(1306.5676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20344 lossL: tensor(1326.0155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20345 lossL: tensor(1328.6836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20346 lossL: tensor(1373.2217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20347 lossL: tensor(1418.3833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20348 lossL: tensor(1158.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20349 lossL: tensor(1262.8649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20350 lossL: tensor(1251.1956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20351 lossL: tensor(1508.8987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20352 lossL: tensor(1366.9039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20353 lossL: tensor(1247.4065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20354 lossL: tensor(1307.6863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20355 lossL: tensor(1343.9519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20356 lossL: tensor(1267.6453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20357 lossL: tensor(1256.9254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20358 lossL: tensor(1262.2440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20359 lossL: tensor(1158.4589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20360 lossL: tensor(1074.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "20361 lossL: tensor(1431.1753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20362 lossL: tensor(1321.9738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20363 lossL: tensor(1209.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20364 lossL: tensor(1249.8251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20365 lossL: tensor(1152.0513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20366 lossL: tensor(1240.7166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20367 lossL: tensor(1218.2815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20368 lossL: tensor(1220.3258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20369 lossL: tensor(1312.6499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20370 lossL: tensor(1326.9545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20371 lossL: tensor(1335.2106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20372 lossL: tensor(1204.4209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20373 lossL: tensor(1332.4751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20374 lossL: tensor(1256.7654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20375 lossL: tensor(1368.5554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20376 lossL: tensor(1263.9749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20377 lossL: tensor(1181.8014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20378 lossL: tensor(1270.7935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20379 lossL: tensor(1249.7001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20380 lossL: tensor(1336.1497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20381 lossL: tensor(1341.1746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20382 lossL: tensor(1218.8479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20383 lossL: tensor(1375.3066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20384 lossL: tensor(1265.8768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20385 lossL: tensor(1343.1305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20386 lossL: tensor(1261.8876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20387 lossL: tensor(1237.2772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20388 lossL: tensor(1273.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20389 lossL: tensor(1244.9036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20390 lossL: tensor(1300.2200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20391 lossL: tensor(1290.0045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20392 lossL: tensor(1301.9915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20393 lossL: tensor(1270.3041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20394 lossL: tensor(1267.5436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20395 lossL: tensor(1273.4370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20396 lossL: tensor(1274.9205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20397 lossL: tensor(1304.9337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20398 lossL: tensor(1314.5222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20399 lossL: tensor(1138.4645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20400 lossL: tensor(1253.9631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20401 lossL: tensor(1280.5397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20402 lossL: tensor(1220.3875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20403 lossL: tensor(1255.1572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20404 lossL: tensor(1212.9923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20405 lossL: tensor(1367.3933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20406 lossL: tensor(1381.8536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20407 lossL: tensor(1278.0247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20408 lossL: tensor(1312.5236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20409 lossL: tensor(1573.2961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20410 lossL: tensor(1387.2400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20411 lossL: tensor(1186.1432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20412 lossL: tensor(1316.8987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20413 lossL: tensor(1277.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20414 lossL: tensor(1296.4194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20415 lossL: tensor(1301.5436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20416 lossL: tensor(1227.1378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20417 lossL: tensor(1310.4437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20418 lossL: tensor(1187.2937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20419 lossL: tensor(1289.8597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20420 lossL: tensor(1035.4783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "20421 lossL: tensor(1266.0963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20422 lossL: tensor(1260.3246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20423 lossL: tensor(1360.6925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20424 lossL: tensor(1200.6990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20425 lossL: tensor(1346.6270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20426 lossL: tensor(1429.3507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20427 lossL: tensor(1256.5337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20428 lossL: tensor(1289.4564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20429 lossL: tensor(1246.8433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20430 lossL: tensor(1298.3912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20431 lossL: tensor(1244.8671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20432 lossL: tensor(1311.8928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20433 lossL: tensor(1205.8137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20434 lossL: tensor(1233.7014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20435 lossL: tensor(1317.2445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20436 lossL: tensor(1248.1371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20437 lossL: tensor(1274.3169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20438 lossL: tensor(1290.1088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20439 lossL: tensor(1154.9126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20440 lossL: tensor(1380.2034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20441 lossL: tensor(1264.1378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20442 lossL: tensor(1328.2771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20443 lossL: tensor(1351.3071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20444 lossL: tensor(1316.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20445 lossL: tensor(1485.0381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20446 lossL: tensor(1247.6757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20447 lossL: tensor(1262.9031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20448 lossL: tensor(1291.4646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20449 lossL: tensor(1407.8109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20450 lossL: tensor(1391.9845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20451 lossL: tensor(1182.8441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20452 lossL: tensor(1343.7753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20453 lossL: tensor(1279.3961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20454 lossL: tensor(1185.9631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20455 lossL: tensor(1365.2408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20456 lossL: tensor(1276.9954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20457 lossL: tensor(1464.1382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20458 lossL: tensor(1223.6908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20459 lossL: tensor(1210.7648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20460 lossL: tensor(1316.3989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20461 lossL: tensor(1181.3467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20462 lossL: tensor(1311.8177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20463 lossL: tensor(1345.7594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20464 lossL: tensor(1344.8804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20465 lossL: tensor(1118.6913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20466 lossL: tensor(1296.1075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20467 lossL: tensor(1390.3478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20468 lossL: tensor(1349.2277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20469 lossL: tensor(1227.1248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20470 lossL: tensor(1413.2526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20471 lossL: tensor(1290.4028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20472 lossL: tensor(1224.0704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20473 lossL: tensor(1282.2274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20474 lossL: tensor(1385.3387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20475 lossL: tensor(1540.2024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20476 lossL: tensor(1378.0752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20477 lossL: tensor(1436.3755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20478 lossL: tensor(1190.7751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20479 lossL: tensor(1327.3862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20480 lossL: tensor(1359.2551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20481 lossL: tensor(1499.6239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20482 lossL: tensor(1192.6534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20483 lossL: tensor(1445.6458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20484 lossL: tensor(1202.1770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20485 lossL: tensor(1545.1224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20486 lossL: tensor(1304.8040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20487 lossL: tensor(1147.9587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20488 lossL: tensor(1236.9785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20489 lossL: tensor(1322.7977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20490 lossL: tensor(1226.1686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20491 lossL: tensor(1221.9832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20492 lossL: tensor(1337.7273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20493 lossL: tensor(1296.6179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20494 lossL: tensor(1333.8384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20495 lossL: tensor(1270.4526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20496 lossL: tensor(1150.6095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20497 lossL: tensor(1231.4645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20498 lossL: tensor(1219.9607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20499 lossL: tensor(1217.9430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20500 lossL: tensor(1375.9194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20501 lossL: tensor(1315.5996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20502 lossL: tensor(1252.4835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20503 lossL: tensor(1225.2048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20504 lossL: tensor(1237.3536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20505 lossL: tensor(1264.8734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20506 lossL: tensor(1243.6371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20507 lossL: tensor(1346.9219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20508 lossL: tensor(1222.7610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20509 lossL: tensor(1325.4286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20510 lossL: tensor(1189.4871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20511 lossL: tensor(1383.6273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20512 lossL: tensor(1373.8845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20513 lossL: tensor(1223.2722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20514 lossL: tensor(1252.9087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20515 lossL: tensor(1149.6381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20516 lossL: tensor(1354.7814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20517 lossL: tensor(1276.5780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20518 lossL: tensor(1154.6034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20519 lossL: tensor(1229.8883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20520 lossL: tensor(1221.9971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20521 lossL: tensor(1197.0363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20522 lossL: tensor(1277.3033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20523 lossL: tensor(1222.0283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20524 lossL: tensor(1261.7438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20525 lossL: tensor(1212.1116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20526 lossL: tensor(1093.7681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20527 lossL: tensor(1146.4110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20528 lossL: tensor(1285.7643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20529 lossL: tensor(1205.0886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20530 lossL: tensor(1338.9069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20531 lossL: tensor(1292.8141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20532 lossL: tensor(1317.7922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20533 lossL: tensor(1310.0239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20534 lossL: tensor(1299.3469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20535 lossL: tensor(1285.4324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20536 lossL: tensor(1225.3098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20537 lossL: tensor(1196.7782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20538 lossL: tensor(1111.5671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20539 lossL: tensor(1278.6918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20540 lossL: tensor(1325.6002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20541 lossL: tensor(1179.3577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20542 lossL: tensor(1249.7112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20543 lossL: tensor(1309.0477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20544 lossL: tensor(1282.2297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20545 lossL: tensor(1135.1852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20546 lossL: tensor(1307.2319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20547 lossL: tensor(1230.8770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20548 lossL: tensor(1148.3115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20549 lossL: tensor(1433.2408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20550 lossL: tensor(1276.7723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20551 lossL: tensor(1224.9832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20552 lossL: tensor(1132.6530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20553 lossL: tensor(1257.3258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20554 lossL: tensor(1202.5479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20555 lossL: tensor(1272.3568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20556 lossL: tensor(1272.9149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20557 lossL: tensor(1273.9078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20558 lossL: tensor(1410.7009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20559 lossL: tensor(1310.4480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20560 lossL: tensor(1284.1107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20561 lossL: tensor(1291.5710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20562 lossL: tensor(1064.5085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20563 lossL: tensor(1222.4177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20564 lossL: tensor(1373.9270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20565 lossL: tensor(1244.9192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20566 lossL: tensor(1281.8696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20567 lossL: tensor(1201.6694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20568 lossL: tensor(1159.1835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20569 lossL: tensor(1269.3943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20570 lossL: tensor(1237.1240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20571 lossL: tensor(1283.6045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20572 lossL: tensor(1319.4197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20573 lossL: tensor(1158.8035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20574 lossL: tensor(1221.2065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20575 lossL: tensor(1199.1019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20576 lossL: tensor(1088.2816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20577 lossL: tensor(1268.7499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20578 lossL: tensor(1308.1129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20579 lossL: tensor(1318.4309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20580 lossL: tensor(1292.1356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20581 lossL: tensor(1290.3217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20582 lossL: tensor(1250.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20583 lossL: tensor(1287.4490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20584 lossL: tensor(1212.9707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20585 lossL: tensor(1340.4503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20586 lossL: tensor(1320.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20587 lossL: tensor(1189.0509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20588 lossL: tensor(1215.8179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20589 lossL: tensor(1199.3638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20590 lossL: tensor(1352.0431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20591 lossL: tensor(1157.7711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20592 lossL: tensor(1261.7406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20593 lossL: tensor(1310.4684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20594 lossL: tensor(1380.2961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20595 lossL: tensor(1274.3397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20596 lossL: tensor(1401.9832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20597 lossL: tensor(1390.2833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20598 lossL: tensor(1155.4973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20599 lossL: tensor(1362.0863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20600 lossL: tensor(1114.2639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20601 lossL: tensor(1353.2994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20602 lossL: tensor(1241.5928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20603 lossL: tensor(1358.2759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20604 lossL: tensor(1367.5629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20605 lossL: tensor(1304.8895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20606 lossL: tensor(1198.9025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20607 lossL: tensor(1312.8053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20608 lossL: tensor(1338.3386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20609 lossL: tensor(1236.0610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20610 lossL: tensor(1364.6781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20611 lossL: tensor(1303.9910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20612 lossL: tensor(1420.2986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20613 lossL: tensor(1409.1989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20614 lossL: tensor(1223.4325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20615 lossL: tensor(1354.0631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20616 lossL: tensor(1167.8611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20617 lossL: tensor(1271.5863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20618 lossL: tensor(1286.9082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20619 lossL: tensor(1202.3478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20620 lossL: tensor(1290.4003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20621 lossL: tensor(1332.2521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20622 lossL: tensor(1279.9927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20623 lossL: tensor(1240.2339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20624 lossL: tensor(1148.7452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20625 lossL: tensor(1229.8119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20626 lossL: tensor(1190.4700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20627 lossL: tensor(1238.1254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20628 lossL: tensor(1254.0691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20629 lossL: tensor(1272.6128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20630 lossL: tensor(1159.9666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20631 lossL: tensor(1371.7866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20632 lossL: tensor(1188.8339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20633 lossL: tensor(1266.1818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20634 lossL: tensor(1266.5071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20635 lossL: tensor(1215.2659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20636 lossL: tensor(1293.0812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20637 lossL: tensor(1305.1827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20638 lossL: tensor(1229.7581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20639 lossL: tensor(1230.9348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20640 lossL: tensor(1278.5023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20641 lossL: tensor(1244.0653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20642 lossL: tensor(1239.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20643 lossL: tensor(1259.4637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20644 lossL: tensor(1189.4086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20645 lossL: tensor(1362.6920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20646 lossL: tensor(1328.7175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20647 lossL: tensor(1265.8680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20648 lossL: tensor(1243.3566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20649 lossL: tensor(1256.3740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20650 lossL: tensor(1355.7316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20651 lossL: tensor(1285.3638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20652 lossL: tensor(1306.1786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20653 lossL: tensor(1215.1870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20654 lossL: tensor(1342.3158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20655 lossL: tensor(1189.9734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20656 lossL: tensor(1372.6235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20657 lossL: tensor(1157.6694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20658 lossL: tensor(1337.0800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20659 lossL: tensor(1343.5676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20660 lossL: tensor(1169.5291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20661 lossL: tensor(1451.0483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20662 lossL: tensor(1145.0071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20663 lossL: tensor(1314.2052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20664 lossL: tensor(1232.0585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20665 lossL: tensor(1461.2164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20666 lossL: tensor(1157.7941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20667 lossL: tensor(1318.7648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20668 lossL: tensor(1330.0685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20669 lossL: tensor(1224.4286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20670 lossL: tensor(1302.7865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20671 lossL: tensor(1267.0085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20672 lossL: tensor(1186.1675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20673 lossL: tensor(1240.9930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20674 lossL: tensor(1377.0381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20675 lossL: tensor(1312.5195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20676 lossL: tensor(1228.1183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20677 lossL: tensor(1366.2948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20678 lossL: tensor(1225.6759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20679 lossL: tensor(1246.7819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20680 lossL: tensor(1288.9762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20681 lossL: tensor(1181.1243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20682 lossL: tensor(1226.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20683 lossL: tensor(1178.0544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20684 lossL: tensor(1342.4645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20685 lossL: tensor(1167.3208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20686 lossL: tensor(1093.2913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20687 lossL: tensor(1310.5112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20688 lossL: tensor(1186.1578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20689 lossL: tensor(1218.6591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20690 lossL: tensor(1397.0348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20691 lossL: tensor(1381.4614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20692 lossL: tensor(1150.2983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20693 lossL: tensor(1426.8691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20694 lossL: tensor(1135.3386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20695 lossL: tensor(1310.5409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20696 lossL: tensor(1360.3939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20697 lossL: tensor(1217.8412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20698 lossL: tensor(1402.8285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20699 lossL: tensor(1179.2482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20700 lossL: tensor(1520.5981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20701 lossL: tensor(1304.4440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20702 lossL: tensor(1166.2449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20703 lossL: tensor(1184.2944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20704 lossL: tensor(1231.3566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20705 lossL: tensor(1246.2263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20706 lossL: tensor(1149.7556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20707 lossL: tensor(1163.5070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20708 lossL: tensor(1255.1664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20709 lossL: tensor(1159.3319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20710 lossL: tensor(1160.4446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20711 lossL: tensor(1160.9583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20712 lossL: tensor(1133.3846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20713 lossL: tensor(1289.5022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20714 lossL: tensor(1389.4684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20715 lossL: tensor(1251.1882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20716 lossL: tensor(1190.8093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20717 lossL: tensor(1279.1146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20718 lossL: tensor(1092.5453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20719 lossL: tensor(1265.4163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20720 lossL: tensor(1139.4910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20721 lossL: tensor(1198.4352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20722 lossL: tensor(1257.9347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20723 lossL: tensor(1335.7062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20724 lossL: tensor(1160.6379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20725 lossL: tensor(1169.2446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20726 lossL: tensor(1228.8206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20727 lossL: tensor(1232.8088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20728 lossL: tensor(1146.2751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20729 lossL: tensor(1112.0581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20730 lossL: tensor(1356.9525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20731 lossL: tensor(1089.1138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20732 lossL: tensor(1219.7346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20733 lossL: tensor(1146.2479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20734 lossL: tensor(1330.9667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20735 lossL: tensor(1378.6375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20736 lossL: tensor(1185.2118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20737 lossL: tensor(1416.4451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20738 lossL: tensor(1134.8268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20739 lossL: tensor(1293.5085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20740 lossL: tensor(1183.9381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20741 lossL: tensor(1327.1244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20742 lossL: tensor(1248.8643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20743 lossL: tensor(1258.2698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20744 lossL: tensor(1161.4554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20745 lossL: tensor(1320.5752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20746 lossL: tensor(1189.5305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20747 lossL: tensor(1169.6807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20748 lossL: tensor(1264.8927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20749 lossL: tensor(1255.6475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20750 lossL: tensor(1337.9520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20751 lossL: tensor(1179.1340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20752 lossL: tensor(1295.8002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20753 lossL: tensor(1287.4191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20754 lossL: tensor(1321.4097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20755 lossL: tensor(1153.9994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20756 lossL: tensor(1227.8849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20757 lossL: tensor(1235.6262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20758 lossL: tensor(1240.8011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20759 lossL: tensor(1166.4393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20760 lossL: tensor(1181.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20761 lossL: tensor(1376.3690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20762 lossL: tensor(1193.0056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20763 lossL: tensor(1382.1885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20764 lossL: tensor(1215.6959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20765 lossL: tensor(1424.2208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20766 lossL: tensor(1203.7375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20767 lossL: tensor(1333.3591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20768 lossL: tensor(1218.4707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20769 lossL: tensor(1517.2487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20770 lossL: tensor(1190.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20771 lossL: tensor(1419.7855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20772 lossL: tensor(1247.1100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20773 lossL: tensor(1332.2654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20774 lossL: tensor(1452.6509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20775 lossL: tensor(1395.0205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20776 lossL: tensor(1538.6823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20777 lossL: tensor(1232.1113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20778 lossL: tensor(1466.7014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20779 lossL: tensor(1177.5667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20780 lossL: tensor(1397.5344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20781 lossL: tensor(1147.0171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20782 lossL: tensor(1574.3269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20783 lossL: tensor(1239.4321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20784 lossL: tensor(1258.5298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20785 lossL: tensor(1314.7979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20786 lossL: tensor(1260.0066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20787 lossL: tensor(1386.1271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20788 lossL: tensor(1183.0208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20789 lossL: tensor(1242.1078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20790 lossL: tensor(1285.6532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20791 lossL: tensor(1302.3845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20792 lossL: tensor(1027.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "20793 lossL: tensor(1374.1619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20794 lossL: tensor(1100.6442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20795 lossL: tensor(1360.6792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20796 lossL: tensor(1376.0894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20797 lossL: tensor(1297.7618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20798 lossL: tensor(1301.0430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20799 lossL: tensor(1201.7126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20800 lossL: tensor(1258.0408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20801 lossL: tensor(1162.5956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20802 lossL: tensor(1224.6211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20803 lossL: tensor(1247.5533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20804 lossL: tensor(1285.4962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20805 lossL: tensor(1329.1571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20806 lossL: tensor(1181.9165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20807 lossL: tensor(1353.9354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20808 lossL: tensor(1166.7441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20809 lossL: tensor(1135.9547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20810 lossL: tensor(1315.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20811 lossL: tensor(1134.1151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20812 lossL: tensor(1302.2754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20813 lossL: tensor(1175.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20814 lossL: tensor(1208.2926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20815 lossL: tensor(1126.9117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20816 lossL: tensor(1245.8644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20817 lossL: tensor(1283.4435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20818 lossL: tensor(1162.0708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20819 lossL: tensor(1137.9517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20820 lossL: tensor(1220.0647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20821 lossL: tensor(1224.7426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20822 lossL: tensor(1233.9905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20823 lossL: tensor(1127.5975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20824 lossL: tensor(1293.0347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20825 lossL: tensor(1231.9119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20826 lossL: tensor(1219.4200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20827 lossL: tensor(1205.4167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20828 lossL: tensor(1153.7883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20829 lossL: tensor(1302.5490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20830 lossL: tensor(1176.8943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20831 lossL: tensor(1204.8370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20832 lossL: tensor(1178.1924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20833 lossL: tensor(1194.5541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20834 lossL: tensor(1225.4674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20835 lossL: tensor(1190.5226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20836 lossL: tensor(1273.8534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20837 lossL: tensor(1209.1948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20838 lossL: tensor(1202.3944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20839 lossL: tensor(1205.0110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20840 lossL: tensor(1213.2952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20841 lossL: tensor(1175.8210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20842 lossL: tensor(1186.1360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20843 lossL: tensor(1080.2379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20844 lossL: tensor(1092.7654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20845 lossL: tensor(1197.0271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20846 lossL: tensor(1192.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20847 lossL: tensor(1237.1727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20848 lossL: tensor(1122.7961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20849 lossL: tensor(1224.0482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20850 lossL: tensor(1154.6060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20851 lossL: tensor(1200.0150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20852 lossL: tensor(1181.9829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20853 lossL: tensor(1124.0570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20854 lossL: tensor(1357.4133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20855 lossL: tensor(1252.1039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20856 lossL: tensor(1175.4751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20857 lossL: tensor(1248.8372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20858 lossL: tensor(1104.4739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20859 lossL: tensor(1154.4720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20860 lossL: tensor(1292.7161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20861 lossL: tensor(1212.4120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20862 lossL: tensor(1149.4463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20863 lossL: tensor(1190.3085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20864 lossL: tensor(1184.0500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20865 lossL: tensor(1209.6742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20866 lossL: tensor(1225.8423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20867 lossL: tensor(1203.1594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20868 lossL: tensor(1234.3710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20869 lossL: tensor(1180.5015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20870 lossL: tensor(1240.7034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20871 lossL: tensor(1147.2177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20872 lossL: tensor(1348.0615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20873 lossL: tensor(1300.3094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20874 lossL: tensor(1292.9667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20875 lossL: tensor(1150.3038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20876 lossL: tensor(1177.7776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20877 lossL: tensor(1330.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20878 lossL: tensor(1269.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20879 lossL: tensor(1153.8474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20880 lossL: tensor(1320.4705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20881 lossL: tensor(1239.4827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20882 lossL: tensor(1254.5319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20883 lossL: tensor(1162.1543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20884 lossL: tensor(1232.7476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20885 lossL: tensor(1205.8188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20886 lossL: tensor(1195.5463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20887 lossL: tensor(1234.9879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20888 lossL: tensor(1248.2209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20889 lossL: tensor(1271.3063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20890 lossL: tensor(1130.4941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20891 lossL: tensor(1145.3420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20892 lossL: tensor(1128.1097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20893 lossL: tensor(1172.8699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20894 lossL: tensor(1279.1116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20895 lossL: tensor(1284.0923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20896 lossL: tensor(1247.5300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20897 lossL: tensor(1218.7111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20898 lossL: tensor(1263.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20899 lossL: tensor(1264.5693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20900 lossL: tensor(1279.0232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20901 lossL: tensor(1344.2733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20902 lossL: tensor(1228.7357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20903 lossL: tensor(1224.6171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20904 lossL: tensor(1269.1287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20905 lossL: tensor(1259.7461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20906 lossL: tensor(1215.4934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20907 lossL: tensor(1415.6913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20908 lossL: tensor(1330.5883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20909 lossL: tensor(1351.7255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20910 lossL: tensor(1274.0521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20911 lossL: tensor(1253.3964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20912 lossL: tensor(1283.3448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20913 lossL: tensor(1229.9897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20914 lossL: tensor(1200.5077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20915 lossL: tensor(1111.5575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20916 lossL: tensor(1225.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20917 lossL: tensor(1160.6858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20918 lossL: tensor(1217.3749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20919 lossL: tensor(1256.9897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20920 lossL: tensor(1129.9052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20921 lossL: tensor(1212.2191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20922 lossL: tensor(1383.9614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20923 lossL: tensor(1282.7368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20924 lossL: tensor(1177.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20925 lossL: tensor(1222.9900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20926 lossL: tensor(1217.7014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20927 lossL: tensor(1169.2502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20928 lossL: tensor(1318.8695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20929 lossL: tensor(1209.7926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20930 lossL: tensor(1228.5737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20931 lossL: tensor(1193.5554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20932 lossL: tensor(1153.5089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20933 lossL: tensor(1269.0371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20934 lossL: tensor(1282.3324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20935 lossL: tensor(1211.8657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20936 lossL: tensor(1365.4264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20937 lossL: tensor(1291.0920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20938 lossL: tensor(1180.1835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20939 lossL: tensor(1319.2208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20940 lossL: tensor(1309.5764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20941 lossL: tensor(1460.7123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20942 lossL: tensor(1168.4287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20943 lossL: tensor(1295.7578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20944 lossL: tensor(1241.7679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20945 lossL: tensor(1563.8334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20946 lossL: tensor(1227.0439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20947 lossL: tensor(1461.2823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20948 lossL: tensor(1243.8567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20949 lossL: tensor(1363.7572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20950 lossL: tensor(1446.4486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20951 lossL: tensor(1242.8071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20952 lossL: tensor(1567.1116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20953 lossL: tensor(1181.1741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20954 lossL: tensor(1511.0747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20955 lossL: tensor(1272.2063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20956 lossL: tensor(1470.3468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20957 lossL: tensor(1419.1267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20958 lossL: tensor(1336.1733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20959 lossL: tensor(1589.1112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20960 lossL: tensor(1215.8164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20961 lossL: tensor(1531.8076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20962 lossL: tensor(1319.7571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20963 lossL: tensor(1607.8132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20964 lossL: tensor(1224.3219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20965 lossL: tensor(1500.0264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20966 lossL: tensor(1271.7368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20967 lossL: tensor(1488.7338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20968 lossL: tensor(1224.7310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20969 lossL: tensor(1394.8474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20970 lossL: tensor(1231.8223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20971 lossL: tensor(1333.0878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20972 lossL: tensor(1435.2250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20973 lossL: tensor(1084.9065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20974 lossL: tensor(1257.5364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20975 lossL: tensor(1190.1139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20976 lossL: tensor(1275.4115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20977 lossL: tensor(1158.4149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20978 lossL: tensor(1249.8054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20979 lossL: tensor(1190.5344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20980 lossL: tensor(1144.2805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20981 lossL: tensor(1276.6599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20982 lossL: tensor(1248.4697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20983 lossL: tensor(1133.5654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20984 lossL: tensor(1165.6833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20985 lossL: tensor(1061.1472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20986 lossL: tensor(1275.7864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20987 lossL: tensor(1104.3977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20988 lossL: tensor(1274.1252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20989 lossL: tensor(1162.3451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20990 lossL: tensor(1374.7948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20991 lossL: tensor(1182.1287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20992 lossL: tensor(1279.3608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20993 lossL: tensor(1213.0134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20994 lossL: tensor(1418.2062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20995 lossL: tensor(1318.7872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20996 lossL: tensor(1203.8809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20997 lossL: tensor(1286.2460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20998 lossL: tensor(1224.5453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "20999 lossL: tensor(1360.3333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21000 lossL: tensor(1135.6987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21001 lossL: tensor(1261.4973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21002 lossL: tensor(1165.8314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21003 lossL: tensor(1416.8229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21004 lossL: tensor(1221.8083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21005 lossL: tensor(1155.7061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21006 lossL: tensor(1155.9419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21007 lossL: tensor(1153.4933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21008 lossL: tensor(1223.7975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21009 lossL: tensor(1230.3856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21010 lossL: tensor(1215.0294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21011 lossL: tensor(1195.6766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21012 lossL: tensor(1267.5217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21013 lossL: tensor(1171.9204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21014 lossL: tensor(1268.3981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21015 lossL: tensor(1097.8721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21016 lossL: tensor(1254.3280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21017 lossL: tensor(1176.0725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21018 lossL: tensor(1164.8666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21019 lossL: tensor(1231.5026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21020 lossL: tensor(1232.2911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21021 lossL: tensor(1156.5012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21022 lossL: tensor(1170.3014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21023 lossL: tensor(1170.8790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21024 lossL: tensor(1189.7794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21025 lossL: tensor(1273.3689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21026 lossL: tensor(1111.9545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21027 lossL: tensor(1127.1097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21028 lossL: tensor(1056.0577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21029 lossL: tensor(1217.6794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21030 lossL: tensor(1182.6565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21031 lossL: tensor(1236.6726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21032 lossL: tensor(1128.5481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21033 lossL: tensor(1259.4451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21034 lossL: tensor(1230.5695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21035 lossL: tensor(1365.7308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21036 lossL: tensor(1076.2146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21037 lossL: tensor(1348.3037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21038 lossL: tensor(1270.2946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21039 lossL: tensor(1422.3375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21040 lossL: tensor(1103.8949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21041 lossL: tensor(1433.3066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21042 lossL: tensor(1250.1732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21043 lossL: tensor(1249.5009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21044 lossL: tensor(1416.3599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21045 lossL: tensor(1188.6995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21046 lossL: tensor(1348.8210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21047 lossL: tensor(1183.0149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21048 lossL: tensor(1518.6923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21049 lossL: tensor(1219.5750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21050 lossL: tensor(1334.3461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21051 lossL: tensor(1215.1716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21052 lossL: tensor(1419.9974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21053 lossL: tensor(1306.8525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21054 lossL: tensor(1246.9366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21055 lossL: tensor(1356.6555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21056 lossL: tensor(1180.3829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21057 lossL: tensor(1347.0449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21058 lossL: tensor(1174.8302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21059 lossL: tensor(1221.0076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21060 lossL: tensor(1138.5022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21061 lossL: tensor(1379.6155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21062 lossL: tensor(1119.2502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21063 lossL: tensor(1171.3772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21064 lossL: tensor(1143.3282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21065 lossL: tensor(1181.4709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21066 lossL: tensor(1293.5005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21067 lossL: tensor(1158.9279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21068 lossL: tensor(1257.5413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21069 lossL: tensor(1208.9863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21070 lossL: tensor(1126.1255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21071 lossL: tensor(1184.8694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21072 lossL: tensor(1111.7212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21073 lossL: tensor(1152.1523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21074 lossL: tensor(1061.8816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21075 lossL: tensor(1116.9723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21076 lossL: tensor(1195.4486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21077 lossL: tensor(1116.3973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21078 lossL: tensor(1175.1545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21079 lossL: tensor(1191.0845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21080 lossL: tensor(1222.0295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21081 lossL: tensor(1173.0305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21082 lossL: tensor(1207.9037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21083 lossL: tensor(1183.8947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21084 lossL: tensor(1189.9768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21085 lossL: tensor(1223.4432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21086 lossL: tensor(1145.8149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21087 lossL: tensor(1277.7137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21088 lossL: tensor(1215.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21089 lossL: tensor(1163.8879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21090 lossL: tensor(1259.1143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21091 lossL: tensor(1241.0182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21092 lossL: tensor(1141.3060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21093 lossL: tensor(1194.7661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21094 lossL: tensor(1365.7192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21095 lossL: tensor(1139.7637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21096 lossL: tensor(1400.7729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21097 lossL: tensor(1254.5222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21098 lossL: tensor(1311.6340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21099 lossL: tensor(1313.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21100 lossL: tensor(1192.1060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21101 lossL: tensor(1261.1448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21102 lossL: tensor(1175.1975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21103 lossL: tensor(1175.4067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21104 lossL: tensor(1170.4856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21105 lossL: tensor(1173.1866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21106 lossL: tensor(1164.6888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21107 lossL: tensor(1201.2190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21108 lossL: tensor(1222.8331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21109 lossL: tensor(1113.2866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21110 lossL: tensor(1206.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21111 lossL: tensor(1195.7454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21112 lossL: tensor(1216.3123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21113 lossL: tensor(1247.1493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21114 lossL: tensor(1112.8099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21115 lossL: tensor(1194.7279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21116 lossL: tensor(1205.2604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21117 lossL: tensor(1174.1056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21118 lossL: tensor(1159.2269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21119 lossL: tensor(1282.1495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21120 lossL: tensor(1149.5179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21121 lossL: tensor(1283.7759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21122 lossL: tensor(1252.0126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21123 lossL: tensor(1263.3918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21124 lossL: tensor(1225.6532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21125 lossL: tensor(1283.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21126 lossL: tensor(1205.9667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21127 lossL: tensor(1255.3986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21128 lossL: tensor(1292.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21129 lossL: tensor(1244.0868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21130 lossL: tensor(1387.5529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21131 lossL: tensor(1134.6422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21132 lossL: tensor(1135.4338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21133 lossL: tensor(1204.5414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21134 lossL: tensor(1113.6348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21135 lossL: tensor(1229.5192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21136 lossL: tensor(1146.2949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21137 lossL: tensor(1227.5989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21138 lossL: tensor(1094.7737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21139 lossL: tensor(1123.1753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21140 lossL: tensor(1138.2351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21141 lossL: tensor(1280.4506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21142 lossL: tensor(1252.1064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21143 lossL: tensor(1214.6576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21144 lossL: tensor(1140.7847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21145 lossL: tensor(1150.9139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21146 lossL: tensor(1157.0912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21147 lossL: tensor(1059.0735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21148 lossL: tensor(1137.4155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21149 lossL: tensor(1206.9387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21150 lossL: tensor(1243.0184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21151 lossL: tensor(1290.3824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21152 lossL: tensor(1301.8578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21153 lossL: tensor(1191.0587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21154 lossL: tensor(1298.3864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21155 lossL: tensor(1231.3990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21156 lossL: tensor(1184.1571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21157 lossL: tensor(1207.9374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21158 lossL: tensor(1187.1611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21159 lossL: tensor(1159.7078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21160 lossL: tensor(1024.6160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "21161 lossL: tensor(1121.5988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21162 lossL: tensor(1126.0096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21163 lossL: tensor(1213.2250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21164 lossL: tensor(1073.7407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21165 lossL: tensor(1220.9529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21166 lossL: tensor(1179.8018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21167 lossL: tensor(1073.0376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21168 lossL: tensor(1200.7643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21169 lossL: tensor(1215.9623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21170 lossL: tensor(1148.9060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21171 lossL: tensor(1072.3452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21172 lossL: tensor(1056.2004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21173 lossL: tensor(1162.3300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21174 lossL: tensor(1262.0581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21175 lossL: tensor(1178.4252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21176 lossL: tensor(1198.7620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21177 lossL: tensor(1156.9591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21178 lossL: tensor(1160.7848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21179 lossL: tensor(1262.8827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21180 lossL: tensor(1227.2693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21181 lossL: tensor(1174.5638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21182 lossL: tensor(1180.6135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21183 lossL: tensor(1167.3728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21184 lossL: tensor(1193.8738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21185 lossL: tensor(1115.4618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21186 lossL: tensor(1158.0638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21187 lossL: tensor(1182.2018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21188 lossL: tensor(1144.4692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21189 lossL: tensor(1086.3868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21190 lossL: tensor(1072.5431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21191 lossL: tensor(1077.4498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21192 lossL: tensor(1178.2677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21193 lossL: tensor(1134.3434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21194 lossL: tensor(1135.3871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21195 lossL: tensor(1235.8958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21196 lossL: tensor(1161.1986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21197 lossL: tensor(1094.7542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21198 lossL: tensor(1411.8721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21199 lossL: tensor(1074.6265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21200 lossL: tensor(1248.1304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21201 lossL: tensor(1293.1475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21202 lossL: tensor(1175.3662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21203 lossL: tensor(1187.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21204 lossL: tensor(1279.2773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21205 lossL: tensor(1184.0591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21206 lossL: tensor(1201.0325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21207 lossL: tensor(1175.9999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21208 lossL: tensor(1163.6105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21209 lossL: tensor(1241.4803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21210 lossL: tensor(1057.3779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21211 lossL: tensor(1241.5553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21212 lossL: tensor(1136.3967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21213 lossL: tensor(1213.4412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21214 lossL: tensor(1119.5006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21215 lossL: tensor(1185.2960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21216 lossL: tensor(1178.6505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21217 lossL: tensor(1118.1270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21218 lossL: tensor(1199.7363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21219 lossL: tensor(1173.6144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21220 lossL: tensor(1334.8262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21221 lossL: tensor(1266.8942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21222 lossL: tensor(1180.4653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21223 lossL: tensor(1133.2262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21224 lossL: tensor(1218.2313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21225 lossL: tensor(1201.4547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21226 lossL: tensor(1248.6615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21227 lossL: tensor(1257.1835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21228 lossL: tensor(1163.6180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21229 lossL: tensor(1269.2141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21230 lossL: tensor(1148.4648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21231 lossL: tensor(1327.6208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21232 lossL: tensor(1031.6760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21233 lossL: tensor(1217.9502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21234 lossL: tensor(1187.3386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21235 lossL: tensor(1202.8505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21236 lossL: tensor(1130.1633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21237 lossL: tensor(1196.9497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21238 lossL: tensor(1116.6298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21239 lossL: tensor(1177.4882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21240 lossL: tensor(1192.6760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21241 lossL: tensor(1322.5126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21242 lossL: tensor(1125.8545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21243 lossL: tensor(1158.5881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21244 lossL: tensor(1180.1547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21245 lossL: tensor(1078.1178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21246 lossL: tensor(1137.0834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21247 lossL: tensor(1156.4685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21248 lossL: tensor(1199.3378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21249 lossL: tensor(1073.7358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21250 lossL: tensor(1179.2126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21251 lossL: tensor(1168.6021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21252 lossL: tensor(1243.3723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21253 lossL: tensor(1133.7501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21254 lossL: tensor(1160.7704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21255 lossL: tensor(1057.8232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21256 lossL: tensor(1137.6173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21257 lossL: tensor(1197.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21258 lossL: tensor(1159.1945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21259 lossL: tensor(1165.9310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21260 lossL: tensor(1096.4227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21261 lossL: tensor(1265.6519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21262 lossL: tensor(1220.2423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21263 lossL: tensor(1180.6218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21264 lossL: tensor(1270.7272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21265 lossL: tensor(1243.8691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21266 lossL: tensor(1226.4373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21267 lossL: tensor(1182.2090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21268 lossL: tensor(1197.3241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21269 lossL: tensor(1243.3179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21270 lossL: tensor(1050.3442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21271 lossL: tensor(1109.7170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21272 lossL: tensor(1183.3470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21273 lossL: tensor(1259.8695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21274 lossL: tensor(1164.1786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21275 lossL: tensor(1278.8328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21276 lossL: tensor(1240.6100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21277 lossL: tensor(1193.4865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21278 lossL: tensor(1172.4498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21279 lossL: tensor(1243.7058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21280 lossL: tensor(1130.2651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21281 lossL: tensor(1158.5515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21282 lossL: tensor(1262.0715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21283 lossL: tensor(1254.3149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21284 lossL: tensor(1237.9980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21285 lossL: tensor(1246.4460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21286 lossL: tensor(1107.8644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21287 lossL: tensor(1111.5936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21288 lossL: tensor(1155.9463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21289 lossL: tensor(1208.3075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21290 lossL: tensor(1227.5731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21291 lossL: tensor(1232.9025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21292 lossL: tensor(1080.6033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21293 lossL: tensor(1264.4841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21294 lossL: tensor(1147.9514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21295 lossL: tensor(1210.3337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21296 lossL: tensor(1234.0105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21297 lossL: tensor(1118.3478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21298 lossL: tensor(1104.5275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21299 lossL: tensor(1063.1262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21300 lossL: tensor(1076.6417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21301 lossL: tensor(1210.5168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21302 lossL: tensor(1196.2095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21303 lossL: tensor(1191.0918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21304 lossL: tensor(1071.1621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21305 lossL: tensor(1069.5005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21306 lossL: tensor(1078.9320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21307 lossL: tensor(1109.9424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21308 lossL: tensor(1214.8197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21309 lossL: tensor(1109.8329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21310 lossL: tensor(1111.3812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21311 lossL: tensor(1195.2415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21312 lossL: tensor(1187.8174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21313 lossL: tensor(1220.8020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21314 lossL: tensor(1179.9485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21315 lossL: tensor(1086.4263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21316 lossL: tensor(1046.5345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21317 lossL: tensor(1152.6482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21318 lossL: tensor(1155.5818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21319 lossL: tensor(1169.8395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21320 lossL: tensor(1046.2296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21321 lossL: tensor(1086.3097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21322 lossL: tensor(1174.0807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21323 lossL: tensor(1169.5477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21324 lossL: tensor(1162.2300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21325 lossL: tensor(1212.9417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21326 lossL: tensor(1184.3163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21327 lossL: tensor(1183.9781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21328 lossL: tensor(1096.7239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21329 lossL: tensor(1155.3291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21330 lossL: tensor(1051.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21331 lossL: tensor(1171.2455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21332 lossL: tensor(1192.0740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21333 lossL: tensor(1129.4695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21334 lossL: tensor(1053.9183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21335 lossL: tensor(1108.2471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21336 lossL: tensor(1151.4142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21337 lossL: tensor(1064.3716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21338 lossL: tensor(1155.5034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21339 lossL: tensor(1164.7443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21340 lossL: tensor(1111.0951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21341 lossL: tensor(1119.8602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21342 lossL: tensor(1083.3274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21343 lossL: tensor(1126.9374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21344 lossL: tensor(1153.0432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21345 lossL: tensor(1172.8792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21346 lossL: tensor(1120.0903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21347 lossL: tensor(1121.2438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21348 lossL: tensor(1149.9618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21349 lossL: tensor(1132.9606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21350 lossL: tensor(1078.2122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21351 lossL: tensor(1214.9207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21352 lossL: tensor(1028.6559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21353 lossL: tensor(1099.5339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21354 lossL: tensor(1149.7211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21355 lossL: tensor(1143.1331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21356 lossL: tensor(1150.9657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21357 lossL: tensor(1287.7585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21358 lossL: tensor(1096.8481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21359 lossL: tensor(1157.6667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21360 lossL: tensor(1156.1229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21361 lossL: tensor(1205.6849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21362 lossL: tensor(1172.9597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21363 lossL: tensor(1101.2839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21364 lossL: tensor(1119.1453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21365 lossL: tensor(1063.9381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21366 lossL: tensor(1158.6562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21367 lossL: tensor(1076.6559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21368 lossL: tensor(1163.3617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21369 lossL: tensor(1125.8154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21370 lossL: tensor(1138.1090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21371 lossL: tensor(1173.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21372 lossL: tensor(1240.3486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21373 lossL: tensor(1251.7173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21374 lossL: tensor(1080.0090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21375 lossL: tensor(1133.9478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21376 lossL: tensor(1089.2145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21377 lossL: tensor(1114.4857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21378 lossL: tensor(1300.4485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21379 lossL: tensor(1135.8425, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21380 lossL: tensor(1276.3329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21381 lossL: tensor(1114.3668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21382 lossL: tensor(1158.7443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21383 lossL: tensor(1211.4973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21384 lossL: tensor(1062.5455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21385 lossL: tensor(1203.0052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21386 lossL: tensor(1215.3300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21387 lossL: tensor(1239.4146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21388 lossL: tensor(1127.4579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21389 lossL: tensor(1298.2572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21390 lossL: tensor(1238.8270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21391 lossL: tensor(1173.7979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21392 lossL: tensor(1238.1849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21393 lossL: tensor(1028.4360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21394 lossL: tensor(1281.9913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21395 lossL: tensor(1240.0739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21396 lossL: tensor(1202.0591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21397 lossL: tensor(1181.1841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21398 lossL: tensor(1184.3002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21399 lossL: tensor(1163.7076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21400 lossL: tensor(1155.7457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21401 lossL: tensor(1232.8455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21402 lossL: tensor(1111.3866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21403 lossL: tensor(1146.7559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21404 lossL: tensor(1040.1384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21405 lossL: tensor(1178.4999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21406 lossL: tensor(1062.5664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21407 lossL: tensor(1181.0642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21408 lossL: tensor(1078.3622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21409 lossL: tensor(1177.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21410 lossL: tensor(1138.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21411 lossL: tensor(1053.0171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21412 lossL: tensor(1193.6866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21413 lossL: tensor(1070.0500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21414 lossL: tensor(1189.1403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21415 lossL: tensor(1101.5001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21416 lossL: tensor(1032.4447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21417 lossL: tensor(1132.5686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21418 lossL: tensor(1210.4983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21419 lossL: tensor(1022.1857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "21420 lossL: tensor(1236.2535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21421 lossL: tensor(1212.9043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21422 lossL: tensor(1156.9348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21423 lossL: tensor(1258.0320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21424 lossL: tensor(1177.2954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21425 lossL: tensor(1119.9451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21426 lossL: tensor(1158.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21427 lossL: tensor(1118.0470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21428 lossL: tensor(1100.2904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21429 lossL: tensor(1122.8987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21430 lossL: tensor(1173.8241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21431 lossL: tensor(1126.1145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21432 lossL: tensor(1103.9205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21433 lossL: tensor(1162.1544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21434 lossL: tensor(1031.9238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21435 lossL: tensor(1069.1782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21436 lossL: tensor(1045.1489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21437 lossL: tensor(1184.2898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21438 lossL: tensor(1116.3618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21439 lossL: tensor(1287.0648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21440 lossL: tensor(1083.5149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21441 lossL: tensor(1105.9106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21442 lossL: tensor(1034.6500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21443 lossL: tensor(1122.3201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21444 lossL: tensor(1131.2764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21445 lossL: tensor(1223.6460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21446 lossL: tensor(1100.1329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21447 lossL: tensor(1125.9465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21448 lossL: tensor(1115.4996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21449 lossL: tensor(1129.1853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21450 lossL: tensor(1096.2064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21451 lossL: tensor(1184.6224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21452 lossL: tensor(1161.6044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21453 lossL: tensor(1145.5045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21454 lossL: tensor(1144.0825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21455 lossL: tensor(1150.3375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21456 lossL: tensor(1161.4312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21457 lossL: tensor(1098.1038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21458 lossL: tensor(1092.4174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21459 lossL: tensor(1161.0486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21460 lossL: tensor(1072.3446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21461 lossL: tensor(1162.4143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21462 lossL: tensor(1140.3992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21463 lossL: tensor(1174.7731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21464 lossL: tensor(1141.2283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21465 lossL: tensor(1030.7811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21466 lossL: tensor(1290.3289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21467 lossL: tensor(1178.9984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21468 lossL: tensor(1116.0101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21469 lossL: tensor(1107.3127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21470 lossL: tensor(1109.3175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21471 lossL: tensor(1132.7241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21472 lossL: tensor(1152.0723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21473 lossL: tensor(1204.7798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21474 lossL: tensor(1193.0380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21475 lossL: tensor(1030.7177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21476 lossL: tensor(1102.5222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21477 lossL: tensor(1136.7440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21478 lossL: tensor(1242.9874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21479 lossL: tensor(1070.2847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21480 lossL: tensor(1107.2909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21481 lossL: tensor(1154.7150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21482 lossL: tensor(1254.4902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21483 lossL: tensor(1227.8765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21484 lossL: tensor(1322.1365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21485 lossL: tensor(1303.1465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21486 lossL: tensor(1209.1033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21487 lossL: tensor(1482.0906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21488 lossL: tensor(1133.3881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21489 lossL: tensor(1325.9204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21490 lossL: tensor(1224.6495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21491 lossL: tensor(1168.2200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21492 lossL: tensor(1330.3336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21493 lossL: tensor(1101.9921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21494 lossL: tensor(1200.9550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21495 lossL: tensor(1115.8755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21496 lossL: tensor(1203.3990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21497 lossL: tensor(1153.3146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21498 lossL: tensor(1338.8824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21499 lossL: tensor(1204.4487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21500 lossL: tensor(1106.3922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21501 lossL: tensor(1202.7080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21502 lossL: tensor(1096.7825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21503 lossL: tensor(1242.7659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21504 lossL: tensor(1180.1757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21505 lossL: tensor(1221.9606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21506 lossL: tensor(1293.8835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21507 lossL: tensor(1234.6633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21508 lossL: tensor(1179.9036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21509 lossL: tensor(1097.4666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21510 lossL: tensor(1089.1180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21511 lossL: tensor(1091.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21512 lossL: tensor(1262.4218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21513 lossL: tensor(1052.1288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21514 lossL: tensor(1052.9401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21515 lossL: tensor(1118.7603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21516 lossL: tensor(1225.5057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21517 lossL: tensor(1059.7671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21518 lossL: tensor(1216.7495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21519 lossL: tensor(1185.2209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21520 lossL: tensor(1212.6454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21521 lossL: tensor(1155.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21522 lossL: tensor(1079.2402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21523 lossL: tensor(1157.2504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21524 lossL: tensor(1117.9728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21525 lossL: tensor(1125.9856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21526 lossL: tensor(1198.2544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21527 lossL: tensor(1091.1599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21528 lossL: tensor(1100.0569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21529 lossL: tensor(1034.3429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21530 lossL: tensor(1125.3729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21531 lossL: tensor(1092.1849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21532 lossL: tensor(1194.0010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21533 lossL: tensor(1058.5428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21534 lossL: tensor(1089.3331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21535 lossL: tensor(1070.6205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21536 lossL: tensor(1159.6500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21537 lossL: tensor(1053.6996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21538 lossL: tensor(1189.8608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21539 lossL: tensor(1178.7012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21540 lossL: tensor(1075.6045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21541 lossL: tensor(1176.4877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21542 lossL: tensor(1124.8763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21543 lossL: tensor(1119.9436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21544 lossL: tensor(1191.1536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21545 lossL: tensor(1016.4908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "21546 lossL: tensor(1187.9980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21547 lossL: tensor(1115.3611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21548 lossL: tensor(1235.7784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21549 lossL: tensor(1096.4496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21550 lossL: tensor(1228.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21551 lossL: tensor(1141.8524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21552 lossL: tensor(1212.9846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21553 lossL: tensor(1394.1172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21554 lossL: tensor(1175.5011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21555 lossL: tensor(1456.8069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21556 lossL: tensor(1362.9236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21557 lossL: tensor(1011.1121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "21558 lossL: tensor(1138.4758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21559 lossL: tensor(1046.0829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21560 lossL: tensor(1083.9679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21561 lossL: tensor(1157.9011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21562 lossL: tensor(1169.6317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21563 lossL: tensor(1229.6357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21564 lossL: tensor(1088.2040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21565 lossL: tensor(1084.5885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21566 lossL: tensor(1150.5728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21567 lossL: tensor(1118.0845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21568 lossL: tensor(1088.0997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21569 lossL: tensor(1003.4412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "21570 lossL: tensor(1332.7561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21571 lossL: tensor(1119.5670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21572 lossL: tensor(1060.5565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21573 lossL: tensor(1182.1318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21574 lossL: tensor(1220.5503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21575 lossL: tensor(1045.8254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21576 lossL: tensor(1087.5015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21577 lossL: tensor(1087.8573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21578 lossL: tensor(1041.3730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21579 lossL: tensor(1111.8153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21580 lossL: tensor(1104.4711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21581 lossL: tensor(1200.8715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21582 lossL: tensor(1163.9260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21583 lossL: tensor(1061.4324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21584 lossL: tensor(1194.5442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21585 lossL: tensor(1125.2313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21586 lossL: tensor(1128.3610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21587 lossL: tensor(1214.7931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21588 lossL: tensor(1237.9442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21589 lossL: tensor(1306.6085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21590 lossL: tensor(1087.0067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21591 lossL: tensor(1206.7139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21592 lossL: tensor(1225.1560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21593 lossL: tensor(1328.2904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21594 lossL: tensor(1366.0428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21595 lossL: tensor(1143.4675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21596 lossL: tensor(1176.8673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21597 lossL: tensor(1160.7035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21598 lossL: tensor(1294.5465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21599 lossL: tensor(1146.6080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21600 lossL: tensor(1201.8369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21601 lossL: tensor(1083.6981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21602 lossL: tensor(1119.6366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21603 lossL: tensor(1163.9464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21604 lossL: tensor(1096.6433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21605 lossL: tensor(1295.8589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21606 lossL: tensor(1119.5353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21607 lossL: tensor(1224.3678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21608 lossL: tensor(1083.7765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21609 lossL: tensor(1342.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21610 lossL: tensor(1266.0220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21611 lossL: tensor(1267.2852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21612 lossL: tensor(1317.9729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21613 lossL: tensor(1144.0566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21614 lossL: tensor(1231.8020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21615 lossL: tensor(1161.5239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21616 lossL: tensor(1176.3911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21617 lossL: tensor(1141.5000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21618 lossL: tensor(1279.8853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21619 lossL: tensor(1208.0552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21620 lossL: tensor(1223.3561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21621 lossL: tensor(1176.3286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21622 lossL: tensor(1089.8619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21623 lossL: tensor(1175.3337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21624 lossL: tensor(1198.5120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21625 lossL: tensor(1091.1511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21626 lossL: tensor(1164.6951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21627 lossL: tensor(1076.4794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21628 lossL: tensor(1180.1925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21629 lossL: tensor(1121.0303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21630 lossL: tensor(1135.6396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21631 lossL: tensor(1106.3131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21632 lossL: tensor(1077.8728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21633 lossL: tensor(1121.4115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21634 lossL: tensor(1064.7872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21635 lossL: tensor(1107.8146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21636 lossL: tensor(1150.8987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21637 lossL: tensor(1224.9177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21638 lossL: tensor(1110.8363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21639 lossL: tensor(1076.4496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21640 lossL: tensor(1103.9333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21641 lossL: tensor(1146.5217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21642 lossL: tensor(1166.1519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21643 lossL: tensor(1234.8099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21644 lossL: tensor(1041.8729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21645 lossL: tensor(1135.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21646 lossL: tensor(1018.3251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21647 lossL: tensor(1111.3616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21648 lossL: tensor(1195.3094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21649 lossL: tensor(1396.7301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21650 lossL: tensor(1224.6187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21651 lossL: tensor(1324.6536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21652 lossL: tensor(1293.9097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21653 lossL: tensor(1284.5474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21654 lossL: tensor(1301.4724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21655 lossL: tensor(1035.8622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21656 lossL: tensor(1196.6660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21657 lossL: tensor(1066.8486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21658 lossL: tensor(1234.0929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21659 lossL: tensor(1163.2654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21660 lossL: tensor(1260.1061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21661 lossL: tensor(1203.4663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21662 lossL: tensor(1012.3038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21663 lossL: tensor(1106.4183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21664 lossL: tensor(1226.6626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21665 lossL: tensor(1181.6395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21666 lossL: tensor(1101.4333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21667 lossL: tensor(1160.5726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21668 lossL: tensor(1187.7395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21669 lossL: tensor(1119.9806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21670 lossL: tensor(1141.2214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21671 lossL: tensor(1138.6304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21672 lossL: tensor(1078.8588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21673 lossL: tensor(1018.7740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21674 lossL: tensor(1017.2047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21675 lossL: tensor(1139.4708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21676 lossL: tensor(1195.1577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21677 lossL: tensor(1044.1174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21678 lossL: tensor(1140.7245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21679 lossL: tensor(1055.5931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21680 lossL: tensor(1159.5759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21681 lossL: tensor(1059.6888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21682 lossL: tensor(1204.0175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21683 lossL: tensor(1129.4337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21684 lossL: tensor(1197.0291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21685 lossL: tensor(1132.7325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21686 lossL: tensor(1095.0677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21687 lossL: tensor(1158.6840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21688 lossL: tensor(1161.9927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21689 lossL: tensor(1142.0243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21690 lossL: tensor(1134.3229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21691 lossL: tensor(1225.6290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21692 lossL: tensor(1215.3682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21693 lossL: tensor(1201.6635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21694 lossL: tensor(1141.9629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21695 lossL: tensor(1087.9645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21696 lossL: tensor(1188.6825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21697 lossL: tensor(1063.8427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21698 lossL: tensor(1051.9291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21699 lossL: tensor(1220.3914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21700 lossL: tensor(1111.9575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21701 lossL: tensor(1069.0920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21702 lossL: tensor(1065.9172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21703 lossL: tensor(1148.6375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21704 lossL: tensor(1144.7517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21705 lossL: tensor(1096.2904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21706 lossL: tensor(1020.1545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21707 lossL: tensor(1148.5531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21708 lossL: tensor(1178.6355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21709 lossL: tensor(1069.4540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21710 lossL: tensor(1319.9008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21711 lossL: tensor(1176.3040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21712 lossL: tensor(1184.5546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21713 lossL: tensor(1155.1295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21714 lossL: tensor(1113.6428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21715 lossL: tensor(1114.6136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21716 lossL: tensor(1156.3827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21717 lossL: tensor(1095.7740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21718 lossL: tensor(1049.9719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21719 lossL: tensor(1145.8484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21720 lossL: tensor(1143.6042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21721 lossL: tensor(1302.7821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21722 lossL: tensor(1312.4314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21723 lossL: tensor(1229.5475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21724 lossL: tensor(1243.5061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21725 lossL: tensor(1206.4397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21726 lossL: tensor(1216.6565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21727 lossL: tensor(1378.6924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21728 lossL: tensor(1078.7693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21729 lossL: tensor(1416.0834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21730 lossL: tensor(1006.4324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21731 lossL: tensor(1336.9265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21732 lossL: tensor(1117.6024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21733 lossL: tensor(1462.8490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21734 lossL: tensor(1236.5929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21735 lossL: tensor(1274.5663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21736 lossL: tensor(1197.6815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21737 lossL: tensor(1237.2100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21738 lossL: tensor(1150.9557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21739 lossL: tensor(1214.7225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21740 lossL: tensor(1290.6852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21741 lossL: tensor(1204.1655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21742 lossL: tensor(1451.3833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21743 lossL: tensor(1125.1570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21744 lossL: tensor(1458.0890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21745 lossL: tensor(1196.0549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21746 lossL: tensor(1349.3123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21747 lossL: tensor(1095.7662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21748 lossL: tensor(1476.0122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21749 lossL: tensor(1120.2194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21750 lossL: tensor(1233.2650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21751 lossL: tensor(1082.1484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21752 lossL: tensor(1225.6564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21753 lossL: tensor(1196.3944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21754 lossL: tensor(973.6885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "21755 lossL: tensor(1139.1218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21756 lossL: tensor(1129.9493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21757 lossL: tensor(1023.3827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21758 lossL: tensor(1144.5558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21759 lossL: tensor(1137.9036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21760 lossL: tensor(1037.2487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21761 lossL: tensor(1082.9382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21762 lossL: tensor(1141.0486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21763 lossL: tensor(1106.9004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21764 lossL: tensor(1076.4153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21765 lossL: tensor(1130.3127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21766 lossL: tensor(1082.4427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21767 lossL: tensor(1103.7590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21768 lossL: tensor(1098.8282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21769 lossL: tensor(1175.3531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21770 lossL: tensor(1031.5164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21771 lossL: tensor(1311.3755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21772 lossL: tensor(1177.3690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21773 lossL: tensor(1195.9183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21774 lossL: tensor(1259.3546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21775 lossL: tensor(1195.7999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21776 lossL: tensor(1156.3003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21777 lossL: tensor(989.1060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21778 lossL: tensor(1200.0281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21779 lossL: tensor(1107.2014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21780 lossL: tensor(1256.4496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21781 lossL: tensor(1113.0583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21782 lossL: tensor(1226.4534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21783 lossL: tensor(1273.1060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21784 lossL: tensor(1086.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21785 lossL: tensor(1380.2128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21786 lossL: tensor(1120.1240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21787 lossL: tensor(1074.3295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21788 lossL: tensor(1121.9656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21789 lossL: tensor(1110.1019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21790 lossL: tensor(1049.3770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21791 lossL: tensor(1048.1033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21792 lossL: tensor(1198.7177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21793 lossL: tensor(1109.1600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21794 lossL: tensor(1173.9321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21795 lossL: tensor(987.8685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21796 lossL: tensor(1052.3257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21797 lossL: tensor(1190.9614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21798 lossL: tensor(1248.1516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21799 lossL: tensor(1126.5826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21800 lossL: tensor(1264.4325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21801 lossL: tensor(1238.1791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21802 lossL: tensor(1185.7325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21803 lossL: tensor(1156.1543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21804 lossL: tensor(1181.6064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21805 lossL: tensor(1309.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21806 lossL: tensor(985.4299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21807 lossL: tensor(1146.9005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21808 lossL: tensor(1235.5791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21809 lossL: tensor(1118.9989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21810 lossL: tensor(1009.8157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21811 lossL: tensor(1231.0322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21812 lossL: tensor(1077.1842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21813 lossL: tensor(1118.4852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21814 lossL: tensor(1132.3004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21815 lossL: tensor(1269.0248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21816 lossL: tensor(1120.3174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21817 lossL: tensor(1097.5453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21818 lossL: tensor(1145.0680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21819 lossL: tensor(1254.7836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21820 lossL: tensor(1132.9720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21821 lossL: tensor(1078.4797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21822 lossL: tensor(1153.8431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21823 lossL: tensor(1202.6189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21824 lossL: tensor(1127.2563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21825 lossL: tensor(1061.2682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21826 lossL: tensor(1146.7146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21827 lossL: tensor(1090.9478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21828 lossL: tensor(1266.8339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21829 lossL: tensor(1069.8168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21830 lossL: tensor(1154.8409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21831 lossL: tensor(1007.5702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21832 lossL: tensor(1091.7361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21833 lossL: tensor(1190.3467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21834 lossL: tensor(1219.2020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21835 lossL: tensor(1055.3611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21836 lossL: tensor(1032.9031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21837 lossL: tensor(1158.1053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21838 lossL: tensor(1166.0437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21839 lossL: tensor(1073.2947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21840 lossL: tensor(1296.9475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21841 lossL: tensor(1047.2260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21842 lossL: tensor(1273.6141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21843 lossL: tensor(1215.6486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21844 lossL: tensor(1056.2777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21845 lossL: tensor(1090.5232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21846 lossL: tensor(1057.8474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21847 lossL: tensor(1106.0905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21848 lossL: tensor(1018.8364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21849 lossL: tensor(1038.5864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21850 lossL: tensor(991.3620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21851 lossL: tensor(1138.8253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21852 lossL: tensor(1040.6537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21853 lossL: tensor(1079.0856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21854 lossL: tensor(1109.4081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21855 lossL: tensor(1189.6478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21856 lossL: tensor(1162.5272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21857 lossL: tensor(1087.8158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21858 lossL: tensor(1124.4994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21859 lossL: tensor(1072.5486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21860 lossL: tensor(1103.4076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21861 lossL: tensor(1109.9894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21862 lossL: tensor(1151.4329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21863 lossL: tensor(1154.7029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21864 lossL: tensor(1066.7372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21865 lossL: tensor(1098.6733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21866 lossL: tensor(1028.5580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21867 lossL: tensor(991.5053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21868 lossL: tensor(1085.5253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21869 lossL: tensor(1216.3922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21870 lossL: tensor(1068.3356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21871 lossL: tensor(1027.8136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21872 lossL: tensor(1006.8484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21873 lossL: tensor(1036.3177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21874 lossL: tensor(1079.0432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21875 lossL: tensor(1085.5366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21876 lossL: tensor(1085.8593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21877 lossL: tensor(1023.3253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21878 lossL: tensor(1120.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21879 lossL: tensor(1154.0543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21880 lossL: tensor(1001.3570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21881 lossL: tensor(1099.6937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21882 lossL: tensor(1049.5220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21883 lossL: tensor(1056.2983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21884 lossL: tensor(1115.4476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21885 lossL: tensor(1111.8165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21886 lossL: tensor(1058.6890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21887 lossL: tensor(1115.2507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21888 lossL: tensor(938.6625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "21889 lossL: tensor(1245.8958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21890 lossL: tensor(1159.3911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21891 lossL: tensor(1142.0979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21892 lossL: tensor(1184.2109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21893 lossL: tensor(1130.3354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21894 lossL: tensor(1334.2200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21895 lossL: tensor(1115.6877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21896 lossL: tensor(1401.5580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21897 lossL: tensor(1027.1007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21898 lossL: tensor(1322.4573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21899 lossL: tensor(1437.7769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21900 lossL: tensor(1044.4282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21901 lossL: tensor(1312.9009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21902 lossL: tensor(1064.7024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21903 lossL: tensor(1219.5594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21904 lossL: tensor(1122.4199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21905 lossL: tensor(1086.1899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21906 lossL: tensor(1023.2405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21907 lossL: tensor(1133.2437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21908 lossL: tensor(1069.6726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21909 lossL: tensor(1151.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21910 lossL: tensor(1030.6217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21911 lossL: tensor(1169.6063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21912 lossL: tensor(1209.8823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21913 lossL: tensor(1372.7306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21914 lossL: tensor(1060.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21915 lossL: tensor(1326.3502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21916 lossL: tensor(1004.8502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21917 lossL: tensor(1243.5596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21918 lossL: tensor(1071.4885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21919 lossL: tensor(1166.6936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21920 lossL: tensor(1191.4930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21921 lossL: tensor(1057.1467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21922 lossL: tensor(1084.9393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21923 lossL: tensor(1086.3726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21924 lossL: tensor(1215.7997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21925 lossL: tensor(1131.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21926 lossL: tensor(1277.2731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21927 lossL: tensor(1096.6392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21928 lossL: tensor(1126.3142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21929 lossL: tensor(1087.0980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21930 lossL: tensor(1198.8566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21931 lossL: tensor(1183.4191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21932 lossL: tensor(1146.0273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21933 lossL: tensor(1206.4905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21934 lossL: tensor(1115.7823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21935 lossL: tensor(1336.6926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21936 lossL: tensor(1102.1553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21937 lossL: tensor(1331.3422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21938 lossL: tensor(981.4548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21939 lossL: tensor(1283.3904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21940 lossL: tensor(1144.5748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21941 lossL: tensor(1087.1382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21942 lossL: tensor(1064.7671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21943 lossL: tensor(1221.0763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21944 lossL: tensor(1040.6792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21945 lossL: tensor(1070.5132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21946 lossL: tensor(1162.2765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21947 lossL: tensor(1093.4518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21948 lossL: tensor(1109.8619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21949 lossL: tensor(1054.8818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21950 lossL: tensor(1062.9222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21951 lossL: tensor(1045.4153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21952 lossL: tensor(1002.1769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21953 lossL: tensor(1096.1527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21954 lossL: tensor(1073.4127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21955 lossL: tensor(1174.2585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21956 lossL: tensor(1019.8375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21957 lossL: tensor(1173.2565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21958 lossL: tensor(1179.8177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21959 lossL: tensor(1162.3500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21960 lossL: tensor(1178.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21961 lossL: tensor(1171.3601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21962 lossL: tensor(1193.4673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21963 lossL: tensor(1055.3342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21964 lossL: tensor(1255.9490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21965 lossL: tensor(1050.6895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21966 lossL: tensor(1199.1530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21967 lossL: tensor(1051.4380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21968 lossL: tensor(1134.2411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21969 lossL: tensor(1090.3677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21970 lossL: tensor(986.6159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21971 lossL: tensor(1082.6709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21972 lossL: tensor(1067.9567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21973 lossL: tensor(1103.4983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21974 lossL: tensor(1129.7667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21975 lossL: tensor(1105.3879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21976 lossL: tensor(1188.1685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21977 lossL: tensor(1057.2997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21978 lossL: tensor(1054.5201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21979 lossL: tensor(1037.1108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21980 lossL: tensor(1072.5593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21981 lossL: tensor(1188.6058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21982 lossL: tensor(1049.3550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21983 lossL: tensor(989.4879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21984 lossL: tensor(1057.9941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21985 lossL: tensor(1116.5122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21986 lossL: tensor(1110.1130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21987 lossL: tensor(1010.9986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21988 lossL: tensor(1016.6646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21989 lossL: tensor(1064.9347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21990 lossL: tensor(1100.8622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21991 lossL: tensor(1034.0835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21992 lossL: tensor(1085.5447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21993 lossL: tensor(1167.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21994 lossL: tensor(1019.2028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21995 lossL: tensor(1126.2762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21996 lossL: tensor(1088.8890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21997 lossL: tensor(1300.6561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21998 lossL: tensor(1082.5963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "21999 lossL: tensor(1385.7516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22000 lossL: tensor(1334.2152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22001 lossL: tensor(1227.0538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22002 lossL: tensor(1375.4921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22003 lossL: tensor(1243.8833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22004 lossL: tensor(1378.8613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22005 lossL: tensor(1186.9025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22006 lossL: tensor(1332.9307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22007 lossL: tensor(1101.7336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22008 lossL: tensor(1433.0603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22009 lossL: tensor(1029.0372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22010 lossL: tensor(1210.2330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22011 lossL: tensor(1099.0165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22012 lossL: tensor(1299.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22013 lossL: tensor(1054.1278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22014 lossL: tensor(1227.0916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22015 lossL: tensor(994.1918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22016 lossL: tensor(1094.0645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22017 lossL: tensor(1227.9197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22018 lossL: tensor(1071.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22019 lossL: tensor(1060.7737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22020 lossL: tensor(1013.8226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22021 lossL: tensor(1215.7004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22022 lossL: tensor(1056.3541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22023 lossL: tensor(1092.0492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22024 lossL: tensor(1094.5583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22025 lossL: tensor(1080.1467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22026 lossL: tensor(1086.8706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22027 lossL: tensor(1160.8063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22028 lossL: tensor(1168.8290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22029 lossL: tensor(992.8804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22030 lossL: tensor(1109.2020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22031 lossL: tensor(1131.6775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22032 lossL: tensor(974.6057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22033 lossL: tensor(1171.5854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22034 lossL: tensor(1134.0797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22035 lossL: tensor(1072.2699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22036 lossL: tensor(1081.0997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22037 lossL: tensor(1146.6924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22038 lossL: tensor(1111.0773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22039 lossL: tensor(1080.2245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22040 lossL: tensor(1102.2515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22041 lossL: tensor(1095.5011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22042 lossL: tensor(1122.3344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22043 lossL: tensor(1069.4945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22044 lossL: tensor(1126.3319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22045 lossL: tensor(1199.6542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22046 lossL: tensor(1120.9144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22047 lossL: tensor(1064.9849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22048 lossL: tensor(1108.2003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22049 lossL: tensor(1131.5853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22050 lossL: tensor(1112.2460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22051 lossL: tensor(1155.7883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22052 lossL: tensor(1071.2009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22053 lossL: tensor(1170.2241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22054 lossL: tensor(1082.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22055 lossL: tensor(1053.7327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22056 lossL: tensor(1115.0116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22057 lossL: tensor(1053.6085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22058 lossL: tensor(961.3875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22059 lossL: tensor(1107.6831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22060 lossL: tensor(1072.2020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22061 lossL: tensor(1097.7516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22062 lossL: tensor(1098.2363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22063 lossL: tensor(1088.4058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22064 lossL: tensor(1205.9623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22065 lossL: tensor(1067.5690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22066 lossL: tensor(1171.9027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22067 lossL: tensor(1047.7521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22068 lossL: tensor(1069.5599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22069 lossL: tensor(1073.6012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22070 lossL: tensor(1060.6760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22071 lossL: tensor(1035.6508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22072 lossL: tensor(983.9788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22073 lossL: tensor(1006.5502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22074 lossL: tensor(1110.2358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22075 lossL: tensor(1153.7533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22076 lossL: tensor(1090.9285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22077 lossL: tensor(1017.1932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22078 lossL: tensor(1038.0522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22079 lossL: tensor(1165.1954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22080 lossL: tensor(1092.3618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22081 lossL: tensor(1152.8690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22082 lossL: tensor(994.1847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22083 lossL: tensor(1000.3817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22084 lossL: tensor(1065.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22085 lossL: tensor(1031.1437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22086 lossL: tensor(1034.9336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22087 lossL: tensor(1089.7260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22088 lossL: tensor(1038.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22089 lossL: tensor(1012.6516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22090 lossL: tensor(1107.9708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22091 lossL: tensor(1088.2977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22092 lossL: tensor(1013.0472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22093 lossL: tensor(1070.9312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22094 lossL: tensor(1066.8188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22095 lossL: tensor(1079.0610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22096 lossL: tensor(1016.1396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22097 lossL: tensor(1188.3098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22098 lossL: tensor(1123.6542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22099 lossL: tensor(1060.4600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22100 lossL: tensor(1062.7211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22101 lossL: tensor(1060.7620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22102 lossL: tensor(1109.6381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22103 lossL: tensor(1108.2441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22104 lossL: tensor(1063.9957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22105 lossL: tensor(1058.2955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22106 lossL: tensor(998.6343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22107 lossL: tensor(1097.9586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22108 lossL: tensor(1063.0175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22109 lossL: tensor(1015.1617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22110 lossL: tensor(1014.6108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22111 lossL: tensor(1059.2679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22112 lossL: tensor(1175.8915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22113 lossL: tensor(1091.8909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22114 lossL: tensor(1067.4329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22115 lossL: tensor(1096.4462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22116 lossL: tensor(1145.0940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22117 lossL: tensor(1010.1005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22118 lossL: tensor(1066.1854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22119 lossL: tensor(1090.6382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22120 lossL: tensor(1268.5796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22121 lossL: tensor(1089.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22122 lossL: tensor(1044.0992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22123 lossL: tensor(1120.4319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22124 lossL: tensor(1126.6672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22125 lossL: tensor(1034.5879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22126 lossL: tensor(1139.2748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22127 lossL: tensor(1143.3126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22128 lossL: tensor(1117.4921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22129 lossL: tensor(1117.2305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22130 lossL: tensor(1017.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22131 lossL: tensor(1155.9032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22132 lossL: tensor(1105.3372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22133 lossL: tensor(1005.3539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22134 lossL: tensor(1065.7224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22135 lossL: tensor(1003.4578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22136 lossL: tensor(1039.2113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22137 lossL: tensor(1034.4114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22138 lossL: tensor(1022.1176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22139 lossL: tensor(1063.9475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22140 lossL: tensor(1126.8762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22141 lossL: tensor(1078.2393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22142 lossL: tensor(976.8439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22143 lossL: tensor(1064.5088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22144 lossL: tensor(1046.2278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22145 lossL: tensor(1021.9340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22146 lossL: tensor(1153.6886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22147 lossL: tensor(1040.1195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22148 lossL: tensor(957.6246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22149 lossL: tensor(1043.7083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22150 lossL: tensor(1194.3915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22151 lossL: tensor(1071.9940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22152 lossL: tensor(994.4525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22153 lossL: tensor(1067.0145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22154 lossL: tensor(1027.1658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22155 lossL: tensor(1038.2878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22156 lossL: tensor(1018.7149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22157 lossL: tensor(1093.4065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22158 lossL: tensor(1065.3468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22159 lossL: tensor(1058.4514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22160 lossL: tensor(1040.7385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22161 lossL: tensor(1081.9447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22162 lossL: tensor(1057.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22163 lossL: tensor(1062.3938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22164 lossL: tensor(1200.5554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22165 lossL: tensor(986.5831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22166 lossL: tensor(995.2901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22167 lossL: tensor(1055.8928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22168 lossL: tensor(1021.2115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22169 lossL: tensor(1069.5243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22170 lossL: tensor(990.0532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22171 lossL: tensor(1120.8318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22172 lossL: tensor(1202.2551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22173 lossL: tensor(1017.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22174 lossL: tensor(1113.6678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22175 lossL: tensor(1045.6541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22176 lossL: tensor(1067.7548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22177 lossL: tensor(1052.7640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22178 lossL: tensor(1173.7629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22179 lossL: tensor(1108.4073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22180 lossL: tensor(1035.5188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22181 lossL: tensor(1117.9485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22182 lossL: tensor(1087.7463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22183 lossL: tensor(1136.0826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22184 lossL: tensor(1054.1350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22185 lossL: tensor(1048.1552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22186 lossL: tensor(1029.1473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22187 lossL: tensor(1032.7095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22188 lossL: tensor(1097.0311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22189 lossL: tensor(1003.6220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22190 lossL: tensor(1092.9805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22191 lossL: tensor(1079.7089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22192 lossL: tensor(1083.2323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22193 lossL: tensor(1003.5372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22194 lossL: tensor(1060.6958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22195 lossL: tensor(1030.3474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22196 lossL: tensor(996.5380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22197 lossL: tensor(1130.6194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22198 lossL: tensor(1052.5934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22199 lossL: tensor(1047.5461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22200 lossL: tensor(1086.4055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22201 lossL: tensor(988.1767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22202 lossL: tensor(1070.3845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22203 lossL: tensor(1053.6923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22204 lossL: tensor(1020.3475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22205 lossL: tensor(1061.5448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22206 lossL: tensor(1049.5684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22207 lossL: tensor(995.7098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22208 lossL: tensor(1177.7515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22209 lossL: tensor(1117.0037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22210 lossL: tensor(1122.8152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22211 lossL: tensor(1028.5535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22212 lossL: tensor(1051.1616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22213 lossL: tensor(939.3156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22214 lossL: tensor(1031.9022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22215 lossL: tensor(1084.7679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22216 lossL: tensor(965.1018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22217 lossL: tensor(1128.5173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22218 lossL: tensor(1113.7866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22219 lossL: tensor(1024.2043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22220 lossL: tensor(1153.6876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22221 lossL: tensor(1135.4742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22222 lossL: tensor(1151.3586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22223 lossL: tensor(1009.6170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22224 lossL: tensor(1066.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22225 lossL: tensor(1053.5278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22226 lossL: tensor(994.6265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22227 lossL: tensor(976.9633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22228 lossL: tensor(1081.5226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22229 lossL: tensor(993.1927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22230 lossL: tensor(1111.5597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22231 lossL: tensor(1046.7699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22232 lossL: tensor(1018.5555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22233 lossL: tensor(1129.6416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22234 lossL: tensor(1054.6473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22235 lossL: tensor(1069.2048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22236 lossL: tensor(1117.0616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22237 lossL: tensor(1125.4908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22238 lossL: tensor(1050.0481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22239 lossL: tensor(1034.3444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22240 lossL: tensor(1061.4674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22241 lossL: tensor(1104.3440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22242 lossL: tensor(1111.5171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22243 lossL: tensor(1039.2330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22244 lossL: tensor(1108.4824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22245 lossL: tensor(1149.1011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22246 lossL: tensor(1121.7831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22247 lossL: tensor(967.9478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22248 lossL: tensor(1025.2450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22249 lossL: tensor(1178.6859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22250 lossL: tensor(1093.0319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22251 lossL: tensor(1095.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22252 lossL: tensor(1167.3146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22253 lossL: tensor(1085.6099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22254 lossL: tensor(1113.3539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22255 lossL: tensor(991.3908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22256 lossL: tensor(1097.0364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22257 lossL: tensor(994.0114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22258 lossL: tensor(1077.9902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22259 lossL: tensor(1016.9167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22260 lossL: tensor(1073.6869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22261 lossL: tensor(1016.8047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22262 lossL: tensor(1037.4402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22263 lossL: tensor(956.9514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22264 lossL: tensor(1084.1263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22265 lossL: tensor(1192.6180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22266 lossL: tensor(1102.7039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22267 lossL: tensor(1023.1470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22268 lossL: tensor(1118.3817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22269 lossL: tensor(1046.3903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22270 lossL: tensor(1126.2074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22271 lossL: tensor(1129.8970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22272 lossL: tensor(1082.7943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22273 lossL: tensor(1128.3319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22274 lossL: tensor(1060.1672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22275 lossL: tensor(1072.0782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22276 lossL: tensor(1060.4767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22277 lossL: tensor(1047.3822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22278 lossL: tensor(1063.8053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22279 lossL: tensor(1132.7015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22280 lossL: tensor(1071.1036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22281 lossL: tensor(1324.5787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22282 lossL: tensor(1038.8845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22283 lossL: tensor(1270.3236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22284 lossL: tensor(1013.4194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22285 lossL: tensor(1108.8345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22286 lossL: tensor(1173.3285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22287 lossL: tensor(1001.7612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22288 lossL: tensor(1133.3613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22289 lossL: tensor(1113.9760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22290 lossL: tensor(1141.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22291 lossL: tensor(1046.7611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22292 lossL: tensor(1076.1826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22293 lossL: tensor(1004.8942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22294 lossL: tensor(997.5153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22295 lossL: tensor(1117.7926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22296 lossL: tensor(1045.2346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22297 lossL: tensor(991.5258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22298 lossL: tensor(1105.3545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22299 lossL: tensor(1022.4890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22300 lossL: tensor(1030.0447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22301 lossL: tensor(985.8907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22302 lossL: tensor(1017.6873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22303 lossL: tensor(1065.6495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22304 lossL: tensor(1045.5526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22305 lossL: tensor(1039.3328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22306 lossL: tensor(1022.3146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22307 lossL: tensor(1071.5176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22308 lossL: tensor(1170.1232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22309 lossL: tensor(1129.3237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22310 lossL: tensor(1106.8943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22311 lossL: tensor(1066.4296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22312 lossL: tensor(1318.6031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22313 lossL: tensor(1060.2465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22314 lossL: tensor(1208.2098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22315 lossL: tensor(1111.8978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22316 lossL: tensor(1104.0162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22317 lossL: tensor(1171.8589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22318 lossL: tensor(992.6873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22319 lossL: tensor(1108.6511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22320 lossL: tensor(1020.2004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22321 lossL: tensor(1084.2747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22322 lossL: tensor(1123.9509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22323 lossL: tensor(1059.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22324 lossL: tensor(1163.0729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22325 lossL: tensor(1025.9164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22326 lossL: tensor(1194.4100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22327 lossL: tensor(1089.5944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22328 lossL: tensor(1205.8774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22329 lossL: tensor(1084.4816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22330 lossL: tensor(1067.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22331 lossL: tensor(1169.0791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22332 lossL: tensor(1046.2814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22333 lossL: tensor(1160.3671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22334 lossL: tensor(988.7961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22335 lossL: tensor(1086.7347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22336 lossL: tensor(1044.7230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22337 lossL: tensor(983.6660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22338 lossL: tensor(1050.5857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22339 lossL: tensor(1021.9095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22340 lossL: tensor(1138.3148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22341 lossL: tensor(1109.3588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22342 lossL: tensor(1161.1293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22343 lossL: tensor(1057.5320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22344 lossL: tensor(1129.5415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22345 lossL: tensor(1102.9938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22346 lossL: tensor(1042.9906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22347 lossL: tensor(998.7678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22348 lossL: tensor(1103.0441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22349 lossL: tensor(1019.8829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22350 lossL: tensor(1078.3903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22351 lossL: tensor(1142.3293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22352 lossL: tensor(1128.7095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22353 lossL: tensor(1070.0800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22354 lossL: tensor(1090.5602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22355 lossL: tensor(1114.3019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22356 lossL: tensor(1091.5619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22357 lossL: tensor(1006.7974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22358 lossL: tensor(1058.4369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22359 lossL: tensor(1086.4286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22360 lossL: tensor(1026.6495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22361 lossL: tensor(936.3615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "22362 lossL: tensor(1011.7593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22363 lossL: tensor(1059.0193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22364 lossL: tensor(996.1790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22365 lossL: tensor(1069.9841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22366 lossL: tensor(1093.7452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22367 lossL: tensor(981.0961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22368 lossL: tensor(994.8692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22369 lossL: tensor(1028.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22370 lossL: tensor(1081.5726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22371 lossL: tensor(991.6767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22372 lossL: tensor(1017.8715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22373 lossL: tensor(1328.1083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22374 lossL: tensor(1178.2725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22375 lossL: tensor(1213.8550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22376 lossL: tensor(1074.4164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22377 lossL: tensor(1070.1396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22378 lossL: tensor(1115.6897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22379 lossL: tensor(1054.5985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22380 lossL: tensor(1162.8430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22381 lossL: tensor(974.7341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22382 lossL: tensor(1177.1509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22383 lossL: tensor(1021.6028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22384 lossL: tensor(1121.7197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22385 lossL: tensor(1024.2211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22386 lossL: tensor(1106.2155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22387 lossL: tensor(1152.8726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22388 lossL: tensor(1068.7004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22389 lossL: tensor(1213.2504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22390 lossL: tensor(1005.0579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22391 lossL: tensor(1207.4092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22392 lossL: tensor(1055.5161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22393 lossL: tensor(1096.6177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22394 lossL: tensor(1064.5922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22395 lossL: tensor(1158.4810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22396 lossL: tensor(1047.5167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22397 lossL: tensor(1015.0929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22398 lossL: tensor(1135.6809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22399 lossL: tensor(1014.4175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22400 lossL: tensor(1154.2476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22401 lossL: tensor(1196.3192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22402 lossL: tensor(998.7837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22403 lossL: tensor(1100.8859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22404 lossL: tensor(1109.2085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22405 lossL: tensor(1150.3821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22406 lossL: tensor(1079.4529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22407 lossL: tensor(1067.1333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22408 lossL: tensor(1234.7769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22409 lossL: tensor(1013.2742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22410 lossL: tensor(1174.8961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22411 lossL: tensor(1041.6157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22412 lossL: tensor(1091.4010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22413 lossL: tensor(1122.8423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22414 lossL: tensor(1067.5131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22415 lossL: tensor(1112.3416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22416 lossL: tensor(1007.3790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22417 lossL: tensor(980.8485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22418 lossL: tensor(1173.4945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22419 lossL: tensor(1054.3766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22420 lossL: tensor(1127.6733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22421 lossL: tensor(996.8491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22422 lossL: tensor(1115.5967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22423 lossL: tensor(1074.5642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22424 lossL: tensor(1030.4977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22425 lossL: tensor(1137.1678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22426 lossL: tensor(1094.7172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22427 lossL: tensor(1105.4618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22428 lossL: tensor(1018.6207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22429 lossL: tensor(924.0658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "22430 lossL: tensor(945.1248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22431 lossL: tensor(1021.4788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22432 lossL: tensor(1028.7120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22433 lossL: tensor(1084.1885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22434 lossL: tensor(1017.4470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22435 lossL: tensor(1030.2709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22436 lossL: tensor(1078.1672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22437 lossL: tensor(1082.9456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22438 lossL: tensor(1111.8617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22439 lossL: tensor(1046.7416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22440 lossL: tensor(1123.4011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22441 lossL: tensor(1166.5251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22442 lossL: tensor(1092.7260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22443 lossL: tensor(1059.9067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22444 lossL: tensor(921.8317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "22445 lossL: tensor(1091.0933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22446 lossL: tensor(1117.5249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22447 lossL: tensor(1050.5785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22448 lossL: tensor(1050.2743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22449 lossL: tensor(923.6302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22450 lossL: tensor(1036.2723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22451 lossL: tensor(941.5875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22452 lossL: tensor(1010.0419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22453 lossL: tensor(1099.9537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22454 lossL: tensor(1073.7607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22455 lossL: tensor(1040.2600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22456 lossL: tensor(1123.9835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22457 lossL: tensor(1203.0768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22458 lossL: tensor(1064.4717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22459 lossL: tensor(1028.6052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22460 lossL: tensor(1125.4236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22461 lossL: tensor(1174.7324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22462 lossL: tensor(1072.9941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22463 lossL: tensor(1220.3026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22464 lossL: tensor(1228.5377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22465 lossL: tensor(1041.6570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22466 lossL: tensor(1078.4606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22467 lossL: tensor(927.3155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22468 lossL: tensor(1126.9197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22469 lossL: tensor(1049.0396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22470 lossL: tensor(937.1365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22471 lossL: tensor(1073.6946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22472 lossL: tensor(1063.7963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22473 lossL: tensor(1252.3176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22474 lossL: tensor(1030.5735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22475 lossL: tensor(979.1171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22476 lossL: tensor(1055.1770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22477 lossL: tensor(1059.7441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22478 lossL: tensor(1164.9523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22479 lossL: tensor(982.7080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22480 lossL: tensor(1081.1534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22481 lossL: tensor(1112.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22482 lossL: tensor(1043.2533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22483 lossL: tensor(1066.0060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22484 lossL: tensor(1012.4967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22485 lossL: tensor(1042.3411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22486 lossL: tensor(1026.6932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22487 lossL: tensor(1143.8447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22488 lossL: tensor(1025.2488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22489 lossL: tensor(1091.0059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22490 lossL: tensor(1139.5593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22491 lossL: tensor(1012.9122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22492 lossL: tensor(1106.2126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22493 lossL: tensor(975.5202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22494 lossL: tensor(1114.6560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22495 lossL: tensor(1089.8645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22496 lossL: tensor(1249.4628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22497 lossL: tensor(1061.6776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22498 lossL: tensor(1255.2003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22499 lossL: tensor(1120.0269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22500 lossL: tensor(994.4344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22501 lossL: tensor(1148.5740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22502 lossL: tensor(1167.3157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22503 lossL: tensor(1168.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22504 lossL: tensor(1017.8022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22505 lossL: tensor(1196.6476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22506 lossL: tensor(1042.1128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22507 lossL: tensor(1179.9791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22508 lossL: tensor(1179.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22509 lossL: tensor(1124.8149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22510 lossL: tensor(1146.0825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22511 lossL: tensor(1033.5630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22512 lossL: tensor(1180.8615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22513 lossL: tensor(1004.1518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22514 lossL: tensor(1117.2217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22515 lossL: tensor(906.5351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "22516 lossL: tensor(1050.2679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22517 lossL: tensor(939.8242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22518 lossL: tensor(1060.6740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22519 lossL: tensor(1119.8846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22520 lossL: tensor(1037.8706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22521 lossL: tensor(1214.6843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22522 lossL: tensor(1085.6964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22523 lossL: tensor(1151.6793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22524 lossL: tensor(1167.3435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22525 lossL: tensor(988.4124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22526 lossL: tensor(1145.3414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22527 lossL: tensor(1045.9343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22528 lossL: tensor(1150.3325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22529 lossL: tensor(1021.1812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22530 lossL: tensor(1164.6362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22531 lossL: tensor(1158.8568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22532 lossL: tensor(1066.3397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22533 lossL: tensor(1076.7440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22534 lossL: tensor(1080.6405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22535 lossL: tensor(1211.8331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22536 lossL: tensor(1005.5010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22537 lossL: tensor(1187.3759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22538 lossL: tensor(1078.3640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22539 lossL: tensor(1075.7963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22540 lossL: tensor(1052.1044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22541 lossL: tensor(1055.4987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22542 lossL: tensor(1161.4141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22543 lossL: tensor(1056.4651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22544 lossL: tensor(1100.1899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22545 lossL: tensor(1048.3849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22546 lossL: tensor(1035.1403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22547 lossL: tensor(927.9518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22548 lossL: tensor(1165.8245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22549 lossL: tensor(1013.1819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22550 lossL: tensor(1087.0038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22551 lossL: tensor(1071.3269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22552 lossL: tensor(1057.2882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22553 lossL: tensor(1023.8409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22554 lossL: tensor(1057.8687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22555 lossL: tensor(1083.4540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22556 lossL: tensor(907.3510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22557 lossL: tensor(1007.1273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22558 lossL: tensor(977.5941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22559 lossL: tensor(1194.1252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22560 lossL: tensor(1038.5365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22561 lossL: tensor(1064.8843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22562 lossL: tensor(947.5056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22563 lossL: tensor(1005.1443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22564 lossL: tensor(999.5372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22565 lossL: tensor(999.6161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22566 lossL: tensor(947.6705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22567 lossL: tensor(1003.1207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22568 lossL: tensor(1021.0707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22569 lossL: tensor(1083.1066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22570 lossL: tensor(1065.2190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22571 lossL: tensor(1037.9941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22572 lossL: tensor(1220.2991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22573 lossL: tensor(1170.7870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22574 lossL: tensor(1202.6156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22575 lossL: tensor(1028.9742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22576 lossL: tensor(1053.8738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22577 lossL: tensor(1178.1805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22578 lossL: tensor(1039.8623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22579 lossL: tensor(1196.3715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22580 lossL: tensor(1106.7181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22581 lossL: tensor(1189.6412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22582 lossL: tensor(1088.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22583 lossL: tensor(1230.9578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22584 lossL: tensor(1132.4403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22585 lossL: tensor(1068.9080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22586 lossL: tensor(1057.7231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22587 lossL: tensor(1003.1958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22588 lossL: tensor(1068.6322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22589 lossL: tensor(1035.3033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22590 lossL: tensor(1058.7808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22591 lossL: tensor(1032.7997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22592 lossL: tensor(1124.1553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22593 lossL: tensor(997.0885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22594 lossL: tensor(1227.0784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22595 lossL: tensor(1158.1174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22596 lossL: tensor(962.3955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22597 lossL: tensor(1055.0834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22598 lossL: tensor(1026.9254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22599 lossL: tensor(1111.1396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22600 lossL: tensor(1086.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22601 lossL: tensor(1144.1515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22602 lossL: tensor(1089.9514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22603 lossL: tensor(1109.5339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22604 lossL: tensor(1015.9959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22605 lossL: tensor(991.9116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22606 lossL: tensor(916.3521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22607 lossL: tensor(1050.4088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22608 lossL: tensor(979.1855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22609 lossL: tensor(1016.1466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22610 lossL: tensor(1016.2993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22611 lossL: tensor(954.6931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22612 lossL: tensor(989.2222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22613 lossL: tensor(895.1165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "22614 lossL: tensor(1049.0631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22615 lossL: tensor(1053.3040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22616 lossL: tensor(998.6588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22617 lossL: tensor(1018.8235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22618 lossL: tensor(1112.3679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22619 lossL: tensor(1005.5770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22620 lossL: tensor(1001.4210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22621 lossL: tensor(1026.6598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22622 lossL: tensor(997.2192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22623 lossL: tensor(1190.9304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22624 lossL: tensor(1175.5305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22625 lossL: tensor(1036.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22626 lossL: tensor(1204.9677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22627 lossL: tensor(1176.5786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22628 lossL: tensor(1134.4340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22629 lossL: tensor(1023.0134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22630 lossL: tensor(971.5170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22631 lossL: tensor(980.8629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22632 lossL: tensor(1129.0812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22633 lossL: tensor(1103.0066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22634 lossL: tensor(961.5857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22635 lossL: tensor(1117.9551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22636 lossL: tensor(1059.4528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22637 lossL: tensor(1058.7198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22638 lossL: tensor(1085.9652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22639 lossL: tensor(1077.8879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22640 lossL: tensor(1011.4683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22641 lossL: tensor(1137.8647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22642 lossL: tensor(956.6021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22643 lossL: tensor(1051.9763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22644 lossL: tensor(994.5247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22645 lossL: tensor(1063.2874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22646 lossL: tensor(1167.4254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22647 lossL: tensor(1010.2770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22648 lossL: tensor(1097.3007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22649 lossL: tensor(1071.4293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22650 lossL: tensor(1086.1752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22651 lossL: tensor(1021.8981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22652 lossL: tensor(1040.6688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22653 lossL: tensor(1073.8257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22654 lossL: tensor(1099.6763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22655 lossL: tensor(1078.2560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22656 lossL: tensor(1123.1470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22657 lossL: tensor(1119.9209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22658 lossL: tensor(1015.3342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22659 lossL: tensor(1012.0838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22660 lossL: tensor(1026.7612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22661 lossL: tensor(1004.3197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22662 lossL: tensor(930.3708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22663 lossL: tensor(1057.2994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22664 lossL: tensor(1112.0574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22665 lossL: tensor(982.6688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22666 lossL: tensor(957.2496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22667 lossL: tensor(999.7285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22668 lossL: tensor(1068.2556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22669 lossL: tensor(1184.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22670 lossL: tensor(1140.2666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22671 lossL: tensor(1029.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22672 lossL: tensor(1066.3846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22673 lossL: tensor(878.5411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "22674 lossL: tensor(1116.4957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22675 lossL: tensor(1034.5790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22676 lossL: tensor(1081.9752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22677 lossL: tensor(1092.4597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22678 lossL: tensor(1010.0586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22679 lossL: tensor(1053.0096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22680 lossL: tensor(1112.5956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22681 lossL: tensor(1052.7266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22682 lossL: tensor(1056.5039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22683 lossL: tensor(1076.9717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22684 lossL: tensor(1018.6248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22685 lossL: tensor(1037.3190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22686 lossL: tensor(975.8353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22687 lossL: tensor(1000.6675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22688 lossL: tensor(999.5370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22689 lossL: tensor(1028.1886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22690 lossL: tensor(972.2932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22691 lossL: tensor(989.2582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22692 lossL: tensor(1045.5825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22693 lossL: tensor(974.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22694 lossL: tensor(1078.0316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22695 lossL: tensor(1014.9008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22696 lossL: tensor(1013.4379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22697 lossL: tensor(1197.3834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22698 lossL: tensor(980.8287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22699 lossL: tensor(1266.0483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22700 lossL: tensor(1116.2886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22701 lossL: tensor(983.5972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22702 lossL: tensor(1137.2815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22703 lossL: tensor(1029.8400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22704 lossL: tensor(1049.2560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22705 lossL: tensor(1109.8843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22706 lossL: tensor(956.2341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22707 lossL: tensor(1023.4328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22708 lossL: tensor(942.8879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22709 lossL: tensor(1017.8046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22710 lossL: tensor(1034.2175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22711 lossL: tensor(981.2059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22712 lossL: tensor(1048.7883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22713 lossL: tensor(1060.0862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22714 lossL: tensor(1190.1477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22715 lossL: tensor(953.2003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22716 lossL: tensor(1085.1481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22717 lossL: tensor(928.1747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22718 lossL: tensor(1015.1067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22719 lossL: tensor(983.9484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22720 lossL: tensor(1033.5795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22721 lossL: tensor(1092.5583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22722 lossL: tensor(982.4274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22723 lossL: tensor(1072.7473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22724 lossL: tensor(968.8387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22725 lossL: tensor(1099.8433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22726 lossL: tensor(1057.2896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22727 lossL: tensor(979.6030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22728 lossL: tensor(1105.5427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22729 lossL: tensor(1056.6406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22730 lossL: tensor(1028.2511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22731 lossL: tensor(1000.8585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22732 lossL: tensor(1129.7875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22733 lossL: tensor(1091.6194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22734 lossL: tensor(959.8682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22735 lossL: tensor(1074.9220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22736 lossL: tensor(923.7943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22737 lossL: tensor(1019.1400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22738 lossL: tensor(1013.7588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22739 lossL: tensor(952.7543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22740 lossL: tensor(1142.0585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22741 lossL: tensor(1014.7874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22742 lossL: tensor(1080.3245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22743 lossL: tensor(961.8840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22744 lossL: tensor(1049.5925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22745 lossL: tensor(919.6031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22746 lossL: tensor(1127.6876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22747 lossL: tensor(1122.3940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22748 lossL: tensor(1047.8650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22749 lossL: tensor(1069.9723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22750 lossL: tensor(888.0980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22751 lossL: tensor(1072.2972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22752 lossL: tensor(1156.0215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22753 lossL: tensor(1034.4889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22754 lossL: tensor(1243.7378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22755 lossL: tensor(1010.0449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22756 lossL: tensor(1021.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22757 lossL: tensor(1094.7740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22758 lossL: tensor(1050.8561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22759 lossL: tensor(1063.2252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22760 lossL: tensor(1026.7292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22761 lossL: tensor(1066.7034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22762 lossL: tensor(1070.2434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22763 lossL: tensor(1175.5458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22764 lossL: tensor(988.7721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22765 lossL: tensor(1075.7755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22766 lossL: tensor(1033.6687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22767 lossL: tensor(1115.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22768 lossL: tensor(1075.0297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22769 lossL: tensor(1060.8386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22770 lossL: tensor(1107.2642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22771 lossL: tensor(949.5748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22772 lossL: tensor(1205.6154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22773 lossL: tensor(1143.1832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22774 lossL: tensor(1021.7390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22775 lossL: tensor(1151.7583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22776 lossL: tensor(997.1448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22777 lossL: tensor(1087.2383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22778 lossL: tensor(1131.6644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22779 lossL: tensor(948.2567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22780 lossL: tensor(1063.6418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22781 lossL: tensor(954.3105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22782 lossL: tensor(1142.4822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22783 lossL: tensor(992.2857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22784 lossL: tensor(1103.6060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22785 lossL: tensor(982.3368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22786 lossL: tensor(975.9282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22787 lossL: tensor(1062.9674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22788 lossL: tensor(981.0393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22789 lossL: tensor(1050.5992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22790 lossL: tensor(1028.4691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22791 lossL: tensor(954.0904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22792 lossL: tensor(1055.8859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22793 lossL: tensor(1032.8132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22794 lossL: tensor(960.8699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22795 lossL: tensor(1048.2726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22796 lossL: tensor(989.3904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22797 lossL: tensor(1011.2581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22798 lossL: tensor(1087.1978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22799 lossL: tensor(1078.6053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22800 lossL: tensor(979.7968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22801 lossL: tensor(981.5738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22802 lossL: tensor(992.7778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22803 lossL: tensor(1059.5288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22804 lossL: tensor(1045., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22805 lossL: tensor(1134.1333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22806 lossL: tensor(1040.1227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22807 lossL: tensor(1014.2087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22808 lossL: tensor(1027.1165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22809 lossL: tensor(1037.1244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22810 lossL: tensor(961.6226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22811 lossL: tensor(957.3192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22812 lossL: tensor(1003.7992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22813 lossL: tensor(980.8804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22814 lossL: tensor(964.7808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22815 lossL: tensor(1126.3661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22816 lossL: tensor(1050.8580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22817 lossL: tensor(1072.3605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22818 lossL: tensor(1041.9825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22819 lossL: tensor(988.5705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22820 lossL: tensor(1118.4307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22821 lossL: tensor(943.2239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22822 lossL: tensor(1145.6735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22823 lossL: tensor(985.4839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22824 lossL: tensor(1034.6821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22825 lossL: tensor(1027.5380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22826 lossL: tensor(1104.4022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22827 lossL: tensor(973.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22828 lossL: tensor(1005.6538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22829 lossL: tensor(960.6153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22830 lossL: tensor(1063.8652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22831 lossL: tensor(1057.7430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22832 lossL: tensor(1109.1469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22833 lossL: tensor(1008.8325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22834 lossL: tensor(983.3315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22835 lossL: tensor(976.1074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22836 lossL: tensor(988.9403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22837 lossL: tensor(982.2011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22838 lossL: tensor(998.9371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22839 lossL: tensor(967.2042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22840 lossL: tensor(945.7509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22841 lossL: tensor(943.7419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22842 lossL: tensor(972.4230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22843 lossL: tensor(979.6829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22844 lossL: tensor(1002.3091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22845 lossL: tensor(1110.0294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22846 lossL: tensor(1007.6414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22847 lossL: tensor(1089.1284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22848 lossL: tensor(1019.8538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22849 lossL: tensor(1000.3509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22850 lossL: tensor(1013.4152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22851 lossL: tensor(1025.3059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22852 lossL: tensor(1078.1031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22853 lossL: tensor(968.2728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22854 lossL: tensor(1062.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22855 lossL: tensor(1006.9240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22856 lossL: tensor(1011.2558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22857 lossL: tensor(983.7250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22858 lossL: tensor(1035.3533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22859 lossL: tensor(973.4725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22860 lossL: tensor(961.6114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22861 lossL: tensor(1033.8522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22862 lossL: tensor(981.0480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22863 lossL: tensor(1158.4049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22864 lossL: tensor(974.8679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22865 lossL: tensor(1220.8727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22866 lossL: tensor(1156.9827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22867 lossL: tensor(1015.9432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22868 lossL: tensor(1076.6564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22869 lossL: tensor(1125.1321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22870 lossL: tensor(1075.7303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22871 lossL: tensor(944.7308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22872 lossL: tensor(1216.0869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22873 lossL: tensor(974.0463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22874 lossL: tensor(1075.4095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22875 lossL: tensor(1007.7437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22876 lossL: tensor(1052.1964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22877 lossL: tensor(1072.9575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22878 lossL: tensor(1075.8932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22879 lossL: tensor(1054.8450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22880 lossL: tensor(929.3900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22881 lossL: tensor(1125.0687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22882 lossL: tensor(1033.9597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22883 lossL: tensor(1098.6075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22884 lossL: tensor(1052.8923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22885 lossL: tensor(945.0487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22886 lossL: tensor(1016.5411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22887 lossL: tensor(972.8994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22888 lossL: tensor(1060.3325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22889 lossL: tensor(1023.8018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22890 lossL: tensor(1029.6687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22891 lossL: tensor(873.6285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "22892 lossL: tensor(965.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22893 lossL: tensor(963.2173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22894 lossL: tensor(1074.2755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22895 lossL: tensor(1005.3944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22896 lossL: tensor(933.1428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22897 lossL: tensor(1028.8928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22898 lossL: tensor(1044.3962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22899 lossL: tensor(1072.7458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22900 lossL: tensor(1100.5042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22901 lossL: tensor(1036.5538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22902 lossL: tensor(1081.5404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22903 lossL: tensor(1062.7350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22904 lossL: tensor(919.4366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22905 lossL: tensor(1065.0428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22906 lossL: tensor(914.2665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22907 lossL: tensor(991.7015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22908 lossL: tensor(1018.2438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22909 lossL: tensor(1078.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22910 lossL: tensor(1093.8608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22911 lossL: tensor(1218.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22912 lossL: tensor(953.7078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22913 lossL: tensor(992.9012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22914 lossL: tensor(1085.7622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22915 lossL: tensor(978.1711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22916 lossL: tensor(962.1333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22917 lossL: tensor(1083.6193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22918 lossL: tensor(1113.0466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22919 lossL: tensor(1215.1921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22920 lossL: tensor(1062.3140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22921 lossL: tensor(1056.8923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22922 lossL: tensor(1207.4323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22923 lossL: tensor(1105.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22924 lossL: tensor(1069.6991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22925 lossL: tensor(1039.1879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22926 lossL: tensor(1221.6301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22927 lossL: tensor(944.8917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22928 lossL: tensor(1206.1307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22929 lossL: tensor(983.9003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22930 lossL: tensor(1112.1573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22931 lossL: tensor(1172.7299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22932 lossL: tensor(1006.2609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22933 lossL: tensor(1097.0529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22934 lossL: tensor(1020.1220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22935 lossL: tensor(1187.8490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22936 lossL: tensor(1012.1800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22937 lossL: tensor(1266.5521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22938 lossL: tensor(1065.2950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22939 lossL: tensor(1289.6487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22940 lossL: tensor(1158.1558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22941 lossL: tensor(1054.2456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22942 lossL: tensor(1141.3108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22943 lossL: tensor(1002.6071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22944 lossL: tensor(1391.4944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22945 lossL: tensor(963.6439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22946 lossL: tensor(1237.7697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22947 lossL: tensor(1037.3147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22948 lossL: tensor(1361.6833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22949 lossL: tensor(985.7241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22950 lossL: tensor(1141.1675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22951 lossL: tensor(1233.1224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22952 lossL: tensor(1066.0574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22953 lossL: tensor(1372.7301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22954 lossL: tensor(982.0244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22955 lossL: tensor(1152.3335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22956 lossL: tensor(946.7021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22957 lossL: tensor(1058.0447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22958 lossL: tensor(982.4384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22959 lossL: tensor(1143.6099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22960 lossL: tensor(1129.0215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22961 lossL: tensor(971.3225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22962 lossL: tensor(1062.4939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22963 lossL: tensor(1076.2054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22964 lossL: tensor(1077.5006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22965 lossL: tensor(936.8961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22966 lossL: tensor(1076.7378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22967 lossL: tensor(914.3326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22968 lossL: tensor(1166.3387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22969 lossL: tensor(1030.3518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22970 lossL: tensor(963.4846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22971 lossL: tensor(1087.7343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22972 lossL: tensor(1033.6831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22973 lossL: tensor(1108.2708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22974 lossL: tensor(980.7494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22975 lossL: tensor(1101.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22976 lossL: tensor(968.5953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22977 lossL: tensor(1129.3372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22978 lossL: tensor(1002.5790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22979 lossL: tensor(1051.9252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22980 lossL: tensor(1053.8989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22981 lossL: tensor(964.8214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22982 lossL: tensor(928.8616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22983 lossL: tensor(1039.9498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22984 lossL: tensor(1010.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22985 lossL: tensor(927.3152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22986 lossL: tensor(1019.3334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22987 lossL: tensor(986.5519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22988 lossL: tensor(1043.7006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22989 lossL: tensor(1009.5623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22990 lossL: tensor(1036.8666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22991 lossL: tensor(980.9636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22992 lossL: tensor(987.2936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22993 lossL: tensor(1093.0233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22994 lossL: tensor(1100.1528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22995 lossL: tensor(1091.3530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22996 lossL: tensor(924.0289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22997 lossL: tensor(1011.5511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22998 lossL: tensor(1053.0638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "22999 lossL: tensor(1072.5149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23000 lossL: tensor(1031.5731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23001 lossL: tensor(994.8076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23002 lossL: tensor(1034.9647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23003 lossL: tensor(1008.4565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23004 lossL: tensor(983.1366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23005 lossL: tensor(960.0862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23006 lossL: tensor(1105.5526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23007 lossL: tensor(959.7191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23008 lossL: tensor(1058.1575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23009 lossL: tensor(896.8272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23010 lossL: tensor(1063.2034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23011 lossL: tensor(1045.2441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23012 lossL: tensor(1037.5862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23013 lossL: tensor(950.0129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23014 lossL: tensor(985.6404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23015 lossL: tensor(996.9693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23016 lossL: tensor(978.2899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23017 lossL: tensor(1039.0109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23018 lossL: tensor(904.2745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23019 lossL: tensor(995.6849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23020 lossL: tensor(898.2001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23021 lossL: tensor(996.6909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23022 lossL: tensor(1071.2097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23023 lossL: tensor(975.1306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23024 lossL: tensor(1018.4064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23025 lossL: tensor(1012.8630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23026 lossL: tensor(1107.0347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23027 lossL: tensor(992.5624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23028 lossL: tensor(915.1710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23029 lossL: tensor(946.3765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23030 lossL: tensor(968.6783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23031 lossL: tensor(1011.1821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23032 lossL: tensor(898.9436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23033 lossL: tensor(988.2554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23034 lossL: tensor(1013.5578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23035 lossL: tensor(943.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23036 lossL: tensor(912.0773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23037 lossL: tensor(1107.6642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23038 lossL: tensor(1119.8007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23039 lossL: tensor(1006.5402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23040 lossL: tensor(1004.1268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23041 lossL: tensor(913.7375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23042 lossL: tensor(1067.0706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23043 lossL: tensor(976.1447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23044 lossL: tensor(1042.5905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23045 lossL: tensor(1033.8639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23046 lossL: tensor(907.7483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23047 lossL: tensor(1060.8466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23048 lossL: tensor(1027.4199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23049 lossL: tensor(1088.0068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23050 lossL: tensor(902.1662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23051 lossL: tensor(1105.5601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23052 lossL: tensor(977.7686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23053 lossL: tensor(982.5300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23054 lossL: tensor(949.8564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23055 lossL: tensor(1014.9538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23056 lossL: tensor(1087.3667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23057 lossL: tensor(925.1674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23058 lossL: tensor(984.6290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23059 lossL: tensor(991.4405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23060 lossL: tensor(1037.3605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23061 lossL: tensor(936.0668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23062 lossL: tensor(1087.5609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23063 lossL: tensor(995.7272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23064 lossL: tensor(1069.4445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23065 lossL: tensor(1095.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23066 lossL: tensor(942.8782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23067 lossL: tensor(1125.9397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23068 lossL: tensor(982.6432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23069 lossL: tensor(1013.6437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23070 lossL: tensor(946.3426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23071 lossL: tensor(1001.4884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23072 lossL: tensor(1036.9349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23073 lossL: tensor(1061.1088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23074 lossL: tensor(976.8436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23075 lossL: tensor(1052.2174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23076 lossL: tensor(941.0989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23077 lossL: tensor(952.8312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23078 lossL: tensor(1018.2804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23079 lossL: tensor(1009.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23080 lossL: tensor(973.7693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23081 lossL: tensor(990.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23082 lossL: tensor(1006.7217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23083 lossL: tensor(989.0692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23084 lossL: tensor(941.5867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23085 lossL: tensor(971.4903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23086 lossL: tensor(1030.5408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23087 lossL: tensor(1084.7644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23088 lossL: tensor(1019.2462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23089 lossL: tensor(1044.1063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23090 lossL: tensor(1009.5882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23091 lossL: tensor(1085.4875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23092 lossL: tensor(939.6555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23093 lossL: tensor(963.0630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23094 lossL: tensor(1061.2661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23095 lossL: tensor(1054.5503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23096 lossL: tensor(1006.1662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23097 lossL: tensor(978.3900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23098 lossL: tensor(951.8101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23099 lossL: tensor(889.6601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23100 lossL: tensor(951.8487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23101 lossL: tensor(991.5604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23102 lossL: tensor(963.3452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23103 lossL: tensor(1157.5764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23104 lossL: tensor(982.8093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23105 lossL: tensor(1030.0983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23106 lossL: tensor(1009.5895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23107 lossL: tensor(1011.9044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23108 lossL: tensor(1008.9684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23109 lossL: tensor(948.3538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23110 lossL: tensor(980.6465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23111 lossL: tensor(1044.6118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23112 lossL: tensor(991.1787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23113 lossL: tensor(981.5172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23114 lossL: tensor(1004.0831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23115 lossL: tensor(895.9417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23116 lossL: tensor(885.4119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23117 lossL: tensor(1034.4841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23118 lossL: tensor(930.1651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23119 lossL: tensor(1112.4875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23120 lossL: tensor(1138.6450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23121 lossL: tensor(915.6449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23122 lossL: tensor(1117.8273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23123 lossL: tensor(1027.5042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23124 lossL: tensor(1215.4613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23125 lossL: tensor(1095.5157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23126 lossL: tensor(1019.4714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23127 lossL: tensor(1069.3938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23128 lossL: tensor(884.4529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23129 lossL: tensor(1263.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23130 lossL: tensor(910.4344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23131 lossL: tensor(1173.4807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23132 lossL: tensor(1009.2546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23133 lossL: tensor(1018.0668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23134 lossL: tensor(999.8055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23135 lossL: tensor(1030.8171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23136 lossL: tensor(1032.6089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23137 lossL: tensor(1007.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23138 lossL: tensor(988.5158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23139 lossL: tensor(964.9335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23140 lossL: tensor(966.4081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23141 lossL: tensor(897.6703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23142 lossL: tensor(922.3014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23143 lossL: tensor(1026.6331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23144 lossL: tensor(862.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "23145 lossL: tensor(1032.8766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23146 lossL: tensor(1009.4719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23147 lossL: tensor(982.7943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23148 lossL: tensor(1048.1046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23149 lossL: tensor(944.7745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23150 lossL: tensor(1053.5757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23151 lossL: tensor(984.2920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23152 lossL: tensor(998.3839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23153 lossL: tensor(957.0086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23154 lossL: tensor(1030.9839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23155 lossL: tensor(1035.5605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23156 lossL: tensor(978.6921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23157 lossL: tensor(938.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23158 lossL: tensor(1019.4286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23159 lossL: tensor(1066.5560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23160 lossL: tensor(1028.7822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23161 lossL: tensor(1022.3659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23162 lossL: tensor(1007.9534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23163 lossL: tensor(964.1978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23164 lossL: tensor(982.5125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23165 lossL: tensor(981.0116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23166 lossL: tensor(988.4037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23167 lossL: tensor(958.8761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23168 lossL: tensor(1125.9773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23169 lossL: tensor(979.5022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23170 lossL: tensor(1013.8693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23171 lossL: tensor(914.4932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23172 lossL: tensor(1001.6982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23173 lossL: tensor(1016.3236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23174 lossL: tensor(954.6106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23175 lossL: tensor(950.6650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23176 lossL: tensor(1000.1185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23177 lossL: tensor(1036.2327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23178 lossL: tensor(910.8216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23179 lossL: tensor(1060.9000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23180 lossL: tensor(1016.6291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23181 lossL: tensor(913.4970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23182 lossL: tensor(934.3188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23183 lossL: tensor(894.0904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23184 lossL: tensor(941.1683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23185 lossL: tensor(981.1451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23186 lossL: tensor(1019.7880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23187 lossL: tensor(967.1984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23188 lossL: tensor(971.9441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23189 lossL: tensor(1026.4735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23190 lossL: tensor(872.7497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23191 lossL: tensor(945.7675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23192 lossL: tensor(1039.4193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23193 lossL: tensor(969.1510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23194 lossL: tensor(978.3101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23195 lossL: tensor(866.4639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23196 lossL: tensor(1049.7290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23197 lossL: tensor(979.1871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23198 lossL: tensor(999.5599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23199 lossL: tensor(1054.9105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23200 lossL: tensor(963.7076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23201 lossL: tensor(1047.7775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23202 lossL: tensor(991.1306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23203 lossL: tensor(993.9366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23204 lossL: tensor(965.6255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23205 lossL: tensor(1001.1682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23206 lossL: tensor(975.6512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23207 lossL: tensor(973.3657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23208 lossL: tensor(945.5487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23209 lossL: tensor(1146.9884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23210 lossL: tensor(1047.9503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23211 lossL: tensor(918.3188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23212 lossL: tensor(1039.1771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23213 lossL: tensor(1008.7112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23214 lossL: tensor(1127.6058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23215 lossL: tensor(964.7579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23216 lossL: tensor(963.6385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23217 lossL: tensor(975.4359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23218 lossL: tensor(1097.4113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23219 lossL: tensor(991.5720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23220 lossL: tensor(909.0801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23221 lossL: tensor(1007.4858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23222 lossL: tensor(981.5566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23223 lossL: tensor(1010.3856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23224 lossL: tensor(1024.3783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23225 lossL: tensor(1094.8132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23226 lossL: tensor(1024.0989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23227 lossL: tensor(1016.6859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23228 lossL: tensor(1054.3416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23229 lossL: tensor(1000.8870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23230 lossL: tensor(946.9237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23231 lossL: tensor(1044.6176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23232 lossL: tensor(965.2062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23233 lossL: tensor(1006.1244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23234 lossL: tensor(1026.1108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23235 lossL: tensor(972.0258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23236 lossL: tensor(1003.0947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23237 lossL: tensor(992.2192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23238 lossL: tensor(931.2804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23239 lossL: tensor(931.5462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23240 lossL: tensor(927.9530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23241 lossL: tensor(1042.0521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23242 lossL: tensor(961.1779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23243 lossL: tensor(954.8033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23244 lossL: tensor(929.2311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23245 lossL: tensor(989.9934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23246 lossL: tensor(991.6807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23247 lossL: tensor(878.3288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23248 lossL: tensor(959.9571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23249 lossL: tensor(924.6127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23250 lossL: tensor(949.0735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23251 lossL: tensor(915.2234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23252 lossL: tensor(898.4627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23253 lossL: tensor(967.7982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23254 lossL: tensor(1052.8698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23255 lossL: tensor(922.2215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23256 lossL: tensor(928.2571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23257 lossL: tensor(954.0881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23258 lossL: tensor(943.9345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23259 lossL: tensor(937.1219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23260 lossL: tensor(1041.3311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23261 lossL: tensor(1005.9243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23262 lossL: tensor(931.5792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23263 lossL: tensor(1033.6906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23264 lossL: tensor(953.4914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23265 lossL: tensor(1031.4989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23266 lossL: tensor(999.8855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23267 lossL: tensor(993.8554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23268 lossL: tensor(1008.9063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23269 lossL: tensor(1011.5880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23270 lossL: tensor(958.2776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23271 lossL: tensor(991.5787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23272 lossL: tensor(959.0943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23273 lossL: tensor(999.5913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23274 lossL: tensor(1034.1147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23275 lossL: tensor(973.4184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23276 lossL: tensor(1067.0284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23277 lossL: tensor(990.9065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23278 lossL: tensor(1052.2407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23279 lossL: tensor(1208.8248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23280 lossL: tensor(1021.6431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23281 lossL: tensor(1116.7188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23282 lossL: tensor(954.4834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23283 lossL: tensor(1162.1569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23284 lossL: tensor(1142.1753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23285 lossL: tensor(965.0449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23286 lossL: tensor(947.9100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23287 lossL: tensor(944.2686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23288 lossL: tensor(1070.7554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23289 lossL: tensor(948.9659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23290 lossL: tensor(1030.7623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23291 lossL: tensor(1071.9349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23292 lossL: tensor(939.4935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23293 lossL: tensor(963.2132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23294 lossL: tensor(1013.7759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23295 lossL: tensor(1010.3779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23296 lossL: tensor(987.9780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23297 lossL: tensor(1077.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23298 lossL: tensor(1046.9647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23299 lossL: tensor(1014.1686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23300 lossL: tensor(938.6206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23301 lossL: tensor(1038.7048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23302 lossL: tensor(978.1738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23303 lossL: tensor(923.9873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23304 lossL: tensor(915.8640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23305 lossL: tensor(1044.7317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23306 lossL: tensor(1001.2350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23307 lossL: tensor(905.2387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23308 lossL: tensor(993.0224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23309 lossL: tensor(914.8003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23310 lossL: tensor(1050.3582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23311 lossL: tensor(993.8740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23312 lossL: tensor(983.7332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23313 lossL: tensor(1043.0466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23314 lossL: tensor(951.6781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23315 lossL: tensor(1025.9193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23316 lossL: tensor(905.8135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23317 lossL: tensor(949.2126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23318 lossL: tensor(914.8674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23319 lossL: tensor(920.7984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23320 lossL: tensor(975.6675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23321 lossL: tensor(1085.6206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23322 lossL: tensor(926.6547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23323 lossL: tensor(956.6194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23324 lossL: tensor(980.4085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23325 lossL: tensor(999.8901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23326 lossL: tensor(998.5699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23327 lossL: tensor(1086.5453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23328 lossL: tensor(961.7336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23329 lossL: tensor(949.7964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23330 lossL: tensor(949.9718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23331 lossL: tensor(1025.7671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23332 lossL: tensor(990.2100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23333 lossL: tensor(921.0648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23334 lossL: tensor(1086.9611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23335 lossL: tensor(1003.2050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23336 lossL: tensor(869.7049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23337 lossL: tensor(1089.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23338 lossL: tensor(933.2937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23339 lossL: tensor(950.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23340 lossL: tensor(971.0682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23341 lossL: tensor(978.9292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23342 lossL: tensor(1073.3359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23343 lossL: tensor(968.8930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23344 lossL: tensor(997.4093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23345 lossL: tensor(999.7008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23346 lossL: tensor(1027.7728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23347 lossL: tensor(870.6442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23348 lossL: tensor(1041.1456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23349 lossL: tensor(988.2347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23350 lossL: tensor(972.5895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23351 lossL: tensor(1099.9822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23352 lossL: tensor(953.1386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23353 lossL: tensor(1180.0598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23354 lossL: tensor(923.9960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23355 lossL: tensor(1180.3976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23356 lossL: tensor(951.1274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23357 lossL: tensor(995.8468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23358 lossL: tensor(1215.1862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23359 lossL: tensor(1010.2562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23360 lossL: tensor(1273.7301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23361 lossL: tensor(966.8856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23362 lossL: tensor(1186.5126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23363 lossL: tensor(1233.9659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23364 lossL: tensor(924.0752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23365 lossL: tensor(1450.0695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23366 lossL: tensor(984.3254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23367 lossL: tensor(1526.8109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23368 lossL: tensor(1061.6078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23369 lossL: tensor(1252.6907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23370 lossL: tensor(1126.7252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23371 lossL: tensor(1072.9432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23372 lossL: tensor(1425.0388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23373 lossL: tensor(955.4481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23374 lossL: tensor(1395.8040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23375 lossL: tensor(908.4857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23376 lossL: tensor(1334.6213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23377 lossL: tensor(983.5516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23378 lossL: tensor(1157.3788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23379 lossL: tensor(1029.1669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23380 lossL: tensor(1085.1881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23381 lossL: tensor(1192.3058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23382 lossL: tensor(1015.0612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23383 lossL: tensor(1122.0562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23384 lossL: tensor(1050.1432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23385 lossL: tensor(1062.9104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23386 lossL: tensor(1002.6495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23387 lossL: tensor(946.6148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23388 lossL: tensor(987.3252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23389 lossL: tensor(955.7751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23390 lossL: tensor(943.8441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23391 lossL: tensor(862.5201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23392 lossL: tensor(1026.8944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23393 lossL: tensor(992.0526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23394 lossL: tensor(997.9026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23395 lossL: tensor(1041.0886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23396 lossL: tensor(994.0961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23397 lossL: tensor(919.1982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23398 lossL: tensor(1051.9161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23399 lossL: tensor(970.7491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23400 lossL: tensor(1079.0762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23401 lossL: tensor(981.8185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23402 lossL: tensor(949.2080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23403 lossL: tensor(964.2488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23404 lossL: tensor(1058.7582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23405 lossL: tensor(900.0457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23406 lossL: tensor(1004.5104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23407 lossL: tensor(986.4807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23408 lossL: tensor(1039.6963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23409 lossL: tensor(980.0453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23410 lossL: tensor(924.2964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23411 lossL: tensor(996.7218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23412 lossL: tensor(906.4979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23413 lossL: tensor(966.1545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23414 lossL: tensor(945.5018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23415 lossL: tensor(853.9456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "23416 lossL: tensor(1001.8275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23417 lossL: tensor(961.8318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23418 lossL: tensor(934.5134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23419 lossL: tensor(940.9070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23420 lossL: tensor(920.6252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23421 lossL: tensor(893.0724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23422 lossL: tensor(979.9989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23423 lossL: tensor(992.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23424 lossL: tensor(932.3536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23425 lossL: tensor(1004.4248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23426 lossL: tensor(986.7858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23427 lossL: tensor(992.3121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23428 lossL: tensor(943.3713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23429 lossL: tensor(912.8943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23430 lossL: tensor(924.0099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23431 lossL: tensor(938.2065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23432 lossL: tensor(938.0892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23433 lossL: tensor(951.8116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23434 lossL: tensor(1011.2834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23435 lossL: tensor(991.0538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23436 lossL: tensor(956.6318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23437 lossL: tensor(1009.5541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23438 lossL: tensor(1041.4049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23439 lossL: tensor(954.2730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23440 lossL: tensor(1058.7783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23441 lossL: tensor(1027.0245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23442 lossL: tensor(1077.5881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23443 lossL: tensor(1022.9927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23444 lossL: tensor(961.4705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23445 lossL: tensor(978.3658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23446 lossL: tensor(925.5078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23447 lossL: tensor(951.1692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23448 lossL: tensor(952.0773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23449 lossL: tensor(890.7575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23450 lossL: tensor(979.6594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23451 lossL: tensor(1033.2023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23452 lossL: tensor(949.9946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23453 lossL: tensor(895.5166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23454 lossL: tensor(908.8970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23455 lossL: tensor(984.8094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23456 lossL: tensor(888.7717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23457 lossL: tensor(909.7363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23458 lossL: tensor(1008.7235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23459 lossL: tensor(1008.4706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23460 lossL: tensor(919.6924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23461 lossL: tensor(896.7830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23462 lossL: tensor(1005.5305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23463 lossL: tensor(1063.5853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23464 lossL: tensor(1008.5919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23465 lossL: tensor(962.3940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23466 lossL: tensor(999.5887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23467 lossL: tensor(887.4572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23468 lossL: tensor(962.4086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23469 lossL: tensor(911.5156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23470 lossL: tensor(1071.9121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23471 lossL: tensor(972.4862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23472 lossL: tensor(948.9501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23473 lossL: tensor(1085.5966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23474 lossL: tensor(1027.8480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23475 lossL: tensor(1152.2070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23476 lossL: tensor(976.4181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23477 lossL: tensor(1045.0939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23478 lossL: tensor(858.4749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23479 lossL: tensor(940.1843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23480 lossL: tensor(981.6777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23481 lossL: tensor(956.7877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23482 lossL: tensor(1067.5406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23483 lossL: tensor(1032.6494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23484 lossL: tensor(1054.5645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23485 lossL: tensor(974.1480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23486 lossL: tensor(995.4701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23487 lossL: tensor(1120.0284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23488 lossL: tensor(1002.3718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23489 lossL: tensor(1089.7083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23490 lossL: tensor(982.6237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23491 lossL: tensor(1070.1184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23492 lossL: tensor(913.8811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23493 lossL: tensor(1000.1057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23494 lossL: tensor(949.0837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23495 lossL: tensor(901.1950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23496 lossL: tensor(1003.7200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23497 lossL: tensor(1021.1698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23498 lossL: tensor(905.9803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23499 lossL: tensor(987.2993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23500 lossL: tensor(993.3226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23501 lossL: tensor(1140.4862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23502 lossL: tensor(1397.7177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23503 lossL: tensor(1016.4755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23504 lossL: tensor(1140.8289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23505 lossL: tensor(1048.1746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23506 lossL: tensor(996.4268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23507 lossL: tensor(1155.3258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23508 lossL: tensor(1021.5031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23509 lossL: tensor(1000.2259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23510 lossL: tensor(920.0948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23511 lossL: tensor(1189.3114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23512 lossL: tensor(947.3705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23513 lossL: tensor(1172.0582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23514 lossL: tensor(1062.5612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23515 lossL: tensor(1095.2618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23516 lossL: tensor(1210.9744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23517 lossL: tensor(967.7269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23518 lossL: tensor(1257.7124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23519 lossL: tensor(931.4224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23520 lossL: tensor(1152.0796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23521 lossL: tensor(951.1478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23522 lossL: tensor(1081.9243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23523 lossL: tensor(1083.5470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23524 lossL: tensor(1116.5251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23525 lossL: tensor(1210.2661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23526 lossL: tensor(948.5902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23527 lossL: tensor(1168.8871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23528 lossL: tensor(983.0585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23529 lossL: tensor(1108.7511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23530 lossL: tensor(1104.3452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23531 lossL: tensor(1101.7535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23532 lossL: tensor(1193.5173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23533 lossL: tensor(953.7139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23534 lossL: tensor(1212.0758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23535 lossL: tensor(894.8737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23536 lossL: tensor(1270.0056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23537 lossL: tensor(904.9500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23538 lossL: tensor(1169.7313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23539 lossL: tensor(1037.7764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23540 lossL: tensor(1018.6365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23541 lossL: tensor(1057.7296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23542 lossL: tensor(983.2473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23543 lossL: tensor(1120.3263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23544 lossL: tensor(983.1938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23545 lossL: tensor(1030.1207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23546 lossL: tensor(969.8417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23547 lossL: tensor(975.0942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23548 lossL: tensor(895.2405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23549 lossL: tensor(971.5414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23550 lossL: tensor(1061.9828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23551 lossL: tensor(878.4447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23552 lossL: tensor(1048.5731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23553 lossL: tensor(872.3041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23554 lossL: tensor(961.8931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23555 lossL: tensor(1027.7727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23556 lossL: tensor(1007.2200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23557 lossL: tensor(942.6681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23558 lossL: tensor(933.4979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23559 lossL: tensor(955.4803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23560 lossL: tensor(884.4059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23561 lossL: tensor(1002.1344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23562 lossL: tensor(996.0904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23563 lossL: tensor(1116.1798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23564 lossL: tensor(978.2272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23565 lossL: tensor(984.8333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23566 lossL: tensor(1066.4286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23567 lossL: tensor(1092.4951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23568 lossL: tensor(1218.5142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23569 lossL: tensor(973.4666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23570 lossL: tensor(1308.3617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23571 lossL: tensor(874.8375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23572 lossL: tensor(1322.0150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23573 lossL: tensor(993.9978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23574 lossL: tensor(1334.7919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23575 lossL: tensor(1102.4927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23576 lossL: tensor(1082.6605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23577 lossL: tensor(1134.4572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23578 lossL: tensor(969.9638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23579 lossL: tensor(1020.5210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23580 lossL: tensor(1007.9277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23581 lossL: tensor(1014.4509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23582 lossL: tensor(958.3528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23583 lossL: tensor(1145.6086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23584 lossL: tensor(920.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23585 lossL: tensor(1058.9934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23586 lossL: tensor(981.1230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23587 lossL: tensor(952.8522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23588 lossL: tensor(970.2813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23589 lossL: tensor(909.1909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23590 lossL: tensor(897.5262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23591 lossL: tensor(936.7141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23592 lossL: tensor(1011.9501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23593 lossL: tensor(910.0529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23594 lossL: tensor(1063.4070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23595 lossL: tensor(1004.8784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23596 lossL: tensor(1083.4525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23597 lossL: tensor(913.5677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23598 lossL: tensor(1057.7516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23599 lossL: tensor(915.6505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23600 lossL: tensor(1235.7367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23601 lossL: tensor(987.9552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23602 lossL: tensor(1034.9857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23603 lossL: tensor(1006.7147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23604 lossL: tensor(1128.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23605 lossL: tensor(1004.3165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23606 lossL: tensor(1011.5783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23607 lossL: tensor(995.0369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23608 lossL: tensor(1008.7095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23609 lossL: tensor(934.7062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23610 lossL: tensor(1115.4907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23611 lossL: tensor(1042.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23612 lossL: tensor(929.6855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23613 lossL: tensor(1068.9597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23614 lossL: tensor(945.3116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23615 lossL: tensor(986.3107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23616 lossL: tensor(882.2677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23617 lossL: tensor(1114.2411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23618 lossL: tensor(1057.6301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23619 lossL: tensor(1131.7411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23620 lossL: tensor(1030.8704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23621 lossL: tensor(1008.2283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23622 lossL: tensor(970.7291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23623 lossL: tensor(949.7527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23624 lossL: tensor(1156.1758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23625 lossL: tensor(954.6495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23626 lossL: tensor(1114.3469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23627 lossL: tensor(914.7012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23628 lossL: tensor(1048.5282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23629 lossL: tensor(1041.4640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23630 lossL: tensor(1043.5139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23631 lossL: tensor(1023.9914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23632 lossL: tensor(974.4944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23633 lossL: tensor(1056.8845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23634 lossL: tensor(986.8673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23635 lossL: tensor(964.2111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23636 lossL: tensor(938.6974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23637 lossL: tensor(985.8003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23638 lossL: tensor(884.6025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23639 lossL: tensor(1044.6642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23640 lossL: tensor(970.7872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23641 lossL: tensor(851.8818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "23642 lossL: tensor(962.1329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23643 lossL: tensor(936.1739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23644 lossL: tensor(977.8671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23645 lossL: tensor(934.1218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23646 lossL: tensor(962.0422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23647 lossL: tensor(943.4626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23648 lossL: tensor(976.4081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23649 lossL: tensor(1013.6937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23650 lossL: tensor(896.1470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23651 lossL: tensor(967.2054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23652 lossL: tensor(928.7762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23653 lossL: tensor(975.0359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23654 lossL: tensor(869.9617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23655 lossL: tensor(969.0482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23656 lossL: tensor(957.9658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23657 lossL: tensor(952.1259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23658 lossL: tensor(915.1218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23659 lossL: tensor(931.1595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23660 lossL: tensor(992.9562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23661 lossL: tensor(907.2516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23662 lossL: tensor(853.8167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23663 lossL: tensor(979.4095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23664 lossL: tensor(968.1982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23665 lossL: tensor(922.7371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23666 lossL: tensor(962.1906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23667 lossL: tensor(854.0489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23668 lossL: tensor(824.2883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "23669 lossL: tensor(931.6069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23670 lossL: tensor(1020.5390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23671 lossL: tensor(957.3135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23672 lossL: tensor(915.8235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23673 lossL: tensor(949.2275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23674 lossL: tensor(870.4705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23675 lossL: tensor(971.8329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23676 lossL: tensor(969.2914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23677 lossL: tensor(1034.2910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23678 lossL: tensor(876.5462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23679 lossL: tensor(1020.1432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23680 lossL: tensor(884.5129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23681 lossL: tensor(973.1768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23682 lossL: tensor(964.2615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23683 lossL: tensor(945.7000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23684 lossL: tensor(887.3125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23685 lossL: tensor(979.9247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23686 lossL: tensor(859.2433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23687 lossL: tensor(934.2977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23688 lossL: tensor(876.0688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23689 lossL: tensor(947.8134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23690 lossL: tensor(975.8849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23691 lossL: tensor(931.0175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23692 lossL: tensor(1013.5290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23693 lossL: tensor(913.8391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23694 lossL: tensor(912.7865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23695 lossL: tensor(913.8884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23696 lossL: tensor(1028.9299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23697 lossL: tensor(1023.0900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23698 lossL: tensor(1077.5933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23699 lossL: tensor(1097.6178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23700 lossL: tensor(932.1069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23701 lossL: tensor(933.8009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23702 lossL: tensor(996.3388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23703 lossL: tensor(1022.9310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23704 lossL: tensor(920.6859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23705 lossL: tensor(1054.2325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23706 lossL: tensor(967.5958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23707 lossL: tensor(967.6379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23708 lossL: tensor(916.2477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23709 lossL: tensor(958.2388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23710 lossL: tensor(886.9531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23711 lossL: tensor(1008.4031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23712 lossL: tensor(995.9327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23713 lossL: tensor(961.2414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23714 lossL: tensor(988.8233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23715 lossL: tensor(979.4948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23716 lossL: tensor(953.1909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23717 lossL: tensor(979.8283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23718 lossL: tensor(879.9818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23719 lossL: tensor(927.3656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23720 lossL: tensor(990.7449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23721 lossL: tensor(914.7023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23722 lossL: tensor(997.0667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23723 lossL: tensor(886.3301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23724 lossL: tensor(943.5552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23725 lossL: tensor(948.2775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23726 lossL: tensor(895.1488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23727 lossL: tensor(892.7288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23728 lossL: tensor(973.2864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23729 lossL: tensor(944.2540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23730 lossL: tensor(998.9838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23731 lossL: tensor(949.8762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23732 lossL: tensor(989.9415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23733 lossL: tensor(1087.4810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23734 lossL: tensor(965.3524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23735 lossL: tensor(979.2686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23736 lossL: tensor(898.5643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23737 lossL: tensor(1058.5089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23738 lossL: tensor(947.1624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23739 lossL: tensor(902.1857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23740 lossL: tensor(1029.5436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23741 lossL: tensor(1083.2710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23742 lossL: tensor(928.4340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23743 lossL: tensor(1152.1396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23744 lossL: tensor(985.6345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23745 lossL: tensor(1003.6733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23746 lossL: tensor(1093.7416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23747 lossL: tensor(906.4916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23748 lossL: tensor(989.5762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23749 lossL: tensor(906.6984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23750 lossL: tensor(1012.2478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23751 lossL: tensor(964.4271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23752 lossL: tensor(943.0831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23753 lossL: tensor(936.4564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23754 lossL: tensor(853.1566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23755 lossL: tensor(1045.2823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23756 lossL: tensor(919.5236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23757 lossL: tensor(1103.5278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23758 lossL: tensor(960.9127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23759 lossL: tensor(958.7953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23760 lossL: tensor(981.2678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23761 lossL: tensor(872.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23762 lossL: tensor(919.8378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23763 lossL: tensor(957.9501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23764 lossL: tensor(1038.7550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23765 lossL: tensor(1016.2900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23766 lossL: tensor(894.7943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23767 lossL: tensor(943.7342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23768 lossL: tensor(918.9047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23769 lossL: tensor(966.7254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23770 lossL: tensor(921.9271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23771 lossL: tensor(961.7782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23772 lossL: tensor(865.9594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23773 lossL: tensor(979.1973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23774 lossL: tensor(917.9546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23775 lossL: tensor(910.1132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23776 lossL: tensor(1021.7736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23777 lossL: tensor(1008.9865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23778 lossL: tensor(980.9556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23779 lossL: tensor(926.7523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23780 lossL: tensor(934.1817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23781 lossL: tensor(990.8107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23782 lossL: tensor(892.9360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23783 lossL: tensor(939.3291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23784 lossL: tensor(962.7090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23785 lossL: tensor(1016.3138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23786 lossL: tensor(915.0955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23787 lossL: tensor(1001.4718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23788 lossL: tensor(883.5803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23789 lossL: tensor(969.9802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23790 lossL: tensor(1028.2532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23791 lossL: tensor(926.6165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23792 lossL: tensor(957.1541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23793 lossL: tensor(979.4197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23794 lossL: tensor(884.7380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23795 lossL: tensor(981.9872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23796 lossL: tensor(974.3492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23797 lossL: tensor(921.9039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23798 lossL: tensor(958.4990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23799 lossL: tensor(901.1604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23800 lossL: tensor(903.6652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23801 lossL: tensor(873.4323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23802 lossL: tensor(903.7700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23803 lossL: tensor(760.8912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "23804 lossL: tensor(935.8590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23805 lossL: tensor(933.0076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23806 lossL: tensor(962.4612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23807 lossL: tensor(1007.2221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23808 lossL: tensor(976.5980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23809 lossL: tensor(1050.9840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23810 lossL: tensor(1101.9547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23811 lossL: tensor(945.8577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23812 lossL: tensor(981.8156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23813 lossL: tensor(942.2286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23814 lossL: tensor(963.0983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23815 lossL: tensor(887.0756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23816 lossL: tensor(944.0873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23817 lossL: tensor(925.8241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23818 lossL: tensor(865.3202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23819 lossL: tensor(947.1305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23820 lossL: tensor(868.7352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23821 lossL: tensor(975.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23822 lossL: tensor(948.6098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23823 lossL: tensor(917.8313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23824 lossL: tensor(971.0356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23825 lossL: tensor(979.1226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23826 lossL: tensor(988.8115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23827 lossL: tensor(941.5491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23828 lossL: tensor(944.2090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23829 lossL: tensor(1003.9498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23830 lossL: tensor(880.4704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23831 lossL: tensor(997.8502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23832 lossL: tensor(955.0390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23833 lossL: tensor(878.6011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23834 lossL: tensor(893.0705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23835 lossL: tensor(891.0874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23836 lossL: tensor(937.6720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23837 lossL: tensor(934.2197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23838 lossL: tensor(907.9092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23839 lossL: tensor(834.7225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23840 lossL: tensor(949.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23841 lossL: tensor(945.5829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23842 lossL: tensor(926.7032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23843 lossL: tensor(1071.3752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23844 lossL: tensor(967.2111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23845 lossL: tensor(1014.4921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23846 lossL: tensor(899.6851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23847 lossL: tensor(943.7440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23848 lossL: tensor(917.5549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23849 lossL: tensor(933.4399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23850 lossL: tensor(962.9508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23851 lossL: tensor(923.8596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23852 lossL: tensor(981.0899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23853 lossL: tensor(879.7720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23854 lossL: tensor(864.5407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23855 lossL: tensor(895.2103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23856 lossL: tensor(963.8876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23857 lossL: tensor(963.8012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23858 lossL: tensor(1009.7805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23859 lossL: tensor(1013.1235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23860 lossL: tensor(964.5089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23861 lossL: tensor(917.9289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23862 lossL: tensor(1019.9104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23863 lossL: tensor(944.2319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23864 lossL: tensor(960.6830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23865 lossL: tensor(929.6712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23866 lossL: tensor(949.3385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23867 lossL: tensor(949.8329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23868 lossL: tensor(854.8811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23869 lossL: tensor(909.8748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23870 lossL: tensor(949.2794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23871 lossL: tensor(952.8907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23872 lossL: tensor(963.2648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23873 lossL: tensor(939.4333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23874 lossL: tensor(906.4576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23875 lossL: tensor(900.8778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23876 lossL: tensor(936.1727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23877 lossL: tensor(916.1390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23878 lossL: tensor(902.9302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23879 lossL: tensor(967.5824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23880 lossL: tensor(907.4821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23881 lossL: tensor(978.3438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23882 lossL: tensor(884.8524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23883 lossL: tensor(995.3269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23884 lossL: tensor(909.3184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23885 lossL: tensor(929.9456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23886 lossL: tensor(918.4753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23887 lossL: tensor(1010.6743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23888 lossL: tensor(1012.4825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23889 lossL: tensor(965.7944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23890 lossL: tensor(1001.7121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23891 lossL: tensor(1019.3654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23892 lossL: tensor(967.0319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23893 lossL: tensor(926.8246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23894 lossL: tensor(978.6452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23895 lossL: tensor(1038.8248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23896 lossL: tensor(975.3719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23897 lossL: tensor(976.5826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23898 lossL: tensor(922.4067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23899 lossL: tensor(951.0268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23900 lossL: tensor(956.0318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23901 lossL: tensor(839.0976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23902 lossL: tensor(996.7742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23903 lossL: tensor(982.4385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23904 lossL: tensor(933.9930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23905 lossL: tensor(927.2819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23906 lossL: tensor(957.0249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23907 lossL: tensor(981.1942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23908 lossL: tensor(1029.9302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23909 lossL: tensor(945.2000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23910 lossL: tensor(997.2521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23911 lossL: tensor(931.9665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23912 lossL: tensor(980.4530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23913 lossL: tensor(948.9114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23914 lossL: tensor(983.7209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23915 lossL: tensor(882.7330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23916 lossL: tensor(914.5728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23917 lossL: tensor(970.4060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23918 lossL: tensor(967.2614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23919 lossL: tensor(949.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23920 lossL: tensor(896.3979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23921 lossL: tensor(968.4427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23922 lossL: tensor(1033.7875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23923 lossL: tensor(964.5212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23924 lossL: tensor(977.7131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23925 lossL: tensor(1037.6056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23926 lossL: tensor(962.9814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23927 lossL: tensor(977.9960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23928 lossL: tensor(877.5815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23929 lossL: tensor(857.8695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23930 lossL: tensor(926.5798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23931 lossL: tensor(884.5289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23932 lossL: tensor(928.1671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23933 lossL: tensor(959.3651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23934 lossL: tensor(966.4739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23935 lossL: tensor(984.7822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23936 lossL: tensor(998.1393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23937 lossL: tensor(999.0804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23938 lossL: tensor(970.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23939 lossL: tensor(942.0397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23940 lossL: tensor(930.3673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23941 lossL: tensor(890.5752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23942 lossL: tensor(984.3594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23943 lossL: tensor(968.3026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23944 lossL: tensor(957.8570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23945 lossL: tensor(945.9631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23946 lossL: tensor(966.6202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23947 lossL: tensor(990.7997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23948 lossL: tensor(962.5251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23949 lossL: tensor(986.3604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23950 lossL: tensor(979.8706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23951 lossL: tensor(920.8481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23952 lossL: tensor(996.4223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23953 lossL: tensor(937.6420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23954 lossL: tensor(977.2033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23955 lossL: tensor(910.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23956 lossL: tensor(966.2759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23957 lossL: tensor(877.2508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23958 lossL: tensor(1024.2699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23959 lossL: tensor(1036.2408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23960 lossL: tensor(1002.2612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23961 lossL: tensor(974.3766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23962 lossL: tensor(923.3157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23963 lossL: tensor(1015.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23964 lossL: tensor(991.2889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23965 lossL: tensor(941.6726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23966 lossL: tensor(987.7576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23967 lossL: tensor(907.2037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23968 lossL: tensor(1002.3683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23969 lossL: tensor(929.4446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23970 lossL: tensor(942.8809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23971 lossL: tensor(948.7728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23972 lossL: tensor(979.9004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23973 lossL: tensor(984.4796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23974 lossL: tensor(873.8149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23975 lossL: tensor(989.5264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23976 lossL: tensor(986.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23977 lossL: tensor(991.3085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23978 lossL: tensor(992.8422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23979 lossL: tensor(923.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23980 lossL: tensor(878.6556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23981 lossL: tensor(946.5269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23982 lossL: tensor(923.0245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23983 lossL: tensor(974.3740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23984 lossL: tensor(894.8681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23985 lossL: tensor(1038.8392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23986 lossL: tensor(904.7033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23987 lossL: tensor(923.8055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23988 lossL: tensor(1102.0221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23989 lossL: tensor(885.9792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23990 lossL: tensor(978.6631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23991 lossL: tensor(1020.4306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23992 lossL: tensor(940.9770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23993 lossL: tensor(931.4327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23994 lossL: tensor(942.0753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23995 lossL: tensor(907.0906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23996 lossL: tensor(1007.4437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23997 lossL: tensor(1132.8737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23998 lossL: tensor(1001.1043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "23999 lossL: tensor(990.2424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24000 lossL: tensor(957.5714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24001 lossL: tensor(934.3581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24002 lossL: tensor(1061.6893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24003 lossL: tensor(940.6852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24004 lossL: tensor(932.2316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24005 lossL: tensor(977.3567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24006 lossL: tensor(975.0752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24007 lossL: tensor(982.6757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24008 lossL: tensor(939.1816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24009 lossL: tensor(884.9588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24010 lossL: tensor(932.5554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24011 lossL: tensor(913.9618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24012 lossL: tensor(1025.9542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24013 lossL: tensor(913.9346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24014 lossL: tensor(986.4731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24015 lossL: tensor(906.3646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24016 lossL: tensor(926.2802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24017 lossL: tensor(863.5866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24018 lossL: tensor(932.3360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24019 lossL: tensor(985.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24020 lossL: tensor(956.1407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24021 lossL: tensor(965.5706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24022 lossL: tensor(898.9345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24023 lossL: tensor(950.9310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24024 lossL: tensor(933.0541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24025 lossL: tensor(946.7727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24026 lossL: tensor(922.4482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24027 lossL: tensor(876.3904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24028 lossL: tensor(1024.9983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24029 lossL: tensor(992.0552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24030 lossL: tensor(903.3525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24031 lossL: tensor(990.8420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24032 lossL: tensor(906.2256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24033 lossL: tensor(938.7774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24034 lossL: tensor(963.1386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24035 lossL: tensor(1010.9834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24036 lossL: tensor(1001.0060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24037 lossL: tensor(964.6813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24038 lossL: tensor(923.4964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24039 lossL: tensor(947.1702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24040 lossL: tensor(885.8566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24041 lossL: tensor(1006.6997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24042 lossL: tensor(961.1403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24043 lossL: tensor(1107.9991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24044 lossL: tensor(970.9886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24045 lossL: tensor(997.5408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24046 lossL: tensor(954.8196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24047 lossL: tensor(975.4268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24048 lossL: tensor(1002.2453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24049 lossL: tensor(926.5550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24050 lossL: tensor(1064.6525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24051 lossL: tensor(973.9631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24052 lossL: tensor(841.1427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24053 lossL: tensor(928.5285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24054 lossL: tensor(925.0579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24055 lossL: tensor(943.2183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24056 lossL: tensor(916.6548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24057 lossL: tensor(940.1839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24058 lossL: tensor(942.4174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24059 lossL: tensor(850.1435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24060 lossL: tensor(918.5594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24061 lossL: tensor(980.8111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24062 lossL: tensor(912.9705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24063 lossL: tensor(918.2970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24064 lossL: tensor(889.2862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24065 lossL: tensor(845.4821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24066 lossL: tensor(902.7789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24067 lossL: tensor(907.4084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24068 lossL: tensor(954.5472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24069 lossL: tensor(846.4305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24070 lossL: tensor(960.3873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24071 lossL: tensor(890.6977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24072 lossL: tensor(1012.0277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24073 lossL: tensor(964.6158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24074 lossL: tensor(893.0009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24075 lossL: tensor(1073.5531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24076 lossL: tensor(975.5056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24077 lossL: tensor(838.1467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24078 lossL: tensor(1068.2832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24079 lossL: tensor(1065.5623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24080 lossL: tensor(854.3080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24081 lossL: tensor(1098.1899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24082 lossL: tensor(910.1186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24083 lossL: tensor(1057.8525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24084 lossL: tensor(1000.1788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24085 lossL: tensor(921.8911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24086 lossL: tensor(1087.7875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24087 lossL: tensor(892.5133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24088 lossL: tensor(1001.8058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24089 lossL: tensor(892.5203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24090 lossL: tensor(1048.6267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24091 lossL: tensor(914.6969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24092 lossL: tensor(910.9097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24093 lossL: tensor(929.6156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24094 lossL: tensor(943.9194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24095 lossL: tensor(1059.7797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24096 lossL: tensor(922.9337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24097 lossL: tensor(869.7009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24098 lossL: tensor(880.7881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24099 lossL: tensor(860.7437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24100 lossL: tensor(896.9774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24101 lossL: tensor(942.1256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24102 lossL: tensor(898.0191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24103 lossL: tensor(939.8173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24104 lossL: tensor(975.3892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24105 lossL: tensor(945.3998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24106 lossL: tensor(983.0707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24107 lossL: tensor(971.5755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24108 lossL: tensor(1154.5747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24109 lossL: tensor(975.3325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24110 lossL: tensor(994.3917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24111 lossL: tensor(1118.1595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24112 lossL: tensor(854.9615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24113 lossL: tensor(1056.0431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24114 lossL: tensor(940.1652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24115 lossL: tensor(1000.4570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24116 lossL: tensor(957.2990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24117 lossL: tensor(971.3001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24118 lossL: tensor(1016.9252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24119 lossL: tensor(953.6373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24120 lossL: tensor(1037.4917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24121 lossL: tensor(882.9453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24122 lossL: tensor(973.8632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24123 lossL: tensor(893.2449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24124 lossL: tensor(908.9026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24125 lossL: tensor(883.0339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24126 lossL: tensor(927.3613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24127 lossL: tensor(772.2521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24128 lossL: tensor(894.9327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24129 lossL: tensor(927.3743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24130 lossL: tensor(900.4707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24131 lossL: tensor(850.3481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24132 lossL: tensor(912.3778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24133 lossL: tensor(891.7950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24134 lossL: tensor(965.3027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24135 lossL: tensor(932.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24136 lossL: tensor(943.6025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24137 lossL: tensor(878.3994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24138 lossL: tensor(805.3079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24139 lossL: tensor(896.6689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24140 lossL: tensor(937.6088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24141 lossL: tensor(936.2360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24142 lossL: tensor(847.9899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24143 lossL: tensor(938.6276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24144 lossL: tensor(925.6825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24145 lossL: tensor(906.4169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24146 lossL: tensor(988.3530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24147 lossL: tensor(998.3207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24148 lossL: tensor(1186.4692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24149 lossL: tensor(920.2288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24150 lossL: tensor(1024.0980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24151 lossL: tensor(967.0077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24152 lossL: tensor(1118.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24153 lossL: tensor(947.6019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24154 lossL: tensor(1052.3569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24155 lossL: tensor(1150.4564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24156 lossL: tensor(965.5467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24157 lossL: tensor(1065.5710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24158 lossL: tensor(962.8436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24159 lossL: tensor(1045.8796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24160 lossL: tensor(878.2153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24161 lossL: tensor(1169.3949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24162 lossL: tensor(949.7115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24163 lossL: tensor(1021.1985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24164 lossL: tensor(979.7274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24165 lossL: tensor(984.1486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24166 lossL: tensor(1063.4845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24167 lossL: tensor(961.1644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24168 lossL: tensor(983.5286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24169 lossL: tensor(931.8327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24170 lossL: tensor(977.4703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24171 lossL: tensor(907.3030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24172 lossL: tensor(920.4073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24173 lossL: tensor(892.2812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24174 lossL: tensor(888.3177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24175 lossL: tensor(946.5485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24176 lossL: tensor(999.3351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24177 lossL: tensor(932.5318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24178 lossL: tensor(945.1681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24179 lossL: tensor(983.7807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24180 lossL: tensor(910.6534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24181 lossL: tensor(918.6334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24182 lossL: tensor(857.6849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24183 lossL: tensor(944.3614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24184 lossL: tensor(876.7368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24185 lossL: tensor(920.4814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24186 lossL: tensor(992.0027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24187 lossL: tensor(904.5842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24188 lossL: tensor(891.6423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24189 lossL: tensor(906.5895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24190 lossL: tensor(1028.2037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24191 lossL: tensor(1019.0466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24192 lossL: tensor(911.2386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24193 lossL: tensor(938.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24194 lossL: tensor(922.7362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24195 lossL: tensor(1069.4512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24196 lossL: tensor(979.4821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24197 lossL: tensor(1095.5460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24198 lossL: tensor(963.8946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24199 lossL: tensor(904.5070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24200 lossL: tensor(877.8997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24201 lossL: tensor(856.8945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24202 lossL: tensor(884.1303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24203 lossL: tensor(877.2601, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24204 lossL: tensor(866.4227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24205 lossL: tensor(875.3562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24206 lossL: tensor(886.4449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24207 lossL: tensor(926.9651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24208 lossL: tensor(951.7884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24209 lossL: tensor(918.8854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24210 lossL: tensor(872.3761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24211 lossL: tensor(943.6351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24212 lossL: tensor(955.8169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24213 lossL: tensor(957.4574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24214 lossL: tensor(888.9045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24215 lossL: tensor(876.5825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24216 lossL: tensor(909.7493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24217 lossL: tensor(937.4406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24218 lossL: tensor(981.3293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24219 lossL: tensor(949.5603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24220 lossL: tensor(890.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24221 lossL: tensor(914.3828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24222 lossL: tensor(939.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24223 lossL: tensor(965.1024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24224 lossL: tensor(917.2314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24225 lossL: tensor(989.8022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24226 lossL: tensor(976.3112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24227 lossL: tensor(878.8958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24228 lossL: tensor(946.4115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24229 lossL: tensor(849.9083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24230 lossL: tensor(940.6744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24231 lossL: tensor(877.4539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24232 lossL: tensor(950.9423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24233 lossL: tensor(939.2873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24234 lossL: tensor(947.2349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24235 lossL: tensor(974.8577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24236 lossL: tensor(884.7321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24237 lossL: tensor(845.9970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24238 lossL: tensor(909.5788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24239 lossL: tensor(894.8818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24240 lossL: tensor(861.8660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24241 lossL: tensor(866.1952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24242 lossL: tensor(930.3940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24243 lossL: tensor(998.2609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24244 lossL: tensor(885.7303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24245 lossL: tensor(936.3868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24246 lossL: tensor(932.7463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24247 lossL: tensor(887.2281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24248 lossL: tensor(840.2763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24249 lossL: tensor(859.4554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24250 lossL: tensor(977.9387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24251 lossL: tensor(861.1290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24252 lossL: tensor(921.6153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24253 lossL: tensor(908.5004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24254 lossL: tensor(870.3129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24255 lossL: tensor(910.0349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24256 lossL: tensor(925.4860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24257 lossL: tensor(905.5956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24258 lossL: tensor(941.4469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24259 lossL: tensor(984.0888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24260 lossL: tensor(898.5349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24261 lossL: tensor(930.8111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24262 lossL: tensor(973.3478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24263 lossL: tensor(975.9881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24264 lossL: tensor(913.8820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24265 lossL: tensor(894.9431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24266 lossL: tensor(906.2350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24267 lossL: tensor(950.0710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24268 lossL: tensor(836.8553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24269 lossL: tensor(1024.3452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24270 lossL: tensor(955.5405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24271 lossL: tensor(962.0241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24272 lossL: tensor(1103.3671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24273 lossL: tensor(812.5885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24274 lossL: tensor(1055.0463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24275 lossL: tensor(927.2480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24276 lossL: tensor(933.1513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24277 lossL: tensor(1077.4016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24278 lossL: tensor(844.8011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24279 lossL: tensor(1159.1086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24280 lossL: tensor(1093.3246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24281 lossL: tensor(940.8400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24282 lossL: tensor(1146.9229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24283 lossL: tensor(867.8107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24284 lossL: tensor(1049.2478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24285 lossL: tensor(953.0811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24286 lossL: tensor(972.8127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24287 lossL: tensor(985.3425, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24288 lossL: tensor(909.0203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24289 lossL: tensor(1155.8326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24290 lossL: tensor(850.1152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24291 lossL: tensor(1068.4498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24292 lossL: tensor(986.1166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24293 lossL: tensor(1031.5974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24294 lossL: tensor(1116.0132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24295 lossL: tensor(933.9613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24296 lossL: tensor(1060.7123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24297 lossL: tensor(908.2455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24298 lossL: tensor(1064.6323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24299 lossL: tensor(885.4767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24300 lossL: tensor(975.6431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24301 lossL: tensor(901.8673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24302 lossL: tensor(1001.0778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24303 lossL: tensor(992.8210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24304 lossL: tensor(972.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24305 lossL: tensor(1018.1375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24306 lossL: tensor(943.9646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24307 lossL: tensor(912.8662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24308 lossL: tensor(820.2686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24309 lossL: tensor(900.4529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24310 lossL: tensor(914.1924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24311 lossL: tensor(922.1614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24312 lossL: tensor(879.8888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24313 lossL: tensor(875.8651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24314 lossL: tensor(925.1685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24315 lossL: tensor(820.6163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24316 lossL: tensor(875.4464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24317 lossL: tensor(846.9148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24318 lossL: tensor(927.8484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24319 lossL: tensor(880.2901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24320 lossL: tensor(925.4984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24321 lossL: tensor(981.7491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24322 lossL: tensor(899.7819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24323 lossL: tensor(1003.9341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24324 lossL: tensor(958.9080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24325 lossL: tensor(931.7770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24326 lossL: tensor(1039.8469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24327 lossL: tensor(910.4725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24328 lossL: tensor(903.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24329 lossL: tensor(921.0798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24330 lossL: tensor(959.1497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24331 lossL: tensor(881.3463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24332 lossL: tensor(906.6633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24333 lossL: tensor(882.4595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24334 lossL: tensor(877.5768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24335 lossL: tensor(924.5032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24336 lossL: tensor(932.3040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24337 lossL: tensor(937.6866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24338 lossL: tensor(899.9906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24339 lossL: tensor(935.5463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24340 lossL: tensor(964.1487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24341 lossL: tensor(893.0154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24342 lossL: tensor(919.2579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24343 lossL: tensor(892.7519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24344 lossL: tensor(843.6505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24345 lossL: tensor(932.9849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24346 lossL: tensor(870.2312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24347 lossL: tensor(934.1873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24348 lossL: tensor(913.2152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24349 lossL: tensor(965.1917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24350 lossL: tensor(859.6138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24351 lossL: tensor(940.7051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24352 lossL: tensor(907.1165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24353 lossL: tensor(903.3738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24354 lossL: tensor(911.4990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24355 lossL: tensor(903.9619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24356 lossL: tensor(904.0557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24357 lossL: tensor(892.8713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24358 lossL: tensor(888.2643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24359 lossL: tensor(960.3289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24360 lossL: tensor(938.6368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24361 lossL: tensor(986.3479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24362 lossL: tensor(848.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24363 lossL: tensor(939.9643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24364 lossL: tensor(981.5457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24365 lossL: tensor(881.7767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24366 lossL: tensor(919.8776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24367 lossL: tensor(898.4388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24368 lossL: tensor(948.2249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24369 lossL: tensor(912.1163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24370 lossL: tensor(947.5900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24371 lossL: tensor(1026.5538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24372 lossL: tensor(991.7379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24373 lossL: tensor(1055.2114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24374 lossL: tensor(980.3740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24375 lossL: tensor(911.9499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24376 lossL: tensor(918.9838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24377 lossL: tensor(920.2350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24378 lossL: tensor(862.3649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24379 lossL: tensor(1013.7488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24380 lossL: tensor(956.3949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24381 lossL: tensor(939.6833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24382 lossL: tensor(961.4768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24383 lossL: tensor(1019.5919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24384 lossL: tensor(889.2130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24385 lossL: tensor(892.2076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24386 lossL: tensor(950.7568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24387 lossL: tensor(949.4120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24388 lossL: tensor(793.8224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24389 lossL: tensor(942.6299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24390 lossL: tensor(967.5956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24391 lossL: tensor(987.0121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24392 lossL: tensor(926.8338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24393 lossL: tensor(884.0989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24394 lossL: tensor(956.7281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24395 lossL: tensor(881.2720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24396 lossL: tensor(889.2568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24397 lossL: tensor(906.2983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24398 lossL: tensor(874.1211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24399 lossL: tensor(879.8636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24400 lossL: tensor(860.3709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24401 lossL: tensor(946.1323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24402 lossL: tensor(936.4509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24403 lossL: tensor(940.6827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24404 lossL: tensor(947.9910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24405 lossL: tensor(974.2034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24406 lossL: tensor(948.8206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24407 lossL: tensor(894.5040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24408 lossL: tensor(988.8627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24409 lossL: tensor(1029.1890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24410 lossL: tensor(1037.8279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24411 lossL: tensor(922.2233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24412 lossL: tensor(1103.8137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24413 lossL: tensor(904.6917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24414 lossL: tensor(1005.9131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24415 lossL: tensor(951.4738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24416 lossL: tensor(945.9888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24417 lossL: tensor(1028.7554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24418 lossL: tensor(897.6267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24419 lossL: tensor(1016.8493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24420 lossL: tensor(910.4070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24421 lossL: tensor(967.2398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24422 lossL: tensor(856.7171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24423 lossL: tensor(918.0311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24424 lossL: tensor(978.1815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24425 lossL: tensor(878.9591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24426 lossL: tensor(958.5692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24427 lossL: tensor(910.5566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24428 lossL: tensor(1051.0775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24429 lossL: tensor(858.1277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24430 lossL: tensor(994.1732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24431 lossL: tensor(961.0380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24432 lossL: tensor(1016.0933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24433 lossL: tensor(961.4161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24434 lossL: tensor(1009.1033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24435 lossL: tensor(1011.9621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24436 lossL: tensor(924.4305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24437 lossL: tensor(957.4380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24438 lossL: tensor(793.0985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24439 lossL: tensor(944.3056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24440 lossL: tensor(870.2087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24441 lossL: tensor(838.4554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24442 lossL: tensor(836.3009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24443 lossL: tensor(912.9517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24444 lossL: tensor(858.5166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24445 lossL: tensor(900.6242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24446 lossL: tensor(883.6401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24447 lossL: tensor(1018.5829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24448 lossL: tensor(866.1299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24449 lossL: tensor(974.9950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24450 lossL: tensor(814.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24451 lossL: tensor(1005.3835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24452 lossL: tensor(975.1303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24453 lossL: tensor(985.9920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24454 lossL: tensor(866.8920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24455 lossL: tensor(878.3358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24456 lossL: tensor(862.3022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24457 lossL: tensor(934.4417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24458 lossL: tensor(970.5731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24459 lossL: tensor(927.6013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24460 lossL: tensor(955.7100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24461 lossL: tensor(943.3925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24462 lossL: tensor(878.7397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24463 lossL: tensor(968.2549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24464 lossL: tensor(967.7528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24465 lossL: tensor(988.7253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24466 lossL: tensor(906.4130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24467 lossL: tensor(932.2020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24468 lossL: tensor(941.1644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24469 lossL: tensor(903.6335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24470 lossL: tensor(763.6940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24471 lossL: tensor(875.4850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24472 lossL: tensor(954.9479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24473 lossL: tensor(911.7245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24474 lossL: tensor(975.7023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24475 lossL: tensor(897.4337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24476 lossL: tensor(855.1237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24477 lossL: tensor(876.8442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24478 lossL: tensor(963.7146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24479 lossL: tensor(876.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24480 lossL: tensor(978.4585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24481 lossL: tensor(994.2951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24482 lossL: tensor(921.1542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24483 lossL: tensor(957.3427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24484 lossL: tensor(937.3340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24485 lossL: tensor(1008.6908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24486 lossL: tensor(1001.4664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24487 lossL: tensor(882.0121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24488 lossL: tensor(895.8002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24489 lossL: tensor(909.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24490 lossL: tensor(947.9060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24491 lossL: tensor(897.7075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24492 lossL: tensor(931.2389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24493 lossL: tensor(921.6808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24494 lossL: tensor(856.1193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24495 lossL: tensor(938.3231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24496 lossL: tensor(959.8344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24497 lossL: tensor(910.7417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24498 lossL: tensor(858.0789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24499 lossL: tensor(879.3333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24500 lossL: tensor(883.8743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24501 lossL: tensor(967.3182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24502 lossL: tensor(842.9094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24503 lossL: tensor(1002.9943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24504 lossL: tensor(946.9711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24505 lossL: tensor(918.4080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24506 lossL: tensor(944.8533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24507 lossL: tensor(908.2458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24508 lossL: tensor(829.9720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24509 lossL: tensor(937.9543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24510 lossL: tensor(898.5422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24511 lossL: tensor(862.2000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24512 lossL: tensor(972.1055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24513 lossL: tensor(860.1640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24514 lossL: tensor(871.4882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24515 lossL: tensor(976.2248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24516 lossL: tensor(823.9051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24517 lossL: tensor(830.3563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24518 lossL: tensor(928.5033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24519 lossL: tensor(966.9662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24520 lossL: tensor(900.1380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24521 lossL: tensor(899.3860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24522 lossL: tensor(915.5353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24523 lossL: tensor(888.1705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24524 lossL: tensor(877.1189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24525 lossL: tensor(902.3419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24526 lossL: tensor(904.0642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24527 lossL: tensor(874.7633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24528 lossL: tensor(865.3502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24529 lossL: tensor(912.4778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24530 lossL: tensor(948.4452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24531 lossL: tensor(846.8469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24532 lossL: tensor(892.7384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24533 lossL: tensor(998.4195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24534 lossL: tensor(919.1501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24535 lossL: tensor(1010.4318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24536 lossL: tensor(925.2084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24537 lossL: tensor(1063.2649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24538 lossL: tensor(900.8682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24539 lossL: tensor(946.9737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24540 lossL: tensor(925.7622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24541 lossL: tensor(892.8217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24542 lossL: tensor(950.2549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24543 lossL: tensor(846.7468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24544 lossL: tensor(897.1235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24545 lossL: tensor(966.6425, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24546 lossL: tensor(847.5699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24547 lossL: tensor(941.1769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24548 lossL: tensor(813.2233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24549 lossL: tensor(906.2257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24550 lossL: tensor(894.0984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24551 lossL: tensor(911.1928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24552 lossL: tensor(900.3784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24553 lossL: tensor(869.9533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24554 lossL: tensor(966.6025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24555 lossL: tensor(921.2491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24556 lossL: tensor(876.3427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24557 lossL: tensor(929.0681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24558 lossL: tensor(933.7979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24559 lossL: tensor(967.0417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24560 lossL: tensor(874.3188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24561 lossL: tensor(1016.6949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24562 lossL: tensor(931.5180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24563 lossL: tensor(939.8431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24564 lossL: tensor(911.1624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24565 lossL: tensor(990.8782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24566 lossL: tensor(884.1588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24567 lossL: tensor(876.7018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24568 lossL: tensor(977.1118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24569 lossL: tensor(930.1852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24570 lossL: tensor(1011.9230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24571 lossL: tensor(858.2250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24572 lossL: tensor(956.6389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24573 lossL: tensor(967.9594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24574 lossL: tensor(1017.3524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24575 lossL: tensor(1055.4348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24576 lossL: tensor(929.2775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24577 lossL: tensor(930.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24578 lossL: tensor(978.2407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24579 lossL: tensor(911.7747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24580 lossL: tensor(866.7553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24581 lossL: tensor(951.3654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24582 lossL: tensor(865.5071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24583 lossL: tensor(916.1223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24584 lossL: tensor(946.8861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24585 lossL: tensor(965.3390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24586 lossL: tensor(1008.0421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24587 lossL: tensor(955.3298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24588 lossL: tensor(957.5291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24589 lossL: tensor(957.7946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24590 lossL: tensor(983.5084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24591 lossL: tensor(946.3465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24592 lossL: tensor(932.4861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24593 lossL: tensor(876.4899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24594 lossL: tensor(886.4710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24595 lossL: tensor(920.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24596 lossL: tensor(847.7471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24597 lossL: tensor(868.3987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24598 lossL: tensor(943.5971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24599 lossL: tensor(851.6385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24600 lossL: tensor(909.7044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24601 lossL: tensor(951.2236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24602 lossL: tensor(937.5159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24603 lossL: tensor(897.4490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24604 lossL: tensor(895.4615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24605 lossL: tensor(901.9498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24606 lossL: tensor(995.9565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24607 lossL: tensor(1005.8109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24608 lossL: tensor(853.3749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24609 lossL: tensor(934.2701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24610 lossL: tensor(862.8351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24611 lossL: tensor(863.2736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24612 lossL: tensor(911.3046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24613 lossL: tensor(867.4479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24614 lossL: tensor(840.6912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24615 lossL: tensor(934.8189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24616 lossL: tensor(934.7580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24617 lossL: tensor(903.4017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24618 lossL: tensor(952.9846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24619 lossL: tensor(900.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24620 lossL: tensor(904.3701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24621 lossL: tensor(1026.1210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24622 lossL: tensor(874.6978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24623 lossL: tensor(841.9882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24624 lossL: tensor(846.2992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24625 lossL: tensor(979.0123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24626 lossL: tensor(914.8317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24627 lossL: tensor(816.8202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24628 lossL: tensor(921.6891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24629 lossL: tensor(956.6866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24630 lossL: tensor(911.8203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24631 lossL: tensor(911.3087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24632 lossL: tensor(873.7911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24633 lossL: tensor(938.0946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24634 lossL: tensor(871.6950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24635 lossL: tensor(837.3051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24636 lossL: tensor(874.2882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24637 lossL: tensor(886.8530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24638 lossL: tensor(971.8379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24639 lossL: tensor(912.8141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24640 lossL: tensor(881.0681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24641 lossL: tensor(897.4203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24642 lossL: tensor(907.6724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24643 lossL: tensor(960.6325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24644 lossL: tensor(919.3910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24645 lossL: tensor(892.1265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24646 lossL: tensor(977.3600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24647 lossL: tensor(803.0599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24648 lossL: tensor(852.5174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24649 lossL: tensor(851.7531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24650 lossL: tensor(859.4157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24651 lossL: tensor(920.4037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24652 lossL: tensor(882.0689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24653 lossL: tensor(980.2169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24654 lossL: tensor(998.4614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24655 lossL: tensor(882.1432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24656 lossL: tensor(889.2316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24657 lossL: tensor(886.3005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24658 lossL: tensor(888.8494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24659 lossL: tensor(858.3420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24660 lossL: tensor(968.8440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24661 lossL: tensor(935.3786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24662 lossL: tensor(878.1764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24663 lossL: tensor(835.3310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24664 lossL: tensor(866.4188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24665 lossL: tensor(816.5531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24666 lossL: tensor(961.4231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24667 lossL: tensor(868.0153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24668 lossL: tensor(983.5699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24669 lossL: tensor(881.2402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24670 lossL: tensor(825.4561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24671 lossL: tensor(915.0349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24672 lossL: tensor(823.2181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24673 lossL: tensor(863.9733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24674 lossL: tensor(923.7527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24675 lossL: tensor(901.6874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24676 lossL: tensor(968.6658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24677 lossL: tensor(840.4659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24678 lossL: tensor(826.5463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24679 lossL: tensor(918.2385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24680 lossL: tensor(1048.2926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24681 lossL: tensor(911.5377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24682 lossL: tensor(944.3611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24683 lossL: tensor(837.1961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24684 lossL: tensor(917.9366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24685 lossL: tensor(956.6807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24686 lossL: tensor(877.3170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24687 lossL: tensor(864.7474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24688 lossL: tensor(872.3009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24689 lossL: tensor(927.4276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24690 lossL: tensor(920.5356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24691 lossL: tensor(869.4263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24692 lossL: tensor(872.7415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24693 lossL: tensor(1066.6530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24694 lossL: tensor(939.6296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24695 lossL: tensor(964.0524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24696 lossL: tensor(1007.6556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24697 lossL: tensor(890.0317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24698 lossL: tensor(1079.2712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24699 lossL: tensor(895.8997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24700 lossL: tensor(1062.6158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24701 lossL: tensor(932.5186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24702 lossL: tensor(1016.0726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24703 lossL: tensor(1257.9122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24704 lossL: tensor(847.4172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24705 lossL: tensor(1068.5165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24706 lossL: tensor(898.3464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24707 lossL: tensor(1014.7884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24708 lossL: tensor(952.4927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24709 lossL: tensor(844.2665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24710 lossL: tensor(951.9299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24711 lossL: tensor(865.3485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24712 lossL: tensor(959.9493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24713 lossL: tensor(999.5588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24714 lossL: tensor(873.8591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24715 lossL: tensor(1017.2086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24716 lossL: tensor(880.0897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24717 lossL: tensor(881.4088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24718 lossL: tensor(904.2418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24719 lossL: tensor(899.7379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24720 lossL: tensor(968.0824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24721 lossL: tensor(879.7631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24722 lossL: tensor(939.5748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24723 lossL: tensor(851.5633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24724 lossL: tensor(824.2122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24725 lossL: tensor(963.6387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24726 lossL: tensor(929.3002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24727 lossL: tensor(957.0769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24728 lossL: tensor(902.1155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24729 lossL: tensor(919.7808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24730 lossL: tensor(912.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24731 lossL: tensor(896.0405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24732 lossL: tensor(970.4906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24733 lossL: tensor(854.9469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24734 lossL: tensor(825.1605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24735 lossL: tensor(883.7913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24736 lossL: tensor(910.3480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24737 lossL: tensor(953.5194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24738 lossL: tensor(892.5450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24739 lossL: tensor(905.4695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24740 lossL: tensor(861.6572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24741 lossL: tensor(860.5398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24742 lossL: tensor(851.5812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24743 lossL: tensor(905.4293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24744 lossL: tensor(827.4869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24745 lossL: tensor(922.5314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24746 lossL: tensor(913.1672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24747 lossL: tensor(850.9819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24748 lossL: tensor(840.9584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24749 lossL: tensor(820.4626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24750 lossL: tensor(862.1948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24751 lossL: tensor(884.6256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24752 lossL: tensor(838.6117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24753 lossL: tensor(846.0201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24754 lossL: tensor(903.7743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24755 lossL: tensor(909.1301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24756 lossL: tensor(877.9965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24757 lossL: tensor(951.3465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24758 lossL: tensor(876.7151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24759 lossL: tensor(939.7057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24760 lossL: tensor(921.7427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24761 lossL: tensor(931.9450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24762 lossL: tensor(919.7672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24763 lossL: tensor(888.7539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24764 lossL: tensor(915.9603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24765 lossL: tensor(1041.5703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24766 lossL: tensor(914.9990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24767 lossL: tensor(929.5496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24768 lossL: tensor(917.2787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24769 lossL: tensor(869.1797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24770 lossL: tensor(905.6348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24771 lossL: tensor(912.3779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24772 lossL: tensor(888.0753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24773 lossL: tensor(861.8732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24774 lossL: tensor(925.0038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24775 lossL: tensor(939.3602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24776 lossL: tensor(897.0048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24777 lossL: tensor(799.3870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24778 lossL: tensor(899.9304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24779 lossL: tensor(887.6049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24780 lossL: tensor(870.1401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24781 lossL: tensor(965.6397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24782 lossL: tensor(912.9907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24783 lossL: tensor(1047.1112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24784 lossL: tensor(838.2847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24785 lossL: tensor(965.1318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24786 lossL: tensor(944.1434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24787 lossL: tensor(900.6990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24788 lossL: tensor(1005.2301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24789 lossL: tensor(871.5582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24790 lossL: tensor(1065.7833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24791 lossL: tensor(874.5641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24792 lossL: tensor(920.9202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24793 lossL: tensor(989.8680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24794 lossL: tensor(857.5025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24795 lossL: tensor(980.8552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24796 lossL: tensor(868.9380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24797 lossL: tensor(980.2107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24798 lossL: tensor(968.9930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24799 lossL: tensor(902.4852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24800 lossL: tensor(969.1469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24801 lossL: tensor(995.8762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24802 lossL: tensor(912.7916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24803 lossL: tensor(1000.0320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24804 lossL: tensor(928.3323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24805 lossL: tensor(890.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24806 lossL: tensor(980.6006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24807 lossL: tensor(891.0696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24808 lossL: tensor(927.5857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24809 lossL: tensor(870.2419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24810 lossL: tensor(936.1595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24811 lossL: tensor(879.2347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24812 lossL: tensor(914.6238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24813 lossL: tensor(926.5034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24814 lossL: tensor(918.6903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24815 lossL: tensor(926.9942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24816 lossL: tensor(889.4096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24817 lossL: tensor(869.9064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24818 lossL: tensor(892.0464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24819 lossL: tensor(886.4130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24820 lossL: tensor(863.1867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24821 lossL: tensor(959.9347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24822 lossL: tensor(916.9110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24823 lossL: tensor(899.0897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24824 lossL: tensor(944.0093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24825 lossL: tensor(915.9518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24826 lossL: tensor(808.6724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24827 lossL: tensor(950.7203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24828 lossL: tensor(1067.6691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24829 lossL: tensor(934.7394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24830 lossL: tensor(982.2725, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24831 lossL: tensor(918.8024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24832 lossL: tensor(863.7169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24833 lossL: tensor(945.7654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24834 lossL: tensor(894.8665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24835 lossL: tensor(954.2034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24836 lossL: tensor(903.9830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24837 lossL: tensor(898.9058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24838 lossL: tensor(931.6889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24839 lossL: tensor(855.0975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24840 lossL: tensor(930.3491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24841 lossL: tensor(867.5778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24842 lossL: tensor(818.2325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24843 lossL: tensor(925.7219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24844 lossL: tensor(919.0504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24845 lossL: tensor(903.2650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24846 lossL: tensor(906.0768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24847 lossL: tensor(876.7759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24848 lossL: tensor(900.6330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24849 lossL: tensor(847.2247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24850 lossL: tensor(879.6672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24851 lossL: tensor(903.8578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24852 lossL: tensor(841.6851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24853 lossL: tensor(954.6691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24854 lossL: tensor(850.0345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24855 lossL: tensor(845.4504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24856 lossL: tensor(905.0590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24857 lossL: tensor(856.1267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24858 lossL: tensor(930.9985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24859 lossL: tensor(963.6908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24860 lossL: tensor(908.7048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24861 lossL: tensor(909.7951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24862 lossL: tensor(910.7052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24863 lossL: tensor(893.8852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24864 lossL: tensor(868.5655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24865 lossL: tensor(865.7908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24866 lossL: tensor(919.0128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24867 lossL: tensor(940.4325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24868 lossL: tensor(892.1964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24869 lossL: tensor(900.6747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24870 lossL: tensor(910.3160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24871 lossL: tensor(894.7812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24872 lossL: tensor(889.2922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24873 lossL: tensor(840.1160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24874 lossL: tensor(919.4217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24875 lossL: tensor(831.0933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24876 lossL: tensor(843.7390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24877 lossL: tensor(1008.7894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24878 lossL: tensor(972.1275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24879 lossL: tensor(958.0256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24880 lossL: tensor(1042.3020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24881 lossL: tensor(861.0598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24882 lossL: tensor(882.2789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24883 lossL: tensor(823.6205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24884 lossL: tensor(922.7346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24885 lossL: tensor(940.8733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24886 lossL: tensor(877.2708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24887 lossL: tensor(1019.7718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24888 lossL: tensor(933.1293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24889 lossL: tensor(1033.3271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24890 lossL: tensor(944.8535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24891 lossL: tensor(896.4106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24892 lossL: tensor(988.8084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24893 lossL: tensor(862.7615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24894 lossL: tensor(950.1426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24895 lossL: tensor(908.3087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24896 lossL: tensor(922.6505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24897 lossL: tensor(844.1776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24898 lossL: tensor(971.3445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24899 lossL: tensor(931.2769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24900 lossL: tensor(894.6780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24901 lossL: tensor(926.5142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24902 lossL: tensor(940.8671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24903 lossL: tensor(983.9383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24904 lossL: tensor(855.3407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24905 lossL: tensor(909.5784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24906 lossL: tensor(863.7579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24907 lossL: tensor(978.4767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24908 lossL: tensor(892.4182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24909 lossL: tensor(909.1283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24910 lossL: tensor(845.3253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24911 lossL: tensor(934.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24912 lossL: tensor(928.1069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24913 lossL: tensor(899.2263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24914 lossL: tensor(920.0243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24915 lossL: tensor(869.8585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24916 lossL: tensor(860.2572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24917 lossL: tensor(931.6296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24918 lossL: tensor(940.8874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24919 lossL: tensor(865.8401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24920 lossL: tensor(832.6443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24921 lossL: tensor(902.7607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24922 lossL: tensor(941.6565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24923 lossL: tensor(884.8386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24924 lossL: tensor(899.1361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24925 lossL: tensor(851.1682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24926 lossL: tensor(880.8368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24927 lossL: tensor(975.7571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24928 lossL: tensor(864.5894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24929 lossL: tensor(910.7745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24930 lossL: tensor(1040.3801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24931 lossL: tensor(891.1487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24932 lossL: tensor(996.6134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24933 lossL: tensor(841.2751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24934 lossL: tensor(899.9556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24935 lossL: tensor(907.2252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24936 lossL: tensor(887.2042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24937 lossL: tensor(875.7126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24938 lossL: tensor(827.1137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24939 lossL: tensor(914.7321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24940 lossL: tensor(889.9365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24941 lossL: tensor(938.6020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24942 lossL: tensor(896.1737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24943 lossL: tensor(802.3925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24944 lossL: tensor(921.1392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24945 lossL: tensor(964.2876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24946 lossL: tensor(811.0393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24947 lossL: tensor(893.0760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24948 lossL: tensor(836.6179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24949 lossL: tensor(908.7649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24950 lossL: tensor(889.3318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24951 lossL: tensor(882.8340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24952 lossL: tensor(932.5261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24953 lossL: tensor(834.8607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24954 lossL: tensor(926.3848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24955 lossL: tensor(874.9722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24956 lossL: tensor(853.6749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24957 lossL: tensor(849.9177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24958 lossL: tensor(922.1215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24959 lossL: tensor(900.3502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24960 lossL: tensor(849.4271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24961 lossL: tensor(841.8623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24962 lossL: tensor(935.3039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24963 lossL: tensor(871.1273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24964 lossL: tensor(870.3275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24965 lossL: tensor(874.3737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24966 lossL: tensor(941.8016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24967 lossL: tensor(901.5344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24968 lossL: tensor(867.5727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24969 lossL: tensor(894.3708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24970 lossL: tensor(824.1947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24971 lossL: tensor(934.8982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24972 lossL: tensor(948.5115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24973 lossL: tensor(902.2192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24974 lossL: tensor(914.9696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24975 lossL: tensor(924.2339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24976 lossL: tensor(944.1127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24977 lossL: tensor(919.0253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24978 lossL: tensor(889.5479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24979 lossL: tensor(875.9705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24980 lossL: tensor(865.0942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24981 lossL: tensor(1033.5927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24982 lossL: tensor(923.7982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24983 lossL: tensor(815.6007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24984 lossL: tensor(1012.4066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24985 lossL: tensor(975.6500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24986 lossL: tensor(882.0256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24987 lossL: tensor(923.9177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24988 lossL: tensor(924.0102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24989 lossL: tensor(915.2572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24990 lossL: tensor(922.4202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24991 lossL: tensor(888.9449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24992 lossL: tensor(1005.6110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24993 lossL: tensor(852.5016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24994 lossL: tensor(825.0056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24995 lossL: tensor(868.2458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24996 lossL: tensor(912.7984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24997 lossL: tensor(948.9098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24998 lossL: tensor(927.4343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "24999 lossL: tensor(932.5815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25000 lossL: tensor(910.9232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25001 lossL: tensor(853.8943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25002 lossL: tensor(858.6717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25003 lossL: tensor(851.3640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25004 lossL: tensor(887.0951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25005 lossL: tensor(842.3789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25006 lossL: tensor(914.0355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25007 lossL: tensor(831.2633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25008 lossL: tensor(902.3085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25009 lossL: tensor(982.1891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25010 lossL: tensor(870.5995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25011 lossL: tensor(897.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25012 lossL: tensor(886.8684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25013 lossL: tensor(903.5919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25014 lossL: tensor(872.1013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25015 lossL: tensor(895.5671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25016 lossL: tensor(809.2466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25017 lossL: tensor(840.8209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25018 lossL: tensor(879.9627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25019 lossL: tensor(906.4012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25020 lossL: tensor(890.5416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25021 lossL: tensor(869.0145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25022 lossL: tensor(844.3646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25023 lossL: tensor(824.7675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25024 lossL: tensor(812.1196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25025 lossL: tensor(882.5739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25026 lossL: tensor(940.9808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25027 lossL: tensor(878.7678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25028 lossL: tensor(968.0834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25029 lossL: tensor(876.5292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25030 lossL: tensor(929.2333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25031 lossL: tensor(874.5525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25032 lossL: tensor(919.2409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25033 lossL: tensor(857.3638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25034 lossL: tensor(931.0065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25035 lossL: tensor(1087.2042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25036 lossL: tensor(850.6125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25037 lossL: tensor(1054.7786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25038 lossL: tensor(1083.1466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25039 lossL: tensor(867.5557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25040 lossL: tensor(955.8569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25041 lossL: tensor(805.0941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25042 lossL: tensor(991.3845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25043 lossL: tensor(901.2119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25044 lossL: tensor(930.5740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25045 lossL: tensor(1043.1339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25046 lossL: tensor(808.1209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25047 lossL: tensor(1073.9729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25048 lossL: tensor(960.6572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25049 lossL: tensor(825.6028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25050 lossL: tensor(1090.8364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25051 lossL: tensor(846.2477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25052 lossL: tensor(984.2271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25053 lossL: tensor(955.4794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25054 lossL: tensor(929.0806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25055 lossL: tensor(1064.3936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25056 lossL: tensor(867.6705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25057 lossL: tensor(1023.1025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25058 lossL: tensor(893.7198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25059 lossL: tensor(1000.5635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25060 lossL: tensor(1104.1307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25061 lossL: tensor(970.0978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25062 lossL: tensor(1078.1268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25063 lossL: tensor(931.9195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25064 lossL: tensor(879.2950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25065 lossL: tensor(1073.5212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25066 lossL: tensor(890.0934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25067 lossL: tensor(897.7509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25068 lossL: tensor(895.4338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25069 lossL: tensor(856.8351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25070 lossL: tensor(912.5438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25071 lossL: tensor(910.4173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25072 lossL: tensor(889.8123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25073 lossL: tensor(946.8932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25074 lossL: tensor(920.4478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25075 lossL: tensor(922.8120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25076 lossL: tensor(941.5459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25077 lossL: tensor(1007.0209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25078 lossL: tensor(1005.4855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25079 lossL: tensor(871.7385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25080 lossL: tensor(910.5812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25081 lossL: tensor(993.1027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25082 lossL: tensor(934.6275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25083 lossL: tensor(1019.1185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25084 lossL: tensor(841.4521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25085 lossL: tensor(953.5086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25086 lossL: tensor(947.8629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25087 lossL: tensor(825.9260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25088 lossL: tensor(936.4777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25089 lossL: tensor(943.3829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25090 lossL: tensor(896.9760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25091 lossL: tensor(921.5314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25092 lossL: tensor(838.9074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25093 lossL: tensor(848.9760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25094 lossL: tensor(879.7687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25095 lossL: tensor(859.9003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25096 lossL: tensor(856.2489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25097 lossL: tensor(831.4932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25098 lossL: tensor(860.7519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25099 lossL: tensor(795.2656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25100 lossL: tensor(884.2584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25101 lossL: tensor(921.4248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25102 lossL: tensor(854.4426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25103 lossL: tensor(844.2061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25104 lossL: tensor(925.1826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25105 lossL: tensor(869.7240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25106 lossL: tensor(974.4987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25107 lossL: tensor(899.1096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25108 lossL: tensor(904.8734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25109 lossL: tensor(939.3720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25110 lossL: tensor(893.9677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25111 lossL: tensor(845.3351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25112 lossL: tensor(904.3684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25113 lossL: tensor(854.1382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25114 lossL: tensor(906.4288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25115 lossL: tensor(877.3386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25116 lossL: tensor(851.7913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25117 lossL: tensor(881.0339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25118 lossL: tensor(859.3619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25119 lossL: tensor(859.5513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25120 lossL: tensor(907.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25121 lossL: tensor(902.6420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25122 lossL: tensor(857.9600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25123 lossL: tensor(952.0812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25124 lossL: tensor(841.7121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25125 lossL: tensor(908.8094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25126 lossL: tensor(876.9229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25127 lossL: tensor(842.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25128 lossL: tensor(892.6224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25129 lossL: tensor(947.1851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25130 lossL: tensor(911.0488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25131 lossL: tensor(915.4645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25132 lossL: tensor(809.3539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25133 lossL: tensor(976.1021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25134 lossL: tensor(877.4872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25135 lossL: tensor(908.2951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25136 lossL: tensor(860.7929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25137 lossL: tensor(917.9657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25138 lossL: tensor(804.6775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25139 lossL: tensor(839.3846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25140 lossL: tensor(923.5668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25141 lossL: tensor(924.1199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25142 lossL: tensor(948.8584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25143 lossL: tensor(802.1299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25144 lossL: tensor(829.0214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25145 lossL: tensor(833.3074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25146 lossL: tensor(822.7484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25147 lossL: tensor(866.5148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25148 lossL: tensor(943.4791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25149 lossL: tensor(924.5805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25150 lossL: tensor(934.9510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25151 lossL: tensor(938.2754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25152 lossL: tensor(841.2239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25153 lossL: tensor(866.7261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25154 lossL: tensor(894.7103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25155 lossL: tensor(794.9048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25156 lossL: tensor(880.6817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25157 lossL: tensor(864.7700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25158 lossL: tensor(877.1102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25159 lossL: tensor(833.7029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25160 lossL: tensor(976.9917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25161 lossL: tensor(849.2108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25162 lossL: tensor(904.4535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25163 lossL: tensor(859.1400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25164 lossL: tensor(864.3918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25165 lossL: tensor(897.2310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25166 lossL: tensor(854.4352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25167 lossL: tensor(833.5481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25168 lossL: tensor(911.3534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25169 lossL: tensor(890.5406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25170 lossL: tensor(871.1982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25171 lossL: tensor(913.6649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25172 lossL: tensor(853.4420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25173 lossL: tensor(919.9003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25174 lossL: tensor(768.9511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25175 lossL: tensor(890.0679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25176 lossL: tensor(928.8707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25177 lossL: tensor(937.7122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25178 lossL: tensor(796.4412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25179 lossL: tensor(936.9141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25180 lossL: tensor(854.9615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25181 lossL: tensor(787.0621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25182 lossL: tensor(890.8821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25183 lossL: tensor(926.3050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25184 lossL: tensor(928.6968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25185 lossL: tensor(889.7224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25186 lossL: tensor(935.2019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25187 lossL: tensor(930.1812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25188 lossL: tensor(915.8249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25189 lossL: tensor(875.8359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25190 lossL: tensor(832.4742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25191 lossL: tensor(920.5911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25192 lossL: tensor(852.9160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25193 lossL: tensor(876.2134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25194 lossL: tensor(853.7587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25195 lossL: tensor(936.8241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25196 lossL: tensor(913.4954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25197 lossL: tensor(938.2778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25198 lossL: tensor(838.0485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25199 lossL: tensor(839.8178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25200 lossL: tensor(882.7810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25201 lossL: tensor(852.0608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25202 lossL: tensor(843.0552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25203 lossL: tensor(775.0897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25204 lossL: tensor(834.1396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25205 lossL: tensor(851.7445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25206 lossL: tensor(905.4136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25207 lossL: tensor(864.8391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25208 lossL: tensor(917.5900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25209 lossL: tensor(909.5988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25210 lossL: tensor(925.2433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25211 lossL: tensor(907.9708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25212 lossL: tensor(856.0940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25213 lossL: tensor(825.5077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25214 lossL: tensor(842.3507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25215 lossL: tensor(867.3788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25216 lossL: tensor(889.9517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25217 lossL: tensor(869.1066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25218 lossL: tensor(853.9930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25219 lossL: tensor(941.6649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25220 lossL: tensor(930.4608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25221 lossL: tensor(879.6269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25222 lossL: tensor(910.5676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25223 lossL: tensor(924.0847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25224 lossL: tensor(914.2198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25225 lossL: tensor(857.0740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25226 lossL: tensor(912.9321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25227 lossL: tensor(923.9738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25228 lossL: tensor(1071.9000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25229 lossL: tensor(909.7607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25230 lossL: tensor(854.3771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25231 lossL: tensor(888.1132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25232 lossL: tensor(878.5099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25233 lossL: tensor(881.4133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25234 lossL: tensor(892.4063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25235 lossL: tensor(930.7072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25236 lossL: tensor(886.3733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25237 lossL: tensor(930.6787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25238 lossL: tensor(1042.8134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25239 lossL: tensor(1060.8029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25240 lossL: tensor(881.3107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25241 lossL: tensor(1034.4597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25242 lossL: tensor(970.6173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25243 lossL: tensor(881.1987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25244 lossL: tensor(1070.0402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25245 lossL: tensor(945.3358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25246 lossL: tensor(894.7544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25247 lossL: tensor(943.3168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25248 lossL: tensor(912.2485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25249 lossL: tensor(958.3453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25250 lossL: tensor(829.6678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25251 lossL: tensor(843.2275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25252 lossL: tensor(968.3884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25253 lossL: tensor(849.7294, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25254 lossL: tensor(1044.5469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25255 lossL: tensor(938.3692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25256 lossL: tensor(912.1681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25257 lossL: tensor(1079.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25258 lossL: tensor(865.7626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25259 lossL: tensor(1036.1410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25260 lossL: tensor(974.2016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25261 lossL: tensor(965.2717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25262 lossL: tensor(1142.1219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25263 lossL: tensor(847.7541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25264 lossL: tensor(1099.6273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25265 lossL: tensor(1052.2140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25266 lossL: tensor(854.6829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25267 lossL: tensor(1173.5626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25268 lossL: tensor(1060.2795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25269 lossL: tensor(936.8531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25270 lossL: tensor(1093.8149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25271 lossL: tensor(886.3389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25272 lossL: tensor(947.7820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25273 lossL: tensor(856.3452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25274 lossL: tensor(939.7927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25275 lossL: tensor(926.0163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25276 lossL: tensor(956.2850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25277 lossL: tensor(926.1180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25278 lossL: tensor(887.3388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25279 lossL: tensor(919.0876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25280 lossL: tensor(946.8544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25281 lossL: tensor(860.6888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25282 lossL: tensor(958.5129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25283 lossL: tensor(878.2675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25284 lossL: tensor(878.3162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25285 lossL: tensor(882.8156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25286 lossL: tensor(804.9418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25287 lossL: tensor(909.2036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25288 lossL: tensor(951.2707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25289 lossL: tensor(921.0318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25290 lossL: tensor(891.8644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25291 lossL: tensor(816.4125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25292 lossL: tensor(809.7100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25293 lossL: tensor(860.3950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25294 lossL: tensor(952.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25295 lossL: tensor(914.1981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25296 lossL: tensor(871.6353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25297 lossL: tensor(924.4059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25298 lossL: tensor(875.9810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25299 lossL: tensor(929.7724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25300 lossL: tensor(831.6682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25301 lossL: tensor(844.4580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25302 lossL: tensor(828.0746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25303 lossL: tensor(830.8995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25304 lossL: tensor(862.7349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25305 lossL: tensor(860.4083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25306 lossL: tensor(873.6285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25307 lossL: tensor(867.5968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25308 lossL: tensor(894.5311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25309 lossL: tensor(908.8975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25310 lossL: tensor(988.0613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25311 lossL: tensor(854.7269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25312 lossL: tensor(846.9774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25313 lossL: tensor(816.9169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25314 lossL: tensor(873.8491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25315 lossL: tensor(944.6447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25316 lossL: tensor(904.6870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25317 lossL: tensor(818.1212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25318 lossL: tensor(890.4166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25319 lossL: tensor(923.9607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25320 lossL: tensor(852.8866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25321 lossL: tensor(837.9935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25322 lossL: tensor(912.9033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25323 lossL: tensor(867.7067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25324 lossL: tensor(895.4028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25325 lossL: tensor(886.6473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25326 lossL: tensor(921.3862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25327 lossL: tensor(916.2242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25328 lossL: tensor(899.7816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25329 lossL: tensor(859.7424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25330 lossL: tensor(868.2607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25331 lossL: tensor(921.4371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25332 lossL: tensor(895.2993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25333 lossL: tensor(806.9684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25334 lossL: tensor(909.4935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25335 lossL: tensor(828.9739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25336 lossL: tensor(842.7670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25337 lossL: tensor(934.2930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25338 lossL: tensor(914.0248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25339 lossL: tensor(875.0944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25340 lossL: tensor(954.4199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25341 lossL: tensor(846.9481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25342 lossL: tensor(963.2169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25343 lossL: tensor(1001.5834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25344 lossL: tensor(897.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25345 lossL: tensor(1003.1804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25346 lossL: tensor(824.8670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25347 lossL: tensor(874.8758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25348 lossL: tensor(874.8157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25349 lossL: tensor(907.0120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25350 lossL: tensor(845.5408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25351 lossL: tensor(831.1151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25352 lossL: tensor(864.9058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25353 lossL: tensor(803.2776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25354 lossL: tensor(854.2351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25355 lossL: tensor(861.9617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25356 lossL: tensor(973.6957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25357 lossL: tensor(913.0950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25358 lossL: tensor(848.2829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25359 lossL: tensor(913.7285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25360 lossL: tensor(880.7261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25361 lossL: tensor(928.0109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25362 lossL: tensor(919.5220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25363 lossL: tensor(796.1320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25364 lossL: tensor(909.8328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25365 lossL: tensor(915.4561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25366 lossL: tensor(807.2911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25367 lossL: tensor(818.4991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25368 lossL: tensor(874.0220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25369 lossL: tensor(884.0275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25370 lossL: tensor(881.5724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25371 lossL: tensor(888.7795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25372 lossL: tensor(954.9417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25373 lossL: tensor(838.0121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25374 lossL: tensor(849.3008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25375 lossL: tensor(862.0773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25376 lossL: tensor(845.8112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25377 lossL: tensor(861.0931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25378 lossL: tensor(893.8027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25379 lossL: tensor(854.1557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25380 lossL: tensor(876.7758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25381 lossL: tensor(910.4924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25382 lossL: tensor(798.1932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25383 lossL: tensor(875.5392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25384 lossL: tensor(883.0800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25385 lossL: tensor(890.7384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25386 lossL: tensor(853.3602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25387 lossL: tensor(816.6119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25388 lossL: tensor(965.0433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25389 lossL: tensor(932.3976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25390 lossL: tensor(861.7086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25391 lossL: tensor(843.4835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25392 lossL: tensor(933.4599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25393 lossL: tensor(919.6055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25394 lossL: tensor(863.9660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25395 lossL: tensor(923.0707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25396 lossL: tensor(891.0673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25397 lossL: tensor(910.7892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25398 lossL: tensor(840.4568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25399 lossL: tensor(798.7548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25400 lossL: tensor(872.4543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25401 lossL: tensor(857.4288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25402 lossL: tensor(857.3366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25403 lossL: tensor(850.3666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25404 lossL: tensor(961.3550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25405 lossL: tensor(913.6096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25406 lossL: tensor(861.9822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25407 lossL: tensor(860.6009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25408 lossL: tensor(811.8539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25409 lossL: tensor(824.1418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25410 lossL: tensor(890.6143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25411 lossL: tensor(901.3979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25412 lossL: tensor(876.9156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25413 lossL: tensor(956.0382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25414 lossL: tensor(982.8303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25415 lossL: tensor(1004.0693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25416 lossL: tensor(925.9715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25417 lossL: tensor(867.2122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25418 lossL: tensor(865.8832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25419 lossL: tensor(860.2993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25420 lossL: tensor(860.5443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25421 lossL: tensor(836.1125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25422 lossL: tensor(865.4232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25423 lossL: tensor(858.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25424 lossL: tensor(866.5737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25425 lossL: tensor(925.8184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25426 lossL: tensor(857.8068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25427 lossL: tensor(970.2917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25428 lossL: tensor(935.4398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25429 lossL: tensor(870.5900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25430 lossL: tensor(896.6709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25431 lossL: tensor(891.0113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25432 lossL: tensor(908.3212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25433 lossL: tensor(868.1745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25434 lossL: tensor(1036.3374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25435 lossL: tensor(1157.9329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25436 lossL: tensor(944.5278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25437 lossL: tensor(1012.5895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25438 lossL: tensor(935.6522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25439 lossL: tensor(846.2014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25440 lossL: tensor(905.7661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25441 lossL: tensor(907.3991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25442 lossL: tensor(982.3054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25443 lossL: tensor(901.7804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25444 lossL: tensor(875.7596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25445 lossL: tensor(942.3431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25446 lossL: tensor(899.5427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25447 lossL: tensor(953.0070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25448 lossL: tensor(862.6844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25449 lossL: tensor(865.8196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25450 lossL: tensor(948.5637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25451 lossL: tensor(893.9366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25452 lossL: tensor(933.1682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25453 lossL: tensor(896.0684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25454 lossL: tensor(824.2520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25455 lossL: tensor(900.5723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25456 lossL: tensor(781.4526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25457 lossL: tensor(881.5042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25458 lossL: tensor(870.4006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25459 lossL: tensor(883.6314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25460 lossL: tensor(912.2121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25461 lossL: tensor(885.6008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25462 lossL: tensor(875.6380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25463 lossL: tensor(959.4161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25464 lossL: tensor(995.6935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25465 lossL: tensor(867.6364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25466 lossL: tensor(1170.0676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25467 lossL: tensor(986.8118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25468 lossL: tensor(930.7512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25469 lossL: tensor(1174.2700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25470 lossL: tensor(889.3851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25471 lossL: tensor(1135.6550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25472 lossL: tensor(968.0104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25473 lossL: tensor(916.6262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25474 lossL: tensor(1085.1874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25475 lossL: tensor(767.3955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25476 lossL: tensor(955.4360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25477 lossL: tensor(905.1909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25478 lossL: tensor(866.8296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25479 lossL: tensor(887.4880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25480 lossL: tensor(775.1711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25481 lossL: tensor(909.9847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25482 lossL: tensor(799.8455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25483 lossL: tensor(884.5207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25484 lossL: tensor(834.2300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25485 lossL: tensor(940.4642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25486 lossL: tensor(942.0676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25487 lossL: tensor(882.1963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25488 lossL: tensor(859.7150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25489 lossL: tensor(875.7776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25490 lossL: tensor(812.2324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25491 lossL: tensor(847.0200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25492 lossL: tensor(915.8511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25493 lossL: tensor(860.7750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25494 lossL: tensor(903.1959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25495 lossL: tensor(898.3453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25496 lossL: tensor(903.0663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25497 lossL: tensor(897.4056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25498 lossL: tensor(894.2214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25499 lossL: tensor(891.2273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25500 lossL: tensor(890.1318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25501 lossL: tensor(833.6718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25502 lossL: tensor(854.9445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25503 lossL: tensor(931.8478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25504 lossL: tensor(826.1909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25505 lossL: tensor(909.5526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25506 lossL: tensor(919.6235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25507 lossL: tensor(854.8731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25508 lossL: tensor(940.6124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25509 lossL: tensor(801.7700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25510 lossL: tensor(985.5494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25511 lossL: tensor(868.7665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25512 lossL: tensor(874.0216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25513 lossL: tensor(899.8079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25514 lossL: tensor(934.6901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25515 lossL: tensor(836.0158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25516 lossL: tensor(792.8154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25517 lossL: tensor(897.9443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25518 lossL: tensor(1033.8049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25519 lossL: tensor(867.4516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25520 lossL: tensor(964.2324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25521 lossL: tensor(1024.3240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25522 lossL: tensor(915.3737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25523 lossL: tensor(1051.8619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25524 lossL: tensor(890.0737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25525 lossL: tensor(996.5446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25526 lossL: tensor(848.1478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25527 lossL: tensor(1059.2277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25528 lossL: tensor(908.2053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25529 lossL: tensor(998.9636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25530 lossL: tensor(1094.0724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25531 lossL: tensor(909.6683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25532 lossL: tensor(1065.3850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25533 lossL: tensor(897.4968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25534 lossL: tensor(834.5122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25535 lossL: tensor(889.6174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25536 lossL: tensor(920.4303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25537 lossL: tensor(1000.3772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25538 lossL: tensor(896.3488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25539 lossL: tensor(929.3549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25540 lossL: tensor(975.3224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25541 lossL: tensor(844.3312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25542 lossL: tensor(1009.3264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25543 lossL: tensor(881.1229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25544 lossL: tensor(922.1664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25545 lossL: tensor(952.7753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25546 lossL: tensor(795.4216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25547 lossL: tensor(950.7114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25548 lossL: tensor(818.8881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25549 lossL: tensor(891.2328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25550 lossL: tensor(857.9887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25551 lossL: tensor(842.1650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25552 lossL: tensor(891.1023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25553 lossL: tensor(885.8947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25554 lossL: tensor(898.0247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25555 lossL: tensor(809.4317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25556 lossL: tensor(845.7033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25557 lossL: tensor(886.7926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25558 lossL: tensor(872.0738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25559 lossL: tensor(981.2686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25560 lossL: tensor(852.4171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25561 lossL: tensor(916.0608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25562 lossL: tensor(942.9851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25563 lossL: tensor(828.0522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25564 lossL: tensor(971.3284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25565 lossL: tensor(808.3748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25566 lossL: tensor(786.9995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25567 lossL: tensor(913.5228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25568 lossL: tensor(805.4191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25569 lossL: tensor(878.7296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25570 lossL: tensor(881.9162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25571 lossL: tensor(825.4161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25572 lossL: tensor(859.7512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25573 lossL: tensor(746.2160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "25574 lossL: tensor(968.7909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25575 lossL: tensor(811.7616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25576 lossL: tensor(872.9190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25577 lossL: tensor(929.7098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25578 lossL: tensor(878.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25579 lossL: tensor(816.7771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25580 lossL: tensor(904.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25581 lossL: tensor(841.5027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25582 lossL: tensor(876.8529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25583 lossL: tensor(859.0563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25584 lossL: tensor(843.9548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25585 lossL: tensor(856.2535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25586 lossL: tensor(901.7208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25587 lossL: tensor(830.0462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25588 lossL: tensor(920.2112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25589 lossL: tensor(837.7337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25590 lossL: tensor(824.1469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25591 lossL: tensor(912.3434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25592 lossL: tensor(893.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25593 lossL: tensor(905.3691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25594 lossL: tensor(865.4983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25595 lossL: tensor(842.5803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25596 lossL: tensor(848.4278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25597 lossL: tensor(877.9020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25598 lossL: tensor(874.9506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25599 lossL: tensor(854.1416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25600 lossL: tensor(898.4821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25601 lossL: tensor(870.6288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25602 lossL: tensor(807.3619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25603 lossL: tensor(834.4282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25604 lossL: tensor(855.3972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25605 lossL: tensor(865.6918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25606 lossL: tensor(843.2245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25607 lossL: tensor(892.3113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25608 lossL: tensor(835.5186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25609 lossL: tensor(809.2956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25610 lossL: tensor(892.5723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25611 lossL: tensor(844.0494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25612 lossL: tensor(890.1270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25613 lossL: tensor(827.9722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25614 lossL: tensor(933.6357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25615 lossL: tensor(825.7647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25616 lossL: tensor(918.6915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25617 lossL: tensor(902.5282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25618 lossL: tensor(846.7651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25619 lossL: tensor(1018.5413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25620 lossL: tensor(1047.1088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25621 lossL: tensor(847.1152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25622 lossL: tensor(1053.1101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25623 lossL: tensor(873.3149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25624 lossL: tensor(1068.4142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25625 lossL: tensor(955.3380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25626 lossL: tensor(955.8401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25627 lossL: tensor(1099.6783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25628 lossL: tensor(946.0538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25629 lossL: tensor(920.4175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25630 lossL: tensor(887.7572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25631 lossL: tensor(969.9758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25632 lossL: tensor(1018.6677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25633 lossL: tensor(900.1274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25634 lossL: tensor(1022.5032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25635 lossL: tensor(829.4356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25636 lossL: tensor(1017.7537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25637 lossL: tensor(846.9520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25638 lossL: tensor(862.7823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25639 lossL: tensor(993.1902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25640 lossL: tensor(873.5915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25641 lossL: tensor(1005.8189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25642 lossL: tensor(959.9000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25643 lossL: tensor(895.9250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25644 lossL: tensor(957.5600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25645 lossL: tensor(826.9891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25646 lossL: tensor(847.4873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25647 lossL: tensor(886.7836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25648 lossL: tensor(885.8847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25649 lossL: tensor(902.5740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25650 lossL: tensor(886.2569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25651 lossL: tensor(902.3494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25652 lossL: tensor(827.9915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25653 lossL: tensor(917.6989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25654 lossL: tensor(812.7642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25655 lossL: tensor(910.0565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25656 lossL: tensor(828.5866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25657 lossL: tensor(849.9636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25658 lossL: tensor(899.6092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25659 lossL: tensor(828.5836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25660 lossL: tensor(902.0128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25661 lossL: tensor(867.0804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25662 lossL: tensor(953.4774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25663 lossL: tensor(831.5162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25664 lossL: tensor(898.3287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25665 lossL: tensor(889.8400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25666 lossL: tensor(805.4471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25667 lossL: tensor(1038.0215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25668 lossL: tensor(926.0133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25669 lossL: tensor(927.6920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25670 lossL: tensor(915.3365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25671 lossL: tensor(877.4312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25672 lossL: tensor(981.5441, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25673 lossL: tensor(877.3924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25674 lossL: tensor(863.1472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25675 lossL: tensor(980.3452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25676 lossL: tensor(873.9379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25677 lossL: tensor(998.9915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25678 lossL: tensor(853.8642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25679 lossL: tensor(874.1420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25680 lossL: tensor(907.7990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25681 lossL: tensor(837.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25682 lossL: tensor(888.5065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25683 lossL: tensor(850.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25684 lossL: tensor(972.9960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25685 lossL: tensor(872.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25686 lossL: tensor(835.6011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25687 lossL: tensor(976.6761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25688 lossL: tensor(856.9398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25689 lossL: tensor(917.4482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25690 lossL: tensor(1017.9233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25691 lossL: tensor(841.9614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25692 lossL: tensor(869.4454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25693 lossL: tensor(895.0656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25694 lossL: tensor(821.7922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25695 lossL: tensor(903.8092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25696 lossL: tensor(854.1915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25697 lossL: tensor(858.2504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25698 lossL: tensor(863.2788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25699 lossL: tensor(918.6788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25700 lossL: tensor(944.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25701 lossL: tensor(861.1257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25702 lossL: tensor(809.0260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25703 lossL: tensor(833.0392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25704 lossL: tensor(831.8644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25705 lossL: tensor(872.1146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25706 lossL: tensor(802.9318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25707 lossL: tensor(937.8289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25708 lossL: tensor(928.8726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25709 lossL: tensor(832.1823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25710 lossL: tensor(1082.6299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25711 lossL: tensor(888.2530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25712 lossL: tensor(950.1185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25713 lossL: tensor(973.1849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25714 lossL: tensor(862.1518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25715 lossL: tensor(938.5608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25716 lossL: tensor(839.6042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25717 lossL: tensor(975.0426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25718 lossL: tensor(864.6782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25719 lossL: tensor(833.6764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25720 lossL: tensor(896.8056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25721 lossL: tensor(757.6275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25722 lossL: tensor(796.4014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25723 lossL: tensor(862.9392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25724 lossL: tensor(856.0613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25725 lossL: tensor(866.6273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25726 lossL: tensor(921.7265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25727 lossL: tensor(914.6378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25728 lossL: tensor(825.8813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25729 lossL: tensor(869.4061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25730 lossL: tensor(864.3954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25731 lossL: tensor(779.1954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25732 lossL: tensor(817.2638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25733 lossL: tensor(775.6739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25734 lossL: tensor(837.7359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25735 lossL: tensor(894.2327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25736 lossL: tensor(914.6075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25737 lossL: tensor(840.7234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25738 lossL: tensor(881.7093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25739 lossL: tensor(917.4230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25740 lossL: tensor(889.0626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25741 lossL: tensor(863.4495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25742 lossL: tensor(926.6395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25743 lossL: tensor(854.1003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25744 lossL: tensor(878.5983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25745 lossL: tensor(936.2416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25746 lossL: tensor(840.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25747 lossL: tensor(952.6555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25748 lossL: tensor(899.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25749 lossL: tensor(867.9221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25750 lossL: tensor(939.6947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25751 lossL: tensor(863.0901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25752 lossL: tensor(926.7816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25753 lossL: tensor(949.3283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25754 lossL: tensor(910.0051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25755 lossL: tensor(915.5059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25756 lossL: tensor(878.7559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25757 lossL: tensor(995.0047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25758 lossL: tensor(822.0319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25759 lossL: tensor(946.6340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25760 lossL: tensor(892.9850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25761 lossL: tensor(798.8389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25762 lossL: tensor(888.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25763 lossL: tensor(838.1929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25764 lossL: tensor(870.1224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25765 lossL: tensor(835.3585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25766 lossL: tensor(918.4117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25767 lossL: tensor(845.9667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25768 lossL: tensor(877.8785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25769 lossL: tensor(886.9062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25770 lossL: tensor(849.6326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25771 lossL: tensor(858.5734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25772 lossL: tensor(840.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25773 lossL: tensor(822.3759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25774 lossL: tensor(940.6459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25775 lossL: tensor(814.7202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25776 lossL: tensor(799.1396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25777 lossL: tensor(893.1277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25778 lossL: tensor(878.3672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25779 lossL: tensor(924.6798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25780 lossL: tensor(960.8989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25781 lossL: tensor(800.6539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25782 lossL: tensor(941.5840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25783 lossL: tensor(882.2859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25784 lossL: tensor(872.5990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25785 lossL: tensor(952.4172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25786 lossL: tensor(879.2446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25787 lossL: tensor(986.9341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25788 lossL: tensor(927.3488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25789 lossL: tensor(927.7668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25790 lossL: tensor(977.8948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25791 lossL: tensor(884.5245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25792 lossL: tensor(885.1677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25793 lossL: tensor(884.4401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25794 lossL: tensor(877.1184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25795 lossL: tensor(797.5123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25796 lossL: tensor(904.3232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25797 lossL: tensor(882.1357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25798 lossL: tensor(934.0737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25799 lossL: tensor(925.8228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25800 lossL: tensor(895.8421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25801 lossL: tensor(932.9619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25802 lossL: tensor(875.0747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25803 lossL: tensor(824.5183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25804 lossL: tensor(884.8962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25805 lossL: tensor(865.8639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25806 lossL: tensor(913.4991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25807 lossL: tensor(899.1359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25808 lossL: tensor(796.0306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25809 lossL: tensor(768.7513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25810 lossL: tensor(908.4354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25811 lossL: tensor(855.3105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25812 lossL: tensor(830.0989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25813 lossL: tensor(885.6505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25814 lossL: tensor(811.5332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25815 lossL: tensor(933.6606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25816 lossL: tensor(817.8020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25817 lossL: tensor(1016.0149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25818 lossL: tensor(854.8597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25819 lossL: tensor(1077.2333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25820 lossL: tensor(888.6362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25821 lossL: tensor(900.0193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25822 lossL: tensor(917.8784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25823 lossL: tensor(872.1691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25824 lossL: tensor(981.6198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25825 lossL: tensor(877.1957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25826 lossL: tensor(826.9186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25827 lossL: tensor(929.4247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25828 lossL: tensor(851.3629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25829 lossL: tensor(781.5569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25830 lossL: tensor(862.5673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25831 lossL: tensor(876.6174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25832 lossL: tensor(950.0335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25833 lossL: tensor(896.9398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25834 lossL: tensor(867.4426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25835 lossL: tensor(849.6076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25836 lossL: tensor(942.5735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25837 lossL: tensor(803.5536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25838 lossL: tensor(982.2332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25839 lossL: tensor(816.3732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25840 lossL: tensor(960.5247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25841 lossL: tensor(915.1252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25842 lossL: tensor(835.8143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25843 lossL: tensor(974.4891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25844 lossL: tensor(865.1192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25845 lossL: tensor(821.9836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25846 lossL: tensor(847.7030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25847 lossL: tensor(892.9460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25848 lossL: tensor(942.6202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25849 lossL: tensor(933.6142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25850 lossL: tensor(785.8287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25851 lossL: tensor(864.9857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25852 lossL: tensor(851.9334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25853 lossL: tensor(911.8600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25854 lossL: tensor(761.8306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25855 lossL: tensor(897.2629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25856 lossL: tensor(795.1460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25857 lossL: tensor(881.8457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25858 lossL: tensor(820.9381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25859 lossL: tensor(912.1237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25860 lossL: tensor(864.0632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25861 lossL: tensor(921.4158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25862 lossL: tensor(865.2277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25863 lossL: tensor(839.7116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25864 lossL: tensor(776.7645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25865 lossL: tensor(810.1289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25866 lossL: tensor(866.0336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25867 lossL: tensor(820.6825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25868 lossL: tensor(846.6192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25869 lossL: tensor(800.0164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25870 lossL: tensor(878.0981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25871 lossL: tensor(847.9458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25872 lossL: tensor(852.0799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25873 lossL: tensor(851.5538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25874 lossL: tensor(822.8900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25875 lossL: tensor(876.4498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25876 lossL: tensor(847.4588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25877 lossL: tensor(899.9836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25878 lossL: tensor(828.1086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25879 lossL: tensor(835.3690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25880 lossL: tensor(936.0949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25881 lossL: tensor(770.1882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25882 lossL: tensor(899.4046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25883 lossL: tensor(804.1795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25884 lossL: tensor(842.3865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25885 lossL: tensor(846.3534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25886 lossL: tensor(911.7849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25887 lossL: tensor(960.3495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25888 lossL: tensor(881.5934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25889 lossL: tensor(1009.7119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25890 lossL: tensor(957.0911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25891 lossL: tensor(802.4893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25892 lossL: tensor(921.7986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25893 lossL: tensor(792.8217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25894 lossL: tensor(910.0027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25895 lossL: tensor(929.4604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25896 lossL: tensor(835.8645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25897 lossL: tensor(893.9991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25898 lossL: tensor(790.6321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25899 lossL: tensor(850.1075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25900 lossL: tensor(923.6154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25901 lossL: tensor(894.1733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25902 lossL: tensor(844.6021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25903 lossL: tensor(885.1232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25904 lossL: tensor(893.7551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25905 lossL: tensor(751.9223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25906 lossL: tensor(783.8654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25907 lossL: tensor(768.2281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25908 lossL: tensor(874.2504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25909 lossL: tensor(900.0505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25910 lossL: tensor(880.1627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25911 lossL: tensor(976.2616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25912 lossL: tensor(941.9642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25913 lossL: tensor(880.4750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25914 lossL: tensor(815.8656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25915 lossL: tensor(858.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25916 lossL: tensor(929.9312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25917 lossL: tensor(860.9990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25918 lossL: tensor(967.5005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25919 lossL: tensor(850.8627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25920 lossL: tensor(839.9539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25921 lossL: tensor(780.7874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25922 lossL: tensor(808.4357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25923 lossL: tensor(774.8420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25924 lossL: tensor(887.3392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25925 lossL: tensor(842.9272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25926 lossL: tensor(820.1564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25927 lossL: tensor(840.3702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25928 lossL: tensor(917.6890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25929 lossL: tensor(789.1169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25930 lossL: tensor(833.9952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25931 lossL: tensor(804.9301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25932 lossL: tensor(816.6545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25933 lossL: tensor(842.0512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25934 lossL: tensor(772.8115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25935 lossL: tensor(904.9495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25936 lossL: tensor(854.6810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25937 lossL: tensor(873.9359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25938 lossL: tensor(810.4595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25939 lossL: tensor(836.7974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25940 lossL: tensor(833.8904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25941 lossL: tensor(887.8539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25942 lossL: tensor(820.0424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25943 lossL: tensor(847.2717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25944 lossL: tensor(786.0039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25945 lossL: tensor(928.7240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25946 lossL: tensor(860.2084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25947 lossL: tensor(863.6194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25948 lossL: tensor(880.1635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25949 lossL: tensor(801.6430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25950 lossL: tensor(894.7885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25951 lossL: tensor(863.9818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25952 lossL: tensor(888.2197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25953 lossL: tensor(947.7317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25954 lossL: tensor(807.6319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25955 lossL: tensor(935.4299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25956 lossL: tensor(909.5203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25957 lossL: tensor(873.9858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25958 lossL: tensor(855.5900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25959 lossL: tensor(819.3459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25960 lossL: tensor(821.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25961 lossL: tensor(908.0389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25962 lossL: tensor(780.0538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25963 lossL: tensor(888.9820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25964 lossL: tensor(927.8239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25965 lossL: tensor(942.2120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25966 lossL: tensor(850.1685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25967 lossL: tensor(903.6110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25968 lossL: tensor(838.9516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25969 lossL: tensor(925.8887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25970 lossL: tensor(759.5564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25971 lossL: tensor(857.0218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25972 lossL: tensor(804.5815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25973 lossL: tensor(931.0784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25974 lossL: tensor(907.2525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25975 lossL: tensor(856.2083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25976 lossL: tensor(835.8513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25977 lossL: tensor(927.3805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25978 lossL: tensor(821.9355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25979 lossL: tensor(891.4108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25980 lossL: tensor(837.7028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25981 lossL: tensor(866.3870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25982 lossL: tensor(973.1779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25983 lossL: tensor(835.8990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25984 lossL: tensor(847.8747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25985 lossL: tensor(802.1975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25986 lossL: tensor(859.1522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25987 lossL: tensor(839.5536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25988 lossL: tensor(833.2214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25989 lossL: tensor(822.5583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25990 lossL: tensor(884.4462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25991 lossL: tensor(848.7037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25992 lossL: tensor(851.1022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25993 lossL: tensor(880.1552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25994 lossL: tensor(885.8612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25995 lossL: tensor(814.8829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25996 lossL: tensor(794.7869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25997 lossL: tensor(904.0615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25998 lossL: tensor(921.8703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "25999 lossL: tensor(860.9802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26000 lossL: tensor(814.1757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26001 lossL: tensor(933.3873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26002 lossL: tensor(840.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26003 lossL: tensor(811.8035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26004 lossL: tensor(832.0310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26005 lossL: tensor(778.9122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26006 lossL: tensor(873.3303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26007 lossL: tensor(876.1359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26008 lossL: tensor(938.3561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26009 lossL: tensor(847.4647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26010 lossL: tensor(881.5863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26011 lossL: tensor(937.4542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26012 lossL: tensor(847.9476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26013 lossL: tensor(816.4753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26014 lossL: tensor(897.8734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26015 lossL: tensor(810.3263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26016 lossL: tensor(845.9056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26017 lossL: tensor(861.2197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26018 lossL: tensor(764.4385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26019 lossL: tensor(906.3855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26020 lossL: tensor(939.1620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26021 lossL: tensor(846.6942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26022 lossL: tensor(963.7201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26023 lossL: tensor(771.6034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26024 lossL: tensor(856.0153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26025 lossL: tensor(854.4980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26026 lossL: tensor(863.1508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26027 lossL: tensor(808.4998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26028 lossL: tensor(854.7299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26029 lossL: tensor(989.9928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26030 lossL: tensor(856.6057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26031 lossL: tensor(849.2349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26032 lossL: tensor(869.0471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26033 lossL: tensor(858.3595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26034 lossL: tensor(970.7106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26035 lossL: tensor(789.7271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26036 lossL: tensor(852.9755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26037 lossL: tensor(898.4517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26038 lossL: tensor(871.8515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26039 lossL: tensor(755.9609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26040 lossL: tensor(847.6774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26041 lossL: tensor(877.7646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26042 lossL: tensor(808.3448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26043 lossL: tensor(978.6118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26044 lossL: tensor(865.8049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26045 lossL: tensor(928.9758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26046 lossL: tensor(873.1062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26047 lossL: tensor(872.5891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26048 lossL: tensor(837.3129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26049 lossL: tensor(819.3274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26050 lossL: tensor(944.9296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26051 lossL: tensor(817.4034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26052 lossL: tensor(911.4569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26053 lossL: tensor(900.2523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26054 lossL: tensor(838.2180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26055 lossL: tensor(870.8423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26056 lossL: tensor(856.1110, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26057 lossL: tensor(837.5054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26058 lossL: tensor(846.6657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26059 lossL: tensor(874.9460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26060 lossL: tensor(908.1897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26061 lossL: tensor(808.5832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26062 lossL: tensor(764.7556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26063 lossL: tensor(818.3715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26064 lossL: tensor(894.9476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26065 lossL: tensor(883.1698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26066 lossL: tensor(868.1443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26067 lossL: tensor(906.6503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26068 lossL: tensor(869.8804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26069 lossL: tensor(940.4747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26070 lossL: tensor(880.7183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26071 lossL: tensor(850.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26072 lossL: tensor(869.0169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26073 lossL: tensor(863.3838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26074 lossL: tensor(935.1990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26075 lossL: tensor(815.7137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26076 lossL: tensor(1011.8950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26077 lossL: tensor(884.0886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26078 lossL: tensor(918.3903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26079 lossL: tensor(1064.1552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26080 lossL: tensor(887.4655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26081 lossL: tensor(1051.7765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26082 lossL: tensor(880.6620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26083 lossL: tensor(927.3478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26084 lossL: tensor(1128.2747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26085 lossL: tensor(843.4717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26086 lossL: tensor(995.9393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26087 lossL: tensor(925.8193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26088 lossL: tensor(859.4949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26089 lossL: tensor(936.7351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26090 lossL: tensor(916.7245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26091 lossL: tensor(939.2422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26092 lossL: tensor(846.7277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26093 lossL: tensor(836.8452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26094 lossL: tensor(885.3058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26095 lossL: tensor(905.2794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26096 lossL: tensor(886.6028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26097 lossL: tensor(864.2224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26098 lossL: tensor(845.5090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26099 lossL: tensor(847.2377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26100 lossL: tensor(838.7629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26101 lossL: tensor(759.2688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26102 lossL: tensor(876.2623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26103 lossL: tensor(902.4194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26104 lossL: tensor(789.8887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26105 lossL: tensor(958.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26106 lossL: tensor(911.9786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26107 lossL: tensor(901.7095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26108 lossL: tensor(867.2495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26109 lossL: tensor(883.9479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26110 lossL: tensor(893.0561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26111 lossL: tensor(749.2762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26112 lossL: tensor(948.4449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26113 lossL: tensor(876.3728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26114 lossL: tensor(852.4005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26115 lossL: tensor(820.2681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26116 lossL: tensor(863.7566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26117 lossL: tensor(915.0755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26118 lossL: tensor(870.0305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26119 lossL: tensor(884.5305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26120 lossL: tensor(889.9291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26121 lossL: tensor(797.2987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26122 lossL: tensor(888.0077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26123 lossL: tensor(840.2220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26124 lossL: tensor(902.0114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26125 lossL: tensor(873.4471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26126 lossL: tensor(876.8651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26127 lossL: tensor(881.2552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26128 lossL: tensor(805.4875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26129 lossL: tensor(889.9081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26130 lossL: tensor(881.2480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26131 lossL: tensor(864.7532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26132 lossL: tensor(847.3409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26133 lossL: tensor(755.8785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26134 lossL: tensor(903.8541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26135 lossL: tensor(815.1091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26136 lossL: tensor(774.4135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26137 lossL: tensor(828.4602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26138 lossL: tensor(788.6623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26139 lossL: tensor(787.7467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26140 lossL: tensor(937.0505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26141 lossL: tensor(847.0549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26142 lossL: tensor(915.4439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26143 lossL: tensor(810.5198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26144 lossL: tensor(805.6582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26145 lossL: tensor(893.6230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26146 lossL: tensor(892.0234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26147 lossL: tensor(881.0232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26148 lossL: tensor(916.5459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26149 lossL: tensor(863.5187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26150 lossL: tensor(874.1552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26151 lossL: tensor(906.5114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26152 lossL: tensor(891.6668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26153 lossL: tensor(864.3483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26154 lossL: tensor(825.2610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26155 lossL: tensor(909.9615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26156 lossL: tensor(823.7115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26157 lossL: tensor(829.7075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26158 lossL: tensor(873.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26159 lossL: tensor(868.1672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26160 lossL: tensor(844.6035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26161 lossL: tensor(811.9745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26162 lossL: tensor(898.6021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26163 lossL: tensor(885.0473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26164 lossL: tensor(804.5135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26165 lossL: tensor(859.7943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26166 lossL: tensor(826.4764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26167 lossL: tensor(826.0330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26168 lossL: tensor(821.3976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26169 lossL: tensor(861.9536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26170 lossL: tensor(868.4373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26171 lossL: tensor(889.7963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26172 lossL: tensor(806.9471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26173 lossL: tensor(852.6113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26174 lossL: tensor(907.6248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26175 lossL: tensor(887.0777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26176 lossL: tensor(874.2816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26177 lossL: tensor(846.3766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26178 lossL: tensor(899.0363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26179 lossL: tensor(855.3181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26180 lossL: tensor(806.0952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26181 lossL: tensor(866.9073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26182 lossL: tensor(858.6047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26183 lossL: tensor(843.1079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26184 lossL: tensor(943.4088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26185 lossL: tensor(854.5560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26186 lossL: tensor(865.7750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26187 lossL: tensor(869.0892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26188 lossL: tensor(861.8093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26189 lossL: tensor(879.3623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26190 lossL: tensor(873.5796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26191 lossL: tensor(777.0677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26192 lossL: tensor(779.9451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26193 lossL: tensor(893.3118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26194 lossL: tensor(828.6476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26195 lossL: tensor(805.1158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26196 lossL: tensor(825.4689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26197 lossL: tensor(836.5368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26198 lossL: tensor(835.9058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26199 lossL: tensor(856.3264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26200 lossL: tensor(842.4183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26201 lossL: tensor(844.7048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26202 lossL: tensor(843.3143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26203 lossL: tensor(813.5421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26204 lossL: tensor(807.6415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26205 lossL: tensor(914.4760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26206 lossL: tensor(813.4511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26207 lossL: tensor(815.7413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26208 lossL: tensor(796.9968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26209 lossL: tensor(830.7109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26210 lossL: tensor(896.4662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26211 lossL: tensor(865.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26212 lossL: tensor(837.3271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26213 lossL: tensor(817.6893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26214 lossL: tensor(789.9167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26215 lossL: tensor(826.1379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26216 lossL: tensor(821.3096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26217 lossL: tensor(857.9789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26218 lossL: tensor(875.9117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26219 lossL: tensor(838.4979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26220 lossL: tensor(842.7614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26221 lossL: tensor(907.9250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26222 lossL: tensor(863.8629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26223 lossL: tensor(773.7892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26224 lossL: tensor(831.5466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26225 lossL: tensor(865.6505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26226 lossL: tensor(756.0358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26227 lossL: tensor(923.2643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26228 lossL: tensor(898.2797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26229 lossL: tensor(880.3115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26230 lossL: tensor(868.6937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26231 lossL: tensor(884.5959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26232 lossL: tensor(779.3824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26233 lossL: tensor(906.5624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26234 lossL: tensor(928.6719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26235 lossL: tensor(915.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26236 lossL: tensor(935.8031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26237 lossL: tensor(837.5742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26238 lossL: tensor(854.8432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26239 lossL: tensor(908.0107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26240 lossL: tensor(857.2458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26241 lossL: tensor(834.3801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26242 lossL: tensor(876.7164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26243 lossL: tensor(796.1592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26244 lossL: tensor(824.8221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26245 lossL: tensor(772.8884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26246 lossL: tensor(832.0640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26247 lossL: tensor(909.2168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26248 lossL: tensor(843.5537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26249 lossL: tensor(940.2659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26250 lossL: tensor(908.8811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26251 lossL: tensor(829.2950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26252 lossL: tensor(865.4560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26253 lossL: tensor(823.1876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26254 lossL: tensor(947.0877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26255 lossL: tensor(878.4703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26256 lossL: tensor(983.2106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26257 lossL: tensor(987.7688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26258 lossL: tensor(862.0219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26259 lossL: tensor(806.6271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26260 lossL: tensor(918.2310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26261 lossL: tensor(949.5652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26262 lossL: tensor(921.5465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26263 lossL: tensor(825.3080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26264 lossL: tensor(851.6492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26265 lossL: tensor(896.5912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26266 lossL: tensor(880.5232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26267 lossL: tensor(864.8367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26268 lossL: tensor(883.7590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26269 lossL: tensor(997.2822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26270 lossL: tensor(894.8578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26271 lossL: tensor(851.8040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26272 lossL: tensor(917.2254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26273 lossL: tensor(818.2713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26274 lossL: tensor(757.5653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26275 lossL: tensor(780.5922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26276 lossL: tensor(789.0387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26277 lossL: tensor(892.8872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26278 lossL: tensor(881.3997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26279 lossL: tensor(776.6049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26280 lossL: tensor(789.2034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26281 lossL: tensor(810.0088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26282 lossL: tensor(882.5499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26283 lossL: tensor(783.5576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26284 lossL: tensor(818.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26285 lossL: tensor(808.2491, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26286 lossL: tensor(793.5394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26287 lossL: tensor(774.3980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26288 lossL: tensor(905.2020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26289 lossL: tensor(883.8920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26290 lossL: tensor(813.4493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26291 lossL: tensor(873.8518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26292 lossL: tensor(866.5959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26293 lossL: tensor(919.7454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26294 lossL: tensor(847.9455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26295 lossL: tensor(746.2284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26296 lossL: tensor(858.4647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26297 lossL: tensor(843.8205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26298 lossL: tensor(850.7469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26299 lossL: tensor(899.3518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26300 lossL: tensor(912.4272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26301 lossL: tensor(868.0735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26302 lossL: tensor(850.1014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26303 lossL: tensor(850.7487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26304 lossL: tensor(767.5421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26305 lossL: tensor(899.3926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26306 lossL: tensor(848.3358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26307 lossL: tensor(840.0304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26308 lossL: tensor(783.0252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26309 lossL: tensor(852.2200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26310 lossL: tensor(750.4685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26311 lossL: tensor(845.5853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26312 lossL: tensor(892.7933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26313 lossL: tensor(897.0923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26314 lossL: tensor(765.1771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26315 lossL: tensor(871.9259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26316 lossL: tensor(830.9828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26317 lossL: tensor(876.8116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26318 lossL: tensor(861.7927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26319 lossL: tensor(896.1777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26320 lossL: tensor(833.2894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26321 lossL: tensor(943.1278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26322 lossL: tensor(849.6442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26323 lossL: tensor(900.8397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26324 lossL: tensor(918.9019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26325 lossL: tensor(870.5585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26326 lossL: tensor(875.0745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26327 lossL: tensor(825.5553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26328 lossL: tensor(933.3174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26329 lossL: tensor(938.4130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26330 lossL: tensor(828.6965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26331 lossL: tensor(1022.3391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26332 lossL: tensor(886.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26333 lossL: tensor(859.6394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26334 lossL: tensor(834.2692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26335 lossL: tensor(866.7540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26336 lossL: tensor(863.4005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26337 lossL: tensor(857.3284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26338 lossL: tensor(882.4814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26339 lossL: tensor(885.9905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26340 lossL: tensor(787.8758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26341 lossL: tensor(827.7180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26342 lossL: tensor(797.1885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26343 lossL: tensor(836.3502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26344 lossL: tensor(857.9957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26345 lossL: tensor(887.6859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26346 lossL: tensor(880.5532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26347 lossL: tensor(845.6273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26348 lossL: tensor(990.2183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26349 lossL: tensor(915.8413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26350 lossL: tensor(880.4191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26351 lossL: tensor(801.7527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26352 lossL: tensor(838.2817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26353 lossL: tensor(819.1260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26354 lossL: tensor(781.2858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26355 lossL: tensor(854.5243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26356 lossL: tensor(873.1270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26357 lossL: tensor(761.1094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26358 lossL: tensor(871.0884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26359 lossL: tensor(847.0369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26360 lossL: tensor(828.0934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26361 lossL: tensor(864.0963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26362 lossL: tensor(783.2917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26363 lossL: tensor(862.8159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26364 lossL: tensor(826.4714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26365 lossL: tensor(806.8257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26366 lossL: tensor(813.0784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26367 lossL: tensor(848.7870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26368 lossL: tensor(838.5856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26369 lossL: tensor(843.6740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26370 lossL: tensor(858.3624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26371 lossL: tensor(785.7045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26372 lossL: tensor(866.4655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26373 lossL: tensor(879.0966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26374 lossL: tensor(825.1092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26375 lossL: tensor(815.3780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26376 lossL: tensor(856.4532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26377 lossL: tensor(824.7212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26378 lossL: tensor(870.1329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26379 lossL: tensor(857.0074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26380 lossL: tensor(827.6362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26381 lossL: tensor(838.0981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26382 lossL: tensor(803.6954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26383 lossL: tensor(862.0685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26384 lossL: tensor(884.3461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26385 lossL: tensor(873.3199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26386 lossL: tensor(803.6868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26387 lossL: tensor(843.7079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26388 lossL: tensor(884.2158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26389 lossL: tensor(801.1600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26390 lossL: tensor(860.5504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26391 lossL: tensor(838.8504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26392 lossL: tensor(886.2322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26393 lossL: tensor(836.4349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26394 lossL: tensor(847.5923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26395 lossL: tensor(844.5160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26396 lossL: tensor(899.9886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26397 lossL: tensor(852.9583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26398 lossL: tensor(949.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26399 lossL: tensor(871.1378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26400 lossL: tensor(857.3748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26401 lossL: tensor(786.2943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26402 lossL: tensor(984.8240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26403 lossL: tensor(869.1039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26404 lossL: tensor(981.3584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26405 lossL: tensor(973.4056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26406 lossL: tensor(885.8234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26407 lossL: tensor(1142.1750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26408 lossL: tensor(940.4382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26409 lossL: tensor(863.5465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26410 lossL: tensor(948.1477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26411 lossL: tensor(771.9461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26412 lossL: tensor(1077.1831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26413 lossL: tensor(852.8354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26414 lossL: tensor(942.0815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26415 lossL: tensor(964.6673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26416 lossL: tensor(814.9636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26417 lossL: tensor(826.8353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26418 lossL: tensor(859.0312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26419 lossL: tensor(864.1718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26420 lossL: tensor(829.0422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26421 lossL: tensor(808.8011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26422 lossL: tensor(767.2648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26423 lossL: tensor(819.1954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26424 lossL: tensor(861.4598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26425 lossL: tensor(802.2316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26426 lossL: tensor(862.5688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26427 lossL: tensor(808.8623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26428 lossL: tensor(825.5476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26429 lossL: tensor(873.9493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26430 lossL: tensor(763.3195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26431 lossL: tensor(903.7230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26432 lossL: tensor(853.8771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26433 lossL: tensor(802.1897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26434 lossL: tensor(888.4076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26435 lossL: tensor(917.9523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26436 lossL: tensor(893.6354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26437 lossL: tensor(822.4037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26438 lossL: tensor(844.1976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26439 lossL: tensor(842.3482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26440 lossL: tensor(824.4123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26441 lossL: tensor(844.1368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26442 lossL: tensor(892.5278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26443 lossL: tensor(811.2947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26444 lossL: tensor(882.5541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26445 lossL: tensor(902.3786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26446 lossL: tensor(856.6426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26447 lossL: tensor(875.5887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26448 lossL: tensor(832.5446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26449 lossL: tensor(791.8032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26450 lossL: tensor(817.0267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26451 lossL: tensor(779.3196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26452 lossL: tensor(886.7840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26453 lossL: tensor(847.7236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26454 lossL: tensor(811.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26455 lossL: tensor(854.6124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26456 lossL: tensor(830.7685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26457 lossL: tensor(875.4002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26458 lossL: tensor(853.0972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26459 lossL: tensor(965.0227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26460 lossL: tensor(840.3879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26461 lossL: tensor(871.9999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26462 lossL: tensor(910.1910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26463 lossL: tensor(836.8068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26464 lossL: tensor(941.1400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26465 lossL: tensor(904.6779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26466 lossL: tensor(879.6669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26467 lossL: tensor(884.1644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26468 lossL: tensor(837.7409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26469 lossL: tensor(829.0493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26470 lossL: tensor(951.0587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26471 lossL: tensor(773.7374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26472 lossL: tensor(1001.4794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26473 lossL: tensor(827.5659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26474 lossL: tensor(970.3061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26475 lossL: tensor(956.6415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26476 lossL: tensor(876.5163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26477 lossL: tensor(1014.6221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26478 lossL: tensor(798.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26479 lossL: tensor(917.0500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26480 lossL: tensor(937.9662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26481 lossL: tensor(853.0522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26482 lossL: tensor(893.9998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26483 lossL: tensor(888.9362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26484 lossL: tensor(824.9832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26485 lossL: tensor(946.4526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26486 lossL: tensor(853.0047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26487 lossL: tensor(962.1035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26488 lossL: tensor(856.7451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26489 lossL: tensor(866.5909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26490 lossL: tensor(852.4897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26491 lossL: tensor(836.0102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26492 lossL: tensor(810.9149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26493 lossL: tensor(886.9171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26494 lossL: tensor(840.5710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26495 lossL: tensor(908.7513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26496 lossL: tensor(897.7250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26497 lossL: tensor(857.6090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26498 lossL: tensor(788.5131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26499 lossL: tensor(793.6062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26500 lossL: tensor(834.6880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26501 lossL: tensor(807.5721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26502 lossL: tensor(751.8198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26503 lossL: tensor(834.3546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26504 lossL: tensor(886.7305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26505 lossL: tensor(968.7313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26506 lossL: tensor(826.1973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26507 lossL: tensor(866.9875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26508 lossL: tensor(776.7545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26509 lossL: tensor(845.3189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26510 lossL: tensor(840.7797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26511 lossL: tensor(823.2131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26512 lossL: tensor(849.2510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26513 lossL: tensor(824.8983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26514 lossL: tensor(860.3267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26515 lossL: tensor(915.2585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26516 lossL: tensor(813.9786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26517 lossL: tensor(796.9232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26518 lossL: tensor(826.5416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26519 lossL: tensor(782.3350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26520 lossL: tensor(827.7532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26521 lossL: tensor(762.4123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26522 lossL: tensor(846.1274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26523 lossL: tensor(831.5088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26524 lossL: tensor(899.7994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26525 lossL: tensor(832.0259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26526 lossL: tensor(869.1937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26527 lossL: tensor(840.2582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26528 lossL: tensor(826.5014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26529 lossL: tensor(802.1844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26530 lossL: tensor(823.3846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26531 lossL: tensor(849.1133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26532 lossL: tensor(772.8461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26533 lossL: tensor(814.2020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26534 lossL: tensor(800.2368, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26535 lossL: tensor(786.9998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26536 lossL: tensor(806.4439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26537 lossL: tensor(808.4676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26538 lossL: tensor(815.3768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26539 lossL: tensor(883.2358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26540 lossL: tensor(841.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26541 lossL: tensor(845.5609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26542 lossL: tensor(808.8586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26543 lossL: tensor(876.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26544 lossL: tensor(820.6860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26545 lossL: tensor(964.1249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26546 lossL: tensor(856.4532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26547 lossL: tensor(748.3139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26548 lossL: tensor(847.8442, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26549 lossL: tensor(820.9575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26550 lossL: tensor(821.6078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26551 lossL: tensor(825.9819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26552 lossL: tensor(829.1572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26553 lossL: tensor(872.3812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26554 lossL: tensor(943.1827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26555 lossL: tensor(877.0382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26556 lossL: tensor(885.2552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26557 lossL: tensor(818.5609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26558 lossL: tensor(800.9962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26559 lossL: tensor(889.4114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26560 lossL: tensor(983.8974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26561 lossL: tensor(786.6351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26562 lossL: tensor(881.2247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26563 lossL: tensor(823.8496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26564 lossL: tensor(842.1782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26565 lossL: tensor(853.6561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26566 lossL: tensor(874.4052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26567 lossL: tensor(856.9315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26568 lossL: tensor(847.4094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26569 lossL: tensor(814.2842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26570 lossL: tensor(765.3655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26571 lossL: tensor(746.9786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26572 lossL: tensor(832.0480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26573 lossL: tensor(873.7670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26574 lossL: tensor(845.6556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26575 lossL: tensor(841.4203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26576 lossL: tensor(868.8884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26577 lossL: tensor(813.1105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26578 lossL: tensor(899.9329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26579 lossL: tensor(808.9248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26580 lossL: tensor(877.4753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26581 lossL: tensor(801.5099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26582 lossL: tensor(827.4744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26583 lossL: tensor(828.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26584 lossL: tensor(839.7955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26585 lossL: tensor(871.3779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26586 lossL: tensor(842.5208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26587 lossL: tensor(853.6373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26588 lossL: tensor(912.9692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26589 lossL: tensor(754.1036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26590 lossL: tensor(787.0616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26591 lossL: tensor(836.1774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26592 lossL: tensor(782.1813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26593 lossL: tensor(842.9411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26594 lossL: tensor(798.0674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26595 lossL: tensor(824.1973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26596 lossL: tensor(800.1117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26597 lossL: tensor(848.9471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26598 lossL: tensor(833.3548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26599 lossL: tensor(758.6229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26600 lossL: tensor(774.8863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26601 lossL: tensor(812.9122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26602 lossL: tensor(799.5963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26603 lossL: tensor(829.2241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26604 lossL: tensor(860.2756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26605 lossL: tensor(923.8356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26606 lossL: tensor(869.2155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26607 lossL: tensor(875.9247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26608 lossL: tensor(845.3496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26609 lossL: tensor(811.5853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26610 lossL: tensor(865.8240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26611 lossL: tensor(824.4731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26612 lossL: tensor(881.5508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26613 lossL: tensor(798.1873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26614 lossL: tensor(826.3477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26615 lossL: tensor(893.0121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26616 lossL: tensor(843.8540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26617 lossL: tensor(850.0570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26618 lossL: tensor(925.0830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26619 lossL: tensor(847.1109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26620 lossL: tensor(799.5720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26621 lossL: tensor(861.1097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26622 lossL: tensor(892.2518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26623 lossL: tensor(863.4798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26624 lossL: tensor(864.4451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26625 lossL: tensor(814.2437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26626 lossL: tensor(901.1158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26627 lossL: tensor(831.8830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26628 lossL: tensor(850.8184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26629 lossL: tensor(986.6439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26630 lossL: tensor(812.3962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26631 lossL: tensor(869.7408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26632 lossL: tensor(823.5450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26633 lossL: tensor(803.2851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26634 lossL: tensor(778.1602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26635 lossL: tensor(921.6627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26636 lossL: tensor(799.0946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26637 lossL: tensor(831.6660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26638 lossL: tensor(844.3624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26639 lossL: tensor(836.2779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26640 lossL: tensor(847.9221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26641 lossL: tensor(897.1434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26642 lossL: tensor(809.9348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26643 lossL: tensor(913.5228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26644 lossL: tensor(860.0598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26645 lossL: tensor(799.9736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26646 lossL: tensor(924.2702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26647 lossL: tensor(907.8507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26648 lossL: tensor(807.9965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26649 lossL: tensor(836.5665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26650 lossL: tensor(870.5728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26651 lossL: tensor(788.2144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26652 lossL: tensor(746.7516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26653 lossL: tensor(840.3547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26654 lossL: tensor(853.6602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26655 lossL: tensor(862.4144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26656 lossL: tensor(812.1219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26657 lossL: tensor(745.1995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "26658 lossL: tensor(825.4880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26659 lossL: tensor(874.5569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26660 lossL: tensor(886.2140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26661 lossL: tensor(807.7563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26662 lossL: tensor(821.0831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26663 lossL: tensor(835.6539, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26664 lossL: tensor(828.0378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26665 lossL: tensor(756.2628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26666 lossL: tensor(793.3908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26667 lossL: tensor(778.4318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26668 lossL: tensor(867.5787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26669 lossL: tensor(884.5065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26670 lossL: tensor(780.8456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26671 lossL: tensor(833.5587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26672 lossL: tensor(770.8862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26673 lossL: tensor(800.1643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26674 lossL: tensor(872.2485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26675 lossL: tensor(894.0588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26676 lossL: tensor(838.3474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26677 lossL: tensor(794.6888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26678 lossL: tensor(811.4493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26679 lossL: tensor(827.1519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26680 lossL: tensor(858.4107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26681 lossL: tensor(770.2202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26682 lossL: tensor(773.9357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26683 lossL: tensor(787.9697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26684 lossL: tensor(890.0198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26685 lossL: tensor(850.9302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26686 lossL: tensor(870.2798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26687 lossL: tensor(846.6120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26688 lossL: tensor(804.3364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26689 lossL: tensor(823.7140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26690 lossL: tensor(829.1210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26691 lossL: tensor(823.6171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26692 lossL: tensor(870.8773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26693 lossL: tensor(840.4448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26694 lossL: tensor(871.3588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26695 lossL: tensor(874.2130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26696 lossL: tensor(821.5901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26697 lossL: tensor(881.8873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26698 lossL: tensor(865.6150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26699 lossL: tensor(853.4583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26700 lossL: tensor(850.5297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26701 lossL: tensor(796.6558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26702 lossL: tensor(905.7450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26703 lossL: tensor(806.7552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26704 lossL: tensor(839.5142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26705 lossL: tensor(840.2966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26706 lossL: tensor(850.8401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26707 lossL: tensor(826.7804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26708 lossL: tensor(868.3631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26709 lossL: tensor(916.5594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26710 lossL: tensor(825.0860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26711 lossL: tensor(854.8099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26712 lossL: tensor(858.5106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26713 lossL: tensor(770.8735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26714 lossL: tensor(864.4637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26715 lossL: tensor(857.5865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26716 lossL: tensor(848.1652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26717 lossL: tensor(909.4530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26718 lossL: tensor(927.6843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26719 lossL: tensor(804.1402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26720 lossL: tensor(850.5969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26721 lossL: tensor(799.3344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26722 lossL: tensor(807.4968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26723 lossL: tensor(825.5987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26724 lossL: tensor(819.3326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26725 lossL: tensor(784.5182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26726 lossL: tensor(827.6833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26727 lossL: tensor(903.0778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26728 lossL: tensor(881.1189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26729 lossL: tensor(832.2059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26730 lossL: tensor(837.1414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26731 lossL: tensor(925.4556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26732 lossL: tensor(783.9410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26733 lossL: tensor(872.9133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26734 lossL: tensor(882.8347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26735 lossL: tensor(826.3792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26736 lossL: tensor(824.9474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26737 lossL: tensor(823.9144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26738 lossL: tensor(885.6251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26739 lossL: tensor(819.4080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26740 lossL: tensor(806.6165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26741 lossL: tensor(855.7674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26742 lossL: tensor(771.1425, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26743 lossL: tensor(849.2924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26744 lossL: tensor(840.0031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26745 lossL: tensor(815.7529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26746 lossL: tensor(838.1645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26747 lossL: tensor(774.1897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26748 lossL: tensor(895.1715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26749 lossL: tensor(825.6653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26750 lossL: tensor(836.1646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26751 lossL: tensor(804.0661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26752 lossL: tensor(784.3626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26753 lossL: tensor(808.2030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26754 lossL: tensor(819.2637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26755 lossL: tensor(879.4638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26756 lossL: tensor(794.5665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26757 lossL: tensor(807.6714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26758 lossL: tensor(824.0204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26759 lossL: tensor(811.7276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26760 lossL: tensor(838.9410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26761 lossL: tensor(798.1821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26762 lossL: tensor(862.2960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26763 lossL: tensor(857.0872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26764 lossL: tensor(870.2375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26765 lossL: tensor(807.9193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26766 lossL: tensor(905.2328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26767 lossL: tensor(833.8083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26768 lossL: tensor(909.6813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26769 lossL: tensor(772.7784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26770 lossL: tensor(832.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26771 lossL: tensor(790.8000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26772 lossL: tensor(839.9585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26773 lossL: tensor(841.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26774 lossL: tensor(829.3835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26775 lossL: tensor(796.7342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26776 lossL: tensor(833.2922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26777 lossL: tensor(832.1838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26778 lossL: tensor(836.1757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26779 lossL: tensor(777.2682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26780 lossL: tensor(762.5764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26781 lossL: tensor(790.8171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26782 lossL: tensor(760.5921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26783 lossL: tensor(818.8388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26784 lossL: tensor(792.9098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26785 lossL: tensor(843.6531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26786 lossL: tensor(815.5284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26787 lossL: tensor(779.9463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26788 lossL: tensor(869.0947, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26789 lossL: tensor(771.7556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26790 lossL: tensor(906.0554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26791 lossL: tensor(873.7910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26792 lossL: tensor(861.9581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26793 lossL: tensor(916.5506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26794 lossL: tensor(766.0071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26795 lossL: tensor(801.6066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26796 lossL: tensor(782.7321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26797 lossL: tensor(930.2029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26798 lossL: tensor(828.6564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26799 lossL: tensor(831.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26800 lossL: tensor(898.1722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26801 lossL: tensor(839.4359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26802 lossL: tensor(851.2484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26803 lossL: tensor(835.7418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26804 lossL: tensor(852.8893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26805 lossL: tensor(860.8358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26806 lossL: tensor(844.1179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26807 lossL: tensor(834.3175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26808 lossL: tensor(843.9498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26809 lossL: tensor(835.1301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26810 lossL: tensor(892.6996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26811 lossL: tensor(815.1314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26812 lossL: tensor(894.0375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26813 lossL: tensor(856.1589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26814 lossL: tensor(829.1197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26815 lossL: tensor(788.7100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26816 lossL: tensor(850.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26817 lossL: tensor(791.7731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26818 lossL: tensor(876.3864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26819 lossL: tensor(778.1643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26820 lossL: tensor(863.0119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26821 lossL: tensor(886.4041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26822 lossL: tensor(810.6076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26823 lossL: tensor(848.3942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26824 lossL: tensor(827.8182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26825 lossL: tensor(949.9016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26826 lossL: tensor(965.5340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26827 lossL: tensor(836.3739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26828 lossL: tensor(895.3706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26829 lossL: tensor(870.9138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26830 lossL: tensor(810.5060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26831 lossL: tensor(869.8447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26832 lossL: tensor(810.5685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26833 lossL: tensor(840.0275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26834 lossL: tensor(916.1818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26835 lossL: tensor(885.7125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26836 lossL: tensor(798.1990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26837 lossL: tensor(930.0882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26838 lossL: tensor(771.8943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26839 lossL: tensor(949.7838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26840 lossL: tensor(1024.8058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26841 lossL: tensor(941.6155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26842 lossL: tensor(940.3693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26843 lossL: tensor(1141.0984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26844 lossL: tensor(806.7867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26845 lossL: tensor(1009.3260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26846 lossL: tensor(943.7647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26847 lossL: tensor(825.9289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26848 lossL: tensor(927.0419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26849 lossL: tensor(850.4484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26850 lossL: tensor(880.6812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26851 lossL: tensor(920.5101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26852 lossL: tensor(835.5665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26853 lossL: tensor(992.9320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26854 lossL: tensor(951.4871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26855 lossL: tensor(842.1365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26856 lossL: tensor(1031.8942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26857 lossL: tensor(819.4868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26858 lossL: tensor(837.7653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26859 lossL: tensor(826.4901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26860 lossL: tensor(734.7964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "26861 lossL: tensor(894.8306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26862 lossL: tensor(826.0627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26863 lossL: tensor(869.4326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26864 lossL: tensor(894.3976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26865 lossL: tensor(787.3238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26866 lossL: tensor(845.8078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26867 lossL: tensor(876.4205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26868 lossL: tensor(847.1083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26869 lossL: tensor(944.4719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26870 lossL: tensor(864.0309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26871 lossL: tensor(839.2765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26872 lossL: tensor(822.3543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26873 lossL: tensor(821.1977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26874 lossL: tensor(900.7639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26875 lossL: tensor(799.6146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26876 lossL: tensor(921.4552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26877 lossL: tensor(897.2064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26878 lossL: tensor(831.3530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26879 lossL: tensor(909.4064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26880 lossL: tensor(1051.1278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26881 lossL: tensor(797.6738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26882 lossL: tensor(866.9751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26883 lossL: tensor(958.6075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26884 lossL: tensor(818.3134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26885 lossL: tensor(888.2166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26886 lossL: tensor(904.5844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26887 lossL: tensor(807.7214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26888 lossL: tensor(956.4345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26889 lossL: tensor(789.0327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26890 lossL: tensor(907.9853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26891 lossL: tensor(1112.6290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26892 lossL: tensor(895.1578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26893 lossL: tensor(887.7557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26894 lossL: tensor(961.8333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26895 lossL: tensor(799.6804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26896 lossL: tensor(1005.5645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26897 lossL: tensor(886.0394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26898 lossL: tensor(836.1849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26899 lossL: tensor(866.7318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26900 lossL: tensor(816.6075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26901 lossL: tensor(1005.7512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26902 lossL: tensor(820.5959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26903 lossL: tensor(1000.4713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26904 lossL: tensor(932.0677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26905 lossL: tensor(813.2687, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26906 lossL: tensor(1043.4758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26907 lossL: tensor(866.0622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26908 lossL: tensor(982.3851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26909 lossL: tensor(1033.2653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26910 lossL: tensor(876.0330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26911 lossL: tensor(1254.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26912 lossL: tensor(900.6008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26913 lossL: tensor(1080.0306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26914 lossL: tensor(1214.8940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26915 lossL: tensor(802.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26916 lossL: tensor(1170.6720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26917 lossL: tensor(921.7966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26918 lossL: tensor(963.0375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26919 lossL: tensor(1011.0327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26920 lossL: tensor(783.6303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26921 lossL: tensor(944.6403, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26922 lossL: tensor(843.1896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26923 lossL: tensor(878.2186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26924 lossL: tensor(918.3243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26925 lossL: tensor(809.8132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26926 lossL: tensor(969.1763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26927 lossL: tensor(870.3638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26928 lossL: tensor(824.3673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26929 lossL: tensor(818.6637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26930 lossL: tensor(809.5524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26931 lossL: tensor(866.5699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26932 lossL: tensor(771.9994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26933 lossL: tensor(839.5724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26934 lossL: tensor(776.0562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26935 lossL: tensor(829.5573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26936 lossL: tensor(826.2917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26937 lossL: tensor(766.2946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26938 lossL: tensor(853.0849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26939 lossL: tensor(893.7440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26940 lossL: tensor(827.6058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26941 lossL: tensor(914.3094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26942 lossL: tensor(915.3729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26943 lossL: tensor(747.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26944 lossL: tensor(851.3164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26945 lossL: tensor(753.1613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26946 lossL: tensor(825.6500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26947 lossL: tensor(850.5069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26948 lossL: tensor(800.9335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26949 lossL: tensor(873.1788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26950 lossL: tensor(826.1304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26951 lossL: tensor(845.0632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26952 lossL: tensor(802.7697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26953 lossL: tensor(843.7327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26954 lossL: tensor(843.9555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26955 lossL: tensor(873.3876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26956 lossL: tensor(832.9321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26957 lossL: tensor(821.8169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26958 lossL: tensor(859.9617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26959 lossL: tensor(783.7440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26960 lossL: tensor(858.1865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26961 lossL: tensor(826.1716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26962 lossL: tensor(787.6783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26963 lossL: tensor(771.2995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26964 lossL: tensor(760.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26965 lossL: tensor(811.4976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26966 lossL: tensor(856.0639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26967 lossL: tensor(843.6724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26968 lossL: tensor(863.0245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26969 lossL: tensor(870.5617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26970 lossL: tensor(860.8835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26971 lossL: tensor(780.7698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26972 lossL: tensor(792.7965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26973 lossL: tensor(848.5012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26974 lossL: tensor(842.9721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26975 lossL: tensor(839.3764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26976 lossL: tensor(805.8853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26977 lossL: tensor(808.9567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26978 lossL: tensor(817.4003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26979 lossL: tensor(833.2258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26980 lossL: tensor(742.2908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26981 lossL: tensor(855.1190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26982 lossL: tensor(825.7302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26983 lossL: tensor(892.6194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26984 lossL: tensor(831.0761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26985 lossL: tensor(858.4136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26986 lossL: tensor(858.3866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26987 lossL: tensor(817.4137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26988 lossL: tensor(760.7962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26989 lossL: tensor(812.2506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26990 lossL: tensor(764.3638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26991 lossL: tensor(789.6286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26992 lossL: tensor(813.4663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26993 lossL: tensor(912.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26994 lossL: tensor(762.0843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26995 lossL: tensor(822.5656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26996 lossL: tensor(794.0989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26997 lossL: tensor(807.5479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26998 lossL: tensor(925.4498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "26999 lossL: tensor(892.6786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27000 lossL: tensor(833.3228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27001 lossL: tensor(1001.1570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27002 lossL: tensor(897.6676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27003 lossL: tensor(774.7149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27004 lossL: tensor(824.0936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27005 lossL: tensor(791.0072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27006 lossL: tensor(854.6948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27007 lossL: tensor(802.2237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27008 lossL: tensor(808.1313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27009 lossL: tensor(828.0577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27010 lossL: tensor(877.7556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27011 lossL: tensor(873.1939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27012 lossL: tensor(835.9760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27013 lossL: tensor(816.5812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27014 lossL: tensor(830.1210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27015 lossL: tensor(850.3878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27016 lossL: tensor(844.1529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27017 lossL: tensor(824.4157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27018 lossL: tensor(816.4084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27019 lossL: tensor(855.9104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27020 lossL: tensor(896.6147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27021 lossL: tensor(870.0253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27022 lossL: tensor(841.1304, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27023 lossL: tensor(746.5715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27024 lossL: tensor(839.1319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27025 lossL: tensor(759.0464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27026 lossL: tensor(856.5280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27027 lossL: tensor(869.6633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27028 lossL: tensor(882.3773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27029 lossL: tensor(943.7955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27030 lossL: tensor(840.6874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27031 lossL: tensor(963.2683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27032 lossL: tensor(1017.7410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27033 lossL: tensor(866.2510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27034 lossL: tensor(900.4652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27035 lossL: tensor(854.8370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27036 lossL: tensor(829.8470, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27037 lossL: tensor(850.4182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27038 lossL: tensor(827.2313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27039 lossL: tensor(842.0929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27040 lossL: tensor(871.5270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27041 lossL: tensor(845.7395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27042 lossL: tensor(806.5557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27043 lossL: tensor(809.7153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27044 lossL: tensor(887.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27045 lossL: tensor(854.3740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27046 lossL: tensor(852.4464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27047 lossL: tensor(804.0730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27048 lossL: tensor(867.1421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27049 lossL: tensor(740.7707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27050 lossL: tensor(783.7978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27051 lossL: tensor(837.9683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27052 lossL: tensor(856.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27053 lossL: tensor(898.1421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27054 lossL: tensor(801.5954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27055 lossL: tensor(817.3406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27056 lossL: tensor(830.3348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27057 lossL: tensor(891.3810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27058 lossL: tensor(848.1545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27059 lossL: tensor(775.8868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27060 lossL: tensor(752.5631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27061 lossL: tensor(868.4542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27062 lossL: tensor(821.3479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27063 lossL: tensor(858.5241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27064 lossL: tensor(786.1353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27065 lossL: tensor(882.0927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27066 lossL: tensor(830.9896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27067 lossL: tensor(732.7257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "27068 lossL: tensor(718.4933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "27069 lossL: tensor(846.5490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27070 lossL: tensor(803.1062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27071 lossL: tensor(857.4272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27072 lossL: tensor(791.4366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27073 lossL: tensor(785.6130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27074 lossL: tensor(853.3043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27075 lossL: tensor(850.7456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27076 lossL: tensor(833.0902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27077 lossL: tensor(912.8494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27078 lossL: tensor(884.0521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27079 lossL: tensor(826.1599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27080 lossL: tensor(897.7761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27081 lossL: tensor(818.4607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27082 lossL: tensor(816.7173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27083 lossL: tensor(837.2786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27084 lossL: tensor(832.1252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27085 lossL: tensor(913.8649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27086 lossL: tensor(838.8950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27087 lossL: tensor(849.1299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27088 lossL: tensor(872.6939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27089 lossL: tensor(759.1879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27090 lossL: tensor(852.3054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27091 lossL: tensor(842.0685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27092 lossL: tensor(835.6332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27093 lossL: tensor(807.1130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27094 lossL: tensor(810.5191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27095 lossL: tensor(728.9124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27096 lossL: tensor(881.1159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27097 lossL: tensor(796.5615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27098 lossL: tensor(786.3731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27099 lossL: tensor(844.1630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27100 lossL: tensor(815.9580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27101 lossL: tensor(811.4752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27102 lossL: tensor(760.5526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27103 lossL: tensor(865.7902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27104 lossL: tensor(809.7151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27105 lossL: tensor(840.1738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27106 lossL: tensor(837.6714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27107 lossL: tensor(901.4683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27108 lossL: tensor(897.9365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27109 lossL: tensor(851.9030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27110 lossL: tensor(857.4001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27111 lossL: tensor(782.1050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27112 lossL: tensor(900.4458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27113 lossL: tensor(867.5793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27114 lossL: tensor(888.3915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27115 lossL: tensor(739.8152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27116 lossL: tensor(835.7285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27117 lossL: tensor(829.7031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27118 lossL: tensor(843.7901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27119 lossL: tensor(814.4730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27120 lossL: tensor(782.7913, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27121 lossL: tensor(806.7626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27122 lossL: tensor(806.9997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27123 lossL: tensor(862.1235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27124 lossL: tensor(838.1409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27125 lossL: tensor(819.9792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27126 lossL: tensor(829.7689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27127 lossL: tensor(791.2406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27128 lossL: tensor(833.8098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27129 lossL: tensor(897.4502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27130 lossL: tensor(807.4660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27131 lossL: tensor(880.1591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27132 lossL: tensor(914.6041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27133 lossL: tensor(868.8928, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27134 lossL: tensor(887.8458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27135 lossL: tensor(870.1677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27136 lossL: tensor(799.2668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27137 lossL: tensor(935.0061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27138 lossL: tensor(823.4169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27139 lossL: tensor(893.0093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27140 lossL: tensor(803.8774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27141 lossL: tensor(863.8344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27142 lossL: tensor(872.0848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27143 lossL: tensor(798.1904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27144 lossL: tensor(870.0695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27145 lossL: tensor(873.8311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27146 lossL: tensor(828.6959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27147 lossL: tensor(747.7079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27148 lossL: tensor(817.3876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27149 lossL: tensor(807.0471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27150 lossL: tensor(811.4875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27151 lossL: tensor(841.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27152 lossL: tensor(793.3945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27153 lossL: tensor(864.7089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27154 lossL: tensor(766.5090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27155 lossL: tensor(831.6704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27156 lossL: tensor(806.8478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27157 lossL: tensor(785.7382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27158 lossL: tensor(821.2177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27159 lossL: tensor(847.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27160 lossL: tensor(772.7272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27161 lossL: tensor(830.6130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27162 lossL: tensor(880.6750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27163 lossL: tensor(770.8665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27164 lossL: tensor(824.1340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27165 lossL: tensor(818.3015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27166 lossL: tensor(854.4341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27167 lossL: tensor(794.5505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27168 lossL: tensor(812.3431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27169 lossL: tensor(860.1669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27170 lossL: tensor(806.7718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27171 lossL: tensor(886.5153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27172 lossL: tensor(826.8287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27173 lossL: tensor(796.3058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27174 lossL: tensor(880.9946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27175 lossL: tensor(880.2051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27176 lossL: tensor(798.2144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27177 lossL: tensor(959.6289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27178 lossL: tensor(835.5397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27179 lossL: tensor(829.6966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27180 lossL: tensor(839.8904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27181 lossL: tensor(782.5080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27182 lossL: tensor(915.2735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27183 lossL: tensor(809.7415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27184 lossL: tensor(907.5217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27185 lossL: tensor(897.8652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27186 lossL: tensor(861.9409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27187 lossL: tensor(716.1555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "27188 lossL: tensor(911.2962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27189 lossL: tensor(828.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27190 lossL: tensor(909.8038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27191 lossL: tensor(904.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27192 lossL: tensor(788.8432, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27193 lossL: tensor(860.6634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27194 lossL: tensor(817.9640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27195 lossL: tensor(843.2528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27196 lossL: tensor(815.6919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27197 lossL: tensor(801.1359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27198 lossL: tensor(754.2045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27199 lossL: tensor(802.7372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27200 lossL: tensor(842.1855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27201 lossL: tensor(903.1935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27202 lossL: tensor(857.1266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27203 lossL: tensor(828.1258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27204 lossL: tensor(796.8018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27205 lossL: tensor(789.5884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27206 lossL: tensor(763.2972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27207 lossL: tensor(839.3051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27208 lossL: tensor(858.3380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27209 lossL: tensor(784.9012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27210 lossL: tensor(822.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27211 lossL: tensor(806.1478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27212 lossL: tensor(816.3831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27213 lossL: tensor(859.5221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27214 lossL: tensor(812.1448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27215 lossL: tensor(857.4234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27216 lossL: tensor(750.3694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27217 lossL: tensor(862.5404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27218 lossL: tensor(871.4083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27219 lossL: tensor(795.7594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27220 lossL: tensor(786.3232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27221 lossL: tensor(806.4131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27222 lossL: tensor(800.1724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27223 lossL: tensor(828.9918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27224 lossL: tensor(840.8691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27225 lossL: tensor(774.9681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27226 lossL: tensor(854.6181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27227 lossL: tensor(839.5005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27228 lossL: tensor(809.6136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27229 lossL: tensor(853.5052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27230 lossL: tensor(830.7021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27231 lossL: tensor(759.5085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27232 lossL: tensor(821.6236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27233 lossL: tensor(817.3779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27234 lossL: tensor(770.1736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27235 lossL: tensor(905.8271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27236 lossL: tensor(839.7655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27237 lossL: tensor(841.9815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27238 lossL: tensor(824.8878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27239 lossL: tensor(783.9776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27240 lossL: tensor(816.6797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27241 lossL: tensor(869.6494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27242 lossL: tensor(784.9510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27243 lossL: tensor(820.7282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27244 lossL: tensor(862.9951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27245 lossL: tensor(793.1014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27246 lossL: tensor(784.6861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27247 lossL: tensor(803.3744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27248 lossL: tensor(795.5873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27249 lossL: tensor(824.1515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27250 lossL: tensor(778.8760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27251 lossL: tensor(733.0577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27252 lossL: tensor(843.7345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27253 lossL: tensor(823.3376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27254 lossL: tensor(815.5182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27255 lossL: tensor(784.0288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27256 lossL: tensor(840.3216, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27257 lossL: tensor(776.7117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27258 lossL: tensor(825.1436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27259 lossL: tensor(820.2102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27260 lossL: tensor(848.4337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27261 lossL: tensor(799.8173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27262 lossL: tensor(783.8282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27263 lossL: tensor(787.4794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27264 lossL: tensor(766.2553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27265 lossL: tensor(778.4077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27266 lossL: tensor(785.8692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27267 lossL: tensor(814.1184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27268 lossL: tensor(816.4354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27269 lossL: tensor(807.1086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27270 lossL: tensor(866.7494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27271 lossL: tensor(803.9409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27272 lossL: tensor(804.9067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27273 lossL: tensor(824.8503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27274 lossL: tensor(869.1357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27275 lossL: tensor(782.8649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27276 lossL: tensor(795.2802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27277 lossL: tensor(861.3826, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27278 lossL: tensor(833.0524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27279 lossL: tensor(814.7333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27280 lossL: tensor(845.2189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27281 lossL: tensor(810.8691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27282 lossL: tensor(843.1022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27283 lossL: tensor(835.1242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27284 lossL: tensor(856.4529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27285 lossL: tensor(792.1654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27286 lossL: tensor(838.3481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27287 lossL: tensor(771.6589, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27288 lossL: tensor(764.9957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27289 lossL: tensor(763.8690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27290 lossL: tensor(728.1060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27291 lossL: tensor(846.1357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27292 lossL: tensor(917.3353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27293 lossL: tensor(814.1492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27294 lossL: tensor(1009.7440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27295 lossL: tensor(1143.7085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27296 lossL: tensor(814.6652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27297 lossL: tensor(1107.6106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27298 lossL: tensor(1010.4478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27299 lossL: tensor(834.3295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27300 lossL: tensor(1041.3729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27301 lossL: tensor(976.6172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27302 lossL: tensor(743.4056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27303 lossL: tensor(947.0262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27304 lossL: tensor(862.6201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27305 lossL: tensor(843.6472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27306 lossL: tensor(952.6382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27307 lossL: tensor(801.3719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27308 lossL: tensor(1112.4159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27309 lossL: tensor(885.0661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27310 lossL: tensor(863.4076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27311 lossL: tensor(902.3165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27312 lossL: tensor(812.8810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27313 lossL: tensor(901.0626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27314 lossL: tensor(785.1534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27315 lossL: tensor(768.2922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27316 lossL: tensor(872.4901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27317 lossL: tensor(790.3604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27318 lossL: tensor(854.1390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27319 lossL: tensor(838.3785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27320 lossL: tensor(807.8351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27321 lossL: tensor(856.0292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27322 lossL: tensor(888.0451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27323 lossL: tensor(792.5549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27324 lossL: tensor(846.4574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27325 lossL: tensor(923.4954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27326 lossL: tensor(811.6114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27327 lossL: tensor(805.1261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27328 lossL: tensor(879.4679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27329 lossL: tensor(839.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27330 lossL: tensor(830.0641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27331 lossL: tensor(809.1042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27332 lossL: tensor(909.9074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27333 lossL: tensor(883.8524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27334 lossL: tensor(879.2906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27335 lossL: tensor(795.5921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27336 lossL: tensor(836.6136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27337 lossL: tensor(838.2418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27338 lossL: tensor(883.6511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27339 lossL: tensor(798.6629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27340 lossL: tensor(815.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27341 lossL: tensor(853.3314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27342 lossL: tensor(803.7885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27343 lossL: tensor(760.0584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27344 lossL: tensor(832.6051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27345 lossL: tensor(763.1032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27346 lossL: tensor(740.5808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27347 lossL: tensor(810.4194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27348 lossL: tensor(810.0200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27349 lossL: tensor(811.7032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27350 lossL: tensor(823.2766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27351 lossL: tensor(873.6123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27352 lossL: tensor(824.6375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27353 lossL: tensor(856.8193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27354 lossL: tensor(782.0746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27355 lossL: tensor(827.5132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27356 lossL: tensor(789.8161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27357 lossL: tensor(799.0695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27358 lossL: tensor(819.3104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27359 lossL: tensor(844.4130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27360 lossL: tensor(775.6637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27361 lossL: tensor(878.1185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27362 lossL: tensor(769.0543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27363 lossL: tensor(785.0976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27364 lossL: tensor(808.1238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27365 lossL: tensor(802.7284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27366 lossL: tensor(813.8474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27367 lossL: tensor(874.5087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27368 lossL: tensor(875.7471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27369 lossL: tensor(853.9852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27370 lossL: tensor(782.0778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27371 lossL: tensor(796.0124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27372 lossL: tensor(805.9020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27373 lossL: tensor(856.8021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27374 lossL: tensor(769.4576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27375 lossL: tensor(825.4525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27376 lossL: tensor(796.8663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27377 lossL: tensor(735.6389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27378 lossL: tensor(791.1525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27379 lossL: tensor(828.8212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27380 lossL: tensor(864.1331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27381 lossL: tensor(791.3878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27382 lossL: tensor(761.6807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27383 lossL: tensor(820.0827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27384 lossL: tensor(842.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27385 lossL: tensor(825.1615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27386 lossL: tensor(820.2767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27387 lossL: tensor(765.2561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27388 lossL: tensor(758.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27389 lossL: tensor(807.5766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27390 lossL: tensor(792.1960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27391 lossL: tensor(910.7243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27392 lossL: tensor(760.5350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27393 lossL: tensor(806.8726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27394 lossL: tensor(871.0424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27395 lossL: tensor(775.8974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27396 lossL: tensor(852.5573, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27397 lossL: tensor(804.2844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27398 lossL: tensor(769.3989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27399 lossL: tensor(899.9515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27400 lossL: tensor(876.0026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27401 lossL: tensor(881.6385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27402 lossL: tensor(794.8478, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27403 lossL: tensor(820.4182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27404 lossL: tensor(781.5392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27405 lossL: tensor(835.7960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27406 lossL: tensor(834.1807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27407 lossL: tensor(762.0878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27408 lossL: tensor(778.3640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27409 lossL: tensor(874.4370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27410 lossL: tensor(912.4037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27411 lossL: tensor(884.2694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27412 lossL: tensor(851.4789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27413 lossL: tensor(807.1380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27414 lossL: tensor(968.6419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27415 lossL: tensor(732.9558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27416 lossL: tensor(785.9698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27417 lossL: tensor(827.3792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27418 lossL: tensor(834.4371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27419 lossL: tensor(787.4484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27420 lossL: tensor(792.4288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27421 lossL: tensor(802.5389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27422 lossL: tensor(843.9509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27423 lossL: tensor(825.6506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27424 lossL: tensor(831.6931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27425 lossL: tensor(868.1207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27426 lossL: tensor(836.8668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27427 lossL: tensor(755.7410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27428 lossL: tensor(802.9855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27429 lossL: tensor(785.5278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27430 lossL: tensor(739.3448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27431 lossL: tensor(776.5496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27432 lossL: tensor(863.7184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27433 lossL: tensor(861.8194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27434 lossL: tensor(912.1675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27435 lossL: tensor(809.9954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27436 lossL: tensor(901.7830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27437 lossL: tensor(821.8672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27438 lossL: tensor(824.5992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27439 lossL: tensor(861.3212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27440 lossL: tensor(874.6461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27441 lossL: tensor(790.9831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27442 lossL: tensor(831.5988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27443 lossL: tensor(874.1681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27444 lossL: tensor(793.9391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27445 lossL: tensor(870.1472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27446 lossL: tensor(775.0637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27447 lossL: tensor(861.7999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27448 lossL: tensor(830.3667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27449 lossL: tensor(756.5944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27450 lossL: tensor(861.9227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27451 lossL: tensor(902.7474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27452 lossL: tensor(886.8728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27453 lossL: tensor(850.5834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27454 lossL: tensor(837.2030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27455 lossL: tensor(899.7115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27456 lossL: tensor(812.8724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27457 lossL: tensor(936.5894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27458 lossL: tensor(856.9598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27459 lossL: tensor(775.2382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27460 lossL: tensor(886.4817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27461 lossL: tensor(776.6890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27462 lossL: tensor(911.3350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27463 lossL: tensor(819.8007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27464 lossL: tensor(808.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27465 lossL: tensor(915.1969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27466 lossL: tensor(789.2735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27467 lossL: tensor(1006.4058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27468 lossL: tensor(923.4576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27469 lossL: tensor(739.4316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27470 lossL: tensor(937.6347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27471 lossL: tensor(807.7709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27472 lossL: tensor(874.3897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27473 lossL: tensor(835.2659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27474 lossL: tensor(874.8078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27475 lossL: tensor(854.5165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27476 lossL: tensor(795.6260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27477 lossL: tensor(863.8080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27478 lossL: tensor(913.0863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27479 lossL: tensor(807.6300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27480 lossL: tensor(911.1531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27481 lossL: tensor(808.1609, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27482 lossL: tensor(875.9855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27483 lossL: tensor(901.5575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27484 lossL: tensor(784.9139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27485 lossL: tensor(908.2628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27486 lossL: tensor(795.5812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27487 lossL: tensor(876.3041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27488 lossL: tensor(874.7656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27489 lossL: tensor(769.1995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27490 lossL: tensor(1079.8480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27491 lossL: tensor(917.2410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27492 lossL: tensor(748.8233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27493 lossL: tensor(898.9669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27494 lossL: tensor(934.0899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27495 lossL: tensor(859.5390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27496 lossL: tensor(919.3544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27497 lossL: tensor(791.4232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27498 lossL: tensor(933.3675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27499 lossL: tensor(893.0817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27500 lossL: tensor(806.4035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27501 lossL: tensor(927.9681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27502 lossL: tensor(734.6514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27503 lossL: tensor(1008.2794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27504 lossL: tensor(824.2634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27505 lossL: tensor(906.9395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27506 lossL: tensor(1034.4603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27507 lossL: tensor(823.9506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27508 lossL: tensor(923.2186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27509 lossL: tensor(866.2097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27510 lossL: tensor(903.2041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27511 lossL: tensor(908.1542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27512 lossL: tensor(763.2837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27513 lossL: tensor(934.7765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27514 lossL: tensor(781.4642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27515 lossL: tensor(895.7974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27516 lossL: tensor(920.3133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27517 lossL: tensor(848.0188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27518 lossL: tensor(840.9433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27519 lossL: tensor(853.0963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27520 lossL: tensor(797.6786, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27521 lossL: tensor(787.8257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27522 lossL: tensor(799.8093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27523 lossL: tensor(865.4075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27524 lossL: tensor(762.3445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27525 lossL: tensor(846.9836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27526 lossL: tensor(845.3895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27527 lossL: tensor(889.9149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27528 lossL: tensor(845.0711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27529 lossL: tensor(893.5822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27530 lossL: tensor(847.4547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27531 lossL: tensor(748.8592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27532 lossL: tensor(821.3453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27533 lossL: tensor(883.5557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27534 lossL: tensor(894.4540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27535 lossL: tensor(836.3421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27536 lossL: tensor(831.9255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27537 lossL: tensor(885.0130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27538 lossL: tensor(799.3631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27539 lossL: tensor(815.4017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27540 lossL: tensor(861.8125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27541 lossL: tensor(766.3944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27542 lossL: tensor(837.0099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27543 lossL: tensor(836.7288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27544 lossL: tensor(829.3007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27545 lossL: tensor(941.1849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27546 lossL: tensor(791.0557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27547 lossL: tensor(854.3454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27548 lossL: tensor(780.9382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27549 lossL: tensor(761.1592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27550 lossL: tensor(866.7039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27551 lossL: tensor(829.2801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27552 lossL: tensor(764.7896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27553 lossL: tensor(942.3743, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27554 lossL: tensor(793.8253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27555 lossL: tensor(849.3718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27556 lossL: tensor(896.2708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27557 lossL: tensor(831.5967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27558 lossL: tensor(932.4966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27559 lossL: tensor(829.6766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27560 lossL: tensor(840.8178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27561 lossL: tensor(820.8824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27562 lossL: tensor(795.6771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27563 lossL: tensor(890.0661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27564 lossL: tensor(793.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27565 lossL: tensor(873.6299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27566 lossL: tensor(800.3758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27567 lossL: tensor(869.4918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27568 lossL: tensor(788.1005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27569 lossL: tensor(789.9576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27570 lossL: tensor(777.6085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27571 lossL: tensor(808.2328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27572 lossL: tensor(873.3065, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27573 lossL: tensor(720.7712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27574 lossL: tensor(850.1268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27575 lossL: tensor(854.2959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27576 lossL: tensor(857.1467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27577 lossL: tensor(948.1324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27578 lossL: tensor(773.7424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27579 lossL: tensor(795.1434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27580 lossL: tensor(843.1277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27581 lossL: tensor(822.6338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27582 lossL: tensor(880.3803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27583 lossL: tensor(801.2815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27584 lossL: tensor(922.3347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27585 lossL: tensor(850.2312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27586 lossL: tensor(795.1440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27587 lossL: tensor(906.1309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27588 lossL: tensor(799.2397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27589 lossL: tensor(903.6021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27590 lossL: tensor(853.3522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27591 lossL: tensor(832.5060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27592 lossL: tensor(821.0316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27593 lossL: tensor(812.5450, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27594 lossL: tensor(800.6424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27595 lossL: tensor(855.5116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27596 lossL: tensor(888.4253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27597 lossL: tensor(801.0269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27598 lossL: tensor(913.1007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27599 lossL: tensor(777.6343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27600 lossL: tensor(791.6746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27601 lossL: tensor(832.3845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27602 lossL: tensor(813.2207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27603 lossL: tensor(993.9871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27604 lossL: tensor(772.4009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27605 lossL: tensor(899.8067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27606 lossL: tensor(879.1129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27607 lossL: tensor(864.5557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27608 lossL: tensor(852.3198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27609 lossL: tensor(830.4876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27610 lossL: tensor(867.6267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27611 lossL: tensor(877.0151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27612 lossL: tensor(843.3397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27613 lossL: tensor(944.0720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27614 lossL: tensor(759.7975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27615 lossL: tensor(766.4189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27616 lossL: tensor(761.4708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27617 lossL: tensor(776.6537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27618 lossL: tensor(889.4571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27619 lossL: tensor(773.5912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27620 lossL: tensor(783.9181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27621 lossL: tensor(838.0120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27622 lossL: tensor(832.2493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27623 lossL: tensor(834.3260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27624 lossL: tensor(952.9354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27625 lossL: tensor(749.3669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27626 lossL: tensor(814.3246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27627 lossL: tensor(864.3723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27628 lossL: tensor(753.0093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27629 lossL: tensor(883.9018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27630 lossL: tensor(766.6572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27631 lossL: tensor(773.1685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27632 lossL: tensor(784.1079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27633 lossL: tensor(801.1037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27634 lossL: tensor(874.5986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27635 lossL: tensor(807.6028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27636 lossL: tensor(841.3489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27637 lossL: tensor(750.6547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27638 lossL: tensor(892.3838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27639 lossL: tensor(836.0352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27640 lossL: tensor(793.8943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27641 lossL: tensor(836.2911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27642 lossL: tensor(805.0367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27643 lossL: tensor(762.3926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27644 lossL: tensor(788.4621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27645 lossL: tensor(816.3774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27646 lossL: tensor(783.4990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27647 lossL: tensor(739.2537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27648 lossL: tensor(858.2052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27649 lossL: tensor(858.3322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27650 lossL: tensor(829.4235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27651 lossL: tensor(908.4116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27652 lossL: tensor(706.4054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "27653 lossL: tensor(825.3105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27654 lossL: tensor(860.5104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27655 lossL: tensor(765.7935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27656 lossL: tensor(766.3004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27657 lossL: tensor(690.7643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "27658 lossL: tensor(824.2069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27659 lossL: tensor(832.1316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27660 lossL: tensor(777.7671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27661 lossL: tensor(783.5033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27662 lossL: tensor(812.0767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27663 lossL: tensor(863.4502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27664 lossL: tensor(836.0899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27665 lossL: tensor(782.7457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27666 lossL: tensor(797.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27667 lossL: tensor(814.6620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27668 lossL: tensor(854.2622, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27669 lossL: tensor(872.9545, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27670 lossL: tensor(818.2062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27671 lossL: tensor(846.3463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27672 lossL: tensor(823.4130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27673 lossL: tensor(879.5203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27674 lossL: tensor(877.4288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27675 lossL: tensor(787.5083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27676 lossL: tensor(801.3011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27677 lossL: tensor(828.2476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27678 lossL: tensor(821.4672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27679 lossL: tensor(826.0134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27680 lossL: tensor(817.2097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27681 lossL: tensor(812.9436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27682 lossL: tensor(724.3507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27683 lossL: tensor(803.3394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27684 lossL: tensor(777.2350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27685 lossL: tensor(834.7956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27686 lossL: tensor(801.7818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27687 lossL: tensor(864.6291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27688 lossL: tensor(800.5682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27689 lossL: tensor(826.2482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27690 lossL: tensor(805.0779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27691 lossL: tensor(810.4937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27692 lossL: tensor(886.9255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27693 lossL: tensor(806.7128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27694 lossL: tensor(767.7709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27695 lossL: tensor(802.4447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27696 lossL: tensor(803.5115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27697 lossL: tensor(729.5161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27698 lossL: tensor(801.6162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27699 lossL: tensor(839.7156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27700 lossL: tensor(788.6400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27701 lossL: tensor(809.8021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27702 lossL: tensor(795.9207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27703 lossL: tensor(783.4921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27704 lossL: tensor(783.7370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27705 lossL: tensor(828.5755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27706 lossL: tensor(832.8813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27707 lossL: tensor(863.9434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27708 lossL: tensor(791.1479, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27709 lossL: tensor(841.9198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27710 lossL: tensor(919.9420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27711 lossL: tensor(749.4561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27712 lossL: tensor(793.9155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27713 lossL: tensor(790.4736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27714 lossL: tensor(803.3839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27715 lossL: tensor(906.6570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27716 lossL: tensor(807.5374, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27717 lossL: tensor(873.2231, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27718 lossL: tensor(809.2744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27719 lossL: tensor(789.5941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27720 lossL: tensor(799.9515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27721 lossL: tensor(727.4736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27722 lossL: tensor(925.2178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27723 lossL: tensor(852.6558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27724 lossL: tensor(816.3551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27725 lossL: tensor(984.3287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27726 lossL: tensor(814.3057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27727 lossL: tensor(823.7811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27728 lossL: tensor(887.7873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27729 lossL: tensor(812.7852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27730 lossL: tensor(830.4128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27731 lossL: tensor(805.4686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27732 lossL: tensor(838.3480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27733 lossL: tensor(892.2212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27734 lossL: tensor(846.2830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27735 lossL: tensor(793.6722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27736 lossL: tensor(862.4517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27737 lossL: tensor(802.9961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27738 lossL: tensor(863.2838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27739 lossL: tensor(807.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27740 lossL: tensor(830.7759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27741 lossL: tensor(731.6964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27742 lossL: tensor(784.1963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27743 lossL: tensor(837.4593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27744 lossL: tensor(856.1634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27745 lossL: tensor(781.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27746 lossL: tensor(883.8839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27747 lossL: tensor(832.9846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27748 lossL: tensor(779.7131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27749 lossL: tensor(776.5749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27750 lossL: tensor(860.4550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27751 lossL: tensor(837.7169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27752 lossL: tensor(909.2508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27753 lossL: tensor(837.9894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27754 lossL: tensor(770.9777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27755 lossL: tensor(774.6149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27756 lossL: tensor(759.4254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27757 lossL: tensor(854.8416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27758 lossL: tensor(782.9443, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27759 lossL: tensor(752.6475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27760 lossL: tensor(763.3428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27761 lossL: tensor(823.2867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27762 lossL: tensor(853.2527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27763 lossL: tensor(822.5758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27764 lossL: tensor(769.7158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27765 lossL: tensor(799.4415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27766 lossL: tensor(843.0370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27767 lossL: tensor(785.1013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27768 lossL: tensor(892.5286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27769 lossL: tensor(797.5584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27770 lossL: tensor(805.0730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27771 lossL: tensor(910.4207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27772 lossL: tensor(770.8121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27773 lossL: tensor(903.3704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27774 lossL: tensor(877.6517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27775 lossL: tensor(819.4604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27776 lossL: tensor(805.6738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27777 lossL: tensor(809.1357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27778 lossL: tensor(815.4388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27779 lossL: tensor(767.9948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27780 lossL: tensor(777.0451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27781 lossL: tensor(788.8166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27782 lossL: tensor(792.1841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27783 lossL: tensor(856.0189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27784 lossL: tensor(751.9009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27785 lossL: tensor(813.0994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27786 lossL: tensor(773.5024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27787 lossL: tensor(811.4133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27788 lossL: tensor(744.9744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27789 lossL: tensor(755.8417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27790 lossL: tensor(750.2939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27791 lossL: tensor(877.0268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27792 lossL: tensor(790.2838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27793 lossL: tensor(832.5955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27794 lossL: tensor(865.8810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27795 lossL: tensor(791.2452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27796 lossL: tensor(809.7274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27797 lossL: tensor(837.2884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27798 lossL: tensor(768.4812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27799 lossL: tensor(982.7317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27800 lossL: tensor(847.0180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27801 lossL: tensor(797.2093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27802 lossL: tensor(803.6929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27803 lossL: tensor(796.9227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27804 lossL: tensor(807.7072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27805 lossL: tensor(818.3975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27806 lossL: tensor(820.8951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27807 lossL: tensor(766.6521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27808 lossL: tensor(912.6680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27809 lossL: tensor(811.9504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27810 lossL: tensor(802.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27811 lossL: tensor(937.5415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27812 lossL: tensor(834.0422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27813 lossL: tensor(808.0513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27814 lossL: tensor(713.6613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27815 lossL: tensor(848.0604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27816 lossL: tensor(823.4277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27817 lossL: tensor(785.2650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27818 lossL: tensor(741.4655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27819 lossL: tensor(849.9406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27820 lossL: tensor(799.3391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27821 lossL: tensor(770.1012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27822 lossL: tensor(910.0335, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27823 lossL: tensor(935.4957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27824 lossL: tensor(778.8744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27825 lossL: tensor(843.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27826 lossL: tensor(735.5537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27827 lossL: tensor(709.2542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27828 lossL: tensor(863.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27829 lossL: tensor(784.2208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27830 lossL: tensor(716.8591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27831 lossL: tensor(848.2935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27832 lossL: tensor(798.6576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27833 lossL: tensor(789.6693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27834 lossL: tensor(863.7773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27835 lossL: tensor(787.8630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27836 lossL: tensor(833.8627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27837 lossL: tensor(827.6699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27838 lossL: tensor(789.2612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27839 lossL: tensor(808.0394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27840 lossL: tensor(762.4579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27841 lossL: tensor(872.7132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27842 lossL: tensor(790.9342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27843 lossL: tensor(835.6688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27844 lossL: tensor(769.4546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27845 lossL: tensor(730.6550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27846 lossL: tensor(776.9047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27847 lossL: tensor(809.8850, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27848 lossL: tensor(808.9075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27849 lossL: tensor(815.5048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27850 lossL: tensor(800.5522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27851 lossL: tensor(798.5446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27852 lossL: tensor(786.7950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27853 lossL: tensor(806.5111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27854 lossL: tensor(773.3081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27855 lossL: tensor(738.1019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27856 lossL: tensor(845.3059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27857 lossL: tensor(811.4258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27858 lossL: tensor(825.1343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27859 lossL: tensor(864.2900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27860 lossL: tensor(777.9303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27861 lossL: tensor(823.4955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27862 lossL: tensor(735.2635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27863 lossL: tensor(811.7941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27864 lossL: tensor(823.0396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27865 lossL: tensor(820.7270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27866 lossL: tensor(902.1123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27867 lossL: tensor(781.2791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27868 lossL: tensor(845.4585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27869 lossL: tensor(828.5904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27870 lossL: tensor(773.7833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27871 lossL: tensor(818.8482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27872 lossL: tensor(859.4048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27873 lossL: tensor(784.2082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27874 lossL: tensor(805.8439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27875 lossL: tensor(787.2695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27876 lossL: tensor(825.6053, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27877 lossL: tensor(797.5020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27878 lossL: tensor(857.7396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27879 lossL: tensor(847.3254, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27880 lossL: tensor(866.8040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27881 lossL: tensor(805.1104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27882 lossL: tensor(834.5202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27883 lossL: tensor(779.4683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27884 lossL: tensor(795.7103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27885 lossL: tensor(841.7200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27886 lossL: tensor(810.1075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27887 lossL: tensor(868.4050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27888 lossL: tensor(756.9872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27889 lossL: tensor(857.5134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27890 lossL: tensor(767.3141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27891 lossL: tensor(860.6600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27892 lossL: tensor(810.6791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27893 lossL: tensor(840.5190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27894 lossL: tensor(803.4543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27895 lossL: tensor(724.0674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27896 lossL: tensor(874.1002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27897 lossL: tensor(844.3704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27898 lossL: tensor(816.0623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27899 lossL: tensor(882.5167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27900 lossL: tensor(809.8259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27901 lossL: tensor(920.3542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27902 lossL: tensor(875.7300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27903 lossL: tensor(749.1030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27904 lossL: tensor(895.0788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27905 lossL: tensor(778.4919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27906 lossL: tensor(937.2922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27907 lossL: tensor(837.3856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27908 lossL: tensor(847.7124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27909 lossL: tensor(757.7271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27910 lossL: tensor(790.0377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27911 lossL: tensor(875.3188, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27912 lossL: tensor(878.1377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27913 lossL: tensor(780.7884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27914 lossL: tensor(896.5620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27915 lossL: tensor(854.9987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27916 lossL: tensor(806.4117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27917 lossL: tensor(800.2867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27918 lossL: tensor(821.2078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27919 lossL: tensor(829.5925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27920 lossL: tensor(832.4927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27921 lossL: tensor(801.3257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27922 lossL: tensor(789.4905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27923 lossL: tensor(778.3817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27924 lossL: tensor(923.8270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27925 lossL: tensor(869.1871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27926 lossL: tensor(809.0751, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27927 lossL: tensor(826.6509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27928 lossL: tensor(879.8390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27929 lossL: tensor(815.7594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27930 lossL: tensor(859.7576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27931 lossL: tensor(845.2068, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27932 lossL: tensor(976.7603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27933 lossL: tensor(850.4451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27934 lossL: tensor(773.8427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27935 lossL: tensor(903.0363, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27936 lossL: tensor(771.4856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27937 lossL: tensor(907.7359, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27938 lossL: tensor(784.2512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27939 lossL: tensor(840.0132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27940 lossL: tensor(891.6046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27941 lossL: tensor(861.7293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27942 lossL: tensor(980.4877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27943 lossL: tensor(801.9874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27944 lossL: tensor(865.9292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27945 lossL: tensor(864.5267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27946 lossL: tensor(814.3893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27947 lossL: tensor(907.2228, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27948 lossL: tensor(917.3035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27949 lossL: tensor(833.6199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27950 lossL: tensor(945.2640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27951 lossL: tensor(835.0238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27952 lossL: tensor(833.9904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27953 lossL: tensor(887.0458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27954 lossL: tensor(777.4224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27955 lossL: tensor(884.3557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27956 lossL: tensor(805.2388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27957 lossL: tensor(851.3618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27958 lossL: tensor(809.4005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27959 lossL: tensor(885.6509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27960 lossL: tensor(872.0101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27961 lossL: tensor(796.3660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27962 lossL: tensor(831.7272, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27963 lossL: tensor(787.4510, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27964 lossL: tensor(778.5739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27965 lossL: tensor(810.3256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27966 lossL: tensor(790.8875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27967 lossL: tensor(831.2419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27968 lossL: tensor(796.3641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27969 lossL: tensor(793.0681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27970 lossL: tensor(847.8979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27971 lossL: tensor(791.8474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27972 lossL: tensor(882.9457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27973 lossL: tensor(793.0526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27974 lossL: tensor(787.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27975 lossL: tensor(785.4520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27976 lossL: tensor(840.9241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27977 lossL: tensor(776.0446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27978 lossL: tensor(829.2401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27979 lossL: tensor(818.3082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27980 lossL: tensor(812.6740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27981 lossL: tensor(798.8707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27982 lossL: tensor(787.5270, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27983 lossL: tensor(839.5017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27984 lossL: tensor(824.7237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27985 lossL: tensor(866.4423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27986 lossL: tensor(850.1379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27987 lossL: tensor(823.3586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27988 lossL: tensor(880.0527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27989 lossL: tensor(801.7977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27990 lossL: tensor(750.1767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27991 lossL: tensor(798.9847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27992 lossL: tensor(831.1926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27993 lossL: tensor(792.6614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27994 lossL: tensor(891.3616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27995 lossL: tensor(793.7498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27996 lossL: tensor(842.6202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27997 lossL: tensor(832.5950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27998 lossL: tensor(793.8838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "27999 lossL: tensor(773.1143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28000 lossL: tensor(737.0037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28001 lossL: tensor(865.7679, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28002 lossL: tensor(858.9252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28003 lossL: tensor(839.4583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28004 lossL: tensor(764.3940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28005 lossL: tensor(760.2437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28006 lossL: tensor(777.2115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28007 lossL: tensor(769.9367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28008 lossL: tensor(789.6945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28009 lossL: tensor(816.0037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28010 lossL: tensor(754.9523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28011 lossL: tensor(752.2507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28012 lossL: tensor(788.7766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28013 lossL: tensor(741.6492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28014 lossL: tensor(834.1024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28015 lossL: tensor(819.4724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28016 lossL: tensor(851.6876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28017 lossL: tensor(705.3474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28018 lossL: tensor(858.7495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28019 lossL: tensor(835.3981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28020 lossL: tensor(828.2727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28021 lossL: tensor(786.3993, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28022 lossL: tensor(848.0369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28023 lossL: tensor(707.2408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28024 lossL: tensor(767.5771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28025 lossL: tensor(790.3537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28026 lossL: tensor(814.4582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28027 lossL: tensor(907.5635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28028 lossL: tensor(721.7322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28029 lossL: tensor(836.7325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28030 lossL: tensor(818.9082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28031 lossL: tensor(792.6666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28032 lossL: tensor(823.6451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28033 lossL: tensor(810.2083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28034 lossL: tensor(807.9646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28035 lossL: tensor(763.6127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28036 lossL: tensor(806.1812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28037 lossL: tensor(754.3436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28038 lossL: tensor(825.2563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28039 lossL: tensor(878.2298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28040 lossL: tensor(866.9763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28041 lossL: tensor(836.1575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28042 lossL: tensor(839.0125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28043 lossL: tensor(810.8051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28044 lossL: tensor(798.9769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28045 lossL: tensor(800.2611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28046 lossL: tensor(755.5809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28047 lossL: tensor(819.1630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28048 lossL: tensor(787.3546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28049 lossL: tensor(789.1424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28050 lossL: tensor(796.4859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28051 lossL: tensor(747.6158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28052 lossL: tensor(742.4260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28053 lossL: tensor(846.6058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28054 lossL: tensor(739.0347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28055 lossL: tensor(844.9449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28056 lossL: tensor(905.7037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28057 lossL: tensor(796.8024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28058 lossL: tensor(772.2803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28059 lossL: tensor(832.9898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28060 lossL: tensor(784.3303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28061 lossL: tensor(806.6060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28062 lossL: tensor(896.7715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28063 lossL: tensor(809.9515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28064 lossL: tensor(783.6804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28065 lossL: tensor(844.1225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28066 lossL: tensor(780.1415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28067 lossL: tensor(842.5900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28068 lossL: tensor(789.9504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28069 lossL: tensor(692.8453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28070 lossL: tensor(860.4067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28071 lossL: tensor(783.6755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28072 lossL: tensor(871.5810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28073 lossL: tensor(860.9057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28074 lossL: tensor(847.1862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28075 lossL: tensor(993.6131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28076 lossL: tensor(801.9674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28077 lossL: tensor(874.1127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28078 lossL: tensor(853.8914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28079 lossL: tensor(833.1882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28080 lossL: tensor(1000.0482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28081 lossL: tensor(751.1202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28082 lossL: tensor(874.4982, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28083 lossL: tensor(880.4118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28084 lossL: tensor(829.9930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28085 lossL: tensor(1043.6477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28086 lossL: tensor(789.1436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28087 lossL: tensor(1031.3219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28088 lossL: tensor(1089.1586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28089 lossL: tensor(745.2167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28090 lossL: tensor(1042.8180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28091 lossL: tensor(834.4297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28092 lossL: tensor(892.5311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28093 lossL: tensor(852.8714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28094 lossL: tensor(827.3686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28095 lossL: tensor(927.4614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28096 lossL: tensor(777.5582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28097 lossL: tensor(885.9416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28098 lossL: tensor(814.8466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28099 lossL: tensor(811.9952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28100 lossL: tensor(859.9274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28101 lossL: tensor(802.7242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28102 lossL: tensor(909.5128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28103 lossL: tensor(765.7994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28104 lossL: tensor(887.0652, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28105 lossL: tensor(1018.8079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28106 lossL: tensor(834.7592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28107 lossL: tensor(843.1981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28108 lossL: tensor(935.3082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28109 lossL: tensor(808.7455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28110 lossL: tensor(855.8060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28111 lossL: tensor(939.8804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28112 lossL: tensor(800.6240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28113 lossL: tensor(839.2369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28114 lossL: tensor(815.3419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28115 lossL: tensor(768.7318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28116 lossL: tensor(758.9656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28117 lossL: tensor(812.5696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28118 lossL: tensor(779.3329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28119 lossL: tensor(835.1992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28120 lossL: tensor(815.0838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28121 lossL: tensor(784.4007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28122 lossL: tensor(951.3045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28123 lossL: tensor(750.5966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28124 lossL: tensor(880.3143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28125 lossL: tensor(869.2769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28126 lossL: tensor(758.0502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28127 lossL: tensor(823.4649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28128 lossL: tensor(820.9940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28129 lossL: tensor(821.4160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28130 lossL: tensor(828.5192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28131 lossL: tensor(729.2629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28132 lossL: tensor(824.8938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28133 lossL: tensor(775.5176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28134 lossL: tensor(874.8868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28135 lossL: tensor(829.2823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28136 lossL: tensor(810.3576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28137 lossL: tensor(916.6354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28138 lossL: tensor(705.6964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28139 lossL: tensor(840.8726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28140 lossL: tensor(791.8810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28141 lossL: tensor(740.4860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28142 lossL: tensor(789.6762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28143 lossL: tensor(791.0199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28144 lossL: tensor(786.0262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28145 lossL: tensor(804.3866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28146 lossL: tensor(819.6057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28147 lossL: tensor(747.3111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28148 lossL: tensor(730.2848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28149 lossL: tensor(710.6592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28150 lossL: tensor(778.2766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28151 lossL: tensor(917.0974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28152 lossL: tensor(762.3431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28153 lossL: tensor(818.8722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28154 lossL: tensor(850.2715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28155 lossL: tensor(858.5676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28156 lossL: tensor(857.5623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28157 lossL: tensor(781.6299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28158 lossL: tensor(833.4296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28159 lossL: tensor(824.9866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28160 lossL: tensor(814.1552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28161 lossL: tensor(789.7073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28162 lossL: tensor(801.8505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28163 lossL: tensor(826.2949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28164 lossL: tensor(791.5109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28165 lossL: tensor(811.2713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28166 lossL: tensor(844.6285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28167 lossL: tensor(793.0765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28168 lossL: tensor(734.0821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28169 lossL: tensor(813.8445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28170 lossL: tensor(786.3711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28171 lossL: tensor(786.2560, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28172 lossL: tensor(828.1050, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28173 lossL: tensor(721.2324, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28174 lossL: tensor(781.8541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28175 lossL: tensor(764.8248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28176 lossL: tensor(758.3375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28177 lossL: tensor(800.4229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28178 lossL: tensor(769.4750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28179 lossL: tensor(746.7660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28180 lossL: tensor(779.1917, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28181 lossL: tensor(750.1509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28182 lossL: tensor(837.8942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28183 lossL: tensor(815.0375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28184 lossL: tensor(720.4002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28185 lossL: tensor(797.4793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28186 lossL: tensor(796.5543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28187 lossL: tensor(803.5753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28188 lossL: tensor(764.2283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28189 lossL: tensor(723.3754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28190 lossL: tensor(842.1409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28191 lossL: tensor(775.1897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28192 lossL: tensor(829.0757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28193 lossL: tensor(796.0990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28194 lossL: tensor(820.6207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28195 lossL: tensor(728.0787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28196 lossL: tensor(900.9978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28197 lossL: tensor(814.7795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28198 lossL: tensor(866.5148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28199 lossL: tensor(815.9701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28200 lossL: tensor(800.0938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28201 lossL: tensor(786.9076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28202 lossL: tensor(781.4055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28203 lossL: tensor(913.8173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28204 lossL: tensor(799.1936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28205 lossL: tensor(848.5373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28206 lossL: tensor(734.3542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28207 lossL: tensor(803.9633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28208 lossL: tensor(742.1249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28209 lossL: tensor(758.6091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28210 lossL: tensor(758.7991, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28211 lossL: tensor(848.0613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28212 lossL: tensor(846.5804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28213 lossL: tensor(804.3132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28214 lossL: tensor(804.1219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28215 lossL: tensor(845.8114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28216 lossL: tensor(761.8715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28217 lossL: tensor(811.5256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28218 lossL: tensor(749.8008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28219 lossL: tensor(759.7103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28220 lossL: tensor(828.9926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28221 lossL: tensor(824.7731, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28222 lossL: tensor(874.3140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28223 lossL: tensor(815.3299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28224 lossL: tensor(782.2086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28225 lossL: tensor(798.4506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28226 lossL: tensor(846.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28227 lossL: tensor(811.5168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28228 lossL: tensor(802.8206, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28229 lossL: tensor(798.7514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28230 lossL: tensor(796.9276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28231 lossL: tensor(794.4901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28232 lossL: tensor(746.2391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28233 lossL: tensor(876.9987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28234 lossL: tensor(822.1660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28235 lossL: tensor(767.7316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28236 lossL: tensor(826.6553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28237 lossL: tensor(803.4927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28238 lossL: tensor(874.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28239 lossL: tensor(835.4636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28240 lossL: tensor(767.1983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28241 lossL: tensor(878.5144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28242 lossL: tensor(815.0721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28243 lossL: tensor(760.8477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28244 lossL: tensor(818.8530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28245 lossL: tensor(825.4758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28246 lossL: tensor(755.6296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28247 lossL: tensor(859.2404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28248 lossL: tensor(748.4972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28249 lossL: tensor(809.0434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28250 lossL: tensor(747.7534, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28251 lossL: tensor(757.0618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28252 lossL: tensor(817.6740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28253 lossL: tensor(789.4082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28254 lossL: tensor(831.3149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28255 lossL: tensor(769.6695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28256 lossL: tensor(832.6483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28257 lossL: tensor(811.1207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28258 lossL: tensor(757.6445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28259 lossL: tensor(747.2238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28260 lossL: tensor(861.2214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28261 lossL: tensor(760.6460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28262 lossL: tensor(808.2529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28263 lossL: tensor(786.1187, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28264 lossL: tensor(725.6451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28265 lossL: tensor(852.2672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28266 lossL: tensor(783.6059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28267 lossL: tensor(824.4014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28268 lossL: tensor(839.3506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28269 lossL: tensor(757.7455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28270 lossL: tensor(853.7360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28271 lossL: tensor(849.5781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28272 lossL: tensor(816.0241, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28273 lossL: tensor(781.0089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28274 lossL: tensor(786.1433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28275 lossL: tensor(874.4828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28276 lossL: tensor(778.2507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28277 lossL: tensor(808.1356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28278 lossL: tensor(836.9681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28279 lossL: tensor(853.8809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28280 lossL: tensor(833.2419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28281 lossL: tensor(810.4376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28282 lossL: tensor(862.5224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28283 lossL: tensor(814.5801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28284 lossL: tensor(843.0169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28285 lossL: tensor(780.1168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28286 lossL: tensor(795.3126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28287 lossL: tensor(921.1750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28288 lossL: tensor(768.8180, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28289 lossL: tensor(784.5859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28290 lossL: tensor(746.5839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28291 lossL: tensor(727.2440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28292 lossL: tensor(793.9021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28293 lossL: tensor(777.6008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28294 lossL: tensor(762.1800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28295 lossL: tensor(829.1356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28296 lossL: tensor(796.2435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28297 lossL: tensor(826.3919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28298 lossL: tensor(790.2958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28299 lossL: tensor(821.4280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28300 lossL: tensor(784.3186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28301 lossL: tensor(740.0158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28302 lossL: tensor(754.0066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28303 lossL: tensor(764.7245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28304 lossL: tensor(784.7297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28305 lossL: tensor(898.5003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28306 lossL: tensor(799.4480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28307 lossL: tensor(802.2610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28308 lossL: tensor(892.0868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28309 lossL: tensor(755.0395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28310 lossL: tensor(782.5759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28311 lossL: tensor(779.1192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28312 lossL: tensor(808.1365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28313 lossL: tensor(761.6546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28314 lossL: tensor(778.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28315 lossL: tensor(841.9882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28316 lossL: tensor(769.8091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28317 lossL: tensor(836.8717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28318 lossL: tensor(721.6747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28319 lossL: tensor(799.0205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28320 lossL: tensor(791.7296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28321 lossL: tensor(840.9238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28322 lossL: tensor(797.0706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28323 lossL: tensor(793.9663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28324 lossL: tensor(831.7883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28325 lossL: tensor(857.1835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28326 lossL: tensor(838.7051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28327 lossL: tensor(796.0197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28328 lossL: tensor(811.6271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28329 lossL: tensor(864.9653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28330 lossL: tensor(758.9213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28331 lossL: tensor(745.6520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28332 lossL: tensor(759.1302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28333 lossL: tensor(830.2275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28334 lossL: tensor(801.4009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28335 lossL: tensor(805.5427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28336 lossL: tensor(766.0057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28337 lossL: tensor(789.4315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28338 lossL: tensor(745.8987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28339 lossL: tensor(733.9911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28340 lossL: tensor(803.5776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28341 lossL: tensor(734.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28342 lossL: tensor(756.3474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28343 lossL: tensor(778.2969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28344 lossL: tensor(807.3682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28345 lossL: tensor(786.5034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28346 lossL: tensor(829.9474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28347 lossL: tensor(821.8060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28348 lossL: tensor(868.1252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28349 lossL: tensor(786.5549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28350 lossL: tensor(825.9301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28351 lossL: tensor(829.7214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28352 lossL: tensor(781.5648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28353 lossL: tensor(829.5546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28354 lossL: tensor(868.2800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28355 lossL: tensor(797.6794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28356 lossL: tensor(820.2835, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28357 lossL: tensor(851.3877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28358 lossL: tensor(846.3390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28359 lossL: tensor(811.1829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28360 lossL: tensor(788.1870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28361 lossL: tensor(826.9197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28362 lossL: tensor(756.1520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28363 lossL: tensor(779.7548, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28364 lossL: tensor(745.8877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28365 lossL: tensor(798.4211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28366 lossL: tensor(807.5103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28367 lossL: tensor(804.8189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28368 lossL: tensor(767.0471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28369 lossL: tensor(753.7643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28370 lossL: tensor(862.7854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28371 lossL: tensor(845.3204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28372 lossL: tensor(850.5486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28373 lossL: tensor(853.7181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28374 lossL: tensor(945.2631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28375 lossL: tensor(807.3235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28376 lossL: tensor(838.7838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28377 lossL: tensor(945.7095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28378 lossL: tensor(784.7774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28379 lossL: tensor(805.2566, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28380 lossL: tensor(824.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28381 lossL: tensor(779.6084, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28382 lossL: tensor(777.4243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28383 lossL: tensor(846.4934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28384 lossL: tensor(812.3528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28385 lossL: tensor(881.1205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28386 lossL: tensor(783.6517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28387 lossL: tensor(817.9555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28388 lossL: tensor(899.5765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28389 lossL: tensor(795.4915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28390 lossL: tensor(874.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28391 lossL: tensor(934.1540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28392 lossL: tensor(817.8433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28393 lossL: tensor(897.3489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28394 lossL: tensor(815.4503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28395 lossL: tensor(767.3542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28396 lossL: tensor(899.5719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28397 lossL: tensor(806.9634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28398 lossL: tensor(787.7971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28399 lossL: tensor(962.5104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28400 lossL: tensor(784.8016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28401 lossL: tensor(809.2831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28402 lossL: tensor(872.9593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28403 lossL: tensor(804.4698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28404 lossL: tensor(830.9760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28405 lossL: tensor(752.5236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28406 lossL: tensor(817.4574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28407 lossL: tensor(800.5237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28408 lossL: tensor(808.9133, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28409 lossL: tensor(770.1201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28410 lossL: tensor(757.4248, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28411 lossL: tensor(748.0923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28412 lossL: tensor(772.4247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28413 lossL: tensor(824.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28414 lossL: tensor(831.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28415 lossL: tensor(855.7371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28416 lossL: tensor(777.4582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28417 lossL: tensor(779.7847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28418 lossL: tensor(777.8181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28419 lossL: tensor(764.4352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28420 lossL: tensor(813.1253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28421 lossL: tensor(810.3452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28422 lossL: tensor(861.9907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28423 lossL: tensor(791.5032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28424 lossL: tensor(735.3802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28425 lossL: tensor(868.8427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28426 lossL: tensor(783.3842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28427 lossL: tensor(752.0861, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28428 lossL: tensor(921.5012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28429 lossL: tensor(838.8380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28430 lossL: tensor(852.0316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28431 lossL: tensor(846.9924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28432 lossL: tensor(726.8655, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28433 lossL: tensor(815.7757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28434 lossL: tensor(808.2321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28435 lossL: tensor(761.6105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28436 lossL: tensor(872.7024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28437 lossL: tensor(836.0506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28438 lossL: tensor(795.9790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28439 lossL: tensor(826.7657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28440 lossL: tensor(806.2369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28441 lossL: tensor(750.3467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28442 lossL: tensor(750.7565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28443 lossL: tensor(794.7370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28444 lossL: tensor(837.0706, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28445 lossL: tensor(801.0957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28446 lossL: tensor(776.3010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28447 lossL: tensor(799.5894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28448 lossL: tensor(753.6056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28449 lossL: tensor(769.2234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28450 lossL: tensor(796.6896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28451 lossL: tensor(757.6327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28452 lossL: tensor(780.6530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28453 lossL: tensor(746.3177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28454 lossL: tensor(752.6630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28455 lossL: tensor(771.8621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28456 lossL: tensor(840.5894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28457 lossL: tensor(769.9168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28458 lossL: tensor(767.4709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28459 lossL: tensor(778.2150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28460 lossL: tensor(830.6722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28461 lossL: tensor(783.6380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28462 lossL: tensor(877.3842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28463 lossL: tensor(973.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28464 lossL: tensor(756.9967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28465 lossL: tensor(916.9656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28466 lossL: tensor(995.7667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28467 lossL: tensor(742.5970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28468 lossL: tensor(998.7672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28469 lossL: tensor(932.0516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28470 lossL: tensor(713.8199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28471 lossL: tensor(1048.7400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28472 lossL: tensor(912.2718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28473 lossL: tensor(795.4865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28474 lossL: tensor(1102.8439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28475 lossL: tensor(962.6400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28476 lossL: tensor(879.7504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28477 lossL: tensor(1020.6890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28478 lossL: tensor(787.8259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28479 lossL: tensor(996.0274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28480 lossL: tensor(1093.5323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28481 lossL: tensor(815.2536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28482 lossL: tensor(945.8787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28483 lossL: tensor(944.3915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28484 lossL: tensor(826.5955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28485 lossL: tensor(1262.3604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28486 lossL: tensor(847.8852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28487 lossL: tensor(999.5457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28488 lossL: tensor(1182.2451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28489 lossL: tensor(756.4527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28490 lossL: tensor(1207.5789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28491 lossL: tensor(1011.1070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28492 lossL: tensor(853.5035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28493 lossL: tensor(1102.1936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28494 lossL: tensor(832.5427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28495 lossL: tensor(1037.5862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28496 lossL: tensor(882.9946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28497 lossL: tensor(794.6770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28498 lossL: tensor(1007.7357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28499 lossL: tensor(859.3699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28500 lossL: tensor(872.2162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28501 lossL: tensor(826.5067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28502 lossL: tensor(814.3331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28503 lossL: tensor(744.9727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28504 lossL: tensor(801.3423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28505 lossL: tensor(875.3841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28506 lossL: tensor(770.3683, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28507 lossL: tensor(873.8761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28508 lossL: tensor(852.2020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28509 lossL: tensor(840.8968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28510 lossL: tensor(792.0604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28511 lossL: tensor(861.5117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28512 lossL: tensor(945.8315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28513 lossL: tensor(728.2407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28514 lossL: tensor(854.4467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28515 lossL: tensor(830.2064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28516 lossL: tensor(771.5143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28517 lossL: tensor(771.7281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28518 lossL: tensor(783.3005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28519 lossL: tensor(752.1057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28520 lossL: tensor(911.5705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28521 lossL: tensor(848.1178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28522 lossL: tensor(872.1061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28523 lossL: tensor(830.6002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28524 lossL: tensor(865.4781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28525 lossL: tensor(753.9748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28526 lossL: tensor(814.2474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28527 lossL: tensor(844.2651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28528 lossL: tensor(791.6780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28529 lossL: tensor(845.0809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28530 lossL: tensor(805.5015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28531 lossL: tensor(884.2671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28532 lossL: tensor(808.6037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28533 lossL: tensor(850.6399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28534 lossL: tensor(854.4246, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28535 lossL: tensor(834.0494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28536 lossL: tensor(887.8386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28537 lossL: tensor(906.3674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28538 lossL: tensor(823.4572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28539 lossL: tensor(871.8126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28540 lossL: tensor(821.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28541 lossL: tensor(916.0798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28542 lossL: tensor(830.2444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28543 lossL: tensor(939.4484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28544 lossL: tensor(999.4512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28545 lossL: tensor(870.2980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28546 lossL: tensor(851.3777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28547 lossL: tensor(772.9907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28548 lossL: tensor(852.7814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28549 lossL: tensor(863.5235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28550 lossL: tensor(775.1166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28551 lossL: tensor(765.8438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28552 lossL: tensor(728.5959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28553 lossL: tensor(915.2078, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28554 lossL: tensor(917.4624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28555 lossL: tensor(767.4529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28556 lossL: tensor(721.1028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28557 lossL: tensor(745.6437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28558 lossL: tensor(789.3673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28559 lossL: tensor(811.0633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28560 lossL: tensor(733.6351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28561 lossL: tensor(792.4487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28562 lossL: tensor(751.3528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28563 lossL: tensor(778.3492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28564 lossL: tensor(730.3223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28565 lossL: tensor(882.0818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28566 lossL: tensor(805.7128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28567 lossL: tensor(759.9017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28568 lossL: tensor(797.7405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28569 lossL: tensor(806.2771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28570 lossL: tensor(754.9089, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28571 lossL: tensor(778.6339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28572 lossL: tensor(828.6401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28573 lossL: tensor(751.9987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28574 lossL: tensor(793.1634, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28575 lossL: tensor(765.5836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28576 lossL: tensor(794.7643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28577 lossL: tensor(773.0381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28578 lossL: tensor(784.9205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28579 lossL: tensor(733.7958, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28580 lossL: tensor(757.3771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28581 lossL: tensor(824.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28582 lossL: tensor(794.9310, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28583 lossL: tensor(732.9945, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28584 lossL: tensor(764.4017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28585 lossL: tensor(796.4618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28586 lossL: tensor(773.3788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28587 lossL: tensor(800.3168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28588 lossL: tensor(861.6014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28589 lossL: tensor(732.3071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28590 lossL: tensor(836.8978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28591 lossL: tensor(771.3506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28592 lossL: tensor(732.0969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28593 lossL: tensor(739.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28594 lossL: tensor(732.6475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28595 lossL: tensor(818.9810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28596 lossL: tensor(793.7418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28597 lossL: tensor(883.1968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28598 lossL: tensor(749.2203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28599 lossL: tensor(858.8060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28600 lossL: tensor(766.3090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28601 lossL: tensor(719.2999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28602 lossL: tensor(786.2693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28603 lossL: tensor(781.6703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28604 lossL: tensor(801.6738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28605 lossL: tensor(767.5439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28606 lossL: tensor(837.2211, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28607 lossL: tensor(857.9672, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28608 lossL: tensor(869.9995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28609 lossL: tensor(778.2025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28610 lossL: tensor(785.9512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28611 lossL: tensor(820.3579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28612 lossL: tensor(762.2636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28613 lossL: tensor(845.0300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28614 lossL: tensor(807.7164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28615 lossL: tensor(796.0107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28616 lossL: tensor(819.1114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28617 lossL: tensor(753.6920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28618 lossL: tensor(858.9391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28619 lossL: tensor(825.3423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28620 lossL: tensor(826.8320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28621 lossL: tensor(882.9138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28622 lossL: tensor(790.2924, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28623 lossL: tensor(882.8392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28624 lossL: tensor(927.7334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28625 lossL: tensor(815.6301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28626 lossL: tensor(856.1286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28627 lossL: tensor(782.7224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28628 lossL: tensor(860.2029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28629 lossL: tensor(757.5017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28630 lossL: tensor(819.7205, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28631 lossL: tensor(836.9191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28632 lossL: tensor(775.9985, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28633 lossL: tensor(849.5425, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28634 lossL: tensor(789.2226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28635 lossL: tensor(787.9673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28636 lossL: tensor(811.7856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28637 lossL: tensor(759.7606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28638 lossL: tensor(757.9367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28639 lossL: tensor(759.3019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28640 lossL: tensor(807.2028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28641 lossL: tensor(757.6251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28642 lossL: tensor(779.2465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28643 lossL: tensor(755.8355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28644 lossL: tensor(734.7995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28645 lossL: tensor(819.6529, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28646 lossL: tensor(798.0981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28647 lossL: tensor(794.3880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28648 lossL: tensor(781.8501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28649 lossL: tensor(824.7135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28650 lossL: tensor(815.5060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28651 lossL: tensor(717.3447, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28652 lossL: tensor(762.0380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28653 lossL: tensor(861.1454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28654 lossL: tensor(792.8828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28655 lossL: tensor(827.7126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28656 lossL: tensor(793.4489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28657 lossL: tensor(756.0948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28658 lossL: tensor(751.8082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28659 lossL: tensor(784.2546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28660 lossL: tensor(823.8126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28661 lossL: tensor(794.6840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28662 lossL: tensor(765.2780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28663 lossL: tensor(789.5674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28664 lossL: tensor(773.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28665 lossL: tensor(848.5233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28666 lossL: tensor(776.1716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28667 lossL: tensor(739.5052, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28668 lossL: tensor(762.0944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28669 lossL: tensor(855.0364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28670 lossL: tensor(702.4382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28671 lossL: tensor(805.9777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28672 lossL: tensor(829.4733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28673 lossL: tensor(747.2191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28674 lossL: tensor(771.1265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28675 lossL: tensor(794.6457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28676 lossL: tensor(722.8892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28677 lossL: tensor(731.8517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28678 lossL: tensor(873.0910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28679 lossL: tensor(751.1726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28680 lossL: tensor(831.4703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28681 lossL: tensor(728.4486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28682 lossL: tensor(761.3502, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28683 lossL: tensor(766.0281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28684 lossL: tensor(727.0342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28685 lossL: tensor(792.4202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28686 lossL: tensor(850.7997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28687 lossL: tensor(736.7692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28688 lossL: tensor(847.1708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28689 lossL: tensor(806.5407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28690 lossL: tensor(788.7014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28691 lossL: tensor(829.3129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28692 lossL: tensor(736.2381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28693 lossL: tensor(772.4474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28694 lossL: tensor(780.3124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28695 lossL: tensor(757.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28696 lossL: tensor(836.5782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28697 lossL: tensor(813.6865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28698 lossL: tensor(762.8923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28699 lossL: tensor(776.2181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28700 lossL: tensor(785.1901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28701 lossL: tensor(792.4016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28702 lossL: tensor(747.0547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28703 lossL: tensor(973.6464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28704 lossL: tensor(891.8527, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28705 lossL: tensor(801.2394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28706 lossL: tensor(873.2813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28707 lossL: tensor(763.3976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28708 lossL: tensor(894.8459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28709 lossL: tensor(838.9530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28710 lossL: tensor(793.5580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28711 lossL: tensor(757.8181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28712 lossL: tensor(818.1313, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28713 lossL: tensor(832.5031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28714 lossL: tensor(798.6138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28715 lossL: tensor(812.1389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28716 lossL: tensor(754.0771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28717 lossL: tensor(825.4373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28718 lossL: tensor(775.3380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28719 lossL: tensor(738.8999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28720 lossL: tensor(775.7694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28721 lossL: tensor(738.0121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28722 lossL: tensor(762.4840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28723 lossL: tensor(741.6937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28724 lossL: tensor(762.0320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28725 lossL: tensor(908.5977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28726 lossL: tensor(742.3871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28727 lossL: tensor(772.0291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28728 lossL: tensor(756.0079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28729 lossL: tensor(918.1708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28730 lossL: tensor(943.1971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28731 lossL: tensor(773.5943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28732 lossL: tensor(798.4979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28733 lossL: tensor(828.7054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28734 lossL: tensor(773.9247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28735 lossL: tensor(806.2988, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28736 lossL: tensor(847.3404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28737 lossL: tensor(764.2889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28738 lossL: tensor(735.5064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28739 lossL: tensor(755.1519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28740 lossL: tensor(774.1201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28741 lossL: tensor(744.0730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28742 lossL: tensor(895.5223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28743 lossL: tensor(779.1935, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28744 lossL: tensor(869.2927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28745 lossL: tensor(832.7831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28746 lossL: tensor(782.3416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28747 lossL: tensor(1009.0062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28748 lossL: tensor(850.2700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28749 lossL: tensor(827.5108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28750 lossL: tensor(1051.7024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28751 lossL: tensor(806.8910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28752 lossL: tensor(961.1002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28753 lossL: tensor(1002.0323, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28754 lossL: tensor(791.2901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28755 lossL: tensor(984.0328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28756 lossL: tensor(842.9766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28757 lossL: tensor(818.7899, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28758 lossL: tensor(967.8931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28759 lossL: tensor(791.7243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28760 lossL: tensor(817.5076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28761 lossL: tensor(784.7818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28762 lossL: tensor(816.1749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28763 lossL: tensor(784.9435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28764 lossL: tensor(798.3772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28765 lossL: tensor(824.4764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28766 lossL: tensor(811.0542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28767 lossL: tensor(835.9433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28768 lossL: tensor(751.8983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28769 lossL: tensor(753.9101, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28770 lossL: tensor(829.6805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28771 lossL: tensor(845.6382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28772 lossL: tensor(821.6576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28773 lossL: tensor(778.3932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28774 lossL: tensor(865.9550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28775 lossL: tensor(773.3342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28776 lossL: tensor(761.8956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28777 lossL: tensor(804.6100, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28778 lossL: tensor(757.1854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28779 lossL: tensor(812.9843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28780 lossL: tensor(832.4296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28781 lossL: tensor(789.9404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28782 lossL: tensor(804.0568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28783 lossL: tensor(823.0259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28784 lossL: tensor(800.3280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28785 lossL: tensor(803.0392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28786 lossL: tensor(702.4340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28787 lossL: tensor(870.4822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28788 lossL: tensor(805.1357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28789 lossL: tensor(769.2001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28790 lossL: tensor(818.7191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28791 lossL: tensor(770.2361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28792 lossL: tensor(742.3449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28793 lossL: tensor(752.9124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28794 lossL: tensor(750.8586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28795 lossL: tensor(771.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28796 lossL: tensor(826.0842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28797 lossL: tensor(819.4581, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28798 lossL: tensor(819.2244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28799 lossL: tensor(750.2319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28800 lossL: tensor(740.6830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28801 lossL: tensor(731.0715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28802 lossL: tensor(768.0143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28803 lossL: tensor(735.5653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28804 lossL: tensor(753.1608, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28805 lossL: tensor(831.5822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28806 lossL: tensor(833.3967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28807 lossL: tensor(804.6459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28808 lossL: tensor(762.5278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28809 lossL: tensor(867.0908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28810 lossL: tensor(761.8153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28811 lossL: tensor(757.8177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28812 lossL: tensor(756.5735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28813 lossL: tensor(768.8472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28814 lossL: tensor(832.0744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28815 lossL: tensor(797.9741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28816 lossL: tensor(829.9668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28817 lossL: tensor(730.8853, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28818 lossL: tensor(846.6716, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28819 lossL: tensor(862.5745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28820 lossL: tensor(720.5651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28821 lossL: tensor(829.1614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28822 lossL: tensor(746.7269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28823 lossL: tensor(861.7116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28824 lossL: tensor(801.7116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28825 lossL: tensor(754.0720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28826 lossL: tensor(834.4083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28827 lossL: tensor(779.3413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28828 lossL: tensor(801.3676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28829 lossL: tensor(757.3635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28830 lossL: tensor(842.6505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28831 lossL: tensor(847.9356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28832 lossL: tensor(676.2703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "28833 lossL: tensor(723.1174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28834 lossL: tensor(815.7906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28835 lossL: tensor(767.4816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28836 lossL: tensor(767.3120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28837 lossL: tensor(809.4126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28838 lossL: tensor(840.8234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28839 lossL: tensor(774.1064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28840 lossL: tensor(730.4199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28841 lossL: tensor(845.3134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28842 lossL: tensor(773.1209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28843 lossL: tensor(775.8398, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28844 lossL: tensor(801.8818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28845 lossL: tensor(769.4158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28846 lossL: tensor(768.1973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28847 lossL: tensor(774.2196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28848 lossL: tensor(760.9075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28849 lossL: tensor(789.7281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28850 lossL: tensor(766.2789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28851 lossL: tensor(756.6366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28852 lossL: tensor(853.8193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28853 lossL: tensor(784.5489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28854 lossL: tensor(684.0996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28855 lossL: tensor(746.6160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28856 lossL: tensor(807.9486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28857 lossL: tensor(752.6058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28858 lossL: tensor(789.3929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28859 lossL: tensor(740.1107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28860 lossL: tensor(797.8207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28861 lossL: tensor(811.1603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28862 lossL: tensor(827.1145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28863 lossL: tensor(814.8923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28864 lossL: tensor(742.5391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28865 lossL: tensor(775.6337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28866 lossL: tensor(763.6145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28867 lossL: tensor(768.6600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28868 lossL: tensor(744.8648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28869 lossL: tensor(858.0964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28870 lossL: tensor(780.7585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28871 lossL: tensor(663.5308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "model saved\n",
      "28872 lossL: tensor(810.9557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28873 lossL: tensor(804.5844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28874 lossL: tensor(780.2571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28875 lossL: tensor(785.1821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28876 lossL: tensor(784.6476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28877 lossL: tensor(742.0492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28878 lossL: tensor(803.0627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28879 lossL: tensor(764.7136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28880 lossL: tensor(758.3129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28881 lossL: tensor(752.1879, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28882 lossL: tensor(787.0852, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28883 lossL: tensor(739.3175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28884 lossL: tensor(718.7264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28885 lossL: tensor(790.6373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28886 lossL: tensor(770.8459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28887 lossL: tensor(786.2309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28888 lossL: tensor(802.9260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28889 lossL: tensor(756.3468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28890 lossL: tensor(776.6838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28891 lossL: tensor(755.7434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28892 lossL: tensor(751.9064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28893 lossL: tensor(820.8994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28894 lossL: tensor(896.5943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28895 lossL: tensor(799.7130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28896 lossL: tensor(871.7489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28897 lossL: tensor(911.1868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28898 lossL: tensor(860.3417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28899 lossL: tensor(844.5585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28900 lossL: tensor(746.8057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28901 lossL: tensor(797.1498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28902 lossL: tensor(761.5457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28903 lossL: tensor(745.8170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28904 lossL: tensor(742.1482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28905 lossL: tensor(788.0635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28906 lossL: tensor(762.0569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28907 lossL: tensor(834.6889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28908 lossL: tensor(806.6124, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28909 lossL: tensor(704.2347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28910 lossL: tensor(812.5833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28911 lossL: tensor(768.1395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28912 lossL: tensor(764.7880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28913 lossL: tensor(772.7811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28914 lossL: tensor(810.0867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28915 lossL: tensor(814.4969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28916 lossL: tensor(735.4561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28917 lossL: tensor(790.5275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28918 lossL: tensor(794.7158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28919 lossL: tensor(751.4262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28920 lossL: tensor(782.3990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28921 lossL: tensor(832.4139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28922 lossL: tensor(803.8409, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28923 lossL: tensor(738.2013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28924 lossL: tensor(829.8768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28925 lossL: tensor(777.2175, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28926 lossL: tensor(780.1082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28927 lossL: tensor(761.6298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28928 lossL: tensor(794.5936, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28929 lossL: tensor(778.7615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28930 lossL: tensor(788.9702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28931 lossL: tensor(716.2922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28932 lossL: tensor(759.4684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28933 lossL: tensor(811.3384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28934 lossL: tensor(800.3918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28935 lossL: tensor(815.3606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28936 lossL: tensor(754.4033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28937 lossL: tensor(743.1008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28938 lossL: tensor(743.3276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28939 lossL: tensor(756.9919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28940 lossL: tensor(814.4695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28941 lossL: tensor(797.4481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28942 lossL: tensor(781.2643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28943 lossL: tensor(763.6267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28944 lossL: tensor(810.9075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28945 lossL: tensor(883.7598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28946 lossL: tensor(787.3623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28947 lossL: tensor(723.1096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28948 lossL: tensor(836.5630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28949 lossL: tensor(753.0193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28950 lossL: tensor(807.8717, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28951 lossL: tensor(866.8076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28952 lossL: tensor(754.1297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28953 lossL: tensor(804.3431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28954 lossL: tensor(758.9574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28955 lossL: tensor(821.7813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28956 lossL: tensor(881.4746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28957 lossL: tensor(748.3995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28958 lossL: tensor(820.0357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28959 lossL: tensor(731.0986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28960 lossL: tensor(792.6485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28961 lossL: tensor(802.9854, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28962 lossL: tensor(773.3113, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28963 lossL: tensor(795.2480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28964 lossL: tensor(766.2306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28965 lossL: tensor(801.0521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28966 lossL: tensor(808.8865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28967 lossL: tensor(868.0250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28968 lossL: tensor(795.5807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28969 lossL: tensor(910.0806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28970 lossL: tensor(888.3733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28971 lossL: tensor(735.8846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28972 lossL: tensor(926.1404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28973 lossL: tensor(776.3273, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28974 lossL: tensor(818.6848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28975 lossL: tensor(853.2554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28976 lossL: tensor(742.8776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28977 lossL: tensor(857.7792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28978 lossL: tensor(800.6485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28979 lossL: tensor(719.0059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28980 lossL: tensor(872.2756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28981 lossL: tensor(786.4595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28982 lossL: tensor(788.7659, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28983 lossL: tensor(929.3522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28984 lossL: tensor(863.0789, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28985 lossL: tensor(768.1737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28986 lossL: tensor(927.1251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28987 lossL: tensor(848.0439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28988 lossL: tensor(772.9513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28989 lossL: tensor(912.6799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28990 lossL: tensor(829.6060, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28991 lossL: tensor(743.5698, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28992 lossL: tensor(814.1141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28993 lossL: tensor(776.7926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28994 lossL: tensor(842.7064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28995 lossL: tensor(695.4602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28996 lossL: tensor(855.4498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28997 lossL: tensor(727.5024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28998 lossL: tensor(777.0961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "28999 lossL: tensor(789.9792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29000 lossL: tensor(768.3362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29001 lossL: tensor(725.0825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29002 lossL: tensor(768.6962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29003 lossL: tensor(757.7120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29004 lossL: tensor(745.4823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29005 lossL: tensor(774.4225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29006 lossL: tensor(783.3036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29007 lossL: tensor(763.0772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29008 lossL: tensor(768.3705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29009 lossL: tensor(798.2517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29010 lossL: tensor(812.7296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29011 lossL: tensor(890.7448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29012 lossL: tensor(769.6202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29013 lossL: tensor(846.7027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29014 lossL: tensor(750.3521, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29015 lossL: tensor(884.6663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29016 lossL: tensor(826.7007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29017 lossL: tensor(770.8866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29018 lossL: tensor(825.3291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29019 lossL: tensor(774.9851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29020 lossL: tensor(861.9371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29021 lossL: tensor(938.2212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29022 lossL: tensor(732.6210, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29023 lossL: tensor(846.8897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29024 lossL: tensor(811.6071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29025 lossL: tensor(710.0977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29026 lossL: tensor(898.0106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29027 lossL: tensor(771.4343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29028 lossL: tensor(827.0862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29029 lossL: tensor(934.7425, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29030 lossL: tensor(852.2340, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29031 lossL: tensor(874.7041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29032 lossL: tensor(924.4844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29033 lossL: tensor(725.5960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29034 lossL: tensor(885.3431, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29035 lossL: tensor(777.7164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29036 lossL: tensor(759.3499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29037 lossL: tensor(748.6818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29038 lossL: tensor(686.6927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29039 lossL: tensor(840.7931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29040 lossL: tensor(833.9701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29041 lossL: tensor(785.2396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29042 lossL: tensor(758.9918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29043 lossL: tensor(780.6396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29044 lossL: tensor(742.8570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29045 lossL: tensor(810.3138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29046 lossL: tensor(758.3902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29047 lossL: tensor(825.1766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29048 lossL: tensor(781.8149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29049 lossL: tensor(804.4376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29050 lossL: tensor(733.0261, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29051 lossL: tensor(752.9823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29052 lossL: tensor(743.8837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29053 lossL: tensor(738.8445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29054 lossL: tensor(789.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29055 lossL: tensor(787.9709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29056 lossL: tensor(813.9606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29057 lossL: tensor(813.1914, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29058 lossL: tensor(750.2134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29059 lossL: tensor(799.3818, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29060 lossL: tensor(808.7844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29061 lossL: tensor(763.1189, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29062 lossL: tensor(804.1459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29063 lossL: tensor(812.4477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29064 lossL: tensor(806.5378, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29065 lossL: tensor(792.1199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29066 lossL: tensor(792.2271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29067 lossL: tensor(736.7507, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29068 lossL: tensor(799.1436, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29069 lossL: tensor(806.6741, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29070 lossL: tensor(792.2277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29071 lossL: tensor(733.6727, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29072 lossL: tensor(823.2661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29073 lossL: tensor(769.7017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29074 lossL: tensor(810.2256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29075 lossL: tensor(788.5135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29076 lossL: tensor(798.7142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29077 lossL: tensor(745.5726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29078 lossL: tensor(726.4619, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29079 lossL: tensor(761.3165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29080 lossL: tensor(808.1966, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29081 lossL: tensor(787.8321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29082 lossL: tensor(864.4209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29083 lossL: tensor(850.7628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29084 lossL: tensor(800.0276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29085 lossL: tensor(785.5305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29086 lossL: tensor(815.1749, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29087 lossL: tensor(865.7250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29088 lossL: tensor(901.8192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29089 lossL: tensor(772.1247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29090 lossL: tensor(904.3505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29091 lossL: tensor(861.7724, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29092 lossL: tensor(755.9242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29093 lossL: tensor(756.5452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29094 lossL: tensor(754.8563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29095 lossL: tensor(867.8064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29096 lossL: tensor(766.0925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29097 lossL: tensor(747.3699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29098 lossL: tensor(765.6752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29099 lossL: tensor(789.1954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29100 lossL: tensor(855.4871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29101 lossL: tensor(930.9421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29102 lossL: tensor(784.9166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29103 lossL: tensor(868.1262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29104 lossL: tensor(767.5377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29105 lossL: tensor(760.3650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29106 lossL: tensor(861.5726, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29107 lossL: tensor(785.1649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29108 lossL: tensor(815.5439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29109 lossL: tensor(793.9332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29110 lossL: tensor(766.9093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29111 lossL: tensor(839.1191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29112 lossL: tensor(872.7576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29113 lossL: tensor(757.4921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29114 lossL: tensor(801.6463, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29115 lossL: tensor(853.3569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29116 lossL: tensor(794.0969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29117 lossL: tensor(761.7637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29118 lossL: tensor(808.7362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29119 lossL: tensor(775.3155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29120 lossL: tensor(746.7494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29121 lossL: tensor(820.7556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29122 lossL: tensor(942.3504, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29123 lossL: tensor(806.1733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29124 lossL: tensor(779.8503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29125 lossL: tensor(871.7343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29126 lossL: tensor(802.8923, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29127 lossL: tensor(826.7984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29128 lossL: tensor(757.4235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29129 lossL: tensor(739.3547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29130 lossL: tensor(801.4034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29131 lossL: tensor(774.8167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29132 lossL: tensor(744.8416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29133 lossL: tensor(715.5422, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29134 lossL: tensor(719.1155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29135 lossL: tensor(777.0087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29136 lossL: tensor(748.4251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29137 lossL: tensor(726.4995, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29138 lossL: tensor(806.8444, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29139 lossL: tensor(787.3149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29140 lossL: tensor(900.2780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29141 lossL: tensor(798.2564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29142 lossL: tensor(807.4971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29143 lossL: tensor(788.7482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29144 lossL: tensor(740.9744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29145 lossL: tensor(772.5583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29146 lossL: tensor(749.7128, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29147 lossL: tensor(744.3459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29148 lossL: tensor(783.0391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29149 lossL: tensor(807.7415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29150 lossL: tensor(817.5817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29151 lossL: tensor(811.1841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29152 lossL: tensor(748.7555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29153 lossL: tensor(742.6841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29154 lossL: tensor(806.0825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29155 lossL: tensor(751.3607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29156 lossL: tensor(779.2562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29157 lossL: tensor(743.4413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29158 lossL: tensor(788.1591, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29159 lossL: tensor(782.6792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29160 lossL: tensor(826.6805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29161 lossL: tensor(738.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29162 lossL: tensor(771.1921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29163 lossL: tensor(732.7407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29164 lossL: tensor(779.7399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29165 lossL: tensor(784.0859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29166 lossL: tensor(758.7090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29167 lossL: tensor(778.6946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29168 lossL: tensor(784.7426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29169 lossL: tensor(773.0090, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29170 lossL: tensor(790.7930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29171 lossL: tensor(693.9811, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29172 lossL: tensor(716.4686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29173 lossL: tensor(844.5720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29174 lossL: tensor(779.3217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29175 lossL: tensor(703.0641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29176 lossL: tensor(812.2129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29177 lossL: tensor(787.2356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29178 lossL: tensor(708.8339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29179 lossL: tensor(779.1186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29180 lossL: tensor(748.3387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29181 lossL: tensor(847.4000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29182 lossL: tensor(813.3347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29183 lossL: tensor(789.6196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29184 lossL: tensor(770.0869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29185 lossL: tensor(769.8617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29186 lossL: tensor(830.8194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29187 lossL: tensor(800.0654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29188 lossL: tensor(802.7513, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29189 lossL: tensor(754.6890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29190 lossL: tensor(765.5283, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29191 lossL: tensor(825.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29192 lossL: tensor(833.7013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29193 lossL: tensor(793.5314, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29194 lossL: tensor(750.9990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29195 lossL: tensor(765.7895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29196 lossL: tensor(829.6219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29197 lossL: tensor(811.7505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29198 lossL: tensor(774.8347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29199 lossL: tensor(831.1489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29200 lossL: tensor(753.2681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29201 lossL: tensor(752.6892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29202 lossL: tensor(855.1882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29203 lossL: tensor(744.3234, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29204 lossL: tensor(763.8558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29205 lossL: tensor(777.4462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29206 lossL: tensor(790.6874, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29207 lossL: tensor(760.2889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29208 lossL: tensor(755.3868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29209 lossL: tensor(812.3361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29210 lossL: tensor(775.8665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29211 lossL: tensor(886.4699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29212 lossL: tensor(770.4485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29213 lossL: tensor(761.0515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29214 lossL: tensor(811.7005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29215 lossL: tensor(810.9112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29216 lossL: tensor(776.6127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29217 lossL: tensor(833.5226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29218 lossL: tensor(744.5959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29219 lossL: tensor(824.7277, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29220 lossL: tensor(770.9553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29221 lossL: tensor(766.7777, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29222 lossL: tensor(833.6774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29223 lossL: tensor(718.2225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29224 lossL: tensor(788.7813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29225 lossL: tensor(792.8925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29226 lossL: tensor(829.4525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29227 lossL: tensor(713.5366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29228 lossL: tensor(798.5707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29229 lossL: tensor(787.2469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29230 lossL: tensor(815.9029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29231 lossL: tensor(748.0345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29232 lossL: tensor(817.4202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29233 lossL: tensor(759.8633, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29234 lossL: tensor(772.2285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29235 lossL: tensor(786.8948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29236 lossL: tensor(732.4506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29237 lossL: tensor(756.7427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29238 lossL: tensor(790.0489, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29239 lossL: tensor(825.9139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29240 lossL: tensor(749.0362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29241 lossL: tensor(857.0131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29242 lossL: tensor(742.8522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29243 lossL: tensor(822.8607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29244 lossL: tensor(887.3752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29245 lossL: tensor(819.1465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29246 lossL: tensor(793.3364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29247 lossL: tensor(861.1740, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29248 lossL: tensor(761.1638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29249 lossL: tensor(823.9012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29250 lossL: tensor(792.6419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29251 lossL: tensor(733.3721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29252 lossL: tensor(780.7494, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29253 lossL: tensor(799.9954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29254 lossL: tensor(766.5312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29255 lossL: tensor(752.1079, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29256 lossL: tensor(808.2098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29257 lossL: tensor(780.7787, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29258 lossL: tensor(803.9011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29259 lossL: tensor(748.6047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29260 lossL: tensor(787.6185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29261 lossL: tensor(837.7223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29262 lossL: tensor(781.6267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29263 lossL: tensor(737.0718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29264 lossL: tensor(748.3959, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29265 lossL: tensor(756.9402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29266 lossL: tensor(788.0413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29267 lossL: tensor(779.0542, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29268 lossL: tensor(773.0944, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29269 lossL: tensor(752.5356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29270 lossL: tensor(829.0616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29271 lossL: tensor(753.1577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29272 lossL: tensor(836.2349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29273 lossL: tensor(848.6722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29274 lossL: tensor(780.9384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29275 lossL: tensor(760.5996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29276 lossL: tensor(791.1684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29277 lossL: tensor(782.0745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29278 lossL: tensor(745.1710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29279 lossL: tensor(714.2506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29280 lossL: tensor(830.7405, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29281 lossL: tensor(760.2505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29282 lossL: tensor(795.4393, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29283 lossL: tensor(871.6286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29284 lossL: tensor(899.0375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29285 lossL: tensor(692.0610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29286 lossL: tensor(829.2477, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29287 lossL: tensor(792.0353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29288 lossL: tensor(799.3600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29289 lossL: tensor(888.6771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29290 lossL: tensor(802.0134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29291 lossL: tensor(775.5336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29292 lossL: tensor(877.1836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29293 lossL: tensor(729.2574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29294 lossL: tensor(761.3621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29295 lossL: tensor(866.7072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29296 lossL: tensor(733.3766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29297 lossL: tensor(852.7130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29298 lossL: tensor(743.3682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29299 lossL: tensor(780.8134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29300 lossL: tensor(845.2293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29301 lossL: tensor(894.9074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29302 lossL: tensor(685.1453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29303 lossL: tensor(777.0864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29304 lossL: tensor(834.3455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29305 lossL: tensor(739.2476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29306 lossL: tensor(755.5511, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29307 lossL: tensor(920.1346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29308 lossL: tensor(793.4370, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29309 lossL: tensor(738.2641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29310 lossL: tensor(818.9590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29311 lossL: tensor(763.5383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29312 lossL: tensor(899.8252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29313 lossL: tensor(905.3472, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29314 lossL: tensor(767.2501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29315 lossL: tensor(860.5905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29316 lossL: tensor(985.1111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29317 lossL: tensor(749.0220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29318 lossL: tensor(921.7800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29319 lossL: tensor(841.7191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29320 lossL: tensor(867.3182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29321 lossL: tensor(831.1873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29322 lossL: tensor(770.1031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29323 lossL: tensor(978.2410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29324 lossL: tensor(974.1889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29325 lossL: tensor(809.1402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29326 lossL: tensor(938.3546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29327 lossL: tensor(889.5151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29328 lossL: tensor(817.0678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29329 lossL: tensor(855.3572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29330 lossL: tensor(773.0341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29331 lossL: tensor(790.9960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29332 lossL: tensor(847.1933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29333 lossL: tensor(777.3799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29334 lossL: tensor(801.9952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29335 lossL: tensor(799.7075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29336 lossL: tensor(855.3421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29337 lossL: tensor(789.7878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29338 lossL: tensor(785.6087, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29339 lossL: tensor(757.3579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29340 lossL: tensor(710.2723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29341 lossL: tensor(864.1380, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29342 lossL: tensor(825.2030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29343 lossL: tensor(845.7572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29344 lossL: tensor(885.5921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29345 lossL: tensor(761.5102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29346 lossL: tensor(852.7099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29347 lossL: tensor(865.8418, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29348 lossL: tensor(797.0103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29349 lossL: tensor(815.9047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29350 lossL: tensor(800.0107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29351 lossL: tensor(773.3875, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29352 lossL: tensor(1023.2057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29353 lossL: tensor(924.4920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29354 lossL: tensor(845.2648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29355 lossL: tensor(1067.8931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29356 lossL: tensor(812.4846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29357 lossL: tensor(919.4579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29358 lossL: tensor(1093.5001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29359 lossL: tensor(778.5828, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29360 lossL: tensor(960.3953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29361 lossL: tensor(898.5975, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29362 lossL: tensor(806.7131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29363 lossL: tensor(1031.6458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29364 lossL: tensor(834.6635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29365 lossL: tensor(928.6239, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29366 lossL: tensor(1025.0790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29367 lossL: tensor(746.0742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29368 lossL: tensor(971.1693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29369 lossL: tensor(745.6519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29370 lossL: tensor(910.5927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29371 lossL: tensor(851.0625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29372 lossL: tensor(767.3523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29373 lossL: tensor(1035.6550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29374 lossL: tensor(689.3550, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29375 lossL: tensor(992.1167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29376 lossL: tensor(781.2485, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29377 lossL: tensor(852.7066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29378 lossL: tensor(826.4293, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29379 lossL: tensor(798.0654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29380 lossL: tensor(870.0593, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29381 lossL: tensor(760.6149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29382 lossL: tensor(823.8574, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29383 lossL: tensor(829.1201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29384 lossL: tensor(735.6042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29385 lossL: tensor(828.0242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29386 lossL: tensor(768.9401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29387 lossL: tensor(735.0290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29388 lossL: tensor(826.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29389 lossL: tensor(755.3797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29390 lossL: tensor(892.2900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29391 lossL: tensor(791.9844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29392 lossL: tensor(855.3202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29393 lossL: tensor(851.8493, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29394 lossL: tensor(716.6322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29395 lossL: tensor(841.0715, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29396 lossL: tensor(732.6214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29397 lossL: tensor(794.9881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29398 lossL: tensor(771.5352, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29399 lossL: tensor(795.3195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29400 lossL: tensor(760.0171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29401 lossL: tensor(734.7421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29402 lossL: tensor(706.4893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29403 lossL: tensor(746.3455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29404 lossL: tensor(774.9561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29405 lossL: tensor(753.7061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29406 lossL: tensor(809.8408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29407 lossL: tensor(858.5361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29408 lossL: tensor(718.0346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29409 lossL: tensor(778.6097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29410 lossL: tensor(747.9389, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29411 lossL: tensor(810.0519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29412 lossL: tensor(807.5275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29413 lossL: tensor(779.4920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29414 lossL: tensor(735.8600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29415 lossL: tensor(802.4536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29416 lossL: tensor(784.0355, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29417 lossL: tensor(839.4916, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29418 lossL: tensor(758.6235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29419 lossL: tensor(823.8907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29420 lossL: tensor(774.1339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29421 lossL: tensor(811.8653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29422 lossL: tensor(771.5258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29423 lossL: tensor(811.4233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29424 lossL: tensor(719.8868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29425 lossL: tensor(742.9306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29426 lossL: tensor(820.3883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29427 lossL: tensor(830.9736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29428 lossL: tensor(792.7626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29429 lossL: tensor(762.3595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29430 lossL: tensor(776.7330, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29431 lossL: tensor(795.3600, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29432 lossL: tensor(861.8305, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29433 lossL: tensor(726.5931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29434 lossL: tensor(829.8893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29435 lossL: tensor(822.8051, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29436 lossL: tensor(714.1183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29437 lossL: tensor(809.3867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29438 lossL: tensor(786.2416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29439 lossL: tensor(746.2676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29440 lossL: tensor(792.5761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29441 lossL: tensor(741.3256, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29442 lossL: tensor(1032.0685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29443 lossL: tensor(846.1645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29444 lossL: tensor(834.5927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29445 lossL: tensor(967.1253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29446 lossL: tensor(755.0336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29447 lossL: tensor(1008.1367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29448 lossL: tensor(754.3824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29449 lossL: tensor(838.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29450 lossL: tensor(834.8739, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29451 lossL: tensor(763.5043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29452 lossL: tensor(811.1556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29453 lossL: tensor(794.2891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29454 lossL: tensor(820.9119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29455 lossL: tensor(805.1631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29456 lossL: tensor(755.3986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29457 lossL: tensor(818.2625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29458 lossL: tensor(715.7909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29459 lossL: tensor(864.0220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29460 lossL: tensor(784.6624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29461 lossL: tensor(756.4495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29462 lossL: tensor(829.9722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29463 lossL: tensor(791.7264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29464 lossL: tensor(804.7377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29465 lossL: tensor(808.9487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29466 lossL: tensor(786.9756, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29467 lossL: tensor(868.5120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29468 lossL: tensor(818.0250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29469 lossL: tensor(768.9107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29470 lossL: tensor(809.9547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29471 lossL: tensor(727.9366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29472 lossL: tensor(749.4892, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29473 lossL: tensor(880.3026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29474 lossL: tensor(745.3376, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29475 lossL: tensor(909.5185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29476 lossL: tensor(890.0837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29477 lossL: tensor(771.7556, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29478 lossL: tensor(802.9895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29479 lossL: tensor(755.0190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29480 lossL: tensor(791.5820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29481 lossL: tensor(808.5119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29482 lossL: tensor(754.6661, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29483 lossL: tensor(789.2615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29484 lossL: tensor(825.2451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29485 lossL: tensor(780.6746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29486 lossL: tensor(761.9625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29487 lossL: tensor(793.1395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29488 lossL: tensor(715.3109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29489 lossL: tensor(779.9623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29490 lossL: tensor(825.1640, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29491 lossL: tensor(839.1571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29492 lossL: tensor(704.0830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29493 lossL: tensor(720.9207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29494 lossL: tensor(743.5367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29495 lossL: tensor(783.0750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29496 lossL: tensor(806.0508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29497 lossL: tensor(813.7177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29498 lossL: tensor(787.1049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29499 lossL: tensor(872.0912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29500 lossL: tensor(810.8625, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29501 lossL: tensor(791.9414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29502 lossL: tensor(753.8768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29503 lossL: tensor(800.2271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29504 lossL: tensor(762.5685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29505 lossL: tensor(726.9577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29506 lossL: tensor(856.3685, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29507 lossL: tensor(810.4671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29508 lossL: tensor(753.5623, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29509 lossL: tensor(794.5531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29510 lossL: tensor(716.0580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29511 lossL: tensor(799.3682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29512 lossL: tensor(771.6812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29513 lossL: tensor(739.2607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29514 lossL: tensor(787.9637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29515 lossL: tensor(767.0569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29516 lossL: tensor(710.4484, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29517 lossL: tensor(835.2753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29518 lossL: tensor(836.5172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29519 lossL: tensor(770.4547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29520 lossL: tensor(805.2074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29521 lossL: tensor(769.8939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29522 lossL: tensor(830.8351, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29523 lossL: tensor(786.3541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29524 lossL: tensor(828.8434, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29525 lossL: tensor(859.6813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29526 lossL: tensor(703.8165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29527 lossL: tensor(859.6337, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29528 lossL: tensor(762.7772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29529 lossL: tensor(766.4729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29530 lossL: tensor(871.6964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29531 lossL: tensor(757.1249, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29532 lossL: tensor(839.1395, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29533 lossL: tensor(864.8474, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29534 lossL: tensor(795.7433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29535 lossL: tensor(915.8509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29536 lossL: tensor(770.7592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29537 lossL: tensor(833.0364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29538 lossL: tensor(778.6407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29539 lossL: tensor(786.5607, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29540 lossL: tensor(742.7001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29541 lossL: tensor(714.2267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29542 lossL: tensor(825.9757, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29543 lossL: tensor(831.5558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29544 lossL: tensor(781.9297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29545 lossL: tensor(863.2300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29546 lossL: tensor(766.6864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29547 lossL: tensor(747.8799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29548 lossL: tensor(816.7114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29549 lossL: tensor(782.0533, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29550 lossL: tensor(799.2162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29551 lossL: tensor(752.4616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29552 lossL: tensor(730.1240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29553 lossL: tensor(753.0615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29554 lossL: tensor(688.7708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29555 lossL: tensor(806.9897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29556 lossL: tensor(759.8172, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29557 lossL: tensor(772.6551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29558 lossL: tensor(816.3416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29559 lossL: tensor(762.1316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29560 lossL: tensor(775.3069, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29561 lossL: tensor(754.2358, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29562 lossL: tensor(752.7166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29563 lossL: tensor(764.6259, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29564 lossL: tensor(744.5806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29565 lossL: tensor(794.5433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29566 lossL: tensor(774.1688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29567 lossL: tensor(859.1938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29568 lossL: tensor(745.6356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29569 lossL: tensor(749.3762, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29570 lossL: tensor(747.1895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29571 lossL: tensor(808.2220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29572 lossL: tensor(738.9429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29573 lossL: tensor(821.5908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29574 lossL: tensor(739.2025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29575 lossL: tensor(693.4085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29576 lossL: tensor(709.8660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29577 lossL: tensor(766.2907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29578 lossL: tensor(868.6779, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29579 lossL: tensor(759.6544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29580 lossL: tensor(772.8702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29581 lossL: tensor(733.4730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29582 lossL: tensor(770.4202, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29583 lossL: tensor(760.0516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29584 lossL: tensor(782.7341, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29585 lossL: tensor(814.9411, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29586 lossL: tensor(849.9086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29587 lossL: tensor(824.4122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29588 lossL: tensor(794.7483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29589 lossL: tensor(731.3693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29590 lossL: tensor(790.3930, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29591 lossL: tensor(797.1301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29592 lossL: tensor(783.4949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29593 lossL: tensor(779.1658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29594 lossL: tensor(712.6934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29595 lossL: tensor(777.3288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29596 lossL: tensor(768.5373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29597 lossL: tensor(768.3157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29598 lossL: tensor(728.2214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29599 lossL: tensor(705.0125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29600 lossL: tensor(753.5247, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29601 lossL: tensor(807.9952, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29602 lossL: tensor(815.9224, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29603 lossL: tensor(751.5793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29604 lossL: tensor(792.2399, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29605 lossL: tensor(782.9979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29606 lossL: tensor(763.7524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29607 lossL: tensor(838.7702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29608 lossL: tensor(783.7778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29609 lossL: tensor(788.0449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29610 lossL: tensor(741.2582, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29611 lossL: tensor(761.7515, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29612 lossL: tensor(765.3132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29613 lossL: tensor(803.0242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29614 lossL: tensor(805.3047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29615 lossL: tensor(771.4793, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29616 lossL: tensor(787.0519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29617 lossL: tensor(843.1804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29618 lossL: tensor(817.9808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29619 lossL: tensor(766.5911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29620 lossL: tensor(772.2302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29621 lossL: tensor(754.2508, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29622 lossL: tensor(722.2544, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29623 lossL: tensor(839.6795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29624 lossL: tensor(741.8032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29625 lossL: tensor(738.4117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29626 lossL: tensor(770.4238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29627 lossL: tensor(783.1346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29628 lossL: tensor(820.7440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29629 lossL: tensor(728.5501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29630 lossL: tensor(822.6519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29631 lossL: tensor(866.2267, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29632 lossL: tensor(728.8666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29633 lossL: tensor(779.9646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29634 lossL: tensor(904.8900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29635 lossL: tensor(753.9094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29636 lossL: tensor(822.4689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29637 lossL: tensor(796.5678, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29638 lossL: tensor(854.3011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29639 lossL: tensor(816.5251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29640 lossL: tensor(809.5895, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29641 lossL: tensor(722.7714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29642 lossL: tensor(754.3503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29643 lossL: tensor(733.0448, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29644 lossL: tensor(808.4419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29645 lossL: tensor(822.0385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29646 lossL: tensor(732.8937, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29647 lossL: tensor(765.2884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29648 lossL: tensor(772.6268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29649 lossL: tensor(783.4606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29650 lossL: tensor(759.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29651 lossL: tensor(684.7540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29652 lossL: tensor(743.1676, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29653 lossL: tensor(738.7537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29654 lossL: tensor(759.6816, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29655 lossL: tensor(789.6367, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29656 lossL: tensor(801.8096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29657 lossL: tensor(829.4680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29658 lossL: tensor(812.1973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29659 lossL: tensor(892.2551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29660 lossL: tensor(789.8519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29661 lossL: tensor(865.8912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29662 lossL: tensor(887.8669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29663 lossL: tensor(758.7383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29664 lossL: tensor(799.7614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29665 lossL: tensor(766.3902, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29666 lossL: tensor(834.2986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29667 lossL: tensor(835.8782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29668 lossL: tensor(759.2977, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29669 lossL: tensor(861.0733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29670 lossL: tensor(817.0912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29671 lossL: tensor(860.3149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29672 lossL: tensor(926.0082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29673 lossL: tensor(760.3621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29674 lossL: tensor(858.8145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29675 lossL: tensor(787.4626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29676 lossL: tensor(719.5181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29677 lossL: tensor(820.8174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29678 lossL: tensor(743.4191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29679 lossL: tensor(771.4026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29680 lossL: tensor(855.6094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29681 lossL: tensor(862.3364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29682 lossL: tensor(824.8907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29683 lossL: tensor(886.7735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29684 lossL: tensor(757.5763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29685 lossL: tensor(749.2186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29686 lossL: tensor(738.5217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29687 lossL: tensor(772.7590, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29688 lossL: tensor(855.3032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29689 lossL: tensor(761.8097, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29690 lossL: tensor(803.4120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29691 lossL: tensor(825.9708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29692 lossL: tensor(788.6656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29693 lossL: tensor(792.5673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29694 lossL: tensor(792.9460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29695 lossL: tensor(763.5220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29696 lossL: tensor(882.2650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29697 lossL: tensor(813.5062, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29698 lossL: tensor(819.8309, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29699 lossL: tensor(788.5768, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29700 lossL: tensor(811.3406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29701 lossL: tensor(905.4911, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29702 lossL: tensor(754.0884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29703 lossL: tensor(876.7300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29704 lossL: tensor(805.4654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29705 lossL: tensor(779.7043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29706 lossL: tensor(859.3000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29707 lossL: tensor(741.0439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29708 lossL: tensor(753.8968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29709 lossL: tensor(830.6275, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29710 lossL: tensor(781.6605, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29711 lossL: tensor(755.6885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29712 lossL: tensor(745.4495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29713 lossL: tensor(708.9122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29714 lossL: tensor(773.8547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29715 lossL: tensor(812.1253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29716 lossL: tensor(775.4260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29717 lossL: tensor(690.6578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29718 lossL: tensor(744.8435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29719 lossL: tensor(792.5004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29720 lossL: tensor(763.8624, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29721 lossL: tensor(804.3315, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29722 lossL: tensor(767.4604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29723 lossL: tensor(753.9666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29724 lossL: tensor(781.8497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29725 lossL: tensor(766.5571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29726 lossL: tensor(783.5193, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29727 lossL: tensor(828.3719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29728 lossL: tensor(823.7408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29729 lossL: tensor(728.7458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29730 lossL: tensor(726.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29731 lossL: tensor(785.9802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29732 lossL: tensor(782.5532, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29733 lossL: tensor(765.8160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29734 lossL: tensor(752.6263, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29735 lossL: tensor(749.4000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29736 lossL: tensor(793.6105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29737 lossL: tensor(800.6873, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29738 lossL: tensor(816.5421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29739 lossL: tensor(820.9035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29740 lossL: tensor(775.1901, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29741 lossL: tensor(753.8867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29742 lossL: tensor(723.7452, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29743 lossL: tensor(749.7614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29744 lossL: tensor(761.6745, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29745 lossL: tensor(751.9862, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29746 lossL: tensor(759.7674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29747 lossL: tensor(819.5665, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29748 lossL: tensor(801.0989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29749 lossL: tensor(825.7858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29750 lossL: tensor(845.3071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29751 lossL: tensor(824.7336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29752 lossL: tensor(815.2978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29753 lossL: tensor(869.2596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29754 lossL: tensor(820.2963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29755 lossL: tensor(805.1528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29756 lossL: tensor(800.6989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29757 lossL: tensor(818.8015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29758 lossL: tensor(714.6586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29759 lossL: tensor(782.1890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29760 lossL: tensor(722.2147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29761 lossL: tensor(770.1857, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29762 lossL: tensor(762.6610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29763 lossL: tensor(840.0718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29764 lossL: tensor(828.0349, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29765 lossL: tensor(758.5763, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29766 lossL: tensor(799.4815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29767 lossL: tensor(836.8568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29768 lossL: tensor(834.3841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29769 lossL: tensor(785.0626, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29770 lossL: tensor(724.7039, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29771 lossL: tensor(732.1317, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29772 lossL: tensor(799.9416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29773 lossL: tensor(844.1586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29774 lossL: tensor(703.8710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29775 lossL: tensor(760.3457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29776 lossL: tensor(724.3009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29777 lossL: tensor(745.4464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29778 lossL: tensor(725.8338, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29779 lossL: tensor(903.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29780 lossL: tensor(827.3353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29781 lossL: tensor(797.0688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29782 lossL: tensor(826.4843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29783 lossL: tensor(806.2578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29784 lossL: tensor(768.8268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29785 lossL: tensor(809.8174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29786 lossL: tensor(777.3243, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29787 lossL: tensor(690.1326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29788 lossL: tensor(746.9554, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29789 lossL: tensor(715.4458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29790 lossL: tensor(759.5651, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29791 lossL: tensor(750.6790, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29792 lossL: tensor(789.8365, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29793 lossL: tensor(802.2955, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29794 lossL: tensor(736.6245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29795 lossL: tensor(771.8112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29796 lossL: tensor(769.1401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29797 lossL: tensor(794.8321, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29798 lossL: tensor(782.1838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29799 lossL: tensor(746.1191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29800 lossL: tensor(741.8845, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29801 lossL: tensor(796.9692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29802 lossL: tensor(732.8298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29803 lossL: tensor(759.7814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29804 lossL: tensor(722.3788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29805 lossL: tensor(759.9281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29806 lossL: tensor(734.2666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29807 lossL: tensor(741.5353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29808 lossL: tensor(681.5278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29809 lossL: tensor(815.9004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29810 lossL: tensor(919.2031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29811 lossL: tensor(750.8198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29812 lossL: tensor(873.5595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29813 lossL: tensor(837.2177, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29814 lossL: tensor(770.8771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29815 lossL: tensor(766.3145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29816 lossL: tensor(743.9595, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29817 lossL: tensor(779.6668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29818 lossL: tensor(722.5007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29819 lossL: tensor(810.2022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29820 lossL: tensor(821.0082, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29821 lossL: tensor(806.1127, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29822 lossL: tensor(756.4967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29823 lossL: tensor(737.6353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29824 lossL: tensor(743.3547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29825 lossL: tensor(773.6074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29826 lossL: tensor(747.3728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29827 lossL: tensor(777.3242, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29828 lossL: tensor(728.5704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29829 lossL: tensor(782.1761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29830 lossL: tensor(731.1126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29831 lossL: tensor(726.9518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29832 lossL: tensor(789.6483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29833 lossL: tensor(800.8963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29834 lossL: tensor(743.3558, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29835 lossL: tensor(801.6018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29836 lossL: tensor(778.4691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29837 lossL: tensor(743.7426, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29838 lossL: tensor(811.2088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29839 lossL: tensor(782.7024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29840 lossL: tensor(786.3345, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29841 lossL: tensor(852.0810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29842 lossL: tensor(782.8653, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29843 lossL: tensor(751.7801, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29844 lossL: tensor(809.7736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29845 lossL: tensor(752.0695, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29846 lossL: tensor(750.1588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29847 lossL: tensor(783.4384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29848 lossL: tensor(756.7667, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29849 lossL: tensor(809.8596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29850 lossL: tensor(751.0765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29851 lossL: tensor(746.4067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29852 lossL: tensor(740.6300, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29853 lossL: tensor(751.4295, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29854 lossL: tensor(719.9099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29855 lossL: tensor(762.7710, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29856 lossL: tensor(716.9750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29857 lossL: tensor(699.8578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29858 lossL: tensor(735.5055, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29859 lossL: tensor(851.8538, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29860 lossL: tensor(779.7344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29861 lossL: tensor(789.7185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29862 lossL: tensor(736.8870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29863 lossL: tensor(778.8666, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29864 lossL: tensor(830.6185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29865 lossL: tensor(845.1046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29866 lossL: tensor(768.2868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29867 lossL: tensor(812.2841, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29868 lossL: tensor(780.6670, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29869 lossL: tensor(776.0339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29870 lossL: tensor(775.3499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29871 lossL: tensor(746.0773, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29872 lossL: tensor(804.5329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29873 lossL: tensor(811.3957, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29874 lossL: tensor(689.9856, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29875 lossL: tensor(746.2964, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29876 lossL: tensor(741.5284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29877 lossL: tensor(754.9592, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29878 lossL: tensor(693.2212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29879 lossL: tensor(767.1669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29880 lossL: tensor(770.4462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29881 lossL: tensor(780.2976, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29882 lossL: tensor(816.1701, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29883 lossL: tensor(790.8042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29884 lossL: tensor(828.3843, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29885 lossL: tensor(757.5721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29886 lossL: tensor(775.7064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29887 lossL: tensor(759.8080, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29888 lossL: tensor(703.1907, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29889 lossL: tensor(790.3094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29890 lossL: tensor(792.2498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29891 lossL: tensor(798.8709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29892 lossL: tensor(761.3664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29893 lossL: tensor(781.9388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29894 lossL: tensor(808.4668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29895 lossL: tensor(773.6636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29896 lossL: tensor(787.1007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29897 lossL: tensor(781.1729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29898 lossL: tensor(807.7881, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29899 lossL: tensor(687.1116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29900 lossL: tensor(865.6800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29901 lossL: tensor(866.6391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29902 lossL: tensor(758.7588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29903 lossL: tensor(827.8006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29904 lossL: tensor(750.7198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29905 lossL: tensor(852.6970, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29906 lossL: tensor(899.7037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29907 lossL: tensor(794.3939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29908 lossL: tensor(876.8499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29909 lossL: tensor(783.9169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29910 lossL: tensor(781.1483, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29911 lossL: tensor(752.6690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29912 lossL: tensor(708.5980, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29913 lossL: tensor(814.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29914 lossL: tensor(774.7054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29915 lossL: tensor(751.5806, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29916 lossL: tensor(831.1658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29917 lossL: tensor(736.6226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29918 lossL: tensor(946.8459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29919 lossL: tensor(941.8200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29920 lossL: tensor(745.9420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29921 lossL: tensor(884.5192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29922 lossL: tensor(891.3064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29923 lossL: tensor(790.5085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29924 lossL: tensor(770.9121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29925 lossL: tensor(808.7388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29926 lossL: tensor(767.7077, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29927 lossL: tensor(868.8526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29928 lossL: tensor(767.2549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29929 lossL: tensor(762.3208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29930 lossL: tensor(876.1815, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29931 lossL: tensor(823.1804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29932 lossL: tensor(823.0490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29933 lossL: tensor(784.9794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29934 lossL: tensor(722.4584, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29935 lossL: tensor(741.0583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29936 lossL: tensor(740.0457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29937 lossL: tensor(784.8817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29938 lossL: tensor(789.7129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29939 lossL: tensor(788.5997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29940 lossL: tensor(731.7120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29941 lossL: tensor(728.6684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29942 lossL: tensor(751.0204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29943 lossL: tensor(782.5414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29944 lossL: tensor(720.2782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29945 lossL: tensor(735.8729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29946 lossL: tensor(795.9308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29947 lossL: tensor(780.4963, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29948 lossL: tensor(731.1388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29949 lossL: tensor(823.9728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29950 lossL: tensor(877.6788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29951 lossL: tensor(795.8922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29952 lossL: tensor(801.1467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29953 lossL: tensor(837.9268, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29954 lossL: tensor(756.8984, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29955 lossL: tensor(757.2765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29956 lossL: tensor(789.7969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29957 lossL: tensor(775.7771, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29958 lossL: tensor(807.5306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29959 lossL: tensor(774.2791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29960 lossL: tensor(714.7148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29961 lossL: tensor(767.4730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29962 lossL: tensor(767.3898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29963 lossL: tensor(758.7628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29964 lossL: tensor(757.7794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29965 lossL: tensor(758.0602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29966 lossL: tensor(756.9320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29967 lossL: tensor(723.3481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29968 lossL: tensor(706.9838, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29969 lossL: tensor(749.5139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29970 lossL: tensor(815.7496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29971 lossL: tensor(757.1285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29972 lossL: tensor(780.8386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29973 lossL: tensor(778.9013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29974 lossL: tensor(731.7279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29975 lossL: tensor(823.1115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29976 lossL: tensor(770.8312, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29977 lossL: tensor(798.8186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29978 lossL: tensor(822.1299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29979 lossL: tensor(928.3298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29980 lossL: tensor(807.6440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29981 lossL: tensor(740.2863, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29982 lossL: tensor(821.3360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29983 lossL: tensor(752.8896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29984 lossL: tensor(783.1682, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29985 lossL: tensor(695.3292, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29986 lossL: tensor(769.8893, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29987 lossL: tensor(770.7921, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29988 lossL: tensor(734.0019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29989 lossL: tensor(756.7161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29990 lossL: tensor(829.1291, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29991 lossL: tensor(741.6571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29992 lossL: tensor(712.0449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29993 lossL: tensor(780.9621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29994 lossL: tensor(822.0720, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29995 lossL: tensor(810.3730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29996 lossL: tensor(783.2805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29997 lossL: tensor(712.6104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29998 lossL: tensor(759.0812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "29999 lossL: tensor(719.0051, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "def sample(n):\n",
    "    x = torch.rand(n,1).to(device)\n",
    "    y = torch.rand(n,1).to(device)\n",
    "    return x.requires_grad_(True),y.requires_grad_(True)\n",
    "def lx(u):\n",
    "    x,y = sample(100)\n",
    "    cond = (2*x).to(device)\n",
    "    xy =torch.cat([x,y],dim=1)\n",
    "    f = u(xy)\n",
    "    dfdx = torch.autograd.grad(f,x,retain_graph=True,grad_outputs=torch.ones_like(f),create_graph=True,only_inputs=True)[0]\n",
    "    return loss(dfdx,cond)\n",
    "def ly(u):\n",
    "    x,y = sample(100)\n",
    "    cond = (2*y).to(device)\n",
    "    xy =torch.cat([x,y],dim=1)\n",
    "    f = u(xy)\n",
    "    dfdy = torch.autograd.grad(f,y,retain_graph=True,grad_outputs=torch.ones_like(f),create_graph=True,only_inputs=True)[0]\n",
    "    return loss(dfdy,cond)\n",
    "\n",
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,1)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "u = model().to(device)\n",
    "opt = torch.optim.Adam(params=u.parameters())\n",
    "loss = torch.nn.MSELoss()\n",
    "Lmin= math.inf\n",
    "for i in range(30000):\n",
    "    opt.zero_grad()\n",
    "    x = 100*torch.rand(1000,1).to(device)\n",
    "    y = 100*torch.rand(1000,1).to(device)\n",
    "    f_r = (x**2 + y**2).to(device)\n",
    "    xy =torch.cat([x,y],dim=1)\n",
    "\n",
    "    l2 = lx(u) + ly(u)\n",
    "    f = u (xy).to(device)\n",
    "    L = loss(f,f_r) + l2\n",
    "    L.backward()\n",
    "    opt.step()\n",
    "    print(i,'lossL:',L)\n",
    "    if Lmin>L:\n",
    "        Lmin = L\n",
    "        torch.save(u.state_dict(), './x**2+y**2-models.ckpt')\n",
    "        print('model saved')\n",
    "\n",
    "u = model().to(device)\n",
    "u.load_state_dict(torch.load('./x**2+y**2-models.ckpt'))\n",
    "x1 = 100*torch.rand(1000,1).to(device)\n",
    "y1 = 100*torch.rand(1000,1).to(device)\n",
    "x1y1 = torch.cat([x1,y1],dim=1)\n",
    "slove = u(x1y1)\n",
    "losstest = loss(slove,(x1**2+y1**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1579.3735, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "u = model()\n",
    "u.load_state_dict(torch.load('./x**2+y**2-models.ckpt'))\n",
    "x1 = 10*torch.rand(1000,1)\n",
    "y1 = 10*torch.rand(1000,1)\n",
    "x1y1 = torch.cat([x1,y1],dim=1)\n",
    "slove = u(x1y1)\n",
    "t = x1**2+y1**2\n",
    "losstest = loss(slove,(x1**2+y1**2))\n",
    "print(losstest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(1)\n",
    "slove = slove.detach().numpy()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x1,y1,t)\n",
    "ax.scatter(x1,y1,slove)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求解公式![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n",
      "2901\n",
      "2902\n",
      "2903\n",
      "2904\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2915\n",
      "2916\n",
      "2917\n",
      "2918\n",
      "2919\n",
      "2920\n",
      "2921\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2935\n",
      "2936\n",
      "2937\n",
      "2938\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2942\n",
      "2943\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2947\n",
      "2948\n",
      "2949\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2954\n",
      "2955\n",
      "2956\n",
      "2957\n",
      "2958\n",
      "2959\n",
      "2960\n",
      "2961\n",
      "2962\n",
      "2963\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2967\n",
      "2968\n",
      "2969\n",
      "2970\n",
      "2971\n",
      "2972\n",
      "2973\n",
      "2974\n",
      "2975\n",
      "2976\n",
      "2977\n",
      "2978\n",
      "2979\n",
      "2980\n",
      "2981\n",
      "2982\n",
      "2983\n",
      "2984\n",
      "2985\n",
      "2986\n",
      "2987\n",
      "2988\n",
      "2989\n",
      "2990\n",
      "2991\n",
      "2992\n",
      "2993\n",
      "2994\n",
      "2995\n",
      "2996\n",
      "2997\n",
      "2998\n",
      "2999\n",
      "3000\n",
      "3001\n",
      "3002\n",
      "3003\n",
      "3004\n",
      "3005\n",
      "3006\n",
      "3007\n",
      "3008\n",
      "3009\n",
      "3010\n",
      "3011\n",
      "3012\n",
      "3013\n",
      "3014\n",
      "3015\n",
      "3016\n",
      "3017\n",
      "3018\n",
      "3019\n",
      "3020\n",
      "3021\n",
      "3022\n",
      "3023\n",
      "3024\n",
      "3025\n",
      "3026\n",
      "3027\n",
      "3028\n",
      "3029\n",
      "3030\n",
      "3031\n",
      "3032\n",
      "3033\n",
      "3034\n",
      "3035\n",
      "3036\n",
      "3037\n",
      "3038\n",
      "3039\n",
      "3040\n",
      "3041\n",
      "3042\n",
      "3043\n",
      "3044\n",
      "3045\n",
      "3046\n",
      "3047\n",
      "3048\n",
      "3049\n",
      "3050\n",
      "3051\n",
      "3052\n",
      "3053\n",
      "3054\n",
      "3055\n",
      "3056\n",
      "3057\n",
      "3058\n",
      "3059\n",
      "3060\n",
      "3061\n",
      "3062\n",
      "3063\n",
      "3064\n",
      "3065\n",
      "3066\n",
      "3067\n",
      "3068\n",
      "3069\n",
      "3070\n",
      "3071\n",
      "3072\n",
      "3073\n",
      "3074\n",
      "3075\n",
      "3076\n",
      "3077\n",
      "3078\n",
      "3079\n",
      "3080\n",
      "3081\n",
      "3082\n",
      "3083\n",
      "3084\n",
      "3085\n",
      "3086\n",
      "3087\n",
      "3088\n",
      "3089\n",
      "3090\n",
      "3091\n",
      "3092\n",
      "3093\n",
      "3094\n",
      "3095\n",
      "3096\n",
      "3097\n",
      "3098\n",
      "3099\n",
      "3100\n",
      "3101\n",
      "3102\n",
      "3103\n",
      "3104\n",
      "3105\n",
      "3106\n",
      "3107\n",
      "3108\n",
      "3109\n",
      "3110\n",
      "3111\n",
      "3112\n",
      "3113\n",
      "3114\n",
      "3115\n",
      "3116\n",
      "3117\n",
      "3118\n",
      "3119\n",
      "3120\n",
      "3121\n",
      "3122\n",
      "3123\n",
      "3124\n",
      "3125\n",
      "3126\n",
      "3127\n",
      "3128\n",
      "3129\n",
      "3130\n",
      "3131\n",
      "3132\n",
      "3133\n",
      "3134\n",
      "3135\n",
      "3136\n",
      "3137\n",
      "3138\n",
      "3139\n",
      "3140\n",
      "3141\n",
      "3142\n",
      "3143\n",
      "3144\n",
      "3145\n",
      "3146\n",
      "3147\n",
      "3148\n",
      "3149\n",
      "3150\n",
      "3151\n",
      "3152\n",
      "3153\n",
      "3154\n",
      "3155\n",
      "3156\n",
      "3157\n",
      "3158\n",
      "3159\n",
      "3160\n",
      "3161\n",
      "3162\n",
      "3163\n",
      "3164\n",
      "3165\n",
      "3166\n",
      "3167\n",
      "3168\n",
      "3169\n",
      "3170\n",
      "3171\n",
      "3172\n",
      "3173\n",
      "3174\n",
      "3175\n",
      "3176\n",
      "3177\n",
      "3178\n",
      "3179\n",
      "3180\n",
      "3181\n",
      "3182\n",
      "3183\n",
      "3184\n",
      "3185\n",
      "3186\n",
      "3187\n",
      "3188\n",
      "3189\n",
      "3190\n",
      "3191\n",
      "3192\n",
      "3193\n",
      "3194\n",
      "3195\n",
      "3196\n",
      "3197\n",
      "3198\n",
      "3199\n",
      "3200\n",
      "3201\n",
      "3202\n",
      "3203\n",
      "3204\n",
      "3205\n",
      "3206\n",
      "3207\n",
      "3208\n",
      "3209\n",
      "3210\n",
      "3211\n",
      "3212\n",
      "3213\n",
      "3214\n",
      "3215\n",
      "3216\n",
      "3217\n",
      "3218\n",
      "3219\n",
      "3220\n",
      "3221\n",
      "3222\n",
      "3223\n",
      "3224\n",
      "3225\n",
      "3226\n",
      "3227\n",
      "3228\n",
      "3229\n",
      "3230\n",
      "3231\n",
      "3232\n",
      "3233\n",
      "3234\n",
      "3235\n",
      "3236\n",
      "3237\n",
      "3238\n",
      "3239\n",
      "3240\n",
      "3241\n",
      "3242\n",
      "3243\n",
      "3244\n",
      "3245\n",
      "3246\n",
      "3247\n",
      "3248\n",
      "3249\n",
      "3250\n",
      "3251\n",
      "3252\n",
      "3253\n",
      "3254\n",
      "3255\n",
      "3256\n",
      "3257\n",
      "3258\n",
      "3259\n",
      "3260\n",
      "3261\n",
      "3262\n",
      "3263\n",
      "3264\n",
      "3265\n",
      "3266\n",
      "3267\n",
      "3268\n",
      "3269\n",
      "3270\n",
      "3271\n",
      "3272\n",
      "3273\n",
      "3274\n",
      "3275\n",
      "3276\n",
      "3277\n",
      "3278\n",
      "3279\n",
      "3280\n",
      "3281\n",
      "3282\n",
      "3283\n",
      "3284\n",
      "3285\n",
      "3286\n",
      "3287\n",
      "3288\n",
      "3289\n",
      "3290\n",
      "3291\n",
      "3292\n",
      "3293\n",
      "3294\n",
      "3295\n",
      "3296\n",
      "3297\n",
      "3298\n",
      "3299\n",
      "3300\n",
      "3301\n",
      "3302\n",
      "3303\n",
      "3304\n",
      "3305\n",
      "3306\n",
      "3307\n",
      "3308\n",
      "3309\n",
      "3310\n",
      "3311\n",
      "3312\n",
      "3313\n",
      "3314\n",
      "3315\n",
      "3316\n",
      "3317\n",
      "3318\n",
      "3319\n",
      "3320\n",
      "3321\n",
      "3322\n",
      "3323\n",
      "3324\n",
      "3325\n",
      "3326\n",
      "3327\n",
      "3328\n",
      "3329\n",
      "3330\n",
      "3331\n",
      "3332\n",
      "3333\n",
      "3334\n",
      "3335\n",
      "3336\n",
      "3337\n",
      "3338\n",
      "3339\n",
      "3340\n",
      "3341\n",
      "3342\n",
      "3343\n",
      "3344\n",
      "3345\n",
      "3346\n",
      "3347\n",
      "3348\n",
      "3349\n",
      "3350\n",
      "3351\n",
      "3352\n",
      "3353\n",
      "3354\n",
      "3355\n",
      "3356\n",
      "3357\n",
      "3358\n",
      "3359\n",
      "3360\n",
      "3361\n",
      "3362\n",
      "3363\n",
      "3364\n",
      "3365\n",
      "3366\n",
      "3367\n",
      "3368\n",
      "3369\n",
      "3370\n",
      "3371\n",
      "3372\n",
      "3373\n",
      "3374\n",
      "3375\n",
      "3376\n",
      "3377\n",
      "3378\n",
      "3379\n",
      "3380\n",
      "3381\n",
      "3382\n",
      "3383\n",
      "3384\n",
      "3385\n",
      "3386\n",
      "3387\n",
      "3388\n",
      "3389\n",
      "3390\n",
      "3391\n",
      "3392\n",
      "3393\n",
      "3394\n",
      "3395\n",
      "3396\n",
      "3397\n",
      "3398\n",
      "3399\n",
      "3400\n",
      "3401\n",
      "3402\n",
      "3403\n",
      "3404\n",
      "3405\n",
      "3406\n",
      "3407\n",
      "3408\n",
      "3409\n",
      "3410\n",
      "3411\n",
      "3412\n",
      "3413\n",
      "3414\n",
      "3415\n",
      "3416\n",
      "3417\n",
      "3418\n",
      "3419\n",
      "3420\n",
      "3421\n",
      "3422\n",
      "3423\n",
      "3424\n",
      "3425\n",
      "3426\n",
      "3427\n",
      "3428\n",
      "3429\n",
      "3430\n",
      "3431\n",
      "3432\n",
      "3433\n",
      "3434\n",
      "3435\n",
      "3436\n",
      "3437\n",
      "3438\n",
      "3439\n",
      "3440\n",
      "3441\n",
      "3442\n",
      "3443\n",
      "3444\n",
      "3445\n",
      "3446\n",
      "3447\n",
      "3448\n",
      "3449\n",
      "3450\n",
      "3451\n",
      "3452\n",
      "3453\n",
      "3454\n",
      "3455\n",
      "3456\n",
      "3457\n",
      "3458\n",
      "3459\n",
      "3460\n",
      "3461\n",
      "3462\n",
      "3463\n",
      "3464\n",
      "3465\n",
      "3466\n",
      "3467\n",
      "3468\n",
      "3469\n",
      "3470\n",
      "3471\n",
      "3472\n",
      "3473\n",
      "3474\n",
      "3475\n",
      "3476\n",
      "3477\n",
      "3478\n",
      "3479\n",
      "3480\n",
      "3481\n",
      "3482\n",
      "3483\n",
      "3484\n",
      "3485\n",
      "3486\n",
      "3487\n",
      "3488\n",
      "3489\n",
      "3490\n",
      "3491\n",
      "3492\n",
      "3493\n",
      "3494\n",
      "3495\n",
      "3496\n",
      "3497\n",
      "3498\n",
      "3499\n",
      "3500\n",
      "3501\n",
      "3502\n",
      "3503\n",
      "3504\n",
      "3505\n",
      "3506\n",
      "3507\n",
      "3508\n",
      "3509\n",
      "3510\n",
      "3511\n",
      "3512\n",
      "3513\n",
      "3514\n",
      "3515\n",
      "3516\n",
      "3517\n",
      "3518\n",
      "3519\n",
      "3520\n",
      "3521\n",
      "3522\n",
      "3523\n",
      "3524\n",
      "3525\n",
      "3526\n",
      "3527\n",
      "3528\n",
      "3529\n",
      "3530\n",
      "3531\n",
      "3532\n",
      "3533\n",
      "3534\n",
      "3535\n",
      "3536\n",
      "3537\n",
      "3538\n",
      "3539\n",
      "3540\n",
      "3541\n",
      "3542\n",
      "3543\n",
      "3544\n",
      "3545\n",
      "3546\n",
      "3547\n",
      "3548\n",
      "3549\n",
      "3550\n",
      "3551\n",
      "3552\n",
      "3553\n",
      "3554\n",
      "3555\n",
      "3556\n",
      "3557\n",
      "3558\n",
      "3559\n",
      "3560\n",
      "3561\n",
      "3562\n",
      "3563\n",
      "3564\n",
      "3565\n",
      "3566\n",
      "3567\n",
      "3568\n",
      "3569\n",
      "3570\n",
      "3571\n",
      "3572\n",
      "3573\n",
      "3574\n",
      "3575\n",
      "3576\n",
      "3577\n",
      "3578\n",
      "3579\n",
      "3580\n",
      "3581\n",
      "3582\n",
      "3583\n",
      "3584\n",
      "3585\n",
      "3586\n",
      "3587\n",
      "3588\n",
      "3589\n",
      "3590\n",
      "3591\n",
      "3592\n",
      "3593\n",
      "3594\n",
      "3595\n",
      "3596\n",
      "3597\n",
      "3598\n",
      "3599\n",
      "3600\n",
      "3601\n",
      "3602\n",
      "3603\n",
      "3604\n",
      "3605\n",
      "3606\n",
      "3607\n",
      "3608\n",
      "3609\n",
      "3610\n",
      "3611\n",
      "3612\n",
      "3613\n",
      "3614\n",
      "3615\n",
      "3616\n",
      "3617\n",
      "3618\n",
      "3619\n",
      "3620\n",
      "3621\n",
      "3622\n",
      "3623\n",
      "3624\n",
      "3625\n",
      "3626\n",
      "3627\n",
      "3628\n",
      "3629\n",
      "3630\n",
      "3631\n",
      "3632\n",
      "3633\n",
      "3634\n",
      "3635\n",
      "3636\n",
      "3637\n",
      "3638\n",
      "3639\n",
      "3640\n",
      "3641\n",
      "3642\n",
      "3643\n",
      "3644\n",
      "3645\n",
      "3646\n",
      "3647\n",
      "3648\n",
      "3649\n",
      "3650\n",
      "3651\n",
      "3652\n",
      "3653\n",
      "3654\n",
      "3655\n",
      "3656\n",
      "3657\n",
      "3658\n",
      "3659\n",
      "3660\n",
      "3661\n",
      "3662\n",
      "3663\n",
      "3664\n",
      "3665\n",
      "3666\n",
      "3667\n",
      "3668\n",
      "3669\n",
      "3670\n",
      "3671\n",
      "3672\n",
      "3673\n",
      "3674\n",
      "3675\n",
      "3676\n",
      "3677\n",
      "3678\n",
      "3679\n",
      "3680\n",
      "3681\n",
      "3682\n",
      "3683\n",
      "3684\n",
      "3685\n",
      "3686\n",
      "3687\n",
      "3688\n",
      "3689\n",
      "3690\n",
      "3691\n",
      "3692\n",
      "3693\n",
      "3694\n",
      "3695\n",
      "3696\n",
      "3697\n",
      "3698\n",
      "3699\n",
      "3700\n",
      "3701\n",
      "3702\n",
      "3703\n",
      "3704\n",
      "3705\n",
      "3706\n",
      "3707\n",
      "3708\n",
      "3709\n",
      "3710\n",
      "3711\n",
      "3712\n",
      "3713\n",
      "3714\n",
      "3715\n",
      "3716\n",
      "3717\n",
      "3718\n",
      "3719\n",
      "3720\n",
      "3721\n",
      "3722\n",
      "3723\n",
      "3724\n",
      "3725\n",
      "3726\n",
      "3727\n",
      "3728\n",
      "3729\n",
      "3730\n",
      "3731\n",
      "3732\n",
      "3733\n",
      "3734\n",
      "3735\n",
      "3736\n",
      "3737\n",
      "3738\n",
      "3739\n",
      "3740\n",
      "3741\n",
      "3742\n",
      "3743\n",
      "3744\n",
      "3745\n",
      "3746\n",
      "3747\n",
      "3748\n",
      "3749\n",
      "3750\n",
      "3751\n",
      "3752\n",
      "3753\n",
      "3754\n",
      "3755\n",
      "3756\n",
      "3757\n",
      "3758\n",
      "3759\n",
      "3760\n",
      "3761\n",
      "3762\n",
      "3763\n",
      "3764\n",
      "3765\n",
      "3766\n",
      "3767\n",
      "3768\n",
      "3769\n",
      "3770\n",
      "3771\n",
      "3772\n",
      "3773\n",
      "3774\n",
      "3775\n",
      "3776\n",
      "3777\n",
      "3778\n",
      "3779\n",
      "3780\n",
      "3781\n",
      "3782\n",
      "3783\n",
      "3784\n",
      "3785\n",
      "3786\n",
      "3787\n",
      "3788\n",
      "3789\n",
      "3790\n",
      "3791\n",
      "3792\n",
      "3793\n",
      "3794\n",
      "3795\n",
      "3796\n",
      "3797\n",
      "3798\n",
      "3799\n",
      "3800\n",
      "3801\n",
      "3802\n",
      "3803\n",
      "3804\n",
      "3805\n",
      "3806\n",
      "3807\n",
      "3808\n",
      "3809\n",
      "3810\n",
      "3811\n",
      "3812\n",
      "3813\n",
      "3814\n",
      "3815\n",
      "3816\n",
      "3817\n",
      "3818\n",
      "3819\n",
      "3820\n",
      "3821\n",
      "3822\n",
      "3823\n",
      "3824\n",
      "3825\n",
      "3826\n",
      "3827\n",
      "3828\n",
      "3829\n",
      "3830\n",
      "3831\n",
      "3832\n",
      "3833\n",
      "3834\n",
      "3835\n",
      "3836\n",
      "3837\n",
      "3838\n",
      "3839\n",
      "3840\n",
      "3841\n",
      "3842\n",
      "3843\n",
      "3844\n",
      "3845\n",
      "3846\n",
      "3847\n",
      "3848\n",
      "3849\n",
      "3850\n",
      "3851\n",
      "3852\n",
      "3853\n",
      "3854\n",
      "3855\n",
      "3856\n",
      "3857\n",
      "3858\n",
      "3859\n",
      "3860\n",
      "3861\n",
      "3862\n",
      "3863\n",
      "3864\n",
      "3865\n",
      "3866\n",
      "3867\n",
      "3868\n",
      "3869\n",
      "3870\n",
      "3871\n",
      "3872\n",
      "3873\n",
      "3874\n",
      "3875\n",
      "3876\n",
      "3877\n",
      "3878\n",
      "3879\n",
      "3880\n",
      "3881\n",
      "3882\n",
      "3883\n",
      "3884\n",
      "3885\n",
      "3886\n",
      "3887\n",
      "3888\n",
      "3889\n",
      "3890\n",
      "3891\n",
      "3892\n",
      "3893\n",
      "3894\n",
      "3895\n",
      "3896\n",
      "3897\n",
      "3898\n",
      "3899\n",
      "3900\n",
      "3901\n",
      "3902\n",
      "3903\n",
      "3904\n",
      "3905\n",
      "3906\n",
      "3907\n",
      "3908\n",
      "3909\n",
      "3910\n",
      "3911\n",
      "3912\n",
      "3913\n",
      "3914\n",
      "3915\n",
      "3916\n",
      "3917\n",
      "3918\n",
      "3919\n",
      "3920\n",
      "3921\n",
      "3922\n",
      "3923\n",
      "3924\n",
      "3925\n",
      "3926\n",
      "3927\n",
      "3928\n",
      "3929\n",
      "3930\n",
      "3931\n",
      "3932\n",
      "3933\n",
      "3934\n",
      "3935\n",
      "3936\n",
      "3937\n",
      "3938\n",
      "3939\n",
      "3940\n",
      "3941\n",
      "3942\n",
      "3943\n",
      "3944\n",
      "3945\n",
      "3946\n",
      "3947\n",
      "3948\n",
      "3949\n",
      "3950\n",
      "3951\n",
      "3952\n",
      "3953\n",
      "3954\n",
      "3955\n",
      "3956\n",
      "3957\n",
      "3958\n",
      "3959\n",
      "3960\n",
      "3961\n",
      "3962\n",
      "3963\n",
      "3964\n",
      "3965\n",
      "3966\n",
      "3967\n",
      "3968\n",
      "3969\n",
      "3970\n",
      "3971\n",
      "3972\n",
      "3973\n",
      "3974\n",
      "3975\n",
      "3976\n",
      "3977\n",
      "3978\n",
      "3979\n",
      "3980\n",
      "3981\n",
      "3982\n",
      "3983\n",
      "3984\n",
      "3985\n",
      "3986\n",
      "3987\n",
      "3988\n",
      "3989\n",
      "3990\n",
      "3991\n",
      "3992\n",
      "3993\n",
      "3994\n",
      "3995\n",
      "3996\n",
      "3997\n",
      "3998\n",
      "3999\n",
      "4000\n",
      "4001\n",
      "4002\n",
      "4003\n",
      "4004\n",
      "4005\n",
      "4006\n",
      "4007\n",
      "4008\n",
      "4009\n",
      "4010\n",
      "4011\n",
      "4012\n",
      "4013\n",
      "4014\n",
      "4015\n",
      "4016\n",
      "4017\n",
      "4018\n",
      "4019\n",
      "4020\n",
      "4021\n",
      "4022\n",
      "4023\n",
      "4024\n",
      "4025\n",
      "4026\n",
      "4027\n",
      "4028\n",
      "4029\n",
      "4030\n",
      "4031\n",
      "4032\n",
      "4033\n",
      "4034\n",
      "4035\n",
      "4036\n",
      "4037\n",
      "4038\n",
      "4039\n",
      "4040\n",
      "4041\n",
      "4042\n",
      "4043\n",
      "4044\n",
      "4045\n",
      "4046\n",
      "4047\n",
      "4048\n",
      "4049\n",
      "4050\n",
      "4051\n",
      "4052\n",
      "4053\n",
      "4054\n",
      "4055\n",
      "4056\n",
      "4057\n",
      "4058\n",
      "4059\n",
      "4060\n",
      "4061\n",
      "4062\n",
      "4063\n",
      "4064\n",
      "4065\n",
      "4066\n",
      "4067\n",
      "4068\n",
      "4069\n",
      "4070\n",
      "4071\n",
      "4072\n",
      "4073\n",
      "4074\n",
      "4075\n",
      "4076\n",
      "4077\n",
      "4078\n",
      "4079\n",
      "4080\n",
      "4081\n",
      "4082\n",
      "4083\n",
      "4084\n",
      "4085\n",
      "4086\n",
      "4087\n",
      "4088\n",
      "4089\n",
      "4090\n",
      "4091\n",
      "4092\n",
      "4093\n",
      "4094\n",
      "4095\n",
      "4096\n",
      "4097\n",
      "4098\n",
      "4099\n",
      "4100\n",
      "4101\n",
      "4102\n",
      "4103\n",
      "4104\n",
      "4105\n",
      "4106\n",
      "4107\n",
      "4108\n",
      "4109\n",
      "4110\n",
      "4111\n",
      "4112\n",
      "4113\n",
      "4114\n",
      "4115\n",
      "4116\n",
      "4117\n",
      "4118\n",
      "4119\n",
      "4120\n",
      "4121\n",
      "4122\n",
      "4123\n",
      "4124\n",
      "4125\n",
      "4126\n",
      "4127\n",
      "4128\n",
      "4129\n",
      "4130\n",
      "4131\n",
      "4132\n",
      "4133\n",
      "4134\n",
      "4135\n",
      "4136\n",
      "4137\n",
      "4138\n",
      "4139\n",
      "4140\n",
      "4141\n",
      "4142\n",
      "4143\n",
      "4144\n",
      "4145\n",
      "4146\n",
      "4147\n",
      "4148\n",
      "4149\n",
      "4150\n",
      "4151\n",
      "4152\n",
      "4153\n",
      "4154\n",
      "4155\n",
      "4156\n",
      "4157\n",
      "4158\n",
      "4159\n",
      "4160\n",
      "4161\n",
      "4162\n",
      "4163\n",
      "4164\n",
      "4165\n",
      "4166\n",
      "4167\n",
      "4168\n",
      "4169\n",
      "4170\n",
      "4171\n",
      "4172\n",
      "4173\n",
      "4174\n",
      "4175\n",
      "4176\n",
      "4177\n",
      "4178\n",
      "4179\n",
      "4180\n",
      "4181\n",
      "4182\n",
      "4183\n",
      "4184\n",
      "4185\n",
      "4186\n",
      "4187\n",
      "4188\n",
      "4189\n",
      "4190\n",
      "4191\n",
      "4192\n",
      "4193\n",
      "4194\n",
      "4195\n",
      "4196\n",
      "4197\n",
      "4198\n",
      "4199\n",
      "4200\n",
      "4201\n",
      "4202\n",
      "4203\n",
      "4204\n",
      "4205\n",
      "4206\n",
      "4207\n",
      "4208\n",
      "4209\n",
      "4210\n",
      "4211\n",
      "4212\n",
      "4213\n",
      "4214\n",
      "4215\n",
      "4216\n",
      "4217\n",
      "4218\n",
      "4219\n",
      "4220\n",
      "4221\n",
      "4222\n",
      "4223\n",
      "4224\n",
      "4225\n",
      "4226\n",
      "4227\n",
      "4228\n",
      "4229\n",
      "4230\n",
      "4231\n",
      "4232\n",
      "4233\n",
      "4234\n",
      "4235\n",
      "4236\n",
      "4237\n",
      "4238\n",
      "4239\n",
      "4240\n",
      "4241\n",
      "4242\n",
      "4243\n",
      "4244\n",
      "4245\n",
      "4246\n",
      "4247\n",
      "4248\n",
      "4249\n",
      "4250\n",
      "4251\n",
      "4252\n",
      "4253\n",
      "4254\n",
      "4255\n",
      "4256\n",
      "4257\n",
      "4258\n",
      "4259\n",
      "4260\n",
      "4261\n",
      "4262\n",
      "4263\n",
      "4264\n",
      "4265\n",
      "4266\n",
      "4267\n",
      "4268\n",
      "4269\n",
      "4270\n",
      "4271\n",
      "4272\n",
      "4273\n",
      "4274\n",
      "4275\n",
      "4276\n",
      "4277\n",
      "4278\n",
      "4279\n",
      "4280\n",
      "4281\n",
      "4282\n",
      "4283\n",
      "4284\n",
      "4285\n",
      "4286\n",
      "4287\n",
      "4288\n",
      "4289\n",
      "4290\n",
      "4291\n",
      "4292\n",
      "4293\n",
      "4294\n",
      "4295\n",
      "4296\n",
      "4297\n",
      "4298\n",
      "4299\n",
      "4300\n",
      "4301\n",
      "4302\n",
      "4303\n",
      "4304\n",
      "4305\n",
      "4306\n",
      "4307\n",
      "4308\n",
      "4309\n",
      "4310\n",
      "4311\n",
      "4312\n",
      "4313\n",
      "4314\n",
      "4315\n",
      "4316\n",
      "4317\n",
      "4318\n",
      "4319\n",
      "4320\n",
      "4321\n",
      "4322\n",
      "4323\n",
      "4324\n",
      "4325\n",
      "4326\n",
      "4327\n",
      "4328\n",
      "4329\n",
      "4330\n",
      "4331\n",
      "4332\n",
      "4333\n",
      "4334\n",
      "4335\n",
      "4336\n",
      "4337\n",
      "4338\n",
      "4339\n",
      "4340\n",
      "4341\n",
      "4342\n",
      "4343\n",
      "4344\n",
      "4345\n",
      "4346\n",
      "4347\n",
      "4348\n",
      "4349\n",
      "4350\n",
      "4351\n",
      "4352\n",
      "4353\n",
      "4354\n",
      "4355\n",
      "4356\n",
      "4357\n",
      "4358\n",
      "4359\n",
      "4360\n",
      "4361\n",
      "4362\n",
      "4363\n",
      "4364\n",
      "4365\n",
      "4366\n",
      "4367\n",
      "4368\n",
      "4369\n",
      "4370\n",
      "4371\n",
      "4372\n",
      "4373\n",
      "4374\n",
      "4375\n",
      "4376\n",
      "4377\n",
      "4378\n",
      "4379\n",
      "4380\n",
      "4381\n",
      "4382\n",
      "4383\n",
      "4384\n",
      "4385\n",
      "4386\n",
      "4387\n",
      "4388\n",
      "4389\n",
      "4390\n",
      "4391\n",
      "4392\n",
      "4393\n",
      "4394\n",
      "4395\n",
      "4396\n",
      "4397\n",
      "4398\n",
      "4399\n",
      "4400\n",
      "4401\n",
      "4402\n",
      "4403\n",
      "4404\n",
      "4405\n",
      "4406\n",
      "4407\n",
      "4408\n",
      "4409\n",
      "4410\n",
      "4411\n",
      "4412\n",
      "4413\n",
      "4414\n",
      "4415\n",
      "4416\n",
      "4417\n",
      "4418\n",
      "4419\n",
      "4420\n",
      "4421\n",
      "4422\n",
      "4423\n",
      "4424\n",
      "4425\n",
      "4426\n",
      "4427\n",
      "4428\n",
      "4429\n",
      "4430\n",
      "4431\n",
      "4432\n",
      "4433\n",
      "4434\n",
      "4435\n",
      "4436\n",
      "4437\n",
      "4438\n",
      "4439\n",
      "4440\n",
      "4441\n",
      "4442\n",
      "4443\n",
      "4444\n",
      "4445\n",
      "4446\n",
      "4447\n",
      "4448\n",
      "4449\n",
      "4450\n",
      "4451\n",
      "4452\n",
      "4453\n",
      "4454\n",
      "4455\n",
      "4456\n",
      "4457\n",
      "4458\n",
      "4459\n",
      "4460\n",
      "4461\n",
      "4462\n",
      "4463\n",
      "4464\n",
      "4465\n",
      "4466\n",
      "4467\n",
      "4468\n",
      "4469\n",
      "4470\n",
      "4471\n",
      "4472\n",
      "4473\n",
      "4474\n",
      "4475\n",
      "4476\n",
      "4477\n",
      "4478\n",
      "4479\n",
      "4480\n",
      "4481\n",
      "4482\n",
      "4483\n",
      "4484\n",
      "4485\n",
      "4486\n",
      "4487\n",
      "4488\n",
      "4489\n",
      "4490\n",
      "4491\n",
      "4492\n",
      "4493\n",
      "4494\n",
      "4495\n",
      "4496\n",
      "4497\n",
      "4498\n",
      "4499\n",
      "4500\n",
      "4501\n",
      "4502\n",
      "4503\n",
      "4504\n",
      "4505\n",
      "4506\n",
      "4507\n",
      "4508\n",
      "4509\n",
      "4510\n",
      "4511\n",
      "4512\n",
      "4513\n",
      "4514\n",
      "4515\n",
      "4516\n",
      "4517\n",
      "4518\n",
      "4519\n",
      "4520\n",
      "4521\n",
      "4522\n",
      "4523\n",
      "4524\n",
      "4525\n",
      "4526\n",
      "4527\n",
      "4528\n",
      "4529\n",
      "4530\n",
      "4531\n",
      "4532\n",
      "4533\n",
      "4534\n",
      "4535\n",
      "4536\n",
      "4537\n",
      "4538\n",
      "4539\n",
      "4540\n",
      "4541\n",
      "4542\n",
      "4543\n",
      "4544\n",
      "4545\n",
      "4546\n",
      "4547\n",
      "4548\n",
      "4549\n",
      "4550\n",
      "4551\n",
      "4552\n",
      "4553\n",
      "4554\n",
      "4555\n",
      "4556\n",
      "4557\n",
      "4558\n",
      "4559\n",
      "4560\n",
      "4561\n",
      "4562\n",
      "4563\n",
      "4564\n",
      "4565\n",
      "4566\n",
      "4567\n",
      "4568\n",
      "4569\n",
      "4570\n",
      "4571\n",
      "4572\n",
      "4573\n",
      "4574\n",
      "4575\n",
      "4576\n",
      "4577\n",
      "4578\n",
      "4579\n",
      "4580\n",
      "4581\n",
      "4582\n",
      "4583\n",
      "4584\n",
      "4585\n",
      "4586\n",
      "4587\n",
      "4588\n",
      "4589\n",
      "4590\n",
      "4591\n",
      "4592\n",
      "4593\n",
      "4594\n",
      "4595\n",
      "4596\n",
      "4597\n",
      "4598\n",
      "4599\n",
      "4600\n",
      "4601\n",
      "4602\n",
      "4603\n",
      "4604\n",
      "4605\n",
      "4606\n",
      "4607\n",
      "4608\n",
      "4609\n",
      "4610\n",
      "4611\n",
      "4612\n",
      "4613\n",
      "4614\n",
      "4615\n",
      "4616\n",
      "4617\n",
      "4618\n",
      "4619\n",
      "4620\n",
      "4621\n",
      "4622\n",
      "4623\n",
      "4624\n",
      "4625\n",
      "4626\n",
      "4627\n",
      "4628\n",
      "4629\n",
      "4630\n",
      "4631\n",
      "4632\n",
      "4633\n",
      "4634\n",
      "4635\n",
      "4636\n",
      "4637\n",
      "4638\n",
      "4639\n",
      "4640\n",
      "4641\n",
      "4642\n",
      "4643\n",
      "4644\n",
      "4645\n",
      "4646\n",
      "4647\n",
      "4648\n",
      "4649\n",
      "4650\n",
      "4651\n",
      "4652\n",
      "4653\n",
      "4654\n",
      "4655\n",
      "4656\n",
      "4657\n",
      "4658\n",
      "4659\n",
      "4660\n",
      "4661\n",
      "4662\n",
      "4663\n",
      "4664\n",
      "4665\n",
      "4666\n",
      "4667\n",
      "4668\n",
      "4669\n",
      "4670\n",
      "4671\n",
      "4672\n",
      "4673\n",
      "4674\n",
      "4675\n",
      "4676\n",
      "4677\n",
      "4678\n",
      "4679\n",
      "4680\n",
      "4681\n",
      "4682\n",
      "4683\n",
      "4684\n",
      "4685\n",
      "4686\n",
      "4687\n",
      "4688\n",
      "4689\n",
      "4690\n",
      "4691\n",
      "4692\n",
      "4693\n",
      "4694\n",
      "4695\n",
      "4696\n",
      "4697\n",
      "4698\n",
      "4699\n",
      "4700\n",
      "4701\n",
      "4702\n",
      "4703\n",
      "4704\n",
      "4705\n",
      "4706\n",
      "4707\n",
      "4708\n",
      "4709\n",
      "4710\n",
      "4711\n",
      "4712\n",
      "4713\n",
      "4714\n",
      "4715\n",
      "4716\n",
      "4717\n",
      "4718\n",
      "4719\n",
      "4720\n",
      "4721\n",
      "4722\n",
      "4723\n",
      "4724\n",
      "4725\n",
      "4726\n",
      "4727\n",
      "4728\n",
      "4729\n",
      "4730\n",
      "4731\n",
      "4732\n",
      "4733\n",
      "4734\n",
      "4735\n",
      "4736\n",
      "4737\n",
      "4738\n",
      "4739\n",
      "4740\n",
      "4741\n",
      "4742\n",
      "4743\n",
      "4744\n",
      "4745\n",
      "4746\n",
      "4747\n",
      "4748\n",
      "4749\n",
      "4750\n",
      "4751\n",
      "4752\n",
      "4753\n",
      "4754\n",
      "4755\n",
      "4756\n",
      "4757\n",
      "4758\n",
      "4759\n",
      "4760\n",
      "4761\n",
      "4762\n",
      "4763\n",
      "4764\n",
      "4765\n",
      "4766\n",
      "4767\n",
      "4768\n",
      "4769\n",
      "4770\n",
      "4771\n",
      "4772\n",
      "4773\n",
      "4774\n",
      "4775\n",
      "4776\n",
      "4777\n",
      "4778\n",
      "4779\n",
      "4780\n",
      "4781\n",
      "4782\n",
      "4783\n",
      "4784\n",
      "4785\n",
      "4786\n",
      "4787\n",
      "4788\n",
      "4789\n",
      "4790\n",
      "4791\n",
      "4792\n",
      "4793\n",
      "4794\n",
      "4795\n",
      "4796\n",
      "4797\n",
      "4798\n",
      "4799\n",
      "4800\n",
      "4801\n",
      "4802\n",
      "4803\n",
      "4804\n",
      "4805\n",
      "4806\n",
      "4807\n",
      "4808\n",
      "4809\n",
      "4810\n",
      "4811\n",
      "4812\n",
      "4813\n",
      "4814\n",
      "4815\n",
      "4816\n",
      "4817\n",
      "4818\n",
      "4819\n",
      "4820\n",
      "4821\n",
      "4822\n",
      "4823\n",
      "4824\n",
      "4825\n",
      "4826\n",
      "4827\n",
      "4828\n",
      "4829\n",
      "4830\n",
      "4831\n",
      "4832\n",
      "4833\n",
      "4834\n",
      "4835\n",
      "4836\n",
      "4837\n",
      "4838\n",
      "4839\n",
      "4840\n",
      "4841\n",
      "4842\n",
      "4843\n",
      "4844\n",
      "4845\n",
      "4846\n",
      "4847\n",
      "4848\n",
      "4849\n",
      "4850\n",
      "4851\n",
      "4852\n",
      "4853\n",
      "4854\n",
      "4855\n",
      "4856\n",
      "4857\n",
      "4858\n",
      "4859\n",
      "4860\n",
      "4861\n",
      "4862\n",
      "4863\n",
      "4864\n",
      "4865\n",
      "4866\n",
      "4867\n",
      "4868\n",
      "4869\n",
      "4870\n",
      "4871\n",
      "4872\n",
      "4873\n",
      "4874\n",
      "4875\n",
      "4876\n",
      "4877\n",
      "4878\n",
      "4879\n",
      "4880\n",
      "4881\n",
      "4882\n",
      "4883\n",
      "4884\n",
      "4885\n",
      "4886\n",
      "4887\n",
      "4888\n",
      "4889\n",
      "4890\n",
      "4891\n",
      "4892\n",
      "4893\n",
      "4894\n",
      "4895\n",
      "4896\n",
      "4897\n",
      "4898\n",
      "4899\n",
      "4900\n",
      "4901\n",
      "4902\n",
      "4903\n",
      "4904\n",
      "4905\n",
      "4906\n",
      "4907\n",
      "4908\n",
      "4909\n",
      "4910\n",
      "4911\n",
      "4912\n",
      "4913\n",
      "4914\n",
      "4915\n",
      "4916\n",
      "4917\n",
      "4918\n",
      "4919\n",
      "4920\n",
      "4921\n",
      "4922\n",
      "4923\n",
      "4924\n",
      "4925\n",
      "4926\n",
      "4927\n",
      "4928\n",
      "4929\n",
      "4930\n",
      "4931\n",
      "4932\n",
      "4933\n",
      "4934\n",
      "4935\n",
      "4936\n",
      "4937\n",
      "4938\n",
      "4939\n",
      "4940\n",
      "4941\n",
      "4942\n",
      "4943\n",
      "4944\n",
      "4945\n",
      "4946\n",
      "4947\n",
      "4948\n",
      "4949\n",
      "4950\n",
      "4951\n",
      "4952\n",
      "4953\n",
      "4954\n",
      "4955\n",
      "4956\n",
      "4957\n",
      "4958\n",
      "4959\n",
      "4960\n",
      "4961\n",
      "4962\n",
      "4963\n",
      "4964\n",
      "4965\n",
      "4966\n",
      "4967\n",
      "4968\n",
      "4969\n",
      "4970\n",
      "4971\n",
      "4972\n",
      "4973\n",
      "4974\n",
      "4975\n",
      "4976\n",
      "4977\n",
      "4978\n",
      "4979\n",
      "4980\n",
      "4981\n",
      "4982\n",
      "4983\n",
      "4984\n",
      "4985\n",
      "4986\n",
      "4987\n",
      "4988\n",
      "4989\n",
      "4990\n",
      "4991\n",
      "4992\n",
      "4993\n",
      "4994\n",
      "4995\n",
      "4996\n",
      "4997\n",
      "4998\n",
      "4999\n",
      "5000\n",
      "5001\n",
      "5002\n",
      "5003\n",
      "5004\n",
      "5005\n",
      "5006\n",
      "5007\n",
      "5008\n",
      "5009\n",
      "5010\n",
      "5011\n",
      "5012\n",
      "5013\n",
      "5014\n",
      "5015\n",
      "5016\n",
      "5017\n",
      "5018\n",
      "5019\n",
      "5020\n",
      "5021\n",
      "5022\n",
      "5023\n",
      "5024\n",
      "5025\n",
      "5026\n",
      "5027\n",
      "5028\n",
      "5029\n",
      "5030\n",
      "5031\n",
      "5032\n",
      "5033\n",
      "5034\n",
      "5035\n",
      "5036\n",
      "5037\n",
      "5038\n",
      "5039\n",
      "5040\n",
      "5041\n",
      "5042\n",
      "5043\n",
      "5044\n",
      "5045\n",
      "5046\n",
      "5047\n",
      "5048\n",
      "5049\n",
      "5050\n",
      "5051\n",
      "5052\n",
      "5053\n",
      "5054\n",
      "5055\n",
      "5056\n",
      "5057\n",
      "5058\n",
      "5059\n",
      "5060\n",
      "5061\n",
      "5062\n",
      "5063\n",
      "5064\n",
      "5065\n",
      "5066\n",
      "5067\n",
      "5068\n",
      "5069\n",
      "5070\n",
      "5071\n",
      "5072\n",
      "5073\n",
      "5074\n",
      "5075\n",
      "5076\n",
      "5077\n",
      "5078\n",
      "5079\n",
      "5080\n",
      "5081\n",
      "5082\n",
      "5083\n",
      "5084\n",
      "5085\n",
      "5086\n",
      "5087\n",
      "5088\n",
      "5089\n",
      "5090\n",
      "5091\n",
      "5092\n",
      "5093\n",
      "5094\n",
      "5095\n",
      "5096\n",
      "5097\n",
      "5098\n",
      "5099\n",
      "5100\n",
      "5101\n",
      "5102\n",
      "5103\n",
      "5104\n",
      "5105\n",
      "5106\n",
      "5107\n",
      "5108\n",
      "5109\n",
      "5110\n",
      "5111\n",
      "5112\n",
      "5113\n",
      "5114\n",
      "5115\n",
      "5116\n",
      "5117\n",
      "5118\n",
      "5119\n",
      "5120\n",
      "5121\n",
      "5122\n",
      "5123\n",
      "5124\n",
      "5125\n",
      "5126\n",
      "5127\n",
      "5128\n",
      "5129\n",
      "5130\n",
      "5131\n",
      "5132\n",
      "5133\n",
      "5134\n",
      "5135\n",
      "5136\n",
      "5137\n",
      "5138\n",
      "5139\n",
      "5140\n",
      "5141\n",
      "5142\n",
      "5143\n",
      "5144\n",
      "5145\n",
      "5146\n",
      "5147\n",
      "5148\n",
      "5149\n",
      "5150\n",
      "5151\n",
      "5152\n",
      "5153\n",
      "5154\n",
      "5155\n",
      "5156\n",
      "5157\n",
      "5158\n",
      "5159\n",
      "5160\n",
      "5161\n",
      "5162\n",
      "5163\n",
      "5164\n",
      "5165\n",
      "5166\n",
      "5167\n",
      "5168\n",
      "5169\n",
      "5170\n",
      "5171\n",
      "5172\n",
      "5173\n",
      "5174\n",
      "5175\n",
      "5176\n",
      "5177\n",
      "5178\n",
      "5179\n",
      "5180\n",
      "5181\n",
      "5182\n",
      "5183\n",
      "5184\n",
      "5185\n",
      "5186\n",
      "5187\n",
      "5188\n",
      "5189\n",
      "5190\n",
      "5191\n",
      "5192\n",
      "5193\n",
      "5194\n",
      "5195\n",
      "5196\n",
      "5197\n",
      "5198\n",
      "5199\n",
      "5200\n",
      "5201\n",
      "5202\n",
      "5203\n",
      "5204\n",
      "5205\n",
      "5206\n",
      "5207\n",
      "5208\n",
      "5209\n",
      "5210\n",
      "5211\n",
      "5212\n",
      "5213\n",
      "5214\n",
      "5215\n",
      "5216\n",
      "5217\n",
      "5218\n",
      "5219\n",
      "5220\n",
      "5221\n",
      "5222\n",
      "5223\n",
      "5224\n",
      "5225\n",
      "5226\n",
      "5227\n",
      "5228\n",
      "5229\n",
      "5230\n",
      "5231\n",
      "5232\n",
      "5233\n",
      "5234\n",
      "5235\n",
      "5236\n",
      "5237\n",
      "5238\n",
      "5239\n",
      "5240\n",
      "5241\n",
      "5242\n",
      "5243\n",
      "5244\n",
      "5245\n",
      "5246\n",
      "5247\n",
      "5248\n",
      "5249\n",
      "5250\n",
      "5251\n",
      "5252\n",
      "5253\n",
      "5254\n",
      "5255\n",
      "5256\n",
      "5257\n",
      "5258\n",
      "5259\n",
      "5260\n",
      "5261\n",
      "5262\n",
      "5263\n",
      "5264\n",
      "5265\n",
      "5266\n",
      "5267\n",
      "5268\n",
      "5269\n",
      "5270\n",
      "5271\n",
      "5272\n",
      "5273\n",
      "5274\n",
      "5275\n",
      "5276\n",
      "5277\n",
      "5278\n",
      "5279\n",
      "5280\n",
      "5281\n",
      "5282\n",
      "5283\n",
      "5284\n",
      "5285\n",
      "5286\n",
      "5287\n",
      "5288\n",
      "5289\n",
      "5290\n",
      "5291\n",
      "5292\n",
      "5293\n",
      "5294\n",
      "5295\n",
      "5296\n",
      "5297\n",
      "5298\n",
      "5299\n",
      "5300\n",
      "5301\n",
      "5302\n",
      "5303\n",
      "5304\n",
      "5305\n",
      "5306\n",
      "5307\n",
      "5308\n",
      "5309\n",
      "5310\n",
      "5311\n",
      "5312\n",
      "5313\n",
      "5314\n",
      "5315\n",
      "5316\n",
      "5317\n",
      "5318\n",
      "5319\n",
      "5320\n",
      "5321\n",
      "5322\n",
      "5323\n",
      "5324\n",
      "5325\n",
      "5326\n",
      "5327\n",
      "5328\n",
      "5329\n",
      "5330\n",
      "5331\n",
      "5332\n",
      "5333\n",
      "5334\n",
      "5335\n",
      "5336\n",
      "5337\n",
      "5338\n",
      "5339\n",
      "5340\n",
      "5341\n",
      "5342\n",
      "5343\n",
      "5344\n",
      "5345\n",
      "5346\n",
      "5347\n",
      "5348\n",
      "5349\n",
      "5350\n",
      "5351\n",
      "5352\n",
      "5353\n",
      "5354\n",
      "5355\n",
      "5356\n",
      "5357\n",
      "5358\n",
      "5359\n",
      "5360\n",
      "5361\n",
      "5362\n",
      "5363\n",
      "5364\n",
      "5365\n",
      "5366\n",
      "5367\n",
      "5368\n",
      "5369\n",
      "5370\n",
      "5371\n",
      "5372\n",
      "5373\n",
      "5374\n",
      "5375\n",
      "5376\n",
      "5377\n",
      "5378\n",
      "5379\n",
      "5380\n",
      "5381\n",
      "5382\n",
      "5383\n",
      "5384\n",
      "5385\n",
      "5386\n",
      "5387\n",
      "5388\n",
      "5389\n",
      "5390\n",
      "5391\n",
      "5392\n",
      "5393\n",
      "5394\n",
      "5395\n",
      "5396\n",
      "5397\n",
      "5398\n",
      "5399\n",
      "5400\n",
      "5401\n",
      "5402\n",
      "5403\n",
      "5404\n",
      "5405\n",
      "5406\n",
      "5407\n",
      "5408\n",
      "5409\n",
      "5410\n",
      "5411\n",
      "5412\n",
      "5413\n",
      "5414\n",
      "5415\n",
      "5416\n",
      "5417\n",
      "5418\n",
      "5419\n",
      "5420\n",
      "5421\n",
      "5422\n",
      "5423\n",
      "5424\n",
      "5425\n",
      "5426\n",
      "5427\n",
      "5428\n",
      "5429\n",
      "5430\n",
      "5431\n",
      "5432\n",
      "5433\n",
      "5434\n",
      "5435\n",
      "5436\n",
      "5437\n",
      "5438\n",
      "5439\n",
      "5440\n",
      "5441\n",
      "5442\n",
      "5443\n",
      "5444\n",
      "5445\n",
      "5446\n",
      "5447\n",
      "5448\n",
      "5449\n",
      "5450\n",
      "5451\n",
      "5452\n",
      "5453\n",
      "5454\n",
      "5455\n",
      "5456\n",
      "5457\n",
      "5458\n",
      "5459\n",
      "5460\n",
      "5461\n",
      "5462\n",
      "5463\n",
      "5464\n",
      "5465\n",
      "5466\n",
      "5467\n",
      "5468\n",
      "5469\n",
      "5470\n",
      "5471\n",
      "5472\n",
      "5473\n",
      "5474\n",
      "5475\n",
      "5476\n",
      "5477\n",
      "5478\n",
      "5479\n",
      "5480\n",
      "5481\n",
      "5482\n",
      "5483\n",
      "5484\n",
      "5485\n",
      "5486\n",
      "5487\n",
      "5488\n",
      "5489\n",
      "5490\n",
      "5491\n",
      "5492\n",
      "5493\n",
      "5494\n",
      "5495\n",
      "5496\n",
      "5497\n",
      "5498\n",
      "5499\n",
      "5500\n",
      "5501\n",
      "5502\n",
      "5503\n",
      "5504\n",
      "5505\n",
      "5506\n",
      "5507\n",
      "5508\n",
      "5509\n",
      "5510\n",
      "5511\n",
      "5512\n",
      "5513\n",
      "5514\n",
      "5515\n",
      "5516\n",
      "5517\n",
      "5518\n",
      "5519\n",
      "5520\n",
      "5521\n",
      "5522\n",
      "5523\n",
      "5524\n",
      "5525\n",
      "5526\n",
      "5527\n",
      "5528\n",
      "5529\n",
      "5530\n",
      "5531\n",
      "5532\n",
      "5533\n",
      "5534\n",
      "5535\n",
      "5536\n",
      "5537\n",
      "5538\n",
      "5539\n",
      "5540\n",
      "5541\n",
      "5542\n",
      "5543\n",
      "5544\n",
      "5545\n",
      "5546\n",
      "5547\n",
      "5548\n",
      "5549\n",
      "5550\n",
      "5551\n",
      "5552\n",
      "5553\n",
      "5554\n",
      "5555\n",
      "5556\n",
      "5557\n",
      "5558\n",
      "5559\n",
      "5560\n",
      "5561\n",
      "5562\n",
      "5563\n",
      "5564\n",
      "5565\n",
      "5566\n",
      "5567\n",
      "5568\n",
      "5569\n",
      "5570\n",
      "5571\n",
      "5572\n",
      "5573\n",
      "5574\n",
      "5575\n",
      "5576\n",
      "5577\n",
      "5578\n",
      "5579\n",
      "5580\n",
      "5581\n",
      "5582\n",
      "5583\n",
      "5584\n",
      "5585\n",
      "5586\n",
      "5587\n",
      "5588\n",
      "5589\n",
      "5590\n",
      "5591\n",
      "5592\n",
      "5593\n",
      "5594\n",
      "5595\n",
      "5596\n",
      "5597\n",
      "5598\n",
      "5599\n",
      "5600\n",
      "5601\n",
      "5602\n",
      "5603\n",
      "5604\n",
      "5605\n",
      "5606\n",
      "5607\n",
      "5608\n",
      "5609\n",
      "5610\n",
      "5611\n",
      "5612\n",
      "5613\n",
      "5614\n",
      "5615\n",
      "5616\n",
      "5617\n",
      "5618\n",
      "5619\n",
      "5620\n",
      "5621\n",
      "5622\n",
      "5623\n",
      "5624\n",
      "5625\n",
      "5626\n",
      "5627\n",
      "5628\n",
      "5629\n",
      "5630\n",
      "5631\n",
      "5632\n",
      "5633\n",
      "5634\n",
      "5635\n",
      "5636\n",
      "5637\n",
      "5638\n",
      "5639\n",
      "5640\n",
      "5641\n",
      "5642\n",
      "5643\n",
      "5644\n",
      "5645\n",
      "5646\n",
      "5647\n",
      "5648\n",
      "5649\n",
      "5650\n",
      "5651\n",
      "5652\n",
      "5653\n",
      "5654\n",
      "5655\n",
      "5656\n",
      "5657\n",
      "5658\n",
      "5659\n",
      "5660\n",
      "5661\n",
      "5662\n",
      "5663\n",
      "5664\n",
      "5665\n",
      "5666\n",
      "5667\n",
      "5668\n",
      "5669\n",
      "5670\n",
      "5671\n",
      "5672\n",
      "5673\n",
      "5674\n",
      "5675\n",
      "5676\n",
      "5677\n",
      "5678\n",
      "5679\n",
      "5680\n",
      "5681\n",
      "5682\n",
      "5683\n",
      "5684\n",
      "5685\n",
      "5686\n",
      "5687\n",
      "5688\n",
      "5689\n",
      "5690\n",
      "5691\n",
      "5692\n",
      "5693\n",
      "5694\n",
      "5695\n",
      "5696\n",
      "5697\n",
      "5698\n",
      "5699\n",
      "5700\n",
      "5701\n",
      "5702\n",
      "5703\n",
      "5704\n",
      "5705\n",
      "5706\n",
      "5707\n",
      "5708\n",
      "5709\n",
      "5710\n",
      "5711\n",
      "5712\n",
      "5713\n",
      "5714\n",
      "5715\n",
      "5716\n",
      "5717\n",
      "5718\n",
      "5719\n",
      "5720\n",
      "5721\n",
      "5722\n",
      "5723\n",
      "5724\n",
      "5725\n",
      "5726\n",
      "5727\n",
      "5728\n",
      "5729\n",
      "5730\n",
      "5731\n",
      "5732\n",
      "5733\n",
      "5734\n",
      "5735\n",
      "5736\n",
      "5737\n",
      "5738\n",
      "5739\n",
      "5740\n",
      "5741\n",
      "5742\n",
      "5743\n",
      "5744\n",
      "5745\n",
      "5746\n",
      "5747\n",
      "5748\n",
      "5749\n",
      "5750\n",
      "5751\n",
      "5752\n",
      "5753\n",
      "5754\n",
      "5755\n",
      "5756\n",
      "5757\n",
      "5758\n",
      "5759\n",
      "5760\n",
      "5761\n",
      "5762\n",
      "5763\n",
      "5764\n",
      "5765\n",
      "5766\n",
      "5767\n",
      "5768\n",
      "5769\n",
      "5770\n",
      "5771\n",
      "5772\n",
      "5773\n",
      "5774\n",
      "5775\n",
      "5776\n",
      "5777\n",
      "5778\n",
      "5779\n",
      "5780\n",
      "5781\n",
      "5782\n",
      "5783\n",
      "5784\n",
      "5785\n",
      "5786\n",
      "5787\n",
      "5788\n",
      "5789\n",
      "5790\n",
      "5791\n",
      "5792\n",
      "5793\n",
      "5794\n",
      "5795\n",
      "5796\n",
      "5797\n",
      "5798\n",
      "5799\n",
      "5800\n",
      "5801\n",
      "5802\n",
      "5803\n",
      "5804\n",
      "5805\n",
      "5806\n",
      "5807\n",
      "5808\n",
      "5809\n",
      "5810\n",
      "5811\n",
      "5812\n",
      "5813\n",
      "5814\n",
      "5815\n",
      "5816\n",
      "5817\n",
      "5818\n",
      "5819\n",
      "5820\n",
      "5821\n",
      "5822\n",
      "5823\n",
      "5824\n",
      "5825\n",
      "5826\n",
      "5827\n",
      "5828\n",
      "5829\n",
      "5830\n",
      "5831\n",
      "5832\n",
      "5833\n",
      "5834\n",
      "5835\n",
      "5836\n",
      "5837\n",
      "5838\n",
      "5839\n",
      "5840\n",
      "5841\n",
      "5842\n",
      "5843\n",
      "5844\n",
      "5845\n",
      "5846\n",
      "5847\n",
      "5848\n",
      "5849\n",
      "5850\n",
      "5851\n",
      "5852\n",
      "5853\n",
      "5854\n",
      "5855\n",
      "5856\n",
      "5857\n",
      "5858\n",
      "5859\n",
      "5860\n",
      "5861\n",
      "5862\n",
      "5863\n",
      "5864\n",
      "5865\n",
      "5866\n",
      "5867\n",
      "5868\n",
      "5869\n",
      "5870\n",
      "5871\n",
      "5872\n",
      "5873\n",
      "5874\n",
      "5875\n",
      "5876\n",
      "5877\n",
      "5878\n",
      "5879\n",
      "5880\n",
      "5881\n",
      "5882\n",
      "5883\n",
      "5884\n",
      "5885\n",
      "5886\n",
      "5887\n",
      "5888\n",
      "5889\n",
      "5890\n",
      "5891\n",
      "5892\n",
      "5893\n",
      "5894\n",
      "5895\n",
      "5896\n",
      "5897\n",
      "5898\n",
      "5899\n",
      "5900\n",
      "5901\n",
      "5902\n",
      "5903\n",
      "5904\n",
      "5905\n",
      "5906\n",
      "5907\n",
      "5908\n",
      "5909\n",
      "5910\n",
      "5911\n",
      "5912\n",
      "5913\n",
      "5914\n",
      "5915\n",
      "5916\n",
      "5917\n",
      "5918\n",
      "5919\n",
      "5920\n",
      "5921\n",
      "5922\n",
      "5923\n",
      "5924\n",
      "5925\n",
      "5926\n",
      "5927\n",
      "5928\n",
      "5929\n",
      "5930\n",
      "5931\n",
      "5932\n",
      "5933\n",
      "5934\n",
      "5935\n",
      "5936\n",
      "5937\n",
      "5938\n",
      "5939\n",
      "5940\n",
      "5941\n",
      "5942\n",
      "5943\n",
      "5944\n",
      "5945\n",
      "5946\n",
      "5947\n",
      "5948\n",
      "5949\n",
      "5950\n",
      "5951\n",
      "5952\n",
      "5953\n",
      "5954\n",
      "5955\n",
      "5956\n",
      "5957\n",
      "5958\n",
      "5959\n",
      "5960\n",
      "5961\n",
      "5962\n",
      "5963\n",
      "5964\n",
      "5965\n",
      "5966\n",
      "5967\n",
      "5968\n",
      "5969\n",
      "5970\n",
      "5971\n",
      "5972\n",
      "5973\n",
      "5974\n",
      "5975\n",
      "5976\n",
      "5977\n",
      "5978\n",
      "5979\n",
      "5980\n",
      "5981\n",
      "5982\n",
      "5983\n",
      "5984\n",
      "5985\n",
      "5986\n",
      "5987\n",
      "5988\n",
      "5989\n",
      "5990\n",
      "5991\n",
      "5992\n",
      "5993\n",
      "5994\n",
      "5995\n",
      "5996\n",
      "5997\n",
      "5998\n",
      "5999\n",
      "6000\n",
      "6001\n",
      "6002\n",
      "6003\n",
      "6004\n",
      "6005\n",
      "6006\n",
      "6007\n",
      "6008\n",
      "6009\n",
      "6010\n",
      "6011\n",
      "6012\n",
      "6013\n",
      "6014\n",
      "6015\n",
      "6016\n",
      "6017\n",
      "6018\n",
      "6019\n",
      "6020\n",
      "6021\n",
      "6022\n",
      "6023\n",
      "6024\n",
      "6025\n",
      "6026\n",
      "6027\n",
      "6028\n",
      "6029\n",
      "6030\n",
      "6031\n",
      "6032\n",
      "6033\n",
      "6034\n",
      "6035\n",
      "6036\n",
      "6037\n",
      "6038\n",
      "6039\n",
      "6040\n",
      "6041\n",
      "6042\n",
      "6043\n",
      "6044\n",
      "6045\n",
      "6046\n",
      "6047\n",
      "6048\n",
      "6049\n",
      "6050\n",
      "6051\n",
      "6052\n",
      "6053\n",
      "6054\n",
      "6055\n",
      "6056\n",
      "6057\n",
      "6058\n",
      "6059\n",
      "6060\n",
      "6061\n",
      "6062\n",
      "6063\n",
      "6064\n",
      "6065\n",
      "6066\n",
      "6067\n",
      "6068\n",
      "6069\n",
      "6070\n",
      "6071\n",
      "6072\n",
      "6073\n",
      "6074\n",
      "6075\n",
      "6076\n",
      "6077\n",
      "6078\n",
      "6079\n",
      "6080\n",
      "6081\n",
      "6082\n",
      "6083\n",
      "6084\n",
      "6085\n",
      "6086\n",
      "6087\n",
      "6088\n",
      "6089\n",
      "6090\n",
      "6091\n",
      "6092\n",
      "6093\n",
      "6094\n",
      "6095\n",
      "6096\n",
      "6097\n",
      "6098\n",
      "6099\n",
      "6100\n",
      "6101\n",
      "6102\n",
      "6103\n",
      "6104\n",
      "6105\n",
      "6106\n",
      "6107\n",
      "6108\n",
      "6109\n",
      "6110\n",
      "6111\n",
      "6112\n",
      "6113\n",
      "6114\n",
      "6115\n",
      "6116\n",
      "6117\n",
      "6118\n",
      "6119\n",
      "6120\n",
      "6121\n",
      "6122\n",
      "6123\n",
      "6124\n",
      "6125\n",
      "6126\n",
      "6127\n",
      "6128\n",
      "6129\n",
      "6130\n",
      "6131\n",
      "6132\n",
      "6133\n",
      "6134\n",
      "6135\n",
      "6136\n",
      "6137\n",
      "6138\n",
      "6139\n",
      "6140\n",
      "6141\n",
      "6142\n",
      "6143\n",
      "6144\n",
      "6145\n",
      "6146\n",
      "6147\n",
      "6148\n",
      "6149\n",
      "6150\n",
      "6151\n",
      "6152\n",
      "6153\n",
      "6154\n",
      "6155\n",
      "6156\n",
      "6157\n",
      "6158\n",
      "6159\n",
      "6160\n",
      "6161\n",
      "6162\n",
      "6163\n",
      "6164\n",
      "6165\n",
      "6166\n",
      "6167\n",
      "6168\n",
      "6169\n",
      "6170\n",
      "6171\n",
      "6172\n",
      "6173\n",
      "6174\n",
      "6175\n",
      "6176\n",
      "6177\n",
      "6178\n",
      "6179\n",
      "6180\n",
      "6181\n",
      "6182\n",
      "6183\n",
      "6184\n",
      "6185\n",
      "6186\n",
      "6187\n",
      "6188\n",
      "6189\n",
      "6190\n",
      "6191\n",
      "6192\n",
      "6193\n",
      "6194\n",
      "6195\n",
      "6196\n",
      "6197\n",
      "6198\n",
      "6199\n",
      "6200\n",
      "6201\n",
      "6202\n",
      "6203\n",
      "6204\n",
      "6205\n",
      "6206\n",
      "6207\n",
      "6208\n",
      "6209\n",
      "6210\n",
      "6211\n",
      "6212\n",
      "6213\n",
      "6214\n",
      "6215\n",
      "6216\n",
      "6217\n",
      "6218\n",
      "6219\n",
      "6220\n",
      "6221\n",
      "6222\n",
      "6223\n",
      "6224\n",
      "6225\n",
      "6226\n",
      "6227\n",
      "6228\n",
      "6229\n",
      "6230\n",
      "6231\n",
      "6232\n",
      "6233\n",
      "6234\n",
      "6235\n",
      "6236\n",
      "6237\n",
      "6238\n",
      "6239\n",
      "6240\n",
      "6241\n",
      "6242\n",
      "6243\n",
      "6244\n",
      "6245\n",
      "6246\n",
      "6247\n",
      "6248\n",
      "6249\n",
      "6250\n",
      "6251\n",
      "6252\n",
      "6253\n",
      "6254\n",
      "6255\n",
      "6256\n",
      "6257\n",
      "6258\n",
      "6259\n",
      "6260\n",
      "6261\n",
      "6262\n",
      "6263\n",
      "6264\n",
      "6265\n",
      "6266\n",
      "6267\n",
      "6268\n",
      "6269\n",
      "6270\n",
      "6271\n",
      "6272\n",
      "6273\n",
      "6274\n",
      "6275\n",
      "6276\n",
      "6277\n",
      "6278\n",
      "6279\n",
      "6280\n",
      "6281\n",
      "6282\n",
      "6283\n",
      "6284\n",
      "6285\n",
      "6286\n",
      "6287\n",
      "6288\n",
      "6289\n",
      "6290\n",
      "6291\n",
      "6292\n",
      "6293\n",
      "6294\n",
      "6295\n",
      "6296\n",
      "6297\n",
      "6298\n",
      "6299\n",
      "6300\n",
      "6301\n",
      "6302\n",
      "6303\n",
      "6304\n",
      "6305\n",
      "6306\n",
      "6307\n",
      "6308\n",
      "6309\n",
      "6310\n",
      "6311\n",
      "6312\n",
      "6313\n",
      "6314\n",
      "6315\n",
      "6316\n",
      "6317\n",
      "6318\n",
      "6319\n",
      "6320\n",
      "6321\n",
      "6322\n",
      "6323\n",
      "6324\n",
      "6325\n",
      "6326\n",
      "6327\n",
      "6328\n",
      "6329\n",
      "6330\n",
      "6331\n",
      "6332\n",
      "6333\n",
      "6334\n",
      "6335\n",
      "6336\n",
      "6337\n",
      "6338\n",
      "6339\n",
      "6340\n",
      "6341\n",
      "6342\n",
      "6343\n",
      "6344\n",
      "6345\n",
      "6346\n",
      "6347\n",
      "6348\n",
      "6349\n",
      "6350\n",
      "6351\n",
      "6352\n",
      "6353\n",
      "6354\n",
      "6355\n",
      "6356\n",
      "6357\n",
      "6358\n",
      "6359\n",
      "6360\n",
      "6361\n",
      "6362\n",
      "6363\n",
      "6364\n",
      "6365\n",
      "6366\n",
      "6367\n",
      "6368\n",
      "6369\n",
      "6370\n",
      "6371\n",
      "6372\n",
      "6373\n",
      "6374\n",
      "6375\n",
      "6376\n",
      "6377\n",
      "6378\n",
      "6379\n",
      "6380\n",
      "6381\n",
      "6382\n",
      "6383\n",
      "6384\n",
      "6385\n",
      "6386\n",
      "6387\n",
      "6388\n",
      "6389\n",
      "6390\n",
      "6391\n",
      "6392\n",
      "6393\n",
      "6394\n",
      "6395\n",
      "6396\n",
      "6397\n",
      "6398\n",
      "6399\n",
      "6400\n",
      "6401\n",
      "6402\n",
      "6403\n",
      "6404\n",
      "6405\n",
      "6406\n",
      "6407\n",
      "6408\n",
      "6409\n",
      "6410\n",
      "6411\n",
      "6412\n",
      "6413\n",
      "6414\n",
      "6415\n",
      "6416\n",
      "6417\n",
      "6418\n",
      "6419\n",
      "6420\n",
      "6421\n",
      "6422\n",
      "6423\n",
      "6424\n",
      "6425\n",
      "6426\n",
      "6427\n",
      "6428\n",
      "6429\n",
      "6430\n",
      "6431\n",
      "6432\n",
      "6433\n",
      "6434\n",
      "6435\n",
      "6436\n",
      "6437\n",
      "6438\n",
      "6439\n",
      "6440\n",
      "6441\n",
      "6442\n",
      "6443\n",
      "6444\n",
      "6445\n",
      "6446\n",
      "6447\n",
      "6448\n",
      "6449\n",
      "6450\n",
      "6451\n",
      "6452\n",
      "6453\n",
      "6454\n",
      "6455\n",
      "6456\n",
      "6457\n",
      "6458\n",
      "6459\n",
      "6460\n",
      "6461\n",
      "6462\n",
      "6463\n",
      "6464\n",
      "6465\n",
      "6466\n",
      "6467\n",
      "6468\n",
      "6469\n",
      "6470\n",
      "6471\n",
      "6472\n",
      "6473\n",
      "6474\n",
      "6475\n",
      "6476\n",
      "6477\n",
      "6478\n",
      "6479\n",
      "6480\n",
      "6481\n",
      "6482\n",
      "6483\n",
      "6484\n",
      "6485\n",
      "6486\n",
      "6487\n",
      "6488\n",
      "6489\n",
      "6490\n",
      "6491\n",
      "6492\n",
      "6493\n",
      "6494\n",
      "6495\n",
      "6496\n",
      "6497\n",
      "6498\n",
      "6499\n",
      "6500\n",
      "6501\n",
      "6502\n",
      "6503\n",
      "6504\n",
      "6505\n",
      "6506\n",
      "6507\n",
      "6508\n",
      "6509\n",
      "6510\n",
      "6511\n",
      "6512\n",
      "6513\n",
      "6514\n",
      "6515\n",
      "6516\n",
      "6517\n",
      "6518\n",
      "6519\n",
      "6520\n",
      "6521\n",
      "6522\n",
      "6523\n",
      "6524\n",
      "6525\n",
      "6526\n",
      "6527\n",
      "6528\n",
      "6529\n",
      "6530\n",
      "6531\n",
      "6532\n",
      "6533\n",
      "6534\n",
      "6535\n",
      "6536\n",
      "6537\n",
      "6538\n",
      "6539\n",
      "6540\n",
      "6541\n",
      "6542\n",
      "6543\n",
      "6544\n",
      "6545\n",
      "6546\n",
      "6547\n",
      "6548\n",
      "6549\n",
      "6550\n",
      "6551\n",
      "6552\n",
      "6553\n",
      "6554\n",
      "6555\n",
      "6556\n",
      "6557\n",
      "6558\n",
      "6559\n",
      "6560\n",
      "6561\n",
      "6562\n",
      "6563\n",
      "6564\n",
      "6565\n",
      "6566\n",
      "6567\n",
      "6568\n",
      "6569\n",
      "6570\n",
      "6571\n",
      "6572\n",
      "6573\n",
      "6574\n",
      "6575\n",
      "6576\n",
      "6577\n",
      "6578\n",
      "6579\n",
      "6580\n",
      "6581\n",
      "6582\n",
      "6583\n",
      "6584\n",
      "6585\n",
      "6586\n",
      "6587\n",
      "6588\n",
      "6589\n",
      "6590\n",
      "6591\n",
      "6592\n",
      "6593\n",
      "6594\n",
      "6595\n",
      "6596\n",
      "6597\n",
      "6598\n",
      "6599\n",
      "6600\n",
      "6601\n",
      "6602\n",
      "6603\n",
      "6604\n",
      "6605\n",
      "6606\n",
      "6607\n",
      "6608\n",
      "6609\n",
      "6610\n",
      "6611\n",
      "6612\n",
      "6613\n",
      "6614\n",
      "6615\n",
      "6616\n",
      "6617\n",
      "6618\n",
      "6619\n",
      "6620\n",
      "6621\n",
      "6622\n",
      "6623\n",
      "6624\n",
      "6625\n",
      "6626\n",
      "6627\n",
      "6628\n",
      "6629\n",
      "6630\n",
      "6631\n",
      "6632\n",
      "6633\n",
      "6634\n",
      "6635\n",
      "6636\n",
      "6637\n",
      "6638\n",
      "6639\n",
      "6640\n",
      "6641\n",
      "6642\n",
      "6643\n",
      "6644\n",
      "6645\n",
      "6646\n",
      "6647\n",
      "6648\n",
      "6649\n",
      "6650\n",
      "6651\n",
      "6652\n",
      "6653\n",
      "6654\n",
      "6655\n",
      "6656\n",
      "6657\n",
      "6658\n",
      "6659\n",
      "6660\n",
      "6661\n",
      "6662\n",
      "6663\n",
      "6664\n",
      "6665\n",
      "6666\n",
      "6667\n",
      "6668\n",
      "6669\n",
      "6670\n",
      "6671\n",
      "6672\n",
      "6673\n",
      "6674\n",
      "6675\n",
      "6676\n",
      "6677\n",
      "6678\n",
      "6679\n",
      "6680\n",
      "6681\n",
      "6682\n",
      "6683\n",
      "6684\n",
      "6685\n",
      "6686\n",
      "6687\n",
      "6688\n",
      "6689\n",
      "6690\n",
      "6691\n",
      "6692\n",
      "6693\n",
      "6694\n",
      "6695\n",
      "6696\n",
      "6697\n",
      "6698\n",
      "6699\n",
      "6700\n",
      "6701\n",
      "6702\n",
      "6703\n",
      "6704\n",
      "6705\n",
      "6706\n",
      "6707\n",
      "6708\n",
      "6709\n",
      "6710\n",
      "6711\n",
      "6712\n",
      "6713\n",
      "6714\n",
      "6715\n",
      "6716\n",
      "6717\n",
      "6718\n",
      "6719\n",
      "6720\n",
      "6721\n",
      "6722\n",
      "6723\n",
      "6724\n",
      "6725\n",
      "6726\n",
      "6727\n",
      "6728\n",
      "6729\n",
      "6730\n",
      "6731\n",
      "6732\n",
      "6733\n",
      "6734\n",
      "6735\n",
      "6736\n",
      "6737\n",
      "6738\n",
      "6739\n",
      "6740\n",
      "6741\n",
      "6742\n",
      "6743\n",
      "6744\n",
      "6745\n",
      "6746\n",
      "6747\n",
      "6748\n",
      "6749\n",
      "6750\n",
      "6751\n",
      "6752\n",
      "6753\n",
      "6754\n",
      "6755\n",
      "6756\n",
      "6757\n",
      "6758\n",
      "6759\n",
      "6760\n",
      "6761\n",
      "6762\n",
      "6763\n",
      "6764\n",
      "6765\n",
      "6766\n",
      "6767\n",
      "6768\n",
      "6769\n",
      "6770\n",
      "6771\n",
      "6772\n",
      "6773\n",
      "6774\n",
      "6775\n",
      "6776\n",
      "6777\n",
      "6778\n",
      "6779\n",
      "6780\n",
      "6781\n",
      "6782\n",
      "6783\n",
      "6784\n",
      "6785\n",
      "6786\n",
      "6787\n",
      "6788\n",
      "6789\n",
      "6790\n",
      "6791\n",
      "6792\n",
      "6793\n",
      "6794\n",
      "6795\n",
      "6796\n",
      "6797\n",
      "6798\n",
      "6799\n",
      "6800\n",
      "6801\n",
      "6802\n",
      "6803\n",
      "6804\n",
      "6805\n",
      "6806\n",
      "6807\n",
      "6808\n",
      "6809\n",
      "6810\n",
      "6811\n",
      "6812\n",
      "6813\n",
      "6814\n",
      "6815\n",
      "6816\n",
      "6817\n",
      "6818\n",
      "6819\n",
      "6820\n",
      "6821\n",
      "6822\n",
      "6823\n",
      "6824\n",
      "6825\n",
      "6826\n",
      "6827\n",
      "6828\n",
      "6829\n",
      "6830\n",
      "6831\n",
      "6832\n",
      "6833\n",
      "6834\n",
      "6835\n",
      "6836\n",
      "6837\n",
      "6838\n",
      "6839\n",
      "6840\n",
      "6841\n",
      "6842\n",
      "6843\n",
      "6844\n",
      "6845\n",
      "6846\n",
      "6847\n",
      "6848\n",
      "6849\n",
      "6850\n",
      "6851\n",
      "6852\n",
      "6853\n",
      "6854\n",
      "6855\n",
      "6856\n",
      "6857\n",
      "6858\n",
      "6859\n",
      "6860\n",
      "6861\n",
      "6862\n",
      "6863\n",
      "6864\n",
      "6865\n",
      "6866\n",
      "6867\n",
      "6868\n",
      "6869\n",
      "6870\n",
      "6871\n",
      "6872\n",
      "6873\n",
      "6874\n",
      "6875\n",
      "6876\n",
      "6877\n",
      "6878\n",
      "6879\n",
      "6880\n",
      "6881\n",
      "6882\n",
      "6883\n",
      "6884\n",
      "6885\n",
      "6886\n",
      "6887\n",
      "6888\n",
      "6889\n",
      "6890\n",
      "6891\n",
      "6892\n",
      "6893\n",
      "6894\n",
      "6895\n",
      "6896\n",
      "6897\n",
      "6898\n",
      "6899\n",
      "6900\n",
      "6901\n",
      "6902\n",
      "6903\n",
      "6904\n",
      "6905\n",
      "6906\n",
      "6907\n",
      "6908\n",
      "6909\n",
      "6910\n",
      "6911\n",
      "6912\n",
      "6913\n",
      "6914\n",
      "6915\n",
      "6916\n",
      "6917\n",
      "6918\n",
      "6919\n",
      "6920\n",
      "6921\n",
      "6922\n",
      "6923\n",
      "6924\n",
      "6925\n",
      "6926\n",
      "6927\n",
      "6928\n",
      "6929\n",
      "6930\n",
      "6931\n",
      "6932\n",
      "6933\n",
      "6934\n",
      "6935\n",
      "6936\n",
      "6937\n",
      "6938\n",
      "6939\n",
      "6940\n",
      "6941\n",
      "6942\n",
      "6943\n",
      "6944\n",
      "6945\n",
      "6946\n",
      "6947\n",
      "6948\n",
      "6949\n",
      "6950\n",
      "6951\n",
      "6952\n",
      "6953\n",
      "6954\n",
      "6955\n",
      "6956\n",
      "6957\n",
      "6958\n",
      "6959\n",
      "6960\n",
      "6961\n",
      "6962\n",
      "6963\n",
      "6964\n",
      "6965\n",
      "6966\n",
      "6967\n",
      "6968\n",
      "6969\n",
      "6970\n",
      "6971\n",
      "6972\n",
      "6973\n",
      "6974\n",
      "6975\n",
      "6976\n",
      "6977\n",
      "6978\n",
      "6979\n",
      "6980\n",
      "6981\n",
      "6982\n",
      "6983\n",
      "6984\n",
      "6985\n",
      "6986\n",
      "6987\n",
      "6988\n",
      "6989\n",
      "6990\n",
      "6991\n",
      "6992\n",
      "6993\n",
      "6994\n",
      "6995\n",
      "6996\n",
      "6997\n",
      "6998\n",
      "6999\n",
      "7000\n",
      "7001\n",
      "7002\n",
      "7003\n",
      "7004\n",
      "7005\n",
      "7006\n",
      "7007\n",
      "7008\n",
      "7009\n",
      "7010\n",
      "7011\n",
      "7012\n",
      "7013\n",
      "7014\n",
      "7015\n",
      "7016\n",
      "7017\n",
      "7018\n",
      "7019\n",
      "7020\n",
      "7021\n",
      "7022\n",
      "7023\n",
      "7024\n",
      "7025\n",
      "7026\n",
      "7027\n",
      "7028\n",
      "7029\n",
      "7030\n",
      "7031\n",
      "7032\n",
      "7033\n",
      "7034\n",
      "7035\n",
      "7036\n",
      "7037\n",
      "7038\n",
      "7039\n",
      "7040\n",
      "7041\n",
      "7042\n",
      "7043\n",
      "7044\n",
      "7045\n",
      "7046\n",
      "7047\n",
      "7048\n",
      "7049\n",
      "7050\n",
      "7051\n",
      "7052\n",
      "7053\n",
      "7054\n",
      "7055\n",
      "7056\n",
      "7057\n",
      "7058\n",
      "7059\n",
      "7060\n",
      "7061\n",
      "7062\n",
      "7063\n",
      "7064\n",
      "7065\n",
      "7066\n",
      "7067\n",
      "7068\n",
      "7069\n",
      "7070\n",
      "7071\n",
      "7072\n",
      "7073\n",
      "7074\n",
      "7075\n",
      "7076\n",
      "7077\n",
      "7078\n",
      "7079\n",
      "7080\n",
      "7081\n",
      "7082\n",
      "7083\n",
      "7084\n",
      "7085\n",
      "7086\n",
      "7087\n",
      "7088\n",
      "7089\n",
      "7090\n",
      "7091\n",
      "7092\n",
      "7093\n",
      "7094\n",
      "7095\n",
      "7096\n",
      "7097\n",
      "7098\n",
      "7099\n",
      "7100\n",
      "7101\n",
      "7102\n",
      "7103\n",
      "7104\n",
      "7105\n",
      "7106\n",
      "7107\n",
      "7108\n",
      "7109\n",
      "7110\n",
      "7111\n",
      "7112\n",
      "7113\n",
      "7114\n",
      "7115\n",
      "7116\n",
      "7117\n",
      "7118\n",
      "7119\n",
      "7120\n",
      "7121\n",
      "7122\n",
      "7123\n",
      "7124\n",
      "7125\n",
      "7126\n",
      "7127\n",
      "7128\n",
      "7129\n",
      "7130\n",
      "7131\n",
      "7132\n",
      "7133\n",
      "7134\n",
      "7135\n",
      "7136\n",
      "7137\n",
      "7138\n",
      "7139\n",
      "7140\n",
      "7141\n",
      "7142\n",
      "7143\n",
      "7144\n",
      "7145\n",
      "7146\n",
      "7147\n",
      "7148\n",
      "7149\n",
      "7150\n",
      "7151\n",
      "7152\n",
      "7153\n",
      "7154\n",
      "7155\n",
      "7156\n",
      "7157\n",
      "7158\n",
      "7159\n",
      "7160\n",
      "7161\n",
      "7162\n",
      "7163\n",
      "7164\n",
      "7165\n",
      "7166\n",
      "7167\n",
      "7168\n",
      "7169\n",
      "7170\n",
      "7171\n",
      "7172\n",
      "7173\n",
      "7174\n",
      "7175\n",
      "7176\n",
      "7177\n",
      "7178\n",
      "7179\n",
      "7180\n",
      "7181\n",
      "7182\n",
      "7183\n",
      "7184\n",
      "7185\n",
      "7186\n",
      "7187\n",
      "7188\n",
      "7189\n",
      "7190\n",
      "7191\n",
      "7192\n",
      "7193\n",
      "7194\n",
      "7195\n",
      "7196\n",
      "7197\n",
      "7198\n",
      "7199\n",
      "7200\n",
      "7201\n",
      "7202\n",
      "7203\n",
      "7204\n",
      "7205\n",
      "7206\n",
      "7207\n",
      "7208\n",
      "7209\n",
      "7210\n",
      "7211\n",
      "7212\n",
      "7213\n",
      "7214\n",
      "7215\n",
      "7216\n",
      "7217\n",
      "7218\n",
      "7219\n",
      "7220\n",
      "7221\n",
      "7222\n",
      "7223\n",
      "7224\n",
      "7225\n",
      "7226\n",
      "7227\n",
      "7228\n",
      "7229\n",
      "7230\n",
      "7231\n",
      "7232\n",
      "7233\n",
      "7234\n",
      "7235\n",
      "7236\n",
      "7237\n",
      "7238\n",
      "7239\n",
      "7240\n",
      "7241\n",
      "7242\n",
      "7243\n",
      "7244\n",
      "7245\n",
      "7246\n",
      "7247\n",
      "7248\n",
      "7249\n",
      "7250\n",
      "7251\n",
      "7252\n",
      "7253\n",
      "7254\n",
      "7255\n",
      "7256\n",
      "7257\n",
      "7258\n",
      "7259\n",
      "7260\n",
      "7261\n",
      "7262\n",
      "7263\n",
      "7264\n",
      "7265\n",
      "7266\n",
      "7267\n",
      "7268\n",
      "7269\n",
      "7270\n",
      "7271\n",
      "7272\n",
      "7273\n",
      "7274\n",
      "7275\n",
      "7276\n",
      "7277\n",
      "7278\n",
      "7279\n",
      "7280\n",
      "7281\n",
      "7282\n",
      "7283\n",
      "7284\n",
      "7285\n",
      "7286\n",
      "7287\n",
      "7288\n",
      "7289\n",
      "7290\n",
      "7291\n",
      "7292\n",
      "7293\n",
      "7294\n",
      "7295\n",
      "7296\n",
      "7297\n",
      "7298\n",
      "7299\n",
      "7300\n",
      "7301\n",
      "7302\n",
      "7303\n",
      "7304\n",
      "7305\n",
      "7306\n",
      "7307\n",
      "7308\n",
      "7309\n",
      "7310\n",
      "7311\n",
      "7312\n",
      "7313\n",
      "7314\n",
      "7315\n",
      "7316\n",
      "7317\n",
      "7318\n",
      "7319\n",
      "7320\n",
      "7321\n",
      "7322\n",
      "7323\n",
      "7324\n",
      "7325\n",
      "7326\n",
      "7327\n",
      "7328\n",
      "7329\n",
      "7330\n",
      "7331\n",
      "7332\n",
      "7333\n",
      "7334\n",
      "7335\n",
      "7336\n",
      "7337\n",
      "7338\n",
      "7339\n",
      "7340\n",
      "7341\n",
      "7342\n",
      "7343\n",
      "7344\n",
      "7345\n",
      "7346\n",
      "7347\n",
      "7348\n",
      "7349\n",
      "7350\n",
      "7351\n",
      "7352\n",
      "7353\n",
      "7354\n",
      "7355\n",
      "7356\n",
      "7357\n",
      "7358\n",
      "7359\n",
      "7360\n",
      "7361\n",
      "7362\n",
      "7363\n",
      "7364\n",
      "7365\n",
      "7366\n",
      "7367\n",
      "7368\n",
      "7369\n",
      "7370\n",
      "7371\n",
      "7372\n",
      "7373\n",
      "7374\n",
      "7375\n",
      "7376\n",
      "7377\n",
      "7378\n",
      "7379\n",
      "7380\n",
      "7381\n",
      "7382\n",
      "7383\n",
      "7384\n",
      "7385\n",
      "7386\n",
      "7387\n",
      "7388\n",
      "7389\n",
      "7390\n",
      "7391\n",
      "7392\n",
      "7393\n",
      "7394\n",
      "7395\n",
      "7396\n",
      "7397\n",
      "7398\n",
      "7399\n",
      "7400\n",
      "7401\n",
      "7402\n",
      "7403\n",
      "7404\n",
      "7405\n",
      "7406\n",
      "7407\n",
      "7408\n",
      "7409\n",
      "7410\n",
      "7411\n",
      "7412\n",
      "7413\n",
      "7414\n",
      "7415\n",
      "7416\n",
      "7417\n",
      "7418\n",
      "7419\n",
      "7420\n",
      "7421\n",
      "7422\n",
      "7423\n",
      "7424\n",
      "7425\n",
      "7426\n",
      "7427\n",
      "7428\n",
      "7429\n",
      "7430\n",
      "7431\n",
      "7432\n",
      "7433\n",
      "7434\n",
      "7435\n",
      "7436\n",
      "7437\n",
      "7438\n",
      "7439\n",
      "7440\n",
      "7441\n",
      "7442\n",
      "7443\n",
      "7444\n",
      "7445\n",
      "7446\n",
      "7447\n",
      "7448\n",
      "7449\n",
      "7450\n",
      "7451\n",
      "7452\n",
      "7453\n",
      "7454\n",
      "7455\n",
      "7456\n",
      "7457\n",
      "7458\n",
      "7459\n",
      "7460\n",
      "7461\n",
      "7462\n",
      "7463\n",
      "7464\n",
      "7465\n",
      "7466\n",
      "7467\n",
      "7468\n",
      "7469\n",
      "7470\n",
      "7471\n",
      "7472\n",
      "7473\n",
      "7474\n",
      "7475\n",
      "7476\n",
      "7477\n",
      "7478\n",
      "7479\n",
      "7480\n",
      "7481\n",
      "7482\n",
      "7483\n",
      "7484\n",
      "7485\n",
      "7486\n",
      "7487\n",
      "7488\n",
      "7489\n",
      "7490\n",
      "7491\n",
      "7492\n",
      "7493\n",
      "7494\n",
      "7495\n",
      "7496\n",
      "7497\n",
      "7498\n",
      "7499\n",
      "7500\n",
      "7501\n",
      "7502\n",
      "7503\n",
      "7504\n",
      "7505\n",
      "7506\n",
      "7507\n",
      "7508\n",
      "7509\n",
      "7510\n",
      "7511\n",
      "7512\n",
      "7513\n",
      "7514\n",
      "7515\n",
      "7516\n",
      "7517\n",
      "7518\n",
      "7519\n",
      "7520\n",
      "7521\n",
      "7522\n",
      "7523\n",
      "7524\n",
      "7525\n",
      "7526\n",
      "7527\n",
      "7528\n",
      "7529\n",
      "7530\n",
      "7531\n",
      "7532\n",
      "7533\n",
      "7534\n",
      "7535\n",
      "7536\n",
      "7537\n",
      "7538\n",
      "7539\n",
      "7540\n",
      "7541\n",
      "7542\n",
      "7543\n",
      "7544\n",
      "7545\n",
      "7546\n",
      "7547\n",
      "7548\n",
      "7549\n",
      "7550\n",
      "7551\n",
      "7552\n",
      "7553\n",
      "7554\n",
      "7555\n",
      "7556\n",
      "7557\n",
      "7558\n",
      "7559\n",
      "7560\n",
      "7561\n",
      "7562\n",
      "7563\n",
      "7564\n",
      "7565\n",
      "7566\n",
      "7567\n",
      "7568\n",
      "7569\n",
      "7570\n",
      "7571\n",
      "7572\n",
      "7573\n",
      "7574\n",
      "7575\n",
      "7576\n",
      "7577\n",
      "7578\n",
      "7579\n",
      "7580\n",
      "7581\n",
      "7582\n",
      "7583\n",
      "7584\n",
      "7585\n",
      "7586\n",
      "7587\n",
      "7588\n",
      "7589\n",
      "7590\n",
      "7591\n",
      "7592\n",
      "7593\n",
      "7594\n",
      "7595\n",
      "7596\n",
      "7597\n",
      "7598\n",
      "7599\n",
      "7600\n",
      "7601\n",
      "7602\n",
      "7603\n",
      "7604\n",
      "7605\n",
      "7606\n",
      "7607\n",
      "7608\n",
      "7609\n",
      "7610\n",
      "7611\n",
      "7612\n",
      "7613\n",
      "7614\n",
      "7615\n",
      "7616\n",
      "7617\n",
      "7618\n",
      "7619\n",
      "7620\n",
      "7621\n",
      "7622\n",
      "7623\n",
      "7624\n",
      "7625\n",
      "7626\n",
      "7627\n",
      "7628\n",
      "7629\n",
      "7630\n",
      "7631\n",
      "7632\n",
      "7633\n",
      "7634\n",
      "7635\n",
      "7636\n",
      "7637\n",
      "7638\n",
      "7639\n",
      "7640\n",
      "7641\n",
      "7642\n",
      "7643\n",
      "7644\n",
      "7645\n",
      "7646\n",
      "7647\n",
      "7648\n",
      "7649\n",
      "7650\n",
      "7651\n",
      "7652\n",
      "7653\n",
      "7654\n",
      "7655\n",
      "7656\n",
      "7657\n",
      "7658\n",
      "7659\n",
      "7660\n",
      "7661\n",
      "7662\n",
      "7663\n",
      "7664\n",
      "7665\n",
      "7666\n",
      "7667\n",
      "7668\n",
      "7669\n",
      "7670\n",
      "7671\n",
      "7672\n",
      "7673\n",
      "7674\n",
      "7675\n",
      "7676\n",
      "7677\n",
      "7678\n",
      "7679\n",
      "7680\n",
      "7681\n",
      "7682\n",
      "7683\n",
      "7684\n",
      "7685\n",
      "7686\n",
      "7687\n",
      "7688\n",
      "7689\n",
      "7690\n",
      "7691\n",
      "7692\n",
      "7693\n",
      "7694\n",
      "7695\n",
      "7696\n",
      "7697\n",
      "7698\n",
      "7699\n",
      "7700\n",
      "7701\n",
      "7702\n",
      "7703\n",
      "7704\n",
      "7705\n",
      "7706\n",
      "7707\n",
      "7708\n",
      "7709\n",
      "7710\n",
      "7711\n",
      "7712\n",
      "7713\n",
      "7714\n",
      "7715\n",
      "7716\n",
      "7717\n",
      "7718\n",
      "7719\n",
      "7720\n",
      "7721\n",
      "7722\n",
      "7723\n",
      "7724\n",
      "7725\n",
      "7726\n",
      "7727\n",
      "7728\n",
      "7729\n",
      "7730\n",
      "7731\n",
      "7732\n",
      "7733\n",
      "7734\n",
      "7735\n",
      "7736\n",
      "7737\n",
      "7738\n",
      "7739\n",
      "7740\n",
      "7741\n",
      "7742\n",
      "7743\n",
      "7744\n",
      "7745\n",
      "7746\n",
      "7747\n",
      "7748\n",
      "7749\n",
      "7750\n",
      "7751\n",
      "7752\n",
      "7753\n",
      "7754\n",
      "7755\n",
      "7756\n",
      "7757\n",
      "7758\n",
      "7759\n",
      "7760\n",
      "7761\n",
      "7762\n",
      "7763\n",
      "7764\n",
      "7765\n",
      "7766\n",
      "7767\n",
      "7768\n",
      "7769\n",
      "7770\n",
      "7771\n",
      "7772\n",
      "7773\n",
      "7774\n",
      "7775\n",
      "7776\n",
      "7777\n",
      "7778\n",
      "7779\n",
      "7780\n",
      "7781\n",
      "7782\n",
      "7783\n",
      "7784\n",
      "7785\n",
      "7786\n",
      "7787\n",
      "7788\n",
      "7789\n",
      "7790\n",
      "7791\n",
      "7792\n",
      "7793\n",
      "7794\n",
      "7795\n",
      "7796\n",
      "7797\n",
      "7798\n",
      "7799\n",
      "7800\n",
      "7801\n",
      "7802\n",
      "7803\n",
      "7804\n",
      "7805\n",
      "7806\n",
      "7807\n",
      "7808\n",
      "7809\n",
      "7810\n",
      "7811\n",
      "7812\n",
      "7813\n",
      "7814\n",
      "7815\n",
      "7816\n",
      "7817\n",
      "7818\n",
      "7819\n",
      "7820\n",
      "7821\n",
      "7822\n",
      "7823\n",
      "7824\n",
      "7825\n",
      "7826\n",
      "7827\n",
      "7828\n",
      "7829\n",
      "7830\n",
      "7831\n",
      "7832\n",
      "7833\n",
      "7834\n",
      "7835\n",
      "7836\n",
      "7837\n",
      "7838\n",
      "7839\n",
      "7840\n",
      "7841\n",
      "7842\n",
      "7843\n",
      "7844\n",
      "7845\n",
      "7846\n",
      "7847\n",
      "7848\n",
      "7849\n",
      "7850\n",
      "7851\n",
      "7852\n",
      "7853\n",
      "7854\n",
      "7855\n",
      "7856\n",
      "7857\n",
      "7858\n",
      "7859\n",
      "7860\n",
      "7861\n",
      "7862\n",
      "7863\n",
      "7864\n",
      "7865\n",
      "7866\n",
      "7867\n",
      "7868\n",
      "7869\n",
      "7870\n",
      "7871\n",
      "7872\n",
      "7873\n",
      "7874\n",
      "7875\n",
      "7876\n",
      "7877\n",
      "7878\n",
      "7879\n",
      "7880\n",
      "7881\n",
      "7882\n",
      "7883\n",
      "7884\n",
      "7885\n",
      "7886\n",
      "7887\n",
      "7888\n",
      "7889\n",
      "7890\n",
      "7891\n",
      "7892\n",
      "7893\n",
      "7894\n",
      "7895\n",
      "7896\n",
      "7897\n",
      "7898\n",
      "7899\n",
      "7900\n",
      "7901\n",
      "7902\n",
      "7903\n",
      "7904\n",
      "7905\n",
      "7906\n",
      "7907\n",
      "7908\n",
      "7909\n",
      "7910\n",
      "7911\n",
      "7912\n",
      "7913\n",
      "7914\n",
      "7915\n",
      "7916\n",
      "7917\n",
      "7918\n",
      "7919\n",
      "7920\n",
      "7921\n",
      "7922\n",
      "7923\n",
      "7924\n",
      "7925\n",
      "7926\n",
      "7927\n",
      "7928\n",
      "7929\n",
      "7930\n",
      "7931\n",
      "7932\n",
      "7933\n",
      "7934\n",
      "7935\n",
      "7936\n",
      "7937\n",
      "7938\n",
      "7939\n",
      "7940\n",
      "7941\n",
      "7942\n",
      "7943\n",
      "7944\n",
      "7945\n",
      "7946\n",
      "7947\n",
      "7948\n",
      "7949\n",
      "7950\n",
      "7951\n",
      "7952\n",
      "7953\n",
      "7954\n",
      "7955\n",
      "7956\n",
      "7957\n",
      "7958\n",
      "7959\n",
      "7960\n",
      "7961\n",
      "7962\n",
      "7963\n",
      "7964\n",
      "7965\n",
      "7966\n",
      "7967\n",
      "7968\n",
      "7969\n",
      "7970\n",
      "7971\n",
      "7972\n",
      "7973\n",
      "7974\n",
      "7975\n",
      "7976\n",
      "7977\n",
      "7978\n",
      "7979\n",
      "7980\n",
      "7981\n",
      "7982\n",
      "7983\n",
      "7984\n",
      "7985\n",
      "7986\n",
      "7987\n",
      "7988\n",
      "7989\n",
      "7990\n",
      "7991\n",
      "7992\n",
      "7993\n",
      "7994\n",
      "7995\n",
      "7996\n",
      "7997\n",
      "7998\n",
      "7999\n",
      "8000\n",
      "8001\n",
      "8002\n",
      "8003\n",
      "8004\n",
      "8005\n",
      "8006\n",
      "8007\n",
      "8008\n",
      "8009\n",
      "8010\n",
      "8011\n",
      "8012\n",
      "8013\n",
      "8014\n",
      "8015\n",
      "8016\n",
      "8017\n",
      "8018\n",
      "8019\n",
      "8020\n",
      "8021\n",
      "8022\n",
      "8023\n",
      "8024\n",
      "8025\n",
      "8026\n",
      "8027\n",
      "8028\n",
      "8029\n",
      "8030\n",
      "8031\n",
      "8032\n",
      "8033\n",
      "8034\n",
      "8035\n",
      "8036\n",
      "8037\n",
      "8038\n",
      "8039\n",
      "8040\n",
      "8041\n",
      "8042\n",
      "8043\n",
      "8044\n",
      "8045\n",
      "8046\n",
      "8047\n",
      "8048\n",
      "8049\n",
      "8050\n",
      "8051\n",
      "8052\n",
      "8053\n",
      "8054\n",
      "8055\n",
      "8056\n",
      "8057\n",
      "8058\n",
      "8059\n",
      "8060\n",
      "8061\n",
      "8062\n",
      "8063\n",
      "8064\n",
      "8065\n",
      "8066\n",
      "8067\n",
      "8068\n",
      "8069\n",
      "8070\n",
      "8071\n",
      "8072\n",
      "8073\n",
      "8074\n",
      "8075\n",
      "8076\n",
      "8077\n",
      "8078\n",
      "8079\n",
      "8080\n",
      "8081\n",
      "8082\n",
      "8083\n",
      "8084\n",
      "8085\n",
      "8086\n",
      "8087\n",
      "8088\n",
      "8089\n",
      "8090\n",
      "8091\n",
      "8092\n",
      "8093\n",
      "8094\n",
      "8095\n",
      "8096\n",
      "8097\n",
      "8098\n",
      "8099\n",
      "8100\n",
      "8101\n",
      "8102\n",
      "8103\n",
      "8104\n",
      "8105\n",
      "8106\n",
      "8107\n",
      "8108\n",
      "8109\n",
      "8110\n",
      "8111\n",
      "8112\n",
      "8113\n",
      "8114\n",
      "8115\n",
      "8116\n",
      "8117\n",
      "8118\n",
      "8119\n",
      "8120\n",
      "8121\n",
      "8122\n",
      "8123\n",
      "8124\n",
      "8125\n",
      "8126\n",
      "8127\n",
      "8128\n",
      "8129\n",
      "8130\n",
      "8131\n",
      "8132\n",
      "8133\n",
      "8134\n",
      "8135\n",
      "8136\n",
      "8137\n",
      "8138\n",
      "8139\n",
      "8140\n",
      "8141\n",
      "8142\n",
      "8143\n",
      "8144\n",
      "8145\n",
      "8146\n",
      "8147\n",
      "8148\n",
      "8149\n",
      "8150\n",
      "8151\n",
      "8152\n",
      "8153\n",
      "8154\n",
      "8155\n",
      "8156\n",
      "8157\n",
      "8158\n",
      "8159\n",
      "8160\n",
      "8161\n",
      "8162\n",
      "8163\n",
      "8164\n",
      "8165\n",
      "8166\n",
      "8167\n",
      "8168\n",
      "8169\n",
      "8170\n",
      "8171\n",
      "8172\n",
      "8173\n",
      "8174\n",
      "8175\n",
      "8176\n",
      "8177\n",
      "8178\n",
      "8179\n",
      "8180\n",
      "8181\n",
      "8182\n",
      "8183\n",
      "8184\n",
      "8185\n",
      "8186\n",
      "8187\n",
      "8188\n",
      "8189\n",
      "8190\n",
      "8191\n",
      "8192\n",
      "8193\n",
      "8194\n",
      "8195\n",
      "8196\n",
      "8197\n",
      "8198\n",
      "8199\n",
      "8200\n",
      "8201\n",
      "8202\n",
      "8203\n",
      "8204\n",
      "8205\n",
      "8206\n",
      "8207\n",
      "8208\n",
      "8209\n",
      "8210\n",
      "8211\n",
      "8212\n",
      "8213\n",
      "8214\n",
      "8215\n",
      "8216\n",
      "8217\n",
      "8218\n",
      "8219\n",
      "8220\n",
      "8221\n",
      "8222\n",
      "8223\n",
      "8224\n",
      "8225\n",
      "8226\n",
      "8227\n",
      "8228\n",
      "8229\n",
      "8230\n",
      "8231\n",
      "8232\n",
      "8233\n",
      "8234\n",
      "8235\n",
      "8236\n",
      "8237\n",
      "8238\n",
      "8239\n",
      "8240\n",
      "8241\n",
      "8242\n",
      "8243\n",
      "8244\n",
      "8245\n",
      "8246\n",
      "8247\n",
      "8248\n",
      "8249\n",
      "8250\n",
      "8251\n",
      "8252\n",
      "8253\n",
      "8254\n",
      "8255\n",
      "8256\n",
      "8257\n",
      "8258\n",
      "8259\n",
      "8260\n",
      "8261\n",
      "8262\n",
      "8263\n",
      "8264\n",
      "8265\n",
      "8266\n",
      "8267\n",
      "8268\n",
      "8269\n",
      "8270\n",
      "8271\n",
      "8272\n",
      "8273\n",
      "8274\n",
      "8275\n",
      "8276\n",
      "8277\n",
      "8278\n",
      "8279\n",
      "8280\n",
      "8281\n",
      "8282\n",
      "8283\n",
      "8284\n",
      "8285\n",
      "8286\n",
      "8287\n",
      "8288\n",
      "8289\n",
      "8290\n",
      "8291\n",
      "8292\n",
      "8293\n",
      "8294\n",
      "8295\n",
      "8296\n",
      "8297\n",
      "8298\n",
      "8299\n",
      "8300\n",
      "8301\n",
      "8302\n",
      "8303\n",
      "8304\n",
      "8305\n",
      "8306\n",
      "8307\n",
      "8308\n",
      "8309\n",
      "8310\n",
      "8311\n",
      "8312\n",
      "8313\n",
      "8314\n",
      "8315\n",
      "8316\n",
      "8317\n",
      "8318\n",
      "8319\n",
      "8320\n",
      "8321\n",
      "8322\n",
      "8323\n",
      "8324\n",
      "8325\n",
      "8326\n",
      "8327\n",
      "8328\n",
      "8329\n",
      "8330\n",
      "8331\n",
      "8332\n",
      "8333\n",
      "8334\n",
      "8335\n",
      "8336\n",
      "8337\n",
      "8338\n",
      "8339\n",
      "8340\n",
      "8341\n",
      "8342\n",
      "8343\n",
      "8344\n",
      "8345\n",
      "8346\n",
      "8347\n",
      "8348\n",
      "8349\n",
      "8350\n",
      "8351\n",
      "8352\n",
      "8353\n",
      "8354\n",
      "8355\n",
      "8356\n",
      "8357\n",
      "8358\n",
      "8359\n",
      "8360\n",
      "8361\n",
      "8362\n",
      "8363\n",
      "8364\n",
      "8365\n",
      "8366\n",
      "8367\n",
      "8368\n",
      "8369\n",
      "8370\n",
      "8371\n",
      "8372\n",
      "8373\n",
      "8374\n",
      "8375\n",
      "8376\n",
      "8377\n",
      "8378\n",
      "8379\n",
      "8380\n",
      "8381\n",
      "8382\n",
      "8383\n",
      "8384\n",
      "8385\n",
      "8386\n",
      "8387\n",
      "8388\n",
      "8389\n",
      "8390\n",
      "8391\n",
      "8392\n",
      "8393\n",
      "8394\n",
      "8395\n",
      "8396\n",
      "8397\n",
      "8398\n",
      "8399\n",
      "8400\n",
      "8401\n",
      "8402\n",
      "8403\n",
      "8404\n",
      "8405\n",
      "8406\n",
      "8407\n",
      "8408\n",
      "8409\n",
      "8410\n",
      "8411\n",
      "8412\n",
      "8413\n",
      "8414\n",
      "8415\n",
      "8416\n",
      "8417\n",
      "8418\n",
      "8419\n",
      "8420\n",
      "8421\n",
      "8422\n",
      "8423\n",
      "8424\n",
      "8425\n",
      "8426\n",
      "8427\n",
      "8428\n",
      "8429\n",
      "8430\n",
      "8431\n",
      "8432\n",
      "8433\n",
      "8434\n",
      "8435\n",
      "8436\n",
      "8437\n",
      "8438\n",
      "8439\n",
      "8440\n",
      "8441\n",
      "8442\n",
      "8443\n",
      "8444\n",
      "8445\n",
      "8446\n",
      "8447\n",
      "8448\n",
      "8449\n",
      "8450\n",
      "8451\n",
      "8452\n",
      "8453\n",
      "8454\n",
      "8455\n",
      "8456\n",
      "8457\n",
      "8458\n",
      "8459\n",
      "8460\n",
      "8461\n",
      "8462\n",
      "8463\n",
      "8464\n",
      "8465\n",
      "8466\n",
      "8467\n",
      "8468\n",
      "8469\n",
      "8470\n",
      "8471\n",
      "8472\n",
      "8473\n",
      "8474\n",
      "8475\n",
      "8476\n",
      "8477\n",
      "8478\n",
      "8479\n",
      "8480\n",
      "8481\n",
      "8482\n",
      "8483\n",
      "8484\n",
      "8485\n",
      "8486\n",
      "8487\n",
      "8488\n",
      "8489\n",
      "8490\n",
      "8491\n",
      "8492\n",
      "8493\n",
      "8494\n",
      "8495\n",
      "8496\n",
      "8497\n",
      "8498\n",
      "8499\n",
      "8500\n",
      "8501\n",
      "8502\n",
      "8503\n",
      "8504\n",
      "8505\n",
      "8506\n",
      "8507\n",
      "8508\n",
      "8509\n",
      "8510\n",
      "8511\n",
      "8512\n",
      "8513\n",
      "8514\n",
      "8515\n",
      "8516\n",
      "8517\n",
      "8518\n",
      "8519\n",
      "8520\n",
      "8521\n",
      "8522\n",
      "8523\n",
      "8524\n",
      "8525\n",
      "8526\n",
      "8527\n",
      "8528\n",
      "8529\n",
      "8530\n",
      "8531\n",
      "8532\n",
      "8533\n",
      "8534\n",
      "8535\n",
      "8536\n",
      "8537\n",
      "8538\n",
      "8539\n",
      "8540\n",
      "8541\n",
      "8542\n",
      "8543\n",
      "8544\n",
      "8545\n",
      "8546\n",
      "8547\n",
      "8548\n",
      "8549\n",
      "8550\n",
      "8551\n",
      "8552\n",
      "8553\n",
      "8554\n",
      "8555\n",
      "8556\n",
      "8557\n",
      "8558\n",
      "8559\n",
      "8560\n",
      "8561\n",
      "8562\n",
      "8563\n",
      "8564\n",
      "8565\n",
      "8566\n",
      "8567\n",
      "8568\n",
      "8569\n",
      "8570\n",
      "8571\n",
      "8572\n",
      "8573\n",
      "8574\n",
      "8575\n",
      "8576\n",
      "8577\n",
      "8578\n",
      "8579\n",
      "8580\n",
      "8581\n",
      "8582\n",
      "8583\n",
      "8584\n",
      "8585\n",
      "8586\n",
      "8587\n",
      "8588\n",
      "8589\n",
      "8590\n",
      "8591\n",
      "8592\n",
      "8593\n",
      "8594\n",
      "8595\n",
      "8596\n",
      "8597\n",
      "8598\n",
      "8599\n",
      "8600\n",
      "8601\n",
      "8602\n",
      "8603\n",
      "8604\n",
      "8605\n",
      "8606\n",
      "8607\n",
      "8608\n",
      "8609\n",
      "8610\n",
      "8611\n",
      "8612\n",
      "8613\n",
      "8614\n",
      "8615\n",
      "8616\n",
      "8617\n",
      "8618\n",
      "8619\n",
      "8620\n",
      "8621\n",
      "8622\n",
      "8623\n",
      "8624\n",
      "8625\n",
      "8626\n",
      "8627\n",
      "8628\n",
      "8629\n",
      "8630\n",
      "8631\n",
      "8632\n",
      "8633\n",
      "8634\n",
      "8635\n",
      "8636\n",
      "8637\n",
      "8638\n",
      "8639\n",
      "8640\n",
      "8641\n",
      "8642\n",
      "8643\n",
      "8644\n",
      "8645\n",
      "8646\n",
      "8647\n",
      "8648\n",
      "8649\n",
      "8650\n",
      "8651\n",
      "8652\n",
      "8653\n",
      "8654\n",
      "8655\n",
      "8656\n",
      "8657\n",
      "8658\n",
      "8659\n",
      "8660\n",
      "8661\n",
      "8662\n",
      "8663\n",
      "8664\n",
      "8665\n",
      "8666\n",
      "8667\n",
      "8668\n",
      "8669\n",
      "8670\n",
      "8671\n",
      "8672\n",
      "8673\n",
      "8674\n",
      "8675\n",
      "8676\n",
      "8677\n",
      "8678\n",
      "8679\n",
      "8680\n",
      "8681\n",
      "8682\n",
      "8683\n",
      "8684\n",
      "8685\n",
      "8686\n",
      "8687\n",
      "8688\n",
      "8689\n",
      "8690\n",
      "8691\n",
      "8692\n",
      "8693\n",
      "8694\n",
      "8695\n",
      "8696\n",
      "8697\n",
      "8698\n",
      "8699\n",
      "8700\n",
      "8701\n",
      "8702\n",
      "8703\n",
      "8704\n",
      "8705\n",
      "8706\n",
      "8707\n",
      "8708\n",
      "8709\n",
      "8710\n",
      "8711\n",
      "8712\n",
      "8713\n",
      "8714\n",
      "8715\n",
      "8716\n",
      "8717\n",
      "8718\n",
      "8719\n",
      "8720\n",
      "8721\n",
      "8722\n",
      "8723\n",
      "8724\n",
      "8725\n",
      "8726\n",
      "8727\n",
      "8728\n",
      "8729\n",
      "8730\n",
      "8731\n",
      "8732\n",
      "8733\n",
      "8734\n",
      "8735\n",
      "8736\n",
      "8737\n",
      "8738\n",
      "8739\n",
      "8740\n",
      "8741\n",
      "8742\n",
      "8743\n",
      "8744\n",
      "8745\n",
      "8746\n",
      "8747\n",
      "8748\n",
      "8749\n",
      "8750\n",
      "8751\n",
      "8752\n",
      "8753\n",
      "8754\n",
      "8755\n",
      "8756\n",
      "8757\n",
      "8758\n",
      "8759\n",
      "8760\n",
      "8761\n",
      "8762\n",
      "8763\n",
      "8764\n",
      "8765\n",
      "8766\n",
      "8767\n",
      "8768\n",
      "8769\n",
      "8770\n",
      "8771\n",
      "8772\n",
      "8773\n",
      "8774\n",
      "8775\n",
      "8776\n",
      "8777\n",
      "8778\n",
      "8779\n",
      "8780\n",
      "8781\n",
      "8782\n",
      "8783\n",
      "8784\n",
      "8785\n",
      "8786\n",
      "8787\n",
      "8788\n",
      "8789\n",
      "8790\n",
      "8791\n",
      "8792\n",
      "8793\n",
      "8794\n",
      "8795\n",
      "8796\n",
      "8797\n",
      "8798\n",
      "8799\n",
      "8800\n",
      "8801\n",
      "8802\n",
      "8803\n",
      "8804\n",
      "8805\n",
      "8806\n",
      "8807\n",
      "8808\n",
      "8809\n",
      "8810\n",
      "8811\n",
      "8812\n",
      "8813\n",
      "8814\n",
      "8815\n",
      "8816\n",
      "8817\n",
      "8818\n",
      "8819\n",
      "8820\n",
      "8821\n",
      "8822\n",
      "8823\n",
      "8824\n",
      "8825\n",
      "8826\n",
      "8827\n",
      "8828\n",
      "8829\n",
      "8830\n",
      "8831\n",
      "8832\n",
      "8833\n",
      "8834\n",
      "8835\n",
      "8836\n",
      "8837\n",
      "8838\n",
      "8839\n",
      "8840\n",
      "8841\n",
      "8842\n",
      "8843\n",
      "8844\n",
      "8845\n",
      "8846\n",
      "8847\n",
      "8848\n",
      "8849\n",
      "8850\n",
      "8851\n",
      "8852\n",
      "8853\n",
      "8854\n",
      "8855\n",
      "8856\n",
      "8857\n",
      "8858\n",
      "8859\n",
      "8860\n",
      "8861\n",
      "8862\n",
      "8863\n",
      "8864\n",
      "8865\n",
      "8866\n",
      "8867\n",
      "8868\n",
      "8869\n",
      "8870\n",
      "8871\n",
      "8872\n",
      "8873\n",
      "8874\n",
      "8875\n",
      "8876\n",
      "8877\n",
      "8878\n",
      "8879\n",
      "8880\n",
      "8881\n",
      "8882\n",
      "8883\n",
      "8884\n",
      "8885\n",
      "8886\n",
      "8887\n",
      "8888\n",
      "8889\n",
      "8890\n",
      "8891\n",
      "8892\n",
      "8893\n",
      "8894\n",
      "8895\n",
      "8896\n",
      "8897\n",
      "8898\n",
      "8899\n",
      "8900\n",
      "8901\n",
      "8902\n",
      "8903\n",
      "8904\n",
      "8905\n",
      "8906\n",
      "8907\n",
      "8908\n",
      "8909\n",
      "8910\n",
      "8911\n",
      "8912\n",
      "8913\n",
      "8914\n",
      "8915\n",
      "8916\n",
      "8917\n",
      "8918\n",
      "8919\n",
      "8920\n",
      "8921\n",
      "8922\n",
      "8923\n",
      "8924\n",
      "8925\n",
      "8926\n",
      "8927\n",
      "8928\n",
      "8929\n",
      "8930\n",
      "8931\n",
      "8932\n",
      "8933\n",
      "8934\n",
      "8935\n",
      "8936\n",
      "8937\n",
      "8938\n",
      "8939\n",
      "8940\n",
      "8941\n",
      "8942\n",
      "8943\n",
      "8944\n",
      "8945\n",
      "8946\n",
      "8947\n",
      "8948\n",
      "8949\n",
      "8950\n",
      "8951\n",
      "8952\n",
      "8953\n",
      "8954\n",
      "8955\n",
      "8956\n",
      "8957\n",
      "8958\n",
      "8959\n",
      "8960\n",
      "8961\n",
      "8962\n",
      "8963\n",
      "8964\n",
      "8965\n",
      "8966\n",
      "8967\n",
      "8968\n",
      "8969\n",
      "8970\n",
      "8971\n",
      "8972\n",
      "8973\n",
      "8974\n",
      "8975\n",
      "8976\n",
      "8977\n",
      "8978\n",
      "8979\n",
      "8980\n",
      "8981\n",
      "8982\n",
      "8983\n",
      "8984\n",
      "8985\n",
      "8986\n",
      "8987\n",
      "8988\n",
      "8989\n",
      "8990\n",
      "8991\n",
      "8992\n",
      "8993\n",
      "8994\n",
      "8995\n",
      "8996\n",
      "8997\n",
      "8998\n",
      "8999\n",
      "9000\n",
      "9001\n",
      "9002\n",
      "9003\n",
      "9004\n",
      "9005\n",
      "9006\n",
      "9007\n",
      "9008\n",
      "9009\n",
      "9010\n",
      "9011\n",
      "9012\n",
      "9013\n",
      "9014\n",
      "9015\n",
      "9016\n",
      "9017\n",
      "9018\n",
      "9019\n",
      "9020\n",
      "9021\n",
      "9022\n",
      "9023\n",
      "9024\n",
      "9025\n",
      "9026\n",
      "9027\n",
      "9028\n",
      "9029\n",
      "9030\n",
      "9031\n",
      "9032\n",
      "9033\n",
      "9034\n",
      "9035\n",
      "9036\n",
      "9037\n",
      "9038\n",
      "9039\n",
      "9040\n",
      "9041\n",
      "9042\n",
      "9043\n",
      "9044\n",
      "9045\n",
      "9046\n",
      "9047\n",
      "9048\n",
      "9049\n",
      "9050\n",
      "9051\n",
      "9052\n",
      "9053\n",
      "9054\n",
      "9055\n",
      "9056\n",
      "9057\n",
      "9058\n",
      "9059\n",
      "9060\n",
      "9061\n",
      "9062\n",
      "9063\n",
      "9064\n",
      "9065\n",
      "9066\n",
      "9067\n",
      "9068\n",
      "9069\n",
      "9070\n",
      "9071\n",
      "9072\n",
      "9073\n",
      "9074\n",
      "9075\n",
      "9076\n",
      "9077\n",
      "9078\n",
      "9079\n",
      "9080\n",
      "9081\n",
      "9082\n",
      "9083\n",
      "9084\n",
      "9085\n",
      "9086\n",
      "9087\n",
      "9088\n",
      "9089\n",
      "9090\n",
      "9091\n",
      "9092\n",
      "9093\n",
      "9094\n",
      "9095\n",
      "9096\n",
      "9097\n",
      "9098\n",
      "9099\n",
      "9100\n",
      "9101\n",
      "9102\n",
      "9103\n",
      "9104\n",
      "9105\n",
      "9106\n",
      "9107\n",
      "9108\n",
      "9109\n",
      "9110\n",
      "9111\n",
      "9112\n",
      "9113\n",
      "9114\n",
      "9115\n",
      "9116\n",
      "9117\n",
      "9118\n",
      "9119\n",
      "9120\n",
      "9121\n",
      "9122\n",
      "9123\n",
      "9124\n",
      "9125\n",
      "9126\n",
      "9127\n",
      "9128\n",
      "9129\n",
      "9130\n",
      "9131\n",
      "9132\n",
      "9133\n",
      "9134\n",
      "9135\n",
      "9136\n",
      "9137\n",
      "9138\n",
      "9139\n",
      "9140\n",
      "9141\n",
      "9142\n",
      "9143\n",
      "9144\n",
      "9145\n",
      "9146\n",
      "9147\n",
      "9148\n",
      "9149\n",
      "9150\n",
      "9151\n",
      "9152\n",
      "9153\n",
      "9154\n",
      "9155\n",
      "9156\n",
      "9157\n",
      "9158\n",
      "9159\n",
      "9160\n",
      "9161\n",
      "9162\n",
      "9163\n",
      "9164\n",
      "9165\n",
      "9166\n",
      "9167\n",
      "9168\n",
      "9169\n",
      "9170\n",
      "9171\n",
      "9172\n",
      "9173\n",
      "9174\n",
      "9175\n",
      "9176\n",
      "9177\n",
      "9178\n",
      "9179\n",
      "9180\n",
      "9181\n",
      "9182\n",
      "9183\n",
      "9184\n",
      "9185\n",
      "9186\n",
      "9187\n",
      "9188\n",
      "9189\n",
      "9190\n",
      "9191\n",
      "9192\n",
      "9193\n",
      "9194\n",
      "9195\n",
      "9196\n",
      "9197\n",
      "9198\n",
      "9199\n",
      "9200\n",
      "9201\n",
      "9202\n",
      "9203\n",
      "9204\n",
      "9205\n",
      "9206\n",
      "9207\n",
      "9208\n",
      "9209\n",
      "9210\n",
      "9211\n",
      "9212\n",
      "9213\n",
      "9214\n",
      "9215\n",
      "9216\n",
      "9217\n",
      "9218\n",
      "9219\n",
      "9220\n",
      "9221\n",
      "9222\n",
      "9223\n",
      "9224\n",
      "9225\n",
      "9226\n",
      "9227\n",
      "9228\n",
      "9229\n",
      "9230\n",
      "9231\n",
      "9232\n",
      "9233\n",
      "9234\n",
      "9235\n",
      "9236\n",
      "9237\n",
      "9238\n",
      "9239\n",
      "9240\n",
      "9241\n",
      "9242\n",
      "9243\n",
      "9244\n",
      "9245\n",
      "9246\n",
      "9247\n",
      "9248\n",
      "9249\n",
      "9250\n",
      "9251\n",
      "9252\n",
      "9253\n",
      "9254\n",
      "9255\n",
      "9256\n",
      "9257\n",
      "9258\n",
      "9259\n",
      "9260\n",
      "9261\n",
      "9262\n",
      "9263\n",
      "9264\n",
      "9265\n",
      "9266\n",
      "9267\n",
      "9268\n",
      "9269\n",
      "9270\n",
      "9271\n",
      "9272\n",
      "9273\n",
      "9274\n",
      "9275\n",
      "9276\n",
      "9277\n",
      "9278\n",
      "9279\n",
      "9280\n",
      "9281\n",
      "9282\n",
      "9283\n",
      "9284\n",
      "9285\n",
      "9286\n",
      "9287\n",
      "9288\n",
      "9289\n",
      "9290\n",
      "9291\n",
      "9292\n",
      "9293\n",
      "9294\n",
      "9295\n",
      "9296\n",
      "9297\n",
      "9298\n",
      "9299\n",
      "9300\n",
      "9301\n",
      "9302\n",
      "9303\n",
      "9304\n",
      "9305\n",
      "9306\n",
      "9307\n",
      "9308\n",
      "9309\n",
      "9310\n",
      "9311\n",
      "9312\n",
      "9313\n",
      "9314\n",
      "9315\n",
      "9316\n",
      "9317\n",
      "9318\n",
      "9319\n",
      "9320\n",
      "9321\n",
      "9322\n",
      "9323\n",
      "9324\n",
      "9325\n",
      "9326\n",
      "9327\n",
      "9328\n",
      "9329\n",
      "9330\n",
      "9331\n",
      "9332\n",
      "9333\n",
      "9334\n",
      "9335\n",
      "9336\n",
      "9337\n",
      "9338\n",
      "9339\n",
      "9340\n",
      "9341\n",
      "9342\n",
      "9343\n",
      "9344\n",
      "9345\n",
      "9346\n",
      "9347\n",
      "9348\n",
      "9349\n",
      "9350\n",
      "9351\n",
      "9352\n",
      "9353\n",
      "9354\n",
      "9355\n",
      "9356\n",
      "9357\n",
      "9358\n",
      "9359\n",
      "9360\n",
      "9361\n",
      "9362\n",
      "9363\n",
      "9364\n",
      "9365\n",
      "9366\n",
      "9367\n",
      "9368\n",
      "9369\n",
      "9370\n",
      "9371\n",
      "9372\n",
      "9373\n",
      "9374\n",
      "9375\n",
      "9376\n",
      "9377\n",
      "9378\n",
      "9379\n",
      "9380\n",
      "9381\n",
      "9382\n",
      "9383\n",
      "9384\n",
      "9385\n",
      "9386\n",
      "9387\n",
      "9388\n",
      "9389\n",
      "9390\n",
      "9391\n",
      "9392\n",
      "9393\n",
      "9394\n",
      "9395\n",
      "9396\n",
      "9397\n",
      "9398\n",
      "9399\n",
      "9400\n",
      "9401\n",
      "9402\n",
      "9403\n",
      "9404\n",
      "9405\n",
      "9406\n",
      "9407\n",
      "9408\n",
      "9409\n",
      "9410\n",
      "9411\n",
      "9412\n",
      "9413\n",
      "9414\n",
      "9415\n",
      "9416\n",
      "9417\n",
      "9418\n",
      "9419\n",
      "9420\n",
      "9421\n",
      "9422\n",
      "9423\n",
      "9424\n",
      "9425\n",
      "9426\n",
      "9427\n",
      "9428\n",
      "9429\n",
      "9430\n",
      "9431\n",
      "9432\n",
      "9433\n",
      "9434\n",
      "9435\n",
      "9436\n",
      "9437\n",
      "9438\n",
      "9439\n",
      "9440\n",
      "9441\n",
      "9442\n",
      "9443\n",
      "9444\n",
      "9445\n",
      "9446\n",
      "9447\n",
      "9448\n",
      "9449\n",
      "9450\n",
      "9451\n",
      "9452\n",
      "9453\n",
      "9454\n",
      "9455\n",
      "9456\n",
      "9457\n",
      "9458\n",
      "9459\n",
      "9460\n",
      "9461\n",
      "9462\n",
      "9463\n",
      "9464\n",
      "9465\n",
      "9466\n",
      "9467\n",
      "9468\n",
      "9469\n",
      "9470\n",
      "9471\n",
      "9472\n",
      "9473\n",
      "9474\n",
      "9475\n",
      "9476\n",
      "9477\n",
      "9478\n",
      "9479\n",
      "9480\n",
      "9481\n",
      "9482\n",
      "9483\n",
      "9484\n",
      "9485\n",
      "9486\n",
      "9487\n",
      "9488\n",
      "9489\n",
      "9490\n",
      "9491\n",
      "9492\n",
      "9493\n",
      "9494\n",
      "9495\n",
      "9496\n",
      "9497\n",
      "9498\n",
      "9499\n",
      "9500\n",
      "9501\n",
      "9502\n",
      "9503\n",
      "9504\n",
      "9505\n",
      "9506\n",
      "9507\n",
      "9508\n",
      "9509\n",
      "9510\n",
      "9511\n",
      "9512\n",
      "9513\n",
      "9514\n",
      "9515\n",
      "9516\n",
      "9517\n",
      "9518\n",
      "9519\n",
      "9520\n",
      "9521\n",
      "9522\n",
      "9523\n",
      "9524\n",
      "9525\n",
      "9526\n",
      "9527\n",
      "9528\n",
      "9529\n",
      "9530\n",
      "9531\n",
      "9532\n",
      "9533\n",
      "9534\n",
      "9535\n",
      "9536\n",
      "9537\n",
      "9538\n",
      "9539\n",
      "9540\n",
      "9541\n",
      "9542\n",
      "9543\n",
      "9544\n",
      "9545\n",
      "9546\n",
      "9547\n",
      "9548\n",
      "9549\n",
      "9550\n",
      "9551\n",
      "9552\n",
      "9553\n",
      "9554\n",
      "9555\n",
      "9556\n",
      "9557\n",
      "9558\n",
      "9559\n",
      "9560\n",
      "9561\n",
      "9562\n",
      "9563\n",
      "9564\n",
      "9565\n",
      "9566\n",
      "9567\n",
      "9568\n",
      "9569\n",
      "9570\n",
      "9571\n",
      "9572\n",
      "9573\n",
      "9574\n",
      "9575\n",
      "9576\n",
      "9577\n",
      "9578\n",
      "9579\n",
      "9580\n",
      "9581\n",
      "9582\n",
      "9583\n",
      "9584\n",
      "9585\n",
      "9586\n",
      "9587\n",
      "9588\n",
      "9589\n",
      "9590\n",
      "9591\n",
      "9592\n",
      "9593\n",
      "9594\n",
      "9595\n",
      "9596\n",
      "9597\n",
      "9598\n",
      "9599\n",
      "9600\n",
      "9601\n",
      "9602\n",
      "9603\n",
      "9604\n",
      "9605\n",
      "9606\n",
      "9607\n",
      "9608\n",
      "9609\n",
      "9610\n",
      "9611\n",
      "9612\n",
      "9613\n",
      "9614\n",
      "9615\n",
      "9616\n",
      "9617\n",
      "9618\n",
      "9619\n",
      "9620\n",
      "9621\n",
      "9622\n",
      "9623\n",
      "9624\n",
      "9625\n",
      "9626\n",
      "9627\n",
      "9628\n",
      "9629\n",
      "9630\n",
      "9631\n",
      "9632\n",
      "9633\n",
      "9634\n",
      "9635\n",
      "9636\n",
      "9637\n",
      "9638\n",
      "9639\n",
      "9640\n",
      "9641\n",
      "9642\n",
      "9643\n",
      "9644\n",
      "9645\n",
      "9646\n",
      "9647\n",
      "9648\n",
      "9649\n",
      "9650\n",
      "9651\n",
      "9652\n",
      "9653\n",
      "9654\n",
      "9655\n",
      "9656\n",
      "9657\n",
      "9658\n",
      "9659\n",
      "9660\n",
      "9661\n",
      "9662\n",
      "9663\n",
      "9664\n",
      "9665\n",
      "9666\n",
      "9667\n",
      "9668\n",
      "9669\n",
      "9670\n",
      "9671\n",
      "9672\n",
      "9673\n",
      "9674\n",
      "9675\n",
      "9676\n",
      "9677\n",
      "9678\n",
      "9679\n",
      "9680\n",
      "9681\n",
      "9682\n",
      "9683\n",
      "9684\n",
      "9685\n",
      "9686\n",
      "9687\n",
      "9688\n",
      "9689\n",
      "9690\n",
      "9691\n",
      "9692\n",
      "9693\n",
      "9694\n",
      "9695\n",
      "9696\n",
      "9697\n",
      "9698\n",
      "9699\n",
      "9700\n",
      "9701\n",
      "9702\n",
      "9703\n",
      "9704\n",
      "9705\n",
      "9706\n",
      "9707\n",
      "9708\n",
      "9709\n",
      "9710\n",
      "9711\n",
      "9712\n",
      "9713\n",
      "9714\n",
      "9715\n",
      "9716\n",
      "9717\n",
      "9718\n",
      "9719\n",
      "9720\n",
      "9721\n",
      "9722\n",
      "9723\n",
      "9724\n",
      "9725\n",
      "9726\n",
      "9727\n",
      "9728\n",
      "9729\n",
      "9730\n",
      "9731\n",
      "9732\n",
      "9733\n",
      "9734\n",
      "9735\n",
      "9736\n",
      "9737\n",
      "9738\n",
      "9739\n",
      "9740\n",
      "9741\n",
      "9742\n",
      "9743\n",
      "9744\n",
      "9745\n",
      "9746\n",
      "9747\n",
      "9748\n",
      "9749\n",
      "9750\n",
      "9751\n",
      "9752\n",
      "9753\n",
      "9754\n",
      "9755\n",
      "9756\n",
      "9757\n",
      "9758\n",
      "9759\n",
      "9760\n",
      "9761\n",
      "9762\n",
      "9763\n",
      "9764\n",
      "9765\n",
      "9766\n",
      "9767\n",
      "9768\n",
      "9769\n",
      "9770\n",
      "9771\n",
      "9772\n",
      "9773\n",
      "9774\n",
      "9775\n",
      "9776\n",
      "9777\n",
      "9778\n",
      "9779\n",
      "9780\n",
      "9781\n",
      "9782\n",
      "9783\n",
      "9784\n",
      "9785\n",
      "9786\n",
      "9787\n",
      "9788\n",
      "9789\n",
      "9790\n",
      "9791\n",
      "9792\n",
      "9793\n",
      "9794\n",
      "9795\n",
      "9796\n",
      "9797\n",
      "9798\n",
      "9799\n",
      "9800\n",
      "9801\n",
      "9802\n",
      "9803\n",
      "9804\n",
      "9805\n",
      "9806\n",
      "9807\n",
      "9808\n",
      "9809\n",
      "9810\n",
      "9811\n",
      "9812\n",
      "9813\n",
      "9814\n",
      "9815\n",
      "9816\n",
      "9817\n",
      "9818\n",
      "9819\n",
      "9820\n",
      "9821\n",
      "9822\n",
      "9823\n",
      "9824\n",
      "9825\n",
      "9826\n",
      "9827\n",
      "9828\n",
      "9829\n",
      "9830\n",
      "9831\n",
      "9832\n",
      "9833\n",
      "9834\n",
      "9835\n",
      "9836\n",
      "9837\n",
      "9838\n",
      "9839\n",
      "9840\n",
      "9841\n",
      "9842\n",
      "9843\n",
      "9844\n",
      "9845\n",
      "9846\n",
      "9847\n",
      "9848\n",
      "9849\n",
      "9850\n",
      "9851\n",
      "9852\n",
      "9853\n",
      "9854\n",
      "9855\n",
      "9856\n",
      "9857\n",
      "9858\n",
      "9859\n",
      "9860\n",
      "9861\n",
      "9862\n",
      "9863\n",
      "9864\n",
      "9865\n",
      "9866\n",
      "9867\n",
      "9868\n",
      "9869\n",
      "9870\n",
      "9871\n",
      "9872\n",
      "9873\n",
      "9874\n",
      "9875\n",
      "9876\n",
      "9877\n",
      "9878\n",
      "9879\n",
      "9880\n",
      "9881\n",
      "9882\n",
      "9883\n",
      "9884\n",
      "9885\n",
      "9886\n",
      "9887\n",
      "9888\n",
      "9889\n",
      "9890\n",
      "9891\n",
      "9892\n",
      "9893\n",
      "9894\n",
      "9895\n",
      "9896\n",
      "9897\n",
      "9898\n",
      "9899\n",
      "9900\n",
      "9901\n",
      "9902\n",
      "9903\n",
      "9904\n",
      "9905\n",
      "9906\n",
      "9907\n",
      "9908\n",
      "9909\n",
      "9910\n",
      "9911\n",
      "9912\n",
      "9913\n",
      "9914\n",
      "9915\n",
      "9916\n",
      "9917\n",
      "9918\n",
      "9919\n",
      "9920\n",
      "9921\n",
      "9922\n",
      "9923\n",
      "9924\n",
      "9925\n",
      "9926\n",
      "9927\n",
      "9928\n",
      "9929\n",
      "9930\n",
      "9931\n",
      "9932\n",
      "9933\n",
      "9934\n",
      "9935\n",
      "9936\n",
      "9937\n",
      "9938\n",
      "9939\n",
      "9940\n",
      "9941\n",
      "9942\n",
      "9943\n",
      "9944\n",
      "9945\n",
      "9946\n",
      "9947\n",
      "9948\n",
      "9949\n",
      "9950\n",
      "9951\n",
      "9952\n",
      "9953\n",
      "9954\n",
      "9955\n",
      "9956\n",
      "9957\n",
      "9958\n",
      "9959\n",
      "9960\n",
      "9961\n",
      "9962\n",
      "9963\n",
      "9964\n",
      "9965\n",
      "9966\n",
      "9967\n",
      "9968\n",
      "9969\n",
      "9970\n",
      "9971\n",
      "9972\n",
      "9973\n",
      "9974\n",
      "9975\n",
      "9976\n",
      "9977\n",
      "9978\n",
      "9979\n",
      "9980\n",
      "9981\n",
      "9982\n",
      "9983\n",
      "9984\n",
      "9985\n",
      "9986\n",
      "9987\n",
      "9988\n",
      "9989\n",
      "9990\n",
      "9991\n",
      "9992\n",
      "9993\n",
      "9994\n",
      "9995\n",
      "9996\n",
      "9997\n",
      "9998\n",
      "9999\n",
      "10000\n",
      "10001\n",
      "10002\n",
      "10003\n",
      "10004\n",
      "10005\n",
      "10006\n",
      "10007\n",
      "10008\n",
      "10009\n",
      "10010\n",
      "10011\n",
      "10012\n",
      "10013\n",
      "10014\n",
      "10015\n",
      "10016\n",
      "10017\n",
      "10018\n",
      "10019\n",
      "10020\n",
      "10021\n",
      "10022\n",
      "10023\n",
      "10024\n",
      "10025\n",
      "10026\n",
      "10027\n",
      "10028\n",
      "10029\n",
      "10030\n",
      "10031\n",
      "10032\n",
      "10033\n",
      "10034\n",
      "10035\n",
      "10036\n",
      "10037\n",
      "10038\n",
      "10039\n",
      "10040\n",
      "10041\n",
      "10042\n",
      "10043\n",
      "10044\n",
      "10045\n",
      "10046\n",
      "10047\n",
      "10048\n",
      "10049\n",
      "10050\n",
      "10051\n",
      "10052\n",
      "10053\n",
      "10054\n",
      "10055\n",
      "10056\n",
      "10057\n",
      "10058\n",
      "10059\n",
      "10060\n",
      "10061\n",
      "10062\n",
      "10063\n",
      "10064\n",
      "10065\n",
      "10066\n",
      "10067\n",
      "10068\n",
      "10069\n",
      "10070\n",
      "10071\n",
      "10072\n",
      "10073\n",
      "10074\n",
      "10075\n",
      "10076\n",
      "10077\n",
      "10078\n",
      "10079\n",
      "10080\n",
      "10081\n",
      "10082\n",
      "10083\n",
      "10084\n",
      "10085\n",
      "10086\n",
      "10087\n",
      "10088\n",
      "10089\n",
      "10090\n",
      "10091\n",
      "10092\n",
      "10093\n",
      "10094\n",
      "10095\n",
      "10096\n",
      "10097\n",
      "10098\n",
      "10099\n",
      "10100\n",
      "10101\n",
      "10102\n",
      "10103\n",
      "10104\n",
      "10105\n",
      "10106\n",
      "10107\n",
      "10108\n",
      "10109\n",
      "10110\n",
      "10111\n",
      "10112\n",
      "10113\n",
      "10114\n",
      "10115\n",
      "10116\n",
      "10117\n",
      "10118\n",
      "10119\n",
      "10120\n",
      "10121\n",
      "10122\n",
      "10123\n",
      "10124\n",
      "10125\n",
      "10126\n",
      "10127\n",
      "10128\n",
      "10129\n",
      "10130\n",
      "10131\n",
      "10132\n",
      "10133\n",
      "10134\n",
      "10135\n",
      "10136\n",
      "10137\n",
      "10138\n",
      "10139\n",
      "10140\n",
      "10141\n",
      "10142\n",
      "10143\n",
      "10144\n",
      "10145\n",
      "10146\n",
      "10147\n",
      "10148\n",
      "10149\n",
      "10150\n",
      "10151\n",
      "10152\n",
      "10153\n",
      "10154\n",
      "10155\n",
      "10156\n",
      "10157\n",
      "10158\n",
      "10159\n",
      "10160\n",
      "10161\n",
      "10162\n",
      "10163\n",
      "10164\n",
      "10165\n",
      "10166\n",
      "10167\n",
      "10168\n",
      "10169\n",
      "10170\n",
      "10171\n",
      "10172\n",
      "10173\n",
      "10174\n",
      "10175\n",
      "10176\n",
      "10177\n",
      "10178\n",
      "10179\n",
      "10180\n",
      "10181\n",
      "10182\n",
      "10183\n",
      "10184\n",
      "10185\n",
      "10186\n",
      "10187\n",
      "10188\n",
      "10189\n",
      "10190\n",
      "10191\n",
      "10192\n",
      "10193\n",
      "10194\n",
      "10195\n",
      "10196\n",
      "10197\n",
      "10198\n",
      "10199\n",
      "10200\n",
      "10201\n",
      "10202\n",
      "10203\n",
      "10204\n",
      "10205\n",
      "10206\n",
      "10207\n",
      "10208\n",
      "10209\n",
      "10210\n",
      "10211\n",
      "10212\n",
      "10213\n",
      "10214\n",
      "10215\n",
      "10216\n",
      "10217\n",
      "10218\n",
      "10219\n",
      "10220\n",
      "10221\n",
      "10222\n",
      "10223\n",
      "10224\n",
      "10225\n",
      "10226\n",
      "10227\n",
      "10228\n",
      "10229\n",
      "10230\n",
      "10231\n",
      "10232\n",
      "10233\n",
      "10234\n",
      "10235\n",
      "10236\n",
      "10237\n",
      "10238\n",
      "10239\n",
      "10240\n",
      "10241\n",
      "10242\n",
      "10243\n",
      "10244\n",
      "10245\n",
      "10246\n",
      "10247\n",
      "10248\n",
      "10249\n",
      "10250\n",
      "10251\n",
      "10252\n",
      "10253\n",
      "10254\n",
      "10255\n",
      "10256\n",
      "10257\n",
      "10258\n",
      "10259\n",
      "10260\n",
      "10261\n",
      "10262\n",
      "10263\n",
      "10264\n",
      "10265\n",
      "10266\n",
      "10267\n",
      "10268\n",
      "10269\n",
      "10270\n",
      "10271\n",
      "10272\n",
      "10273\n",
      "10274\n",
      "10275\n",
      "10276\n",
      "10277\n",
      "10278\n",
      "10279\n",
      "10280\n",
      "10281\n",
      "10282\n",
      "10283\n",
      "10284\n",
      "10285\n",
      "10286\n",
      "10287\n",
      "10288\n",
      "10289\n",
      "10290\n",
      "10291\n",
      "10292\n",
      "10293\n",
      "10294\n",
      "10295\n",
      "10296\n",
      "10297\n",
      "10298\n",
      "10299\n",
      "10300\n",
      "10301\n",
      "10302\n",
      "10303\n",
      "10304\n",
      "10305\n",
      "10306\n",
      "10307\n",
      "10308\n",
      "10309\n",
      "10310\n",
      "10311\n",
      "10312\n",
      "10313\n",
      "10314\n",
      "10315\n",
      "10316\n",
      "10317\n",
      "10318\n",
      "10319\n",
      "10320\n",
      "10321\n",
      "10322\n",
      "10323\n",
      "10324\n",
      "10325\n",
      "10326\n",
      "10327\n",
      "10328\n",
      "10329\n",
      "10330\n",
      "10331\n",
      "10332\n",
      "10333\n",
      "10334\n",
      "10335\n",
      "10336\n",
      "10337\n",
      "10338\n",
      "10339\n",
      "10340\n",
      "10341\n",
      "10342\n",
      "10343\n",
      "10344\n",
      "10345\n",
      "10346\n",
      "10347\n",
      "10348\n",
      "10349\n",
      "10350\n",
      "10351\n",
      "10352\n",
      "10353\n",
      "10354\n",
      "10355\n",
      "10356\n",
      "10357\n",
      "10358\n",
      "10359\n",
      "10360\n",
      "10361\n",
      "10362\n",
      "10363\n",
      "10364\n",
      "10365\n",
      "10366\n",
      "10367\n",
      "10368\n",
      "10369\n",
      "10370\n",
      "10371\n",
      "10372\n",
      "10373\n",
      "10374\n",
      "10375\n",
      "10376\n",
      "10377\n",
      "10378\n",
      "10379\n",
      "10380\n",
      "10381\n",
      "10382\n",
      "10383\n",
      "10384\n",
      "10385\n",
      "10386\n",
      "10387\n",
      "10388\n",
      "10389\n",
      "10390\n",
      "10391\n",
      "10392\n",
      "10393\n",
      "10394\n",
      "10395\n",
      "10396\n",
      "10397\n",
      "10398\n",
      "10399\n",
      "10400\n",
      "10401\n",
      "10402\n",
      "10403\n",
      "10404\n",
      "10405\n",
      "10406\n",
      "10407\n",
      "10408\n",
      "10409\n",
      "10410\n",
      "10411\n",
      "10412\n",
      "10413\n",
      "10414\n",
      "10415\n",
      "10416\n",
      "10417\n",
      "10418\n",
      "10419\n",
      "10420\n",
      "10421\n",
      "10422\n",
      "10423\n",
      "10424\n",
      "10425\n",
      "10426\n",
      "10427\n",
      "10428\n",
      "10429\n",
      "10430\n",
      "10431\n",
      "10432\n",
      "10433\n",
      "10434\n",
      "10435\n",
      "10436\n",
      "10437\n",
      "10438\n",
      "10439\n",
      "10440\n",
      "10441\n",
      "10442\n",
      "10443\n",
      "10444\n",
      "10445\n",
      "10446\n",
      "10447\n",
      "10448\n",
      "10449\n",
      "10450\n",
      "10451\n",
      "10452\n",
      "10453\n",
      "10454\n",
      "10455\n",
      "10456\n",
      "10457\n",
      "10458\n",
      "10459\n",
      "10460\n",
      "10461\n",
      "10462\n",
      "10463\n",
      "10464\n",
      "10465\n",
      "10466\n",
      "10467\n",
      "10468\n",
      "10469\n",
      "10470\n",
      "10471\n",
      "10472\n",
      "10473\n",
      "10474\n",
      "10475\n",
      "10476\n",
      "10477\n",
      "10478\n",
      "10479\n",
      "10480\n",
      "10481\n",
      "10482\n",
      "10483\n",
      "10484\n",
      "10485\n",
      "10486\n",
      "10487\n",
      "10488\n",
      "10489\n",
      "10490\n",
      "10491\n",
      "10492\n",
      "10493\n",
      "10494\n",
      "10495\n",
      "10496\n",
      "10497\n",
      "10498\n",
      "10499\n",
      "10500\n",
      "10501\n",
      "10502\n",
      "10503\n",
      "10504\n",
      "10505\n",
      "10506\n",
      "10507\n",
      "10508\n",
      "10509\n",
      "10510\n",
      "10511\n",
      "10512\n",
      "10513\n",
      "10514\n",
      "10515\n",
      "10516\n",
      "10517\n",
      "10518\n",
      "10519\n",
      "10520\n",
      "10521\n",
      "10522\n",
      "10523\n",
      "10524\n",
      "10525\n",
      "10526\n",
      "10527\n",
      "10528\n",
      "10529\n",
      "10530\n",
      "10531\n",
      "10532\n",
      "10533\n",
      "10534\n",
      "10535\n",
      "10536\n",
      "10537\n",
      "10538\n",
      "10539\n",
      "10540\n",
      "10541\n",
      "10542\n",
      "10543\n",
      "10544\n",
      "10545\n",
      "10546\n",
      "10547\n",
      "10548\n",
      "10549\n",
      "10550\n",
      "10551\n",
      "10552\n",
      "10553\n",
      "10554\n",
      "10555\n",
      "10556\n",
      "10557\n",
      "10558\n",
      "10559\n",
      "10560\n",
      "10561\n",
      "10562\n",
      "10563\n",
      "10564\n",
      "10565\n",
      "10566\n",
      "10567\n",
      "10568\n",
      "10569\n",
      "10570\n",
      "10571\n",
      "10572\n",
      "10573\n",
      "10574\n",
      "10575\n",
      "10576\n",
      "10577\n",
      "10578\n",
      "10579\n",
      "10580\n",
      "10581\n",
      "10582\n",
      "10583\n",
      "10584\n",
      "10585\n",
      "10586\n",
      "10587\n",
      "10588\n",
      "10589\n",
      "10590\n",
      "10591\n",
      "10592\n",
      "10593\n",
      "10594\n",
      "10595\n",
      "10596\n",
      "10597\n",
      "10598\n",
      "10599\n",
      "10600\n",
      "10601\n",
      "10602\n",
      "10603\n",
      "10604\n",
      "10605\n",
      "10606\n",
      "10607\n",
      "10608\n",
      "10609\n",
      "10610\n",
      "10611\n",
      "10612\n",
      "10613\n",
      "10614\n",
      "10615\n",
      "10616\n",
      "10617\n",
      "10618\n",
      "10619\n",
      "10620\n",
      "10621\n",
      "10622\n",
      "10623\n",
      "10624\n",
      "10625\n",
      "10626\n",
      "10627\n",
      "10628\n",
      "10629\n",
      "10630\n",
      "10631\n",
      "10632\n",
      "10633\n",
      "10634\n",
      "10635\n",
      "10636\n",
      "10637\n",
      "10638\n",
      "10639\n",
      "10640\n",
      "10641\n",
      "10642\n",
      "10643\n",
      "10644\n",
      "10645\n",
      "10646\n",
      "10647\n",
      "10648\n",
      "10649\n",
      "10650\n",
      "10651\n",
      "10652\n",
      "10653\n",
      "10654\n",
      "10655\n",
      "10656\n",
      "10657\n",
      "10658\n",
      "10659\n",
      "10660\n",
      "10661\n",
      "10662\n",
      "10663\n",
      "10664\n",
      "10665\n",
      "10666\n",
      "10667\n",
      "10668\n",
      "10669\n",
      "10670\n",
      "10671\n",
      "10672\n",
      "10673\n",
      "10674\n",
      "10675\n",
      "10676\n",
      "10677\n",
      "10678\n",
      "10679\n",
      "10680\n",
      "10681\n",
      "10682\n",
      "10683\n",
      "10684\n",
      "10685\n",
      "10686\n",
      "10687\n",
      "10688\n",
      "10689\n",
      "10690\n",
      "10691\n",
      "10692\n",
      "10693\n",
      "10694\n",
      "10695\n",
      "10696\n",
      "10697\n",
      "10698\n",
      "10699\n",
      "10700\n",
      "10701\n",
      "10702\n",
      "10703\n",
      "10704\n",
      "10705\n",
      "10706\n",
      "10707\n",
      "10708\n",
      "10709\n",
      "10710\n",
      "10711\n",
      "10712\n",
      "10713\n",
      "10714\n",
      "10715\n",
      "10716\n",
      "10717\n",
      "10718\n",
      "10719\n",
      "10720\n",
      "10721\n",
      "10722\n",
      "10723\n",
      "10724\n",
      "10725\n",
      "10726\n",
      "10727\n",
      "10728\n",
      "10729\n",
      "10730\n",
      "10731\n",
      "10732\n",
      "10733\n",
      "10734\n",
      "10735\n",
      "10736\n",
      "10737\n",
      "10738\n",
      "10739\n",
      "10740\n",
      "10741\n",
      "10742\n",
      "10743\n",
      "10744\n",
      "10745\n",
      "10746\n",
      "10747\n",
      "10748\n",
      "10749\n",
      "10750\n",
      "10751\n",
      "10752\n",
      "10753\n",
      "10754\n",
      "10755\n",
      "10756\n",
      "10757\n",
      "10758\n",
      "10759\n",
      "10760\n",
      "10761\n",
      "10762\n",
      "10763\n",
      "10764\n",
      "10765\n",
      "10766\n",
      "10767\n",
      "10768\n",
      "10769\n",
      "10770\n",
      "10771\n",
      "10772\n",
      "10773\n",
      "10774\n",
      "10775\n",
      "10776\n",
      "10777\n",
      "10778\n",
      "10779\n",
      "10780\n",
      "10781\n",
      "10782\n",
      "10783\n",
      "10784\n",
      "10785\n",
      "10786\n",
      "10787\n",
      "10788\n",
      "10789\n",
      "10790\n",
      "10791\n",
      "10792\n",
      "10793\n",
      "10794\n",
      "10795\n",
      "10796\n",
      "10797\n",
      "10798\n",
      "10799\n",
      "10800\n",
      "10801\n",
      "10802\n",
      "10803\n",
      "10804\n",
      "10805\n",
      "10806\n",
      "10807\n",
      "10808\n",
      "10809\n",
      "10810\n",
      "10811\n",
      "10812\n",
      "10813\n",
      "10814\n",
      "10815\n",
      "10816\n",
      "10817\n",
      "10818\n",
      "10819\n",
      "10820\n",
      "10821\n",
      "10822\n",
      "10823\n",
      "10824\n",
      "10825\n",
      "10826\n",
      "10827\n",
      "10828\n",
      "10829\n",
      "10830\n",
      "10831\n",
      "10832\n",
      "10833\n",
      "10834\n",
      "10835\n",
      "10836\n",
      "10837\n",
      "10838\n",
      "10839\n",
      "10840\n",
      "10841\n",
      "10842\n",
      "10843\n",
      "10844\n",
      "10845\n",
      "10846\n",
      "10847\n",
      "10848\n",
      "10849\n",
      "10850\n",
      "10851\n",
      "10852\n",
      "10853\n",
      "10854\n",
      "10855\n",
      "10856\n",
      "10857\n",
      "10858\n",
      "10859\n",
      "10860\n",
      "10861\n",
      "10862\n",
      "10863\n",
      "10864\n",
      "10865\n",
      "10866\n",
      "10867\n",
      "10868\n",
      "10869\n",
      "10870\n",
      "10871\n",
      "10872\n",
      "10873\n",
      "10874\n",
      "10875\n",
      "10876\n",
      "10877\n",
      "10878\n",
      "10879\n",
      "10880\n",
      "10881\n",
      "10882\n",
      "10883\n",
      "10884\n",
      "10885\n",
      "10886\n",
      "10887\n",
      "10888\n",
      "10889\n",
      "10890\n",
      "10891\n",
      "10892\n",
      "10893\n",
      "10894\n",
      "10895\n",
      "10896\n",
      "10897\n",
      "10898\n",
      "10899\n",
      "10900\n",
      "10901\n",
      "10902\n",
      "10903\n",
      "10904\n",
      "10905\n",
      "10906\n",
      "10907\n",
      "10908\n",
      "10909\n",
      "10910\n",
      "10911\n",
      "10912\n",
      "10913\n",
      "10914\n",
      "10915\n",
      "10916\n",
      "10917\n",
      "10918\n",
      "10919\n",
      "10920\n",
      "10921\n",
      "10922\n",
      "10923\n",
      "10924\n",
      "10925\n",
      "10926\n",
      "10927\n",
      "10928\n",
      "10929\n",
      "10930\n",
      "10931\n",
      "10932\n",
      "10933\n",
      "10934\n",
      "10935\n",
      "10936\n",
      "10937\n",
      "10938\n",
      "10939\n",
      "10940\n",
      "10941\n",
      "10942\n",
      "10943\n",
      "10944\n",
      "10945\n",
      "10946\n",
      "10947\n",
      "10948\n",
      "10949\n",
      "10950\n",
      "10951\n",
      "10952\n",
      "10953\n",
      "10954\n",
      "10955\n",
      "10956\n",
      "10957\n",
      "10958\n",
      "10959\n",
      "10960\n",
      "10961\n",
      "10962\n",
      "10963\n",
      "10964\n",
      "10965\n",
      "10966\n",
      "10967\n",
      "10968\n",
      "10969\n",
      "10970\n",
      "10971\n",
      "10972\n",
      "10973\n",
      "10974\n",
      "10975\n",
      "10976\n",
      "10977\n",
      "10978\n",
      "10979\n",
      "10980\n",
      "10981\n",
      "10982\n",
      "10983\n",
      "10984\n",
      "10985\n",
      "10986\n",
      "10987\n",
      "10988\n",
      "10989\n",
      "10990\n",
      "10991\n",
      "10992\n",
      "10993\n",
      "10994\n",
      "10995\n",
      "10996\n",
      "10997\n",
      "10998\n",
      "10999\n",
      "11000\n",
      "11001\n",
      "11002\n",
      "11003\n",
      "11004\n",
      "11005\n",
      "11006\n",
      "11007\n",
      "11008\n",
      "11009\n",
      "11010\n",
      "11011\n",
      "11012\n",
      "11013\n",
      "11014\n",
      "11015\n",
      "11016\n",
      "11017\n",
      "11018\n",
      "11019\n",
      "11020\n",
      "11021\n",
      "11022\n",
      "11023\n",
      "11024\n",
      "11025\n",
      "11026\n",
      "11027\n",
      "11028\n",
      "11029\n",
      "11030\n",
      "11031\n",
      "11032\n",
      "11033\n",
      "11034\n",
      "11035\n",
      "11036\n",
      "11037\n",
      "11038\n",
      "11039\n",
      "11040\n",
      "11041\n",
      "11042\n",
      "11043\n",
      "11044\n",
      "11045\n",
      "11046\n",
      "11047\n",
      "11048\n",
      "11049\n",
      "11050\n",
      "11051\n",
      "11052\n",
      "11053\n",
      "11054\n",
      "11055\n",
      "11056\n",
      "11057\n",
      "11058\n",
      "11059\n",
      "11060\n",
      "11061\n",
      "11062\n",
      "11063\n",
      "11064\n",
      "11065\n",
      "11066\n",
      "11067\n",
      "11068\n",
      "11069\n",
      "11070\n",
      "11071\n",
      "11072\n",
      "11073\n",
      "11074\n",
      "11075\n",
      "11076\n",
      "11077\n",
      "11078\n",
      "11079\n",
      "11080\n",
      "11081\n",
      "11082\n",
      "11083\n",
      "11084\n",
      "11085\n",
      "11086\n",
      "11087\n",
      "11088\n",
      "11089\n",
      "11090\n",
      "11091\n",
      "11092\n",
      "11093\n",
      "11094\n",
      "11095\n",
      "11096\n",
      "11097\n",
      "11098\n",
      "11099\n",
      "11100\n",
      "11101\n",
      "11102\n",
      "11103\n",
      "11104\n",
      "11105\n",
      "11106\n",
      "11107\n",
      "11108\n",
      "11109\n",
      "11110\n",
      "11111\n",
      "11112\n",
      "11113\n",
      "11114\n",
      "11115\n",
      "11116\n",
      "11117\n",
      "11118\n",
      "11119\n",
      "11120\n",
      "11121\n",
      "11122\n",
      "11123\n",
      "11124\n",
      "11125\n",
      "11126\n",
      "11127\n",
      "11128\n",
      "11129\n",
      "11130\n",
      "11131\n",
      "11132\n",
      "11133\n",
      "11134\n",
      "11135\n",
      "11136\n",
      "11137\n",
      "11138\n",
      "11139\n",
      "11140\n",
      "11141\n",
      "11142\n",
      "11143\n",
      "11144\n",
      "11145\n",
      "11146\n",
      "11147\n",
      "11148\n",
      "11149\n",
      "11150\n",
      "11151\n",
      "11152\n",
      "11153\n",
      "11154\n",
      "11155\n",
      "11156\n",
      "11157\n",
      "11158\n",
      "11159\n",
      "11160\n",
      "11161\n",
      "11162\n",
      "11163\n",
      "11164\n",
      "11165\n",
      "11166\n",
      "11167\n",
      "11168\n",
      "11169\n",
      "11170\n",
      "11171\n",
      "11172\n",
      "11173\n",
      "11174\n",
      "11175\n",
      "11176\n",
      "11177\n",
      "11178\n",
      "11179\n",
      "11180\n",
      "11181\n",
      "11182\n",
      "11183\n",
      "11184\n",
      "11185\n",
      "11186\n",
      "11187\n",
      "11188\n",
      "11189\n",
      "11190\n",
      "11191\n",
      "11192\n",
      "11193\n",
      "11194\n",
      "11195\n",
      "11196\n",
      "11197\n",
      "11198\n",
      "11199\n",
      "11200\n",
      "11201\n",
      "11202\n",
      "11203\n",
      "11204\n",
      "11205\n",
      "11206\n",
      "11207\n",
      "11208\n",
      "11209\n",
      "11210\n",
      "11211\n",
      "11212\n",
      "11213\n",
      "11214\n",
      "11215\n",
      "11216\n",
      "11217\n",
      "11218\n",
      "11219\n",
      "11220\n",
      "11221\n",
      "11222\n",
      "11223\n",
      "11224\n",
      "11225\n",
      "11226\n",
      "11227\n",
      "11228\n",
      "11229\n",
      "11230\n",
      "11231\n",
      "11232\n",
      "11233\n",
      "11234\n",
      "11235\n",
      "11236\n",
      "11237\n",
      "11238\n",
      "11239\n",
      "11240\n",
      "11241\n",
      "11242\n",
      "11243\n",
      "11244\n",
      "11245\n",
      "11246\n",
      "11247\n",
      "11248\n",
      "11249\n",
      "11250\n",
      "11251\n",
      "11252\n",
      "11253\n",
      "11254\n",
      "11255\n",
      "11256\n",
      "11257\n",
      "11258\n",
      "11259\n",
      "11260\n",
      "11261\n",
      "11262\n",
      "11263\n",
      "11264\n",
      "11265\n",
      "11266\n",
      "11267\n",
      "11268\n",
      "11269\n",
      "11270\n",
      "11271\n",
      "11272\n",
      "11273\n",
      "11274\n",
      "11275\n",
      "11276\n",
      "11277\n",
      "11278\n",
      "11279\n",
      "11280\n",
      "11281\n",
      "11282\n",
      "11283\n",
      "11284\n",
      "11285\n",
      "11286\n",
      "11287\n",
      "11288\n",
      "11289\n",
      "11290\n",
      "11291\n",
      "11292\n",
      "11293\n",
      "11294\n",
      "11295\n",
      "11296\n",
      "11297\n",
      "11298\n",
      "11299\n",
      "11300\n",
      "11301\n",
      "11302\n",
      "11303\n",
      "11304\n",
      "11305\n",
      "11306\n",
      "11307\n",
      "11308\n",
      "11309\n",
      "11310\n",
      "11311\n",
      "11312\n",
      "11313\n",
      "11314\n",
      "11315\n",
      "11316\n",
      "11317\n",
      "11318\n",
      "11319\n",
      "11320\n",
      "11321\n",
      "11322\n",
      "11323\n",
      "11324\n",
      "11325\n",
      "11326\n",
      "11327\n",
      "11328\n",
      "11329\n",
      "11330\n",
      "11331\n",
      "11332\n",
      "11333\n",
      "11334\n",
      "11335\n",
      "11336\n",
      "11337\n",
      "11338\n",
      "11339\n",
      "11340\n",
      "11341\n",
      "11342\n",
      "11343\n",
      "11344\n",
      "11345\n",
      "11346\n",
      "11347\n",
      "11348\n",
      "11349\n",
      "11350\n",
      "11351\n",
      "11352\n",
      "11353\n",
      "11354\n",
      "11355\n",
      "11356\n",
      "11357\n",
      "11358\n",
      "11359\n",
      "11360\n",
      "11361\n",
      "11362\n",
      "11363\n",
      "11364\n",
      "11365\n",
      "11366\n",
      "11367\n",
      "11368\n",
      "11369\n",
      "11370\n",
      "11371\n",
      "11372\n",
      "11373\n",
      "11374\n",
      "11375\n",
      "11376\n",
      "11377\n",
      "11378\n",
      "11379\n",
      "11380\n",
      "11381\n",
      "11382\n",
      "11383\n",
      "11384\n",
      "11385\n",
      "11386\n",
      "11387\n",
      "11388\n",
      "11389\n",
      "11390\n",
      "11391\n",
      "11392\n",
      "11393\n",
      "11394\n",
      "11395\n",
      "11396\n",
      "11397\n",
      "11398\n",
      "11399\n",
      "11400\n",
      "11401\n",
      "11402\n",
      "11403\n",
      "11404\n",
      "11405\n",
      "11406\n",
      "11407\n",
      "11408\n",
      "11409\n",
      "11410\n",
      "11411\n",
      "11412\n",
      "11413\n",
      "11414\n",
      "11415\n",
      "11416\n",
      "11417\n",
      "11418\n",
      "11419\n",
      "11420\n",
      "11421\n",
      "11422\n",
      "11423\n",
      "11424\n",
      "11425\n",
      "11426\n",
      "11427\n",
      "11428\n",
      "11429\n",
      "11430\n",
      "11431\n",
      "11432\n",
      "11433\n",
      "11434\n",
      "11435\n",
      "11436\n",
      "11437\n",
      "11438\n",
      "11439\n",
      "11440\n",
      "11441\n",
      "11442\n",
      "11443\n",
      "11444\n",
      "11445\n",
      "11446\n",
      "11447\n",
      "11448\n",
      "11449\n",
      "11450\n",
      "11451\n",
      "11452\n",
      "11453\n",
      "11454\n",
      "11455\n",
      "11456\n",
      "11457\n",
      "11458\n",
      "11459\n",
      "11460\n",
      "11461\n",
      "11462\n",
      "11463\n",
      "11464\n",
      "11465\n",
      "11466\n",
      "11467\n",
      "11468\n",
      "11469\n",
      "11470\n",
      "11471\n",
      "11472\n",
      "11473\n",
      "11474\n",
      "11475\n",
      "11476\n",
      "11477\n",
      "11478\n",
      "11479\n",
      "11480\n",
      "11481\n",
      "11482\n",
      "11483\n",
      "11484\n",
      "11485\n",
      "11486\n",
      "11487\n",
      "11488\n",
      "11489\n",
      "11490\n",
      "11491\n",
      "11492\n",
      "11493\n",
      "11494\n",
      "11495\n",
      "11496\n",
      "11497\n",
      "11498\n",
      "11499\n",
      "11500\n",
      "11501\n",
      "11502\n",
      "11503\n",
      "11504\n",
      "11505\n",
      "11506\n",
      "11507\n",
      "11508\n",
      "11509\n",
      "11510\n",
      "11511\n",
      "11512\n",
      "11513\n",
      "11514\n",
      "11515\n",
      "11516\n",
      "11517\n",
      "11518\n",
      "11519\n",
      "11520\n",
      "11521\n",
      "11522\n",
      "11523\n",
      "11524\n",
      "11525\n",
      "11526\n",
      "11527\n",
      "11528\n",
      "11529\n",
      "11530\n",
      "11531\n",
      "11532\n",
      "11533\n",
      "11534\n",
      "11535\n",
      "11536\n",
      "11537\n",
      "11538\n",
      "11539\n",
      "11540\n",
      "11541\n",
      "11542\n",
      "11543\n",
      "11544\n",
      "11545\n",
      "11546\n",
      "11547\n",
      "11548\n",
      "11549\n",
      "11550\n",
      "11551\n",
      "11552\n",
      "11553\n",
      "11554\n",
      "11555\n",
      "11556\n",
      "11557\n",
      "11558\n",
      "11559\n",
      "11560\n",
      "11561\n",
      "11562\n",
      "11563\n",
      "11564\n",
      "11565\n",
      "11566\n",
      "11567\n",
      "11568\n",
      "11569\n",
      "11570\n",
      "11571\n",
      "11572\n",
      "11573\n",
      "11574\n",
      "11575\n",
      "11576\n",
      "11577\n",
      "11578\n",
      "11579\n",
      "11580\n",
      "11581\n",
      "11582\n",
      "11583\n",
      "11584\n",
      "11585\n",
      "11586\n",
      "11587\n",
      "11588\n",
      "11589\n",
      "11590\n",
      "11591\n",
      "11592\n",
      "11593\n",
      "11594\n",
      "11595\n",
      "11596\n",
      "11597\n",
      "11598\n",
      "11599\n",
      "11600\n",
      "11601\n",
      "11602\n",
      "11603\n",
      "11604\n",
      "11605\n",
      "11606\n",
      "11607\n",
      "11608\n",
      "11609\n",
      "11610\n",
      "11611\n",
      "11612\n",
      "11613\n",
      "11614\n",
      "11615\n",
      "11616\n",
      "11617\n",
      "11618\n",
      "11619\n",
      "11620\n",
      "11621\n",
      "11622\n",
      "11623\n",
      "11624\n",
      "11625\n",
      "11626\n",
      "11627\n",
      "11628\n",
      "11629\n",
      "11630\n",
      "11631\n",
      "11632\n",
      "11633\n",
      "11634\n",
      "11635\n",
      "11636\n",
      "11637\n",
      "11638\n",
      "11639\n",
      "11640\n",
      "11641\n",
      "11642\n",
      "11643\n",
      "11644\n",
      "11645\n",
      "11646\n",
      "11647\n",
      "11648\n",
      "11649\n",
      "11650\n",
      "11651\n",
      "11652\n",
      "11653\n",
      "11654\n",
      "11655\n",
      "11656\n",
      "11657\n",
      "11658\n",
      "11659\n",
      "11660\n",
      "11661\n",
      "11662\n",
      "11663\n",
      "11664\n",
      "11665\n",
      "11666\n",
      "11667\n",
      "11668\n",
      "11669\n",
      "11670\n",
      "11671\n",
      "11672\n",
      "11673\n",
      "11674\n",
      "11675\n",
      "11676\n",
      "11677\n",
      "11678\n",
      "11679\n",
      "11680\n",
      "11681\n",
      "11682\n",
      "11683\n",
      "11684\n",
      "11685\n",
      "11686\n",
      "11687\n",
      "11688\n",
      "11689\n",
      "11690\n",
      "11691\n",
      "11692\n",
      "11693\n",
      "11694\n",
      "11695\n",
      "11696\n",
      "11697\n",
      "11698\n",
      "11699\n",
      "11700\n",
      "11701\n",
      "11702\n",
      "11703\n",
      "11704\n",
      "11705\n",
      "11706\n",
      "11707\n",
      "11708\n",
      "11709\n",
      "11710\n",
      "11711\n",
      "11712\n",
      "11713\n",
      "11714\n",
      "11715\n",
      "11716\n",
      "11717\n",
      "11718\n",
      "11719\n",
      "11720\n",
      "11721\n",
      "11722\n",
      "11723\n",
      "11724\n",
      "11725\n",
      "11726\n",
      "11727\n",
      "11728\n",
      "11729\n",
      "11730\n",
      "11731\n",
      "11732\n",
      "11733\n",
      "11734\n",
      "11735\n",
      "11736\n",
      "11737\n",
      "11738\n",
      "11739\n",
      "11740\n",
      "11741\n",
      "11742\n",
      "11743\n",
      "11744\n",
      "11745\n",
      "11746\n",
      "11747\n",
      "11748\n",
      "11749\n",
      "11750\n",
      "11751\n",
      "11752\n",
      "11753\n",
      "11754\n",
      "11755\n",
      "11756\n",
      "11757\n",
      "11758\n",
      "11759\n",
      "11760\n",
      "11761\n",
      "11762\n",
      "11763\n",
      "11764\n",
      "11765\n",
      "11766\n",
      "11767\n",
      "11768\n",
      "11769\n",
      "11770\n",
      "11771\n",
      "11772\n",
      "11773\n",
      "11774\n",
      "11775\n",
      "11776\n",
      "11777\n",
      "11778\n",
      "11779\n",
      "11780\n",
      "11781\n",
      "11782\n",
      "11783\n",
      "11784\n",
      "11785\n",
      "11786\n",
      "11787\n",
      "11788\n",
      "11789\n",
      "11790\n",
      "11791\n",
      "11792\n",
      "11793\n",
      "11794\n",
      "11795\n",
      "11796\n",
      "11797\n",
      "11798\n",
      "11799\n",
      "11800\n",
      "11801\n",
      "11802\n",
      "11803\n",
      "11804\n",
      "11805\n",
      "11806\n",
      "11807\n",
      "11808\n",
      "11809\n",
      "11810\n",
      "11811\n",
      "11812\n",
      "11813\n",
      "11814\n",
      "11815\n",
      "11816\n",
      "11817\n",
      "11818\n",
      "11819\n",
      "11820\n",
      "11821\n",
      "11822\n",
      "11823\n",
      "11824\n",
      "11825\n",
      "11826\n",
      "11827\n",
      "11828\n",
      "11829\n",
      "11830\n",
      "11831\n",
      "11832\n",
      "11833\n",
      "11834\n",
      "11835\n",
      "11836\n",
      "11837\n",
      "11838\n",
      "11839\n",
      "11840\n",
      "11841\n",
      "11842\n",
      "11843\n",
      "11844\n",
      "11845\n",
      "11846\n",
      "11847\n",
      "11848\n",
      "11849\n",
      "11850\n",
      "11851\n",
      "11852\n",
      "11853\n",
      "11854\n",
      "11855\n",
      "11856\n",
      "11857\n",
      "11858\n",
      "11859\n",
      "11860\n",
      "11861\n",
      "11862\n",
      "11863\n",
      "11864\n",
      "11865\n",
      "11866\n",
      "11867\n",
      "11868\n",
      "11869\n",
      "11870\n",
      "11871\n",
      "11872\n",
      "11873\n",
      "11874\n",
      "11875\n",
      "11876\n",
      "11877\n",
      "11878\n",
      "11879\n",
      "11880\n",
      "11881\n",
      "11882\n",
      "11883\n",
      "11884\n",
      "11885\n",
      "11886\n",
      "11887\n",
      "11888\n",
      "11889\n",
      "11890\n",
      "11891\n",
      "11892\n",
      "11893\n",
      "11894\n",
      "11895\n",
      "11896\n",
      "11897\n",
      "11898\n",
      "11899\n",
      "11900\n",
      "11901\n",
      "11902\n",
      "11903\n",
      "11904\n",
      "11905\n",
      "11906\n",
      "11907\n",
      "11908\n",
      "11909\n",
      "11910\n",
      "11911\n",
      "11912\n",
      "11913\n",
      "11914\n",
      "11915\n",
      "11916\n",
      "11917\n",
      "11918\n",
      "11919\n",
      "11920\n",
      "11921\n",
      "11922\n",
      "11923\n",
      "11924\n",
      "11925\n",
      "11926\n",
      "11927\n",
      "11928\n",
      "11929\n",
      "11930\n",
      "11931\n",
      "11932\n",
      "11933\n",
      "11934\n",
      "11935\n",
      "11936\n",
      "11937\n",
      "11938\n",
      "11939\n",
      "11940\n",
      "11941\n",
      "11942\n",
      "11943\n",
      "11944\n",
      "11945\n",
      "11946\n",
      "11947\n",
      "11948\n",
      "11949\n",
      "11950\n",
      "11951\n",
      "11952\n",
      "11953\n",
      "11954\n",
      "11955\n",
      "11956\n",
      "11957\n",
      "11958\n",
      "11959\n",
      "11960\n",
      "11961\n",
      "11962\n",
      "11963\n",
      "11964\n",
      "11965\n",
      "11966\n",
      "11967\n",
      "11968\n",
      "11969\n",
      "11970\n",
      "11971\n",
      "11972\n",
      "11973\n",
      "11974\n",
      "11975\n",
      "11976\n",
      "11977\n",
      "11978\n",
      "11979\n",
      "11980\n",
      "11981\n",
      "11982\n",
      "11983\n",
      "11984\n",
      "11985\n",
      "11986\n",
      "11987\n",
      "11988\n",
      "11989\n",
      "11990\n",
      "11991\n",
      "11992\n",
      "11993\n",
      "11994\n",
      "11995\n",
      "11996\n",
      "11997\n",
      "11998\n",
      "11999\n",
      "12000\n",
      "12001\n",
      "12002\n",
      "12003\n",
      "12004\n",
      "12005\n",
      "12006\n",
      "12007\n",
      "12008\n",
      "12009\n",
      "12010\n",
      "12011\n",
      "12012\n",
      "12013\n",
      "12014\n",
      "12015\n",
      "12016\n",
      "12017\n",
      "12018\n",
      "12019\n",
      "12020\n",
      "12021\n",
      "12022\n",
      "12023\n",
      "12024\n",
      "12025\n",
      "12026\n",
      "12027\n",
      "12028\n",
      "12029\n",
      "12030\n",
      "12031\n",
      "12032\n",
      "12033\n",
      "12034\n",
      "12035\n",
      "12036\n",
      "12037\n",
      "12038\n",
      "12039\n",
      "12040\n",
      "12041\n",
      "12042\n",
      "12043\n",
      "12044\n",
      "12045\n",
      "12046\n",
      "12047\n",
      "12048\n",
      "12049\n",
      "12050\n",
      "12051\n",
      "12052\n",
      "12053\n",
      "12054\n",
      "12055\n",
      "12056\n",
      "12057\n",
      "12058\n",
      "12059\n",
      "12060\n",
      "12061\n",
      "12062\n",
      "12063\n",
      "12064\n",
      "12065\n",
      "12066\n",
      "12067\n",
      "12068\n",
      "12069\n",
      "12070\n",
      "12071\n",
      "12072\n",
      "12073\n",
      "12074\n",
      "12075\n",
      "12076\n",
      "12077\n",
      "12078\n",
      "12079\n",
      "12080\n",
      "12081\n",
      "12082\n",
      "12083\n",
      "12084\n",
      "12085\n",
      "12086\n",
      "12087\n",
      "12088\n",
      "12089\n",
      "12090\n",
      "12091\n",
      "12092\n",
      "12093\n",
      "12094\n",
      "12095\n",
      "12096\n",
      "12097\n",
      "12098\n",
      "12099\n",
      "12100\n",
      "12101\n",
      "12102\n",
      "12103\n",
      "12104\n",
      "12105\n",
      "12106\n",
      "12107\n",
      "12108\n",
      "12109\n",
      "12110\n",
      "12111\n",
      "12112\n",
      "12113\n",
      "12114\n",
      "12115\n",
      "12116\n",
      "12117\n",
      "12118\n",
      "12119\n",
      "12120\n",
      "12121\n",
      "12122\n",
      "12123\n",
      "12124\n",
      "12125\n",
      "12126\n",
      "12127\n",
      "12128\n",
      "12129\n",
      "12130\n",
      "12131\n",
      "12132\n",
      "12133\n",
      "12134\n",
      "12135\n",
      "12136\n",
      "12137\n",
      "12138\n",
      "12139\n",
      "12140\n",
      "12141\n",
      "12142\n",
      "12143\n",
      "12144\n",
      "12145\n",
      "12146\n",
      "12147\n",
      "12148\n",
      "12149\n",
      "12150\n",
      "12151\n",
      "12152\n",
      "12153\n",
      "12154\n",
      "12155\n",
      "12156\n",
      "12157\n",
      "12158\n",
      "12159\n",
      "12160\n",
      "12161\n",
      "12162\n",
      "12163\n",
      "12164\n",
      "12165\n",
      "12166\n",
      "12167\n",
      "12168\n",
      "12169\n",
      "12170\n",
      "12171\n",
      "12172\n",
      "12173\n",
      "12174\n",
      "12175\n",
      "12176\n",
      "12177\n",
      "12178\n",
      "12179\n",
      "12180\n",
      "12181\n",
      "12182\n",
      "12183\n",
      "12184\n",
      "12185\n",
      "12186\n",
      "12187\n",
      "12188\n",
      "12189\n",
      "12190\n",
      "12191\n",
      "12192\n",
      "12193\n",
      "12194\n",
      "12195\n",
      "12196\n",
      "12197\n",
      "12198\n",
      "12199\n",
      "12200\n",
      "12201\n",
      "12202\n",
      "12203\n",
      "12204\n",
      "12205\n",
      "12206\n",
      "12207\n",
      "12208\n",
      "12209\n",
      "12210\n",
      "12211\n",
      "12212\n",
      "12213\n",
      "12214\n",
      "12215\n",
      "12216\n",
      "12217\n",
      "12218\n",
      "12219\n",
      "12220\n",
      "12221\n",
      "12222\n",
      "12223\n",
      "12224\n",
      "12225\n",
      "12226\n",
      "12227\n",
      "12228\n",
      "12229\n",
      "12230\n",
      "12231\n",
      "12232\n",
      "12233\n",
      "12234\n",
      "12235\n",
      "12236\n",
      "12237\n",
      "12238\n",
      "12239\n",
      "12240\n",
      "12241\n",
      "12242\n",
      "12243\n",
      "12244\n",
      "12245\n",
      "12246\n",
      "12247\n",
      "12248\n",
      "12249\n",
      "12250\n",
      "12251\n",
      "12252\n",
      "12253\n",
      "12254\n",
      "12255\n",
      "12256\n",
      "12257\n",
      "12258\n",
      "12259\n",
      "12260\n",
      "12261\n",
      "12262\n",
      "12263\n",
      "12264\n",
      "12265\n",
      "12266\n",
      "12267\n",
      "12268\n",
      "12269\n",
      "12270\n",
      "12271\n",
      "12272\n",
      "12273\n",
      "12274\n",
      "12275\n",
      "12276\n",
      "12277\n",
      "12278\n",
      "12279\n",
      "12280\n",
      "12281\n",
      "12282\n",
      "12283\n",
      "12284\n",
      "12285\n",
      "12286\n",
      "12287\n",
      "12288\n",
      "12289\n",
      "12290\n",
      "12291\n",
      "12292\n",
      "12293\n",
      "12294\n",
      "12295\n",
      "12296\n",
      "12297\n",
      "12298\n",
      "12299\n",
      "12300\n",
      "12301\n",
      "12302\n",
      "12303\n",
      "12304\n",
      "12305\n",
      "12306\n",
      "12307\n",
      "12308\n",
      "12309\n",
      "12310\n",
      "12311\n",
      "12312\n",
      "12313\n",
      "12314\n",
      "12315\n",
      "12316\n",
      "12317\n",
      "12318\n",
      "12319\n",
      "12320\n",
      "12321\n",
      "12322\n",
      "12323\n",
      "12324\n",
      "12325\n",
      "12326\n",
      "12327\n",
      "12328\n",
      "12329\n",
      "12330\n",
      "12331\n",
      "12332\n",
      "12333\n",
      "12334\n",
      "12335\n",
      "12336\n",
      "12337\n",
      "12338\n",
      "12339\n",
      "12340\n",
      "12341\n",
      "12342\n",
      "12343\n",
      "12344\n",
      "12345\n",
      "12346\n",
      "12347\n",
      "12348\n",
      "12349\n",
      "12350\n",
      "12351\n",
      "12352\n",
      "12353\n",
      "12354\n",
      "12355\n",
      "12356\n",
      "12357\n",
      "12358\n",
      "12359\n",
      "12360\n",
      "12361\n",
      "12362\n",
      "12363\n",
      "12364\n",
      "12365\n",
      "12366\n",
      "12367\n",
      "12368\n",
      "12369\n",
      "12370\n",
      "12371\n",
      "12372\n",
      "12373\n",
      "12374\n",
      "12375\n",
      "12376\n",
      "12377\n",
      "12378\n",
      "12379\n",
      "12380\n",
      "12381\n",
      "12382\n",
      "12383\n",
      "12384\n",
      "12385\n",
      "12386\n",
      "12387\n",
      "12388\n",
      "12389\n",
      "12390\n",
      "12391\n",
      "12392\n",
      "12393\n",
      "12394\n",
      "12395\n",
      "12396\n",
      "12397\n",
      "12398\n",
      "12399\n",
      "12400\n",
      "12401\n",
      "12402\n",
      "12403\n",
      "12404\n",
      "12405\n",
      "12406\n",
      "12407\n",
      "12408\n",
      "12409\n",
      "12410\n",
      "12411\n",
      "12412\n",
      "12413\n",
      "12414\n",
      "12415\n",
      "12416\n",
      "12417\n",
      "12418\n",
      "12419\n",
      "12420\n",
      "12421\n",
      "12422\n",
      "12423\n",
      "12424\n",
      "12425\n",
      "12426\n",
      "12427\n",
      "12428\n",
      "12429\n",
      "12430\n",
      "12431\n",
      "12432\n",
      "12433\n",
      "12434\n",
      "12435\n",
      "12436\n",
      "12437\n",
      "12438\n",
      "12439\n",
      "12440\n",
      "12441\n",
      "12442\n",
      "12443\n",
      "12444\n",
      "12445\n",
      "12446\n",
      "12447\n",
      "12448\n",
      "12449\n",
      "12450\n",
      "12451\n",
      "12452\n",
      "12453\n",
      "12454\n",
      "12455\n",
      "12456\n",
      "12457\n",
      "12458\n",
      "12459\n",
      "12460\n",
      "12461\n",
      "12462\n",
      "12463\n",
      "12464\n",
      "12465\n",
      "12466\n",
      "12467\n",
      "12468\n",
      "12469\n",
      "12470\n",
      "12471\n",
      "12472\n",
      "12473\n",
      "12474\n",
      "12475\n",
      "12476\n",
      "12477\n",
      "12478\n",
      "12479\n",
      "12480\n",
      "12481\n",
      "12482\n",
      "12483\n",
      "12484\n",
      "12485\n",
      "12486\n",
      "12487\n",
      "12488\n",
      "12489\n",
      "12490\n",
      "12491\n",
      "12492\n",
      "12493\n",
      "12494\n",
      "12495\n",
      "12496\n",
      "12497\n",
      "12498\n",
      "12499\n",
      "12500\n",
      "12501\n",
      "12502\n",
      "12503\n",
      "12504\n",
      "12505\n",
      "12506\n",
      "12507\n",
      "12508\n",
      "12509\n",
      "12510\n",
      "12511\n",
      "12512\n",
      "12513\n",
      "12514\n",
      "12515\n",
      "12516\n",
      "12517\n",
      "12518\n",
      "12519\n",
      "12520\n",
      "12521\n",
      "12522\n",
      "12523\n",
      "12524\n",
      "12525\n",
      "12526\n",
      "12527\n",
      "12528\n",
      "12529\n",
      "12530\n",
      "12531\n",
      "12532\n",
      "12533\n",
      "12534\n",
      "12535\n",
      "12536\n",
      "12537\n",
      "12538\n",
      "12539\n",
      "12540\n",
      "12541\n",
      "12542\n",
      "12543\n",
      "12544\n",
      "12545\n",
      "12546\n",
      "12547\n",
      "12548\n",
      "12549\n",
      "12550\n",
      "12551\n",
      "12552\n",
      "12553\n",
      "12554\n",
      "12555\n",
      "12556\n",
      "12557\n",
      "12558\n",
      "12559\n",
      "12560\n",
      "12561\n",
      "12562\n",
      "12563\n",
      "12564\n",
      "12565\n",
      "12566\n",
      "12567\n",
      "12568\n",
      "12569\n",
      "12570\n",
      "12571\n",
      "12572\n",
      "12573\n",
      "12574\n",
      "12575\n",
      "12576\n",
      "12577\n",
      "12578\n",
      "12579\n",
      "12580\n",
      "12581\n",
      "12582\n",
      "12583\n",
      "12584\n",
      "12585\n",
      "12586\n",
      "12587\n",
      "12588\n",
      "12589\n",
      "12590\n",
      "12591\n",
      "12592\n",
      "12593\n",
      "12594\n",
      "12595\n",
      "12596\n",
      "12597\n",
      "12598\n",
      "12599\n",
      "12600\n",
      "12601\n",
      "12602\n",
      "12603\n",
      "12604\n",
      "12605\n",
      "12606\n",
      "12607\n",
      "12608\n",
      "12609\n",
      "12610\n",
      "12611\n",
      "12612\n",
      "12613\n",
      "12614\n",
      "12615\n",
      "12616\n",
      "12617\n",
      "12618\n",
      "12619\n",
      "12620\n",
      "12621\n",
      "12622\n",
      "12623\n",
      "12624\n",
      "12625\n",
      "12626\n",
      "12627\n",
      "12628\n",
      "12629\n",
      "12630\n",
      "12631\n",
      "12632\n",
      "12633\n",
      "12634\n",
      "12635\n",
      "12636\n",
      "12637\n",
      "12638\n",
      "12639\n",
      "12640\n",
      "12641\n",
      "12642\n",
      "12643\n",
      "12644\n",
      "12645\n",
      "12646\n",
      "12647\n",
      "12648\n",
      "12649\n",
      "12650\n",
      "12651\n",
      "12652\n",
      "12653\n",
      "12654\n",
      "12655\n",
      "12656\n",
      "12657\n",
      "12658\n",
      "12659\n",
      "12660\n",
      "12661\n",
      "12662\n",
      "12663\n",
      "12664\n",
      "12665\n",
      "12666\n",
      "12667\n",
      "12668\n",
      "12669\n",
      "12670\n",
      "12671\n",
      "12672\n",
      "12673\n",
      "12674\n",
      "12675\n",
      "12676\n",
      "12677\n",
      "12678\n",
      "12679\n",
      "12680\n",
      "12681\n",
      "12682\n",
      "12683\n",
      "12684\n",
      "12685\n",
      "12686\n",
      "12687\n",
      "12688\n",
      "12689\n",
      "12690\n",
      "12691\n",
      "12692\n",
      "12693\n",
      "12694\n",
      "12695\n",
      "12696\n",
      "12697\n",
      "12698\n",
      "12699\n",
      "12700\n",
      "12701\n",
      "12702\n",
      "12703\n",
      "12704\n",
      "12705\n",
      "12706\n",
      "12707\n",
      "12708\n",
      "12709\n",
      "12710\n",
      "12711\n",
      "12712\n",
      "12713\n",
      "12714\n",
      "12715\n",
      "12716\n",
      "12717\n",
      "12718\n",
      "12719\n",
      "12720\n",
      "12721\n",
      "12722\n",
      "12723\n",
      "12724\n",
      "12725\n",
      "12726\n",
      "12727\n",
      "12728\n",
      "12729\n",
      "12730\n",
      "12731\n",
      "12732\n",
      "12733\n",
      "12734\n",
      "12735\n",
      "12736\n",
      "12737\n",
      "12738\n",
      "12739\n",
      "12740\n",
      "12741\n",
      "12742\n",
      "12743\n",
      "12744\n",
      "12745\n",
      "12746\n",
      "12747\n",
      "12748\n",
      "12749\n",
      "12750\n",
      "12751\n",
      "12752\n",
      "12753\n",
      "12754\n",
      "12755\n",
      "12756\n",
      "12757\n",
      "12758\n",
      "12759\n",
      "12760\n",
      "12761\n",
      "12762\n",
      "12763\n",
      "12764\n",
      "12765\n",
      "12766\n",
      "12767\n",
      "12768\n",
      "12769\n",
      "12770\n",
      "12771\n",
      "12772\n",
      "12773\n",
      "12774\n",
      "12775\n",
      "12776\n",
      "12777\n",
      "12778\n",
      "12779\n",
      "12780\n",
      "12781\n",
      "12782\n",
      "12783\n",
      "12784\n",
      "12785\n",
      "12786\n",
      "12787\n",
      "12788\n",
      "12789\n",
      "12790\n",
      "12791\n",
      "12792\n",
      "12793\n",
      "12794\n",
      "12795\n",
      "12796\n",
      "12797\n",
      "12798\n",
      "12799\n",
      "12800\n",
      "12801\n",
      "12802\n",
      "12803\n",
      "12804\n",
      "12805\n",
      "12806\n",
      "12807\n",
      "12808\n",
      "12809\n",
      "12810\n",
      "12811\n",
      "12812\n",
      "12813\n",
      "12814\n",
      "12815\n",
      "12816\n",
      "12817\n",
      "12818\n",
      "12819\n",
      "12820\n",
      "12821\n",
      "12822\n",
      "12823\n",
      "12824\n",
      "12825\n",
      "12826\n",
      "12827\n",
      "12828\n",
      "12829\n",
      "12830\n",
      "12831\n",
      "12832\n",
      "12833\n",
      "12834\n",
      "12835\n",
      "12836\n",
      "12837\n",
      "12838\n",
      "12839\n",
      "12840\n",
      "12841\n",
      "12842\n",
      "12843\n",
      "12844\n",
      "12845\n",
      "12846\n",
      "12847\n",
      "12848\n",
      "12849\n",
      "12850\n",
      "12851\n",
      "12852\n",
      "12853\n",
      "12854\n",
      "12855\n",
      "12856\n",
      "12857\n",
      "12858\n",
      "12859\n",
      "12860\n",
      "12861\n",
      "12862\n",
      "12863\n",
      "12864\n",
      "12865\n",
      "12866\n",
      "12867\n",
      "12868\n",
      "12869\n",
      "12870\n",
      "12871\n",
      "12872\n",
      "12873\n",
      "12874\n",
      "12875\n",
      "12876\n",
      "12877\n",
      "12878\n",
      "12879\n",
      "12880\n",
      "12881\n",
      "12882\n",
      "12883\n",
      "12884\n",
      "12885\n",
      "12886\n",
      "12887\n",
      "12888\n",
      "12889\n",
      "12890\n",
      "12891\n",
      "12892\n",
      "12893\n",
      "12894\n",
      "12895\n",
      "12896\n",
      "12897\n",
      "12898\n",
      "12899\n",
      "12900\n",
      "12901\n",
      "12902\n",
      "12903\n",
      "12904\n",
      "12905\n",
      "12906\n",
      "12907\n",
      "12908\n",
      "12909\n",
      "12910\n",
      "12911\n",
      "12912\n",
      "12913\n",
      "12914\n",
      "12915\n",
      "12916\n",
      "12917\n",
      "12918\n",
      "12919\n",
      "12920\n",
      "12921\n",
      "12922\n",
      "12923\n",
      "12924\n",
      "12925\n",
      "12926\n",
      "12927\n",
      "12928\n",
      "12929\n",
      "12930\n",
      "12931\n",
      "12932\n",
      "12933\n",
      "12934\n",
      "12935\n",
      "12936\n",
      "12937\n",
      "12938\n",
      "12939\n",
      "12940\n",
      "12941\n",
      "12942\n",
      "12943\n",
      "12944\n",
      "12945\n",
      "12946\n",
      "12947\n",
      "12948\n",
      "12949\n",
      "12950\n",
      "12951\n",
      "12952\n",
      "12953\n",
      "12954\n",
      "12955\n",
      "12956\n",
      "12957\n",
      "12958\n",
      "12959\n",
      "12960\n",
      "12961\n",
      "12962\n",
      "12963\n",
      "12964\n",
      "12965\n",
      "12966\n",
      "12967\n",
      "12968\n",
      "12969\n",
      "12970\n",
      "12971\n",
      "12972\n",
      "12973\n",
      "12974\n",
      "12975\n",
      "12976\n",
      "12977\n",
      "12978\n",
      "12979\n",
      "12980\n",
      "12981\n",
      "12982\n",
      "12983\n",
      "12984\n",
      "12985\n",
      "12986\n",
      "12987\n",
      "12988\n",
      "12989\n",
      "12990\n",
      "12991\n",
      "12992\n",
      "12993\n",
      "12994\n",
      "12995\n",
      "12996\n",
      "12997\n",
      "12998\n",
      "12999\n",
      "13000\n",
      "13001\n",
      "13002\n",
      "13003\n",
      "13004\n",
      "13005\n",
      "13006\n",
      "13007\n",
      "13008\n",
      "13009\n",
      "13010\n",
      "13011\n",
      "13012\n",
      "13013\n",
      "13014\n",
      "13015\n",
      "13016\n",
      "13017\n",
      "13018\n",
      "13019\n",
      "13020\n",
      "13021\n",
      "13022\n",
      "13023\n",
      "13024\n",
      "13025\n",
      "13026\n",
      "13027\n",
      "13028\n",
      "13029\n",
      "13030\n",
      "13031\n",
      "13032\n",
      "13033\n",
      "13034\n",
      "13035\n",
      "13036\n",
      "13037\n",
      "13038\n",
      "13039\n",
      "13040\n",
      "13041\n",
      "13042\n",
      "13043\n",
      "13044\n",
      "13045\n",
      "13046\n",
      "13047\n",
      "13048\n",
      "13049\n",
      "13050\n",
      "13051\n",
      "13052\n",
      "13053\n",
      "13054\n",
      "13055\n",
      "13056\n",
      "13057\n",
      "13058\n",
      "13059\n",
      "13060\n",
      "13061\n",
      "13062\n",
      "13063\n",
      "13064\n",
      "13065\n",
      "13066\n",
      "13067\n",
      "13068\n",
      "13069\n",
      "13070\n",
      "13071\n",
      "13072\n",
      "13073\n",
      "13074\n",
      "13075\n",
      "13076\n",
      "13077\n",
      "13078\n",
      "13079\n",
      "13080\n",
      "13081\n",
      "13082\n",
      "13083\n",
      "13084\n",
      "13085\n",
      "13086\n",
      "13087\n",
      "13088\n",
      "13089\n",
      "13090\n",
      "13091\n",
      "13092\n",
      "13093\n",
      "13094\n",
      "13095\n",
      "13096\n",
      "13097\n",
      "13098\n",
      "13099\n",
      "13100\n",
      "13101\n",
      "13102\n",
      "13103\n",
      "13104\n",
      "13105\n",
      "13106\n",
      "13107\n",
      "13108\n",
      "13109\n",
      "13110\n",
      "13111\n",
      "13112\n",
      "13113\n",
      "13114\n",
      "13115\n",
      "13116\n",
      "13117\n",
      "13118\n",
      "13119\n",
      "13120\n",
      "13121\n",
      "13122\n",
      "13123\n",
      "13124\n",
      "13125\n",
      "13126\n",
      "13127\n",
      "13128\n",
      "13129\n",
      "13130\n",
      "13131\n",
      "13132\n",
      "13133\n",
      "13134\n",
      "13135\n",
      "13136\n",
      "13137\n",
      "13138\n",
      "13139\n",
      "13140\n",
      "13141\n",
      "13142\n",
      "13143\n",
      "13144\n",
      "13145\n",
      "13146\n",
      "13147\n",
      "13148\n",
      "13149\n",
      "13150\n",
      "13151\n",
      "13152\n",
      "13153\n",
      "13154\n",
      "13155\n",
      "13156\n",
      "13157\n",
      "13158\n",
      "13159\n",
      "13160\n",
      "13161\n",
      "13162\n",
      "13163\n",
      "13164\n",
      "13165\n",
      "13166\n",
      "13167\n",
      "13168\n",
      "13169\n",
      "13170\n",
      "13171\n",
      "13172\n",
      "13173\n",
      "13174\n",
      "13175\n",
      "13176\n",
      "13177\n",
      "13178\n",
      "13179\n",
      "13180\n",
      "13181\n",
      "13182\n",
      "13183\n",
      "13184\n",
      "13185\n",
      "13186\n",
      "13187\n",
      "13188\n",
      "13189\n",
      "13190\n",
      "13191\n",
      "13192\n",
      "13193\n",
      "13194\n",
      "13195\n",
      "13196\n",
      "13197\n",
      "13198\n",
      "13199\n",
      "13200\n",
      "13201\n",
      "13202\n",
      "13203\n",
      "13204\n",
      "13205\n",
      "13206\n",
      "13207\n",
      "13208\n",
      "13209\n",
      "13210\n",
      "13211\n",
      "13212\n",
      "13213\n",
      "13214\n",
      "13215\n",
      "13216\n",
      "13217\n",
      "13218\n",
      "13219\n",
      "13220\n",
      "13221\n",
      "13222\n",
      "13223\n",
      "13224\n",
      "13225\n",
      "13226\n",
      "13227\n",
      "13228\n",
      "13229\n",
      "13230\n",
      "13231\n",
      "13232\n",
      "13233\n",
      "13234\n",
      "13235\n",
      "13236\n",
      "13237\n",
      "13238\n",
      "13239\n",
      "13240\n",
      "13241\n",
      "13242\n",
      "13243\n",
      "13244\n",
      "13245\n",
      "13246\n",
      "13247\n",
      "13248\n",
      "13249\n",
      "13250\n",
      "13251\n",
      "13252\n",
      "13253\n",
      "13254\n",
      "13255\n",
      "13256\n",
      "13257\n",
      "13258\n",
      "13259\n",
      "13260\n",
      "13261\n",
      "13262\n",
      "13263\n",
      "13264\n",
      "13265\n",
      "13266\n",
      "13267\n",
      "13268\n",
      "13269\n",
      "13270\n",
      "13271\n",
      "13272\n",
      "13273\n",
      "13274\n",
      "13275\n",
      "13276\n",
      "13277\n",
      "13278\n",
      "13279\n",
      "13280\n",
      "13281\n",
      "13282\n",
      "13283\n",
      "13284\n",
      "13285\n",
      "13286\n",
      "13287\n",
      "13288\n",
      "13289\n",
      "13290\n",
      "13291\n",
      "13292\n",
      "13293\n",
      "13294\n",
      "13295\n",
      "13296\n",
      "13297\n",
      "13298\n",
      "13299\n",
      "13300\n",
      "13301\n",
      "13302\n",
      "13303\n",
      "13304\n",
      "13305\n",
      "13306\n",
      "13307\n",
      "13308\n",
      "13309\n",
      "13310\n",
      "13311\n",
      "13312\n",
      "13313\n",
      "13314\n",
      "13315\n",
      "13316\n",
      "13317\n",
      "13318\n",
      "13319\n",
      "13320\n",
      "13321\n",
      "13322\n",
      "13323\n",
      "13324\n",
      "13325\n",
      "13326\n",
      "13327\n",
      "13328\n",
      "13329\n",
      "13330\n",
      "13331\n",
      "13332\n",
      "13333\n",
      "13334\n",
      "13335\n",
      "13336\n",
      "13337\n",
      "13338\n",
      "13339\n",
      "13340\n",
      "13341\n",
      "13342\n",
      "13343\n",
      "13344\n",
      "13345\n",
      "13346\n",
      "13347\n",
      "13348\n",
      "13349\n",
      "13350\n",
      "13351\n",
      "13352\n",
      "13353\n",
      "13354\n",
      "13355\n",
      "13356\n",
      "13357\n",
      "13358\n",
      "13359\n",
      "13360\n",
      "13361\n",
      "13362\n",
      "13363\n",
      "13364\n",
      "13365\n",
      "13366\n",
      "13367\n",
      "13368\n",
      "13369\n",
      "13370\n",
      "13371\n",
      "13372\n",
      "13373\n",
      "13374\n",
      "13375\n",
      "13376\n",
      "13377\n",
      "13378\n",
      "13379\n",
      "13380\n",
      "13381\n",
      "13382\n",
      "13383\n",
      "13384\n",
      "13385\n",
      "13386\n",
      "13387\n",
      "13388\n",
      "13389\n",
      "13390\n",
      "13391\n",
      "13392\n",
      "13393\n",
      "13394\n",
      "13395\n",
      "13396\n",
      "13397\n",
      "13398\n",
      "13399\n",
      "13400\n",
      "13401\n",
      "13402\n",
      "13403\n",
      "13404\n",
      "13405\n",
      "13406\n",
      "13407\n",
      "13408\n",
      "13409\n",
      "13410\n",
      "13411\n",
      "13412\n",
      "13413\n",
      "13414\n",
      "13415\n",
      "13416\n",
      "13417\n",
      "13418\n",
      "13419\n",
      "13420\n",
      "13421\n",
      "13422\n",
      "13423\n",
      "13424\n",
      "13425\n",
      "13426\n",
      "13427\n",
      "13428\n",
      "13429\n",
      "13430\n",
      "13431\n",
      "13432\n",
      "13433\n",
      "13434\n",
      "13435\n",
      "13436\n",
      "13437\n",
      "13438\n",
      "13439\n",
      "13440\n",
      "13441\n",
      "13442\n",
      "13443\n",
      "13444\n",
      "13445\n",
      "13446\n",
      "13447\n",
      "13448\n",
      "13449\n",
      "13450\n",
      "13451\n",
      "13452\n",
      "13453\n",
      "13454\n",
      "13455\n",
      "13456\n",
      "13457\n",
      "13458\n",
      "13459\n",
      "13460\n",
      "13461\n",
      "13462\n",
      "13463\n",
      "13464\n",
      "13465\n",
      "13466\n",
      "13467\n",
      "13468\n",
      "13469\n",
      "13470\n",
      "13471\n",
      "13472\n",
      "13473\n",
      "13474\n",
      "13475\n",
      "13476\n",
      "13477\n",
      "13478\n",
      "13479\n",
      "13480\n",
      "13481\n",
      "13482\n",
      "13483\n",
      "13484\n",
      "13485\n",
      "13486\n",
      "13487\n",
      "13488\n",
      "13489\n",
      "13490\n",
      "13491\n",
      "13492\n",
      "13493\n",
      "13494\n",
      "13495\n",
      "13496\n",
      "13497\n",
      "13498\n",
      "13499\n",
      "13500\n",
      "13501\n",
      "13502\n",
      "13503\n",
      "13504\n",
      "13505\n",
      "13506\n",
      "13507\n",
      "13508\n",
      "13509\n",
      "13510\n",
      "13511\n",
      "13512\n",
      "13513\n",
      "13514\n",
      "13515\n",
      "13516\n",
      "13517\n",
      "13518\n",
      "13519\n",
      "13520\n",
      "13521\n",
      "13522\n",
      "13523\n",
      "13524\n",
      "13525\n",
      "13526\n",
      "13527\n",
      "13528\n",
      "13529\n",
      "13530\n",
      "13531\n",
      "13532\n",
      "13533\n",
      "13534\n",
      "13535\n",
      "13536\n",
      "13537\n",
      "13538\n",
      "13539\n",
      "13540\n",
      "13541\n",
      "13542\n",
      "13543\n",
      "13544\n",
      "13545\n",
      "13546\n",
      "13547\n",
      "13548\n",
      "13549\n",
      "13550\n",
      "13551\n",
      "13552\n",
      "13553\n",
      "13554\n",
      "13555\n",
      "13556\n",
      "13557\n",
      "13558\n",
      "13559\n",
      "13560\n",
      "13561\n",
      "13562\n",
      "13563\n",
      "13564\n",
      "13565\n",
      "13566\n",
      "13567\n",
      "13568\n",
      "13569\n",
      "13570\n",
      "13571\n",
      "13572\n",
      "13573\n",
      "13574\n",
      "13575\n",
      "13576\n",
      "13577\n",
      "13578\n",
      "13579\n",
      "13580\n",
      "13581\n",
      "13582\n",
      "13583\n",
      "13584\n",
      "13585\n",
      "13586\n",
      "13587\n",
      "13588\n",
      "13589\n",
      "13590\n",
      "13591\n",
      "13592\n",
      "13593\n",
      "13594\n",
      "13595\n",
      "13596\n",
      "13597\n",
      "13598\n",
      "13599\n",
      "13600\n",
      "13601\n",
      "13602\n",
      "13603\n",
      "13604\n",
      "13605\n",
      "13606\n",
      "13607\n",
      "13608\n",
      "13609\n",
      "13610\n",
      "13611\n",
      "13612\n",
      "13613\n",
      "13614\n",
      "13615\n",
      "13616\n",
      "13617\n",
      "13618\n",
      "13619\n",
      "13620\n",
      "13621\n",
      "13622\n",
      "13623\n",
      "13624\n",
      "13625\n",
      "13626\n",
      "13627\n",
      "13628\n",
      "13629\n",
      "13630\n",
      "13631\n",
      "13632\n",
      "13633\n",
      "13634\n",
      "13635\n",
      "13636\n",
      "13637\n",
      "13638\n",
      "13639\n",
      "13640\n",
      "13641\n",
      "13642\n",
      "13643\n",
      "13644\n",
      "13645\n",
      "13646\n",
      "13647\n",
      "13648\n",
      "13649\n",
      "13650\n",
      "13651\n",
      "13652\n",
      "13653\n",
      "13654\n",
      "13655\n",
      "13656\n",
      "13657\n",
      "13658\n",
      "13659\n",
      "13660\n",
      "13661\n",
      "13662\n",
      "13663\n",
      "13664\n",
      "13665\n",
      "13666\n",
      "13667\n",
      "13668\n",
      "13669\n",
      "13670\n",
      "13671\n",
      "13672\n",
      "13673\n",
      "13674\n",
      "13675\n",
      "13676\n",
      "13677\n",
      "13678\n",
      "13679\n",
      "13680\n",
      "13681\n",
      "13682\n",
      "13683\n",
      "13684\n",
      "13685\n",
      "13686\n",
      "13687\n",
      "13688\n",
      "13689\n",
      "13690\n",
      "13691\n",
      "13692\n",
      "13693\n",
      "13694\n",
      "13695\n",
      "13696\n",
      "13697\n",
      "13698\n",
      "13699\n",
      "13700\n",
      "13701\n",
      "13702\n",
      "13703\n",
      "13704\n",
      "13705\n",
      "13706\n",
      "13707\n",
      "13708\n",
      "13709\n",
      "13710\n",
      "13711\n",
      "13712\n",
      "13713\n",
      "13714\n",
      "13715\n",
      "13716\n",
      "13717\n",
      "13718\n",
      "13719\n",
      "13720\n",
      "13721\n",
      "13722\n",
      "13723\n",
      "13724\n",
      "13725\n",
      "13726\n",
      "13727\n",
      "13728\n",
      "13729\n",
      "13730\n",
      "13731\n",
      "13732\n",
      "13733\n",
      "13734\n",
      "13735\n",
      "13736\n",
      "13737\n",
      "13738\n",
      "13739\n",
      "13740\n",
      "13741\n",
      "13742\n",
      "13743\n",
      "13744\n",
      "13745\n",
      "13746\n",
      "13747\n",
      "13748\n",
      "13749\n",
      "13750\n",
      "13751\n",
      "13752\n",
      "13753\n",
      "13754\n",
      "13755\n",
      "13756\n",
      "13757\n",
      "13758\n",
      "13759\n",
      "13760\n",
      "13761\n",
      "13762\n",
      "13763\n",
      "13764\n",
      "13765\n",
      "13766\n",
      "13767\n",
      "13768\n",
      "13769\n",
      "13770\n",
      "13771\n",
      "13772\n",
      "13773\n",
      "13774\n",
      "13775\n",
      "13776\n",
      "13777\n",
      "13778\n",
      "13779\n",
      "13780\n",
      "13781\n",
      "13782\n",
      "13783\n",
      "13784\n",
      "13785\n",
      "13786\n",
      "13787\n",
      "13788\n",
      "13789\n",
      "13790\n",
      "13791\n",
      "13792\n",
      "13793\n",
      "13794\n",
      "13795\n",
      "13796\n",
      "13797\n",
      "13798\n",
      "13799\n",
      "13800\n",
      "13801\n",
      "13802\n",
      "13803\n",
      "13804\n",
      "13805\n",
      "13806\n",
      "13807\n",
      "13808\n",
      "13809\n",
      "13810\n",
      "13811\n",
      "13812\n",
      "13813\n",
      "13814\n",
      "13815\n",
      "13816\n",
      "13817\n",
      "13818\n",
      "13819\n",
      "13820\n",
      "13821\n",
      "13822\n",
      "13823\n",
      "13824\n",
      "13825\n",
      "13826\n",
      "13827\n",
      "13828\n",
      "13829\n",
      "13830\n",
      "13831\n",
      "13832\n",
      "13833\n",
      "13834\n",
      "13835\n",
      "13836\n",
      "13837\n",
      "13838\n",
      "13839\n",
      "13840\n",
      "13841\n",
      "13842\n",
      "13843\n",
      "13844\n",
      "13845\n",
      "13846\n",
      "13847\n",
      "13848\n",
      "13849\n",
      "13850\n",
      "13851\n",
      "13852\n",
      "13853\n",
      "13854\n",
      "13855\n",
      "13856\n",
      "13857\n",
      "13858\n",
      "13859\n",
      "13860\n",
      "13861\n",
      "13862\n",
      "13863\n",
      "13864\n",
      "13865\n",
      "13866\n",
      "13867\n",
      "13868\n",
      "13869\n",
      "13870\n",
      "13871\n",
      "13872\n",
      "13873\n",
      "13874\n",
      "13875\n",
      "13876\n",
      "13877\n",
      "13878\n",
      "13879\n",
      "13880\n",
      "13881\n",
      "13882\n",
      "13883\n",
      "13884\n",
      "13885\n",
      "13886\n",
      "13887\n",
      "13888\n",
      "13889\n",
      "13890\n",
      "13891\n",
      "13892\n",
      "13893\n",
      "13894\n",
      "13895\n",
      "13896\n",
      "13897\n",
      "13898\n",
      "13899\n",
      "13900\n",
      "13901\n",
      "13902\n",
      "13903\n",
      "13904\n",
      "13905\n",
      "13906\n",
      "13907\n",
      "13908\n",
      "13909\n",
      "13910\n",
      "13911\n",
      "13912\n",
      "13913\n",
      "13914\n",
      "13915\n",
      "13916\n",
      "13917\n",
      "13918\n",
      "13919\n",
      "13920\n",
      "13921\n",
      "13922\n",
      "13923\n",
      "13924\n",
      "13925\n",
      "13926\n",
      "13927\n",
      "13928\n",
      "13929\n",
      "13930\n",
      "13931\n",
      "13932\n",
      "13933\n",
      "13934\n",
      "13935\n",
      "13936\n",
      "13937\n",
      "13938\n",
      "13939\n",
      "13940\n",
      "13941\n",
      "13942\n",
      "13943\n",
      "13944\n",
      "13945\n",
      "13946\n",
      "13947\n",
      "13948\n",
      "13949\n",
      "13950\n",
      "13951\n",
      "13952\n",
      "13953\n",
      "13954\n",
      "13955\n",
      "13956\n",
      "13957\n",
      "13958\n",
      "13959\n",
      "13960\n",
      "13961\n",
      "13962\n",
      "13963\n",
      "13964\n",
      "13965\n",
      "13966\n",
      "13967\n",
      "13968\n",
      "13969\n",
      "13970\n",
      "13971\n",
      "13972\n",
      "13973\n",
      "13974\n",
      "13975\n",
      "13976\n",
      "13977\n",
      "13978\n",
      "13979\n",
      "13980\n",
      "13981\n",
      "13982\n",
      "13983\n",
      "13984\n",
      "13985\n",
      "13986\n",
      "13987\n",
      "13988\n",
      "13989\n",
      "13990\n",
      "13991\n",
      "13992\n",
      "13993\n",
      "13994\n",
      "13995\n",
      "13996\n",
      "13997\n",
      "13998\n",
      "13999\n",
      "14000\n",
      "14001\n",
      "14002\n",
      "14003\n",
      "14004\n",
      "14005\n",
      "14006\n",
      "14007\n",
      "14008\n",
      "14009\n",
      "14010\n",
      "14011\n",
      "14012\n",
      "14013\n",
      "14014\n",
      "14015\n",
      "14016\n",
      "14017\n",
      "14018\n",
      "14019\n",
      "14020\n",
      "14021\n",
      "14022\n",
      "14023\n",
      "14024\n",
      "14025\n",
      "14026\n",
      "14027\n",
      "14028\n",
      "14029\n",
      "14030\n",
      "14031\n",
      "14032\n",
      "14033\n",
      "14034\n",
      "14035\n",
      "14036\n",
      "14037\n",
      "14038\n",
      "14039\n",
      "14040\n",
      "14041\n",
      "14042\n",
      "14043\n",
      "14044\n",
      "14045\n",
      "14046\n",
      "14047\n",
      "14048\n",
      "14049\n",
      "14050\n",
      "14051\n",
      "14052\n",
      "14053\n",
      "14054\n",
      "14055\n",
      "14056\n",
      "14057\n",
      "14058\n",
      "14059\n",
      "14060\n",
      "14061\n",
      "14062\n",
      "14063\n",
      "14064\n",
      "14065\n",
      "14066\n",
      "14067\n",
      "14068\n",
      "14069\n",
      "14070\n",
      "14071\n",
      "14072\n",
      "14073\n",
      "14074\n",
      "14075\n",
      "14076\n",
      "14077\n",
      "14078\n",
      "14079\n",
      "14080\n",
      "14081\n",
      "14082\n",
      "14083\n",
      "14084\n",
      "14085\n",
      "14086\n",
      "14087\n",
      "14088\n",
      "14089\n",
      "14090\n",
      "14091\n",
      "14092\n",
      "14093\n",
      "14094\n",
      "14095\n",
      "14096\n",
      "14097\n",
      "14098\n",
      "14099\n",
      "14100\n",
      "14101\n",
      "14102\n",
      "14103\n",
      "14104\n",
      "14105\n",
      "14106\n",
      "14107\n",
      "14108\n",
      "14109\n",
      "14110\n",
      "14111\n",
      "14112\n",
      "14113\n",
      "14114\n",
      "14115\n",
      "14116\n",
      "14117\n",
      "14118\n",
      "14119\n",
      "14120\n",
      "14121\n",
      "14122\n",
      "14123\n",
      "14124\n",
      "14125\n",
      "14126\n",
      "14127\n",
      "14128\n",
      "14129\n",
      "14130\n",
      "14131\n",
      "14132\n",
      "14133\n",
      "14134\n",
      "14135\n",
      "14136\n",
      "14137\n",
      "14138\n",
      "14139\n",
      "14140\n",
      "14141\n",
      "14142\n",
      "14143\n",
      "14144\n",
      "14145\n",
      "14146\n",
      "14147\n",
      "14148\n",
      "14149\n",
      "14150\n",
      "14151\n",
      "14152\n",
      "14153\n",
      "14154\n",
      "14155\n",
      "14156\n",
      "14157\n",
      "14158\n",
      "14159\n",
      "14160\n",
      "14161\n",
      "14162\n",
      "14163\n",
      "14164\n",
      "14165\n",
      "14166\n",
      "14167\n",
      "14168\n",
      "14169\n",
      "14170\n",
      "14171\n",
      "14172\n",
      "14173\n",
      "14174\n",
      "14175\n",
      "14176\n",
      "14177\n",
      "14178\n",
      "14179\n",
      "14180\n",
      "14181\n",
      "14182\n",
      "14183\n",
      "14184\n",
      "14185\n",
      "14186\n",
      "14187\n",
      "14188\n",
      "14189\n",
      "14190\n",
      "14191\n",
      "14192\n",
      "14193\n",
      "14194\n",
      "14195\n",
      "14196\n",
      "14197\n",
      "14198\n",
      "14199\n",
      "14200\n",
      "14201\n",
      "14202\n",
      "14203\n",
      "14204\n",
      "14205\n",
      "14206\n",
      "14207\n",
      "14208\n",
      "14209\n",
      "14210\n",
      "14211\n",
      "14212\n",
      "14213\n",
      "14214\n",
      "14215\n",
      "14216\n",
      "14217\n",
      "14218\n",
      "14219\n",
      "14220\n",
      "14221\n",
      "14222\n",
      "14223\n",
      "14224\n",
      "14225\n",
      "14226\n",
      "14227\n",
      "14228\n",
      "14229\n",
      "14230\n",
      "14231\n",
      "14232\n",
      "14233\n",
      "14234\n",
      "14235\n",
      "14236\n",
      "14237\n",
      "14238\n",
      "14239\n",
      "14240\n",
      "14241\n",
      "14242\n",
      "14243\n",
      "14244\n",
      "14245\n",
      "14246\n",
      "14247\n",
      "14248\n",
      "14249\n",
      "14250\n",
      "14251\n",
      "14252\n",
      "14253\n",
      "14254\n",
      "14255\n",
      "14256\n",
      "14257\n",
      "14258\n",
      "14259\n",
      "14260\n",
      "14261\n",
      "14262\n",
      "14263\n",
      "14264\n",
      "14265\n",
      "14266\n",
      "14267\n",
      "14268\n",
      "14269\n",
      "14270\n",
      "14271\n",
      "14272\n",
      "14273\n",
      "14274\n",
      "14275\n",
      "14276\n",
      "14277\n",
      "14278\n",
      "14279\n",
      "14280\n",
      "14281\n",
      "14282\n",
      "14283\n",
      "14284\n",
      "14285\n",
      "14286\n",
      "14287\n",
      "14288\n",
      "14289\n",
      "14290\n",
      "14291\n",
      "14292\n",
      "14293\n",
      "14294\n",
      "14295\n",
      "14296\n",
      "14297\n",
      "14298\n",
      "14299\n",
      "14300\n",
      "14301\n",
      "14302\n",
      "14303\n",
      "14304\n",
      "14305\n",
      "14306\n",
      "14307\n",
      "14308\n",
      "14309\n",
      "14310\n",
      "14311\n",
      "14312\n",
      "14313\n",
      "14314\n",
      "14315\n",
      "14316\n",
      "14317\n",
      "14318\n",
      "14319\n",
      "14320\n",
      "14321\n",
      "14322\n",
      "14323\n",
      "14324\n",
      "14325\n",
      "14326\n",
      "14327\n",
      "14328\n",
      "14329\n",
      "14330\n",
      "14331\n",
      "14332\n",
      "14333\n",
      "14334\n",
      "14335\n",
      "14336\n",
      "14337\n",
      "14338\n",
      "14339\n",
      "14340\n",
      "14341\n",
      "14342\n",
      "14343\n",
      "14344\n",
      "14345\n",
      "14346\n",
      "14347\n",
      "14348\n",
      "14349\n",
      "14350\n",
      "14351\n",
      "14352\n",
      "14353\n",
      "14354\n",
      "14355\n",
      "14356\n",
      "14357\n",
      "14358\n",
      "14359\n",
      "14360\n",
      "14361\n",
      "14362\n",
      "14363\n",
      "14364\n",
      "14365\n",
      "14366\n",
      "14367\n",
      "14368\n",
      "14369\n",
      "14370\n",
      "14371\n",
      "14372\n",
      "14373\n",
      "14374\n",
      "14375\n",
      "14376\n",
      "14377\n",
      "14378\n",
      "14379\n",
      "14380\n",
      "14381\n",
      "14382\n",
      "14383\n",
      "14384\n",
      "14385\n",
      "14386\n",
      "14387\n",
      "14388\n",
      "14389\n",
      "14390\n",
      "14391\n",
      "14392\n",
      "14393\n",
      "14394\n",
      "14395\n",
      "14396\n",
      "14397\n",
      "14398\n",
      "14399\n",
      "14400\n",
      "14401\n",
      "14402\n",
      "14403\n",
      "14404\n",
      "14405\n",
      "14406\n",
      "14407\n",
      "14408\n",
      "14409\n",
      "14410\n",
      "14411\n",
      "14412\n",
      "14413\n",
      "14414\n",
      "14415\n",
      "14416\n",
      "14417\n",
      "14418\n",
      "14419\n",
      "14420\n",
      "14421\n",
      "14422\n",
      "14423\n",
      "14424\n",
      "14425\n",
      "14426\n",
      "14427\n",
      "14428\n",
      "14429\n",
      "14430\n",
      "14431\n",
      "14432\n",
      "14433\n",
      "14434\n",
      "14435\n",
      "14436\n",
      "14437\n",
      "14438\n",
      "14439\n",
      "14440\n",
      "14441\n",
      "14442\n",
      "14443\n",
      "14444\n",
      "14445\n",
      "14446\n",
      "14447\n",
      "14448\n",
      "14449\n",
      "14450\n",
      "14451\n",
      "14452\n",
      "14453\n",
      "14454\n",
      "14455\n",
      "14456\n",
      "14457\n",
      "14458\n",
      "14459\n",
      "14460\n",
      "14461\n",
      "14462\n",
      "14463\n",
      "14464\n",
      "14465\n",
      "14466\n",
      "14467\n",
      "14468\n",
      "14469\n",
      "14470\n",
      "14471\n",
      "14472\n",
      "14473\n",
      "14474\n",
      "14475\n",
      "14476\n",
      "14477\n",
      "14478\n",
      "14479\n",
      "14480\n",
      "14481\n",
      "14482\n",
      "14483\n",
      "14484\n",
      "14485\n",
      "14486\n",
      "14487\n",
      "14488\n",
      "14489\n",
      "14490\n",
      "14491\n",
      "14492\n",
      "14493\n",
      "14494\n",
      "14495\n",
      "14496\n",
      "14497\n",
      "14498\n",
      "14499\n",
      "14500\n",
      "14501\n",
      "14502\n",
      "14503\n",
      "14504\n",
      "14505\n",
      "14506\n",
      "14507\n",
      "14508\n",
      "14509\n",
      "14510\n",
      "14511\n",
      "14512\n",
      "14513\n",
      "14514\n",
      "14515\n",
      "14516\n",
      "14517\n",
      "14518\n",
      "14519\n",
      "14520\n",
      "14521\n",
      "14522\n",
      "14523\n",
      "14524\n",
      "14525\n",
      "14526\n",
      "14527\n",
      "14528\n",
      "14529\n",
      "14530\n",
      "14531\n",
      "14532\n",
      "14533\n",
      "14534\n",
      "14535\n",
      "14536\n",
      "14537\n",
      "14538\n",
      "14539\n",
      "14540\n",
      "14541\n",
      "14542\n",
      "14543\n",
      "14544\n",
      "14545\n",
      "14546\n",
      "14547\n",
      "14548\n",
      "14549\n",
      "14550\n",
      "14551\n",
      "14552\n",
      "14553\n",
      "14554\n",
      "14555\n",
      "14556\n",
      "14557\n",
      "14558\n",
      "14559\n",
      "14560\n",
      "14561\n",
      "14562\n",
      "14563\n",
      "14564\n",
      "14565\n",
      "14566\n",
      "14567\n",
      "14568\n",
      "14569\n",
      "14570\n",
      "14571\n",
      "14572\n",
      "14573\n",
      "14574\n",
      "14575\n",
      "14576\n",
      "14577\n",
      "14578\n",
      "14579\n",
      "14580\n",
      "14581\n",
      "14582\n",
      "14583\n",
      "14584\n",
      "14585\n",
      "14586\n",
      "14587\n",
      "14588\n",
      "14589\n",
      "14590\n",
      "14591\n",
      "14592\n",
      "14593\n",
      "14594\n",
      "14595\n",
      "14596\n",
      "14597\n",
      "14598\n",
      "14599\n",
      "14600\n",
      "14601\n",
      "14602\n",
      "14603\n",
      "14604\n",
      "14605\n",
      "14606\n",
      "14607\n",
      "14608\n",
      "14609\n",
      "14610\n",
      "14611\n",
      "14612\n",
      "14613\n",
      "14614\n",
      "14615\n",
      "14616\n",
      "14617\n",
      "14618\n",
      "14619\n",
      "14620\n",
      "14621\n",
      "14622\n",
      "14623\n",
      "14624\n",
      "14625\n",
      "14626\n",
      "14627\n",
      "14628\n",
      "14629\n",
      "14630\n",
      "14631\n",
      "14632\n",
      "14633\n",
      "14634\n",
      "14635\n",
      "14636\n",
      "14637\n",
      "14638\n",
      "14639\n",
      "14640\n",
      "14641\n",
      "14642\n",
      "14643\n",
      "14644\n",
      "14645\n",
      "14646\n",
      "14647\n",
      "14648\n",
      "14649\n",
      "14650\n",
      "14651\n",
      "14652\n",
      "14653\n",
      "14654\n",
      "14655\n",
      "14656\n",
      "14657\n",
      "14658\n",
      "14659\n",
      "14660\n",
      "14661\n",
      "14662\n",
      "14663\n",
      "14664\n",
      "14665\n",
      "14666\n",
      "14667\n",
      "14668\n",
      "14669\n",
      "14670\n",
      "14671\n",
      "14672\n",
      "14673\n",
      "14674\n",
      "14675\n",
      "14676\n",
      "14677\n",
      "14678\n",
      "14679\n",
      "14680\n",
      "14681\n",
      "14682\n",
      "14683\n",
      "14684\n",
      "14685\n",
      "14686\n",
      "14687\n",
      "14688\n",
      "14689\n",
      "14690\n",
      "14691\n",
      "14692\n",
      "14693\n",
      "14694\n",
      "14695\n",
      "14696\n",
      "14697\n",
      "14698\n",
      "14699\n",
      "14700\n",
      "14701\n",
      "14702\n",
      "14703\n",
      "14704\n",
      "14705\n",
      "14706\n",
      "14707\n",
      "14708\n",
      "14709\n",
      "14710\n",
      "14711\n",
      "14712\n",
      "14713\n",
      "14714\n",
      "14715\n",
      "14716\n",
      "14717\n",
      "14718\n",
      "14719\n",
      "14720\n",
      "14721\n",
      "14722\n",
      "14723\n",
      "14724\n",
      "14725\n",
      "14726\n",
      "14727\n",
      "14728\n",
      "14729\n",
      "14730\n",
      "14731\n",
      "14732\n",
      "14733\n",
      "14734\n",
      "14735\n",
      "14736\n",
      "14737\n",
      "14738\n",
      "14739\n",
      "14740\n",
      "14741\n",
      "14742\n",
      "14743\n",
      "14744\n",
      "14745\n",
      "14746\n",
      "14747\n",
      "14748\n",
      "14749\n",
      "14750\n",
      "14751\n",
      "14752\n",
      "14753\n",
      "14754\n",
      "14755\n",
      "14756\n",
      "14757\n",
      "14758\n",
      "14759\n",
      "14760\n",
      "14761\n",
      "14762\n",
      "14763\n",
      "14764\n",
      "14765\n",
      "14766\n",
      "14767\n",
      "14768\n",
      "14769\n",
      "14770\n",
      "14771\n",
      "14772\n",
      "14773\n",
      "14774\n",
      "14775\n",
      "14776\n",
      "14777\n",
      "14778\n",
      "14779\n",
      "14780\n",
      "14781\n",
      "14782\n",
      "14783\n",
      "14784\n",
      "14785\n",
      "14786\n",
      "14787\n",
      "14788\n",
      "14789\n",
      "14790\n",
      "14791\n",
      "14792\n",
      "14793\n",
      "14794\n",
      "14795\n",
      "14796\n",
      "14797\n",
      "14798\n",
      "14799\n",
      "14800\n",
      "14801\n",
      "14802\n",
      "14803\n",
      "14804\n",
      "14805\n",
      "14806\n",
      "14807\n",
      "14808\n",
      "14809\n",
      "14810\n",
      "14811\n",
      "14812\n",
      "14813\n",
      "14814\n",
      "14815\n",
      "14816\n",
      "14817\n",
      "14818\n",
      "14819\n",
      "14820\n",
      "14821\n",
      "14822\n",
      "14823\n",
      "14824\n",
      "14825\n",
      "14826\n",
      "14827\n",
      "14828\n",
      "14829\n",
      "14830\n",
      "14831\n",
      "14832\n",
      "14833\n",
      "14834\n",
      "14835\n",
      "14836\n",
      "14837\n",
      "14838\n",
      "14839\n",
      "14840\n",
      "14841\n",
      "14842\n",
      "14843\n",
      "14844\n",
      "14845\n",
      "14846\n",
      "14847\n",
      "14848\n",
      "14849\n",
      "14850\n",
      "14851\n",
      "14852\n",
      "14853\n",
      "14854\n",
      "14855\n",
      "14856\n",
      "14857\n",
      "14858\n",
      "14859\n",
      "14860\n",
      "14861\n",
      "14862\n",
      "14863\n",
      "14864\n",
      "14865\n",
      "14866\n",
      "14867\n",
      "14868\n",
      "14869\n",
      "14870\n",
      "14871\n",
      "14872\n",
      "14873\n",
      "14874\n",
      "14875\n",
      "14876\n",
      "14877\n",
      "14878\n",
      "14879\n",
      "14880\n",
      "14881\n",
      "14882\n",
      "14883\n",
      "14884\n",
      "14885\n",
      "14886\n",
      "14887\n",
      "14888\n",
      "14889\n",
      "14890\n",
      "14891\n",
      "14892\n",
      "14893\n",
      "14894\n",
      "14895\n",
      "14896\n",
      "14897\n",
      "14898\n",
      "14899\n",
      "14900\n",
      "14901\n",
      "14902\n",
      "14903\n",
      "14904\n",
      "14905\n",
      "14906\n",
      "14907\n",
      "14908\n",
      "14909\n",
      "14910\n",
      "14911\n",
      "14912\n",
      "14913\n",
      "14914\n",
      "14915\n",
      "14916\n",
      "14917\n",
      "14918\n",
      "14919\n",
      "14920\n",
      "14921\n",
      "14922\n",
      "14923\n",
      "14924\n",
      "14925\n",
      "14926\n",
      "14927\n",
      "14928\n",
      "14929\n",
      "14930\n",
      "14931\n",
      "14932\n",
      "14933\n",
      "14934\n",
      "14935\n",
      "14936\n",
      "14937\n",
      "14938\n",
      "14939\n",
      "14940\n",
      "14941\n",
      "14942\n",
      "14943\n",
      "14944\n",
      "14945\n",
      "14946\n",
      "14947\n",
      "14948\n",
      "14949\n",
      "14950\n",
      "14951\n",
      "14952\n",
      "14953\n",
      "14954\n",
      "14955\n",
      "14956\n",
      "14957\n",
      "14958\n",
      "14959\n",
      "14960\n",
      "14961\n",
      "14962\n",
      "14963\n",
      "14964\n",
      "14965\n",
      "14966\n",
      "14967\n",
      "14968\n",
      "14969\n",
      "14970\n",
      "14971\n",
      "14972\n",
      "14973\n",
      "14974\n",
      "14975\n",
      "14976\n",
      "14977\n",
      "14978\n",
      "14979\n",
      "14980\n",
      "14981\n",
      "14982\n",
      "14983\n",
      "14984\n",
      "14985\n",
      "14986\n",
      "14987\n",
      "14988\n",
      "14989\n",
      "14990\n",
      "14991\n",
      "14992\n",
      "14993\n",
      "14994\n",
      "14995\n",
      "14996\n",
      "14997\n",
      "14998\n",
      "14999\n",
      "15000\n",
      "15001\n",
      "15002\n",
      "15003\n",
      "15004\n",
      "15005\n",
      "15006\n",
      "15007\n",
      "15008\n",
      "15009\n",
      "15010\n",
      "15011\n",
      "15012\n",
      "15013\n",
      "15014\n",
      "15015\n",
      "15016\n",
      "15017\n",
      "15018\n",
      "15019\n",
      "15020\n",
      "15021\n",
      "15022\n",
      "15023\n",
      "15024\n",
      "15025\n",
      "15026\n",
      "15027\n",
      "15028\n",
      "15029\n",
      "15030\n",
      "15031\n",
      "15032\n",
      "15033\n",
      "15034\n",
      "15035\n",
      "15036\n",
      "15037\n",
      "15038\n",
      "15039\n",
      "15040\n",
      "15041\n",
      "15042\n",
      "15043\n",
      "15044\n",
      "15045\n",
      "15046\n",
      "15047\n",
      "15048\n",
      "15049\n",
      "15050\n",
      "15051\n",
      "15052\n",
      "15053\n",
      "15054\n",
      "15055\n",
      "15056\n",
      "15057\n",
      "15058\n",
      "15059\n",
      "15060\n",
      "15061\n",
      "15062\n",
      "15063\n",
      "15064\n",
      "15065\n",
      "15066\n",
      "15067\n",
      "15068\n",
      "15069\n",
      "15070\n",
      "15071\n",
      "15072\n",
      "15073\n",
      "15074\n",
      "15075\n",
      "15076\n",
      "15077\n",
      "15078\n",
      "15079\n",
      "15080\n",
      "15081\n",
      "15082\n",
      "15083\n",
      "15084\n",
      "15085\n",
      "15086\n",
      "15087\n",
      "15088\n",
      "15089\n",
      "15090\n",
      "15091\n",
      "15092\n",
      "15093\n",
      "15094\n",
      "15095\n",
      "15096\n",
      "15097\n",
      "15098\n",
      "15099\n",
      "15100\n",
      "15101\n",
      "15102\n",
      "15103\n",
      "15104\n",
      "15105\n",
      "15106\n",
      "15107\n",
      "15108\n",
      "15109\n",
      "15110\n",
      "15111\n",
      "15112\n",
      "15113\n",
      "15114\n",
      "15115\n",
      "15116\n",
      "15117\n",
      "15118\n",
      "15119\n",
      "15120\n",
      "15121\n",
      "15122\n",
      "15123\n",
      "15124\n",
      "15125\n",
      "15126\n",
      "15127\n",
      "15128\n",
      "15129\n",
      "15130\n",
      "15131\n",
      "15132\n",
      "15133\n",
      "15134\n",
      "15135\n",
      "15136\n",
      "15137\n",
      "15138\n",
      "15139\n",
      "15140\n",
      "15141\n",
      "15142\n",
      "15143\n",
      "15144\n",
      "15145\n",
      "15146\n",
      "15147\n",
      "15148\n",
      "15149\n",
      "15150\n",
      "15151\n",
      "15152\n",
      "15153\n",
      "15154\n",
      "15155\n",
      "15156\n",
      "15157\n",
      "15158\n",
      "15159\n",
      "15160\n",
      "15161\n",
      "15162\n",
      "15163\n",
      "15164\n",
      "15165\n",
      "15166\n",
      "15167\n",
      "15168\n",
      "15169\n",
      "15170\n",
      "15171\n",
      "15172\n",
      "15173\n",
      "15174\n",
      "15175\n",
      "15176\n",
      "15177\n",
      "15178\n",
      "15179\n",
      "15180\n",
      "15181\n",
      "15182\n",
      "15183\n",
      "15184\n",
      "15185\n",
      "15186\n",
      "15187\n",
      "15188\n",
      "15189\n",
      "15190\n",
      "15191\n",
      "15192\n",
      "15193\n",
      "15194\n",
      "15195\n",
      "15196\n",
      "15197\n",
      "15198\n",
      "15199\n",
      "15200\n",
      "15201\n",
      "15202\n",
      "15203\n",
      "15204\n",
      "15205\n",
      "15206\n",
      "15207\n",
      "15208\n",
      "15209\n",
      "15210\n",
      "15211\n",
      "15212\n",
      "15213\n",
      "15214\n",
      "15215\n",
      "15216\n",
      "15217\n",
      "15218\n",
      "15219\n",
      "15220\n",
      "15221\n",
      "15222\n",
      "15223\n",
      "15224\n",
      "15225\n",
      "15226\n",
      "15227\n",
      "15228\n",
      "15229\n",
      "15230\n",
      "15231\n",
      "15232\n",
      "15233\n",
      "15234\n",
      "15235\n",
      "15236\n",
      "15237\n",
      "15238\n",
      "15239\n",
      "15240\n",
      "15241\n",
      "15242\n",
      "15243\n",
      "15244\n",
      "15245\n",
      "15246\n",
      "15247\n",
      "15248\n",
      "15249\n",
      "15250\n",
      "15251\n",
      "15252\n",
      "15253\n",
      "15254\n",
      "15255\n",
      "15256\n",
      "15257\n",
      "15258\n",
      "15259\n",
      "15260\n",
      "15261\n",
      "15262\n",
      "15263\n",
      "15264\n",
      "15265\n",
      "15266\n",
      "15267\n",
      "15268\n",
      "15269\n",
      "15270\n",
      "15271\n",
      "15272\n",
      "15273\n",
      "15274\n",
      "15275\n",
      "15276\n",
      "15277\n",
      "15278\n",
      "15279\n",
      "15280\n",
      "15281\n",
      "15282\n",
      "15283\n",
      "15284\n",
      "15285\n",
      "15286\n",
      "15287\n",
      "15288\n",
      "15289\n",
      "15290\n",
      "15291\n",
      "15292\n",
      "15293\n",
      "15294\n",
      "15295\n",
      "15296\n",
      "15297\n",
      "15298\n",
      "15299\n",
      "15300\n",
      "15301\n",
      "15302\n",
      "15303\n",
      "15304\n",
      "15305\n",
      "15306\n",
      "15307\n",
      "15308\n",
      "15309\n",
      "15310\n",
      "15311\n",
      "15312\n",
      "15313\n",
      "15314\n",
      "15315\n",
      "15316\n",
      "15317\n",
      "15318\n",
      "15319\n",
      "15320\n",
      "15321\n",
      "15322\n",
      "15323\n",
      "15324\n",
      "15325\n",
      "15326\n",
      "15327\n",
      "15328\n",
      "15329\n",
      "15330\n",
      "15331\n",
      "15332\n",
      "15333\n",
      "15334\n",
      "15335\n",
      "15336\n",
      "15337\n",
      "15338\n",
      "15339\n",
      "15340\n",
      "15341\n",
      "15342\n",
      "15343\n",
      "15344\n",
      "15345\n",
      "15346\n",
      "15347\n",
      "15348\n",
      "15349\n",
      "15350\n",
      "15351\n",
      "15352\n",
      "15353\n",
      "15354\n",
      "15355\n",
      "15356\n",
      "15357\n",
      "15358\n",
      "15359\n",
      "15360\n",
      "15361\n",
      "15362\n",
      "15363\n",
      "15364\n",
      "15365\n",
      "15366\n",
      "15367\n",
      "15368\n",
      "15369\n",
      "15370\n",
      "15371\n",
      "15372\n",
      "15373\n",
      "15374\n",
      "15375\n",
      "15376\n",
      "15377\n",
      "15378\n",
      "15379\n",
      "15380\n",
      "15381\n",
      "15382\n",
      "15383\n",
      "15384\n",
      "15385\n",
      "15386\n",
      "15387\n",
      "15388\n",
      "15389\n",
      "15390\n",
      "15391\n",
      "15392\n",
      "15393\n",
      "15394\n",
      "15395\n",
      "15396\n",
      "15397\n",
      "15398\n",
      "15399\n",
      "15400\n",
      "15401\n",
      "15402\n",
      "15403\n",
      "15404\n",
      "15405\n",
      "15406\n",
      "15407\n",
      "15408\n",
      "15409\n",
      "15410\n",
      "15411\n",
      "15412\n",
      "15413\n",
      "15414\n",
      "15415\n",
      "15416\n",
      "15417\n",
      "15418\n",
      "15419\n",
      "15420\n",
      "15421\n",
      "15422\n",
      "15423\n",
      "15424\n",
      "15425\n",
      "15426\n",
      "15427\n",
      "15428\n",
      "15429\n",
      "15430\n",
      "15431\n",
      "15432\n",
      "15433\n",
      "15434\n",
      "15435\n",
      "15436\n",
      "15437\n",
      "15438\n",
      "15439\n",
      "15440\n",
      "15441\n",
      "15442\n",
      "15443\n",
      "15444\n",
      "15445\n",
      "15446\n",
      "15447\n",
      "15448\n",
      "15449\n",
      "15450\n",
      "15451\n",
      "15452\n",
      "15453\n",
      "15454\n",
      "15455\n",
      "15456\n",
      "15457\n",
      "15458\n",
      "15459\n",
      "15460\n",
      "15461\n",
      "15462\n",
      "15463\n",
      "15464\n",
      "15465\n",
      "15466\n",
      "15467\n",
      "15468\n",
      "15469\n",
      "15470\n",
      "15471\n",
      "15472\n",
      "15473\n",
      "15474\n",
      "15475\n",
      "15476\n",
      "15477\n",
      "15478\n",
      "15479\n",
      "15480\n",
      "15481\n",
      "15482\n",
      "15483\n",
      "15484\n",
      "15485\n",
      "15486\n",
      "15487\n",
      "15488\n",
      "15489\n",
      "15490\n",
      "15491\n",
      "15492\n",
      "15493\n",
      "15494\n",
      "15495\n",
      "15496\n",
      "15497\n",
      "15498\n",
      "15499\n",
      "15500\n",
      "15501\n",
      "15502\n",
      "15503\n",
      "15504\n",
      "15505\n",
      "15506\n",
      "15507\n",
      "15508\n",
      "15509\n",
      "15510\n",
      "15511\n",
      "15512\n",
      "15513\n",
      "15514\n",
      "15515\n",
      "15516\n",
      "15517\n",
      "15518\n",
      "15519\n",
      "15520\n",
      "15521\n",
      "15522\n",
      "15523\n",
      "15524\n",
      "15525\n",
      "15526\n",
      "15527\n",
      "15528\n",
      "15529\n",
      "15530\n",
      "15531\n",
      "15532\n",
      "15533\n",
      "15534\n",
      "15535\n",
      "15536\n",
      "15537\n",
      "15538\n",
      "15539\n",
      "15540\n",
      "15541\n",
      "15542\n",
      "15543\n",
      "15544\n",
      "15545\n",
      "15546\n",
      "15547\n",
      "15548\n",
      "15549\n",
      "15550\n",
      "15551\n",
      "15552\n",
      "15553\n",
      "15554\n",
      "15555\n",
      "15556\n",
      "15557\n",
      "15558\n",
      "15559\n",
      "15560\n",
      "15561\n",
      "15562\n",
      "15563\n",
      "15564\n",
      "15565\n",
      "15566\n",
      "15567\n",
      "15568\n",
      "15569\n",
      "15570\n",
      "15571\n",
      "15572\n",
      "15573\n",
      "15574\n",
      "15575\n",
      "15576\n",
      "15577\n",
      "15578\n",
      "15579\n",
      "15580\n",
      "15581\n",
      "15582\n",
      "15583\n",
      "15584\n",
      "15585\n",
      "15586\n",
      "15587\n",
      "15588\n",
      "15589\n",
      "15590\n",
      "15591\n",
      "15592\n",
      "15593\n",
      "15594\n",
      "15595\n",
      "15596\n",
      "15597\n",
      "15598\n",
      "15599\n",
      "15600\n",
      "15601\n",
      "15602\n",
      "15603\n",
      "15604\n",
      "15605\n",
      "15606\n",
      "15607\n",
      "15608\n",
      "15609\n",
      "15610\n",
      "15611\n",
      "15612\n",
      "15613\n",
      "15614\n",
      "15615\n",
      "15616\n",
      "15617\n",
      "15618\n",
      "15619\n",
      "15620\n",
      "15621\n",
      "15622\n",
      "15623\n",
      "15624\n",
      "15625\n",
      "15626\n",
      "15627\n",
      "15628\n",
      "15629\n",
      "15630\n",
      "15631\n",
      "15632\n",
      "15633\n",
      "15634\n",
      "15635\n",
      "15636\n",
      "15637\n",
      "15638\n",
      "15639\n",
      "15640\n",
      "15641\n",
      "15642\n",
      "15643\n",
      "15644\n",
      "15645\n",
      "15646\n",
      "15647\n",
      "15648\n",
      "15649\n",
      "15650\n",
      "15651\n",
      "15652\n",
      "15653\n",
      "15654\n",
      "15655\n",
      "15656\n",
      "15657\n",
      "15658\n",
      "15659\n",
      "15660\n",
      "15661\n",
      "15662\n",
      "15663\n",
      "15664\n",
      "15665\n",
      "15666\n",
      "15667\n",
      "15668\n",
      "15669\n",
      "15670\n",
      "15671\n",
      "15672\n",
      "15673\n",
      "15674\n",
      "15675\n",
      "15676\n",
      "15677\n",
      "15678\n",
      "15679\n",
      "15680\n",
      "15681\n",
      "15682\n",
      "15683\n",
      "15684\n",
      "15685\n",
      "15686\n",
      "15687\n",
      "15688\n",
      "15689\n",
      "15690\n",
      "15691\n",
      "15692\n",
      "15693\n",
      "15694\n",
      "15695\n",
      "15696\n",
      "15697\n",
      "15698\n",
      "15699\n",
      "15700\n",
      "15701\n",
      "15702\n",
      "15703\n",
      "15704\n",
      "15705\n",
      "15706\n",
      "15707\n",
      "15708\n",
      "15709\n",
      "15710\n",
      "15711\n",
      "15712\n",
      "15713\n",
      "15714\n",
      "15715\n",
      "15716\n",
      "15717\n",
      "15718\n",
      "15719\n",
      "15720\n",
      "15721\n",
      "15722\n",
      "15723\n",
      "15724\n",
      "15725\n",
      "15726\n",
      "15727\n",
      "15728\n",
      "15729\n",
      "15730\n",
      "15731\n",
      "15732\n",
      "15733\n",
      "15734\n",
      "15735\n",
      "15736\n",
      "15737\n",
      "15738\n",
      "15739\n",
      "15740\n",
      "15741\n",
      "15742\n",
      "15743\n",
      "15744\n",
      "15745\n",
      "15746\n",
      "15747\n",
      "15748\n",
      "15749\n",
      "15750\n",
      "15751\n",
      "15752\n",
      "15753\n",
      "15754\n",
      "15755\n",
      "15756\n",
      "15757\n",
      "15758\n",
      "15759\n",
      "15760\n",
      "15761\n",
      "15762\n",
      "15763\n",
      "15764\n",
      "15765\n",
      "15766\n",
      "15767\n",
      "15768\n",
      "15769\n",
      "15770\n",
      "15771\n",
      "15772\n",
      "15773\n",
      "15774\n",
      "15775\n",
      "15776\n",
      "15777\n",
      "15778\n",
      "15779\n",
      "15780\n",
      "15781\n",
      "15782\n",
      "15783\n",
      "15784\n",
      "15785\n",
      "15786\n",
      "15787\n",
      "15788\n",
      "15789\n",
      "15790\n",
      "15791\n",
      "15792\n",
      "15793\n",
      "15794\n",
      "15795\n",
      "15796\n",
      "15797\n",
      "15798\n",
      "15799\n",
      "15800\n",
      "15801\n",
      "15802\n",
      "15803\n",
      "15804\n",
      "15805\n",
      "15806\n",
      "15807\n",
      "15808\n",
      "15809\n",
      "15810\n",
      "15811\n",
      "15812\n",
      "15813\n",
      "15814\n",
      "15815\n",
      "15816\n",
      "15817\n",
      "15818\n",
      "15819\n",
      "15820\n",
      "15821\n",
      "15822\n",
      "15823\n",
      "15824\n",
      "15825\n",
      "15826\n",
      "15827\n",
      "15828\n",
      "15829\n",
      "15830\n",
      "15831\n",
      "15832\n",
      "15833\n",
      "15834\n",
      "15835\n",
      "15836\n",
      "15837\n",
      "15838\n",
      "15839\n",
      "15840\n",
      "15841\n",
      "15842\n",
      "15843\n",
      "15844\n",
      "15845\n",
      "15846\n",
      "15847\n",
      "15848\n",
      "15849\n",
      "15850\n",
      "15851\n",
      "15852\n",
      "15853\n",
      "15854\n",
      "15855\n",
      "15856\n",
      "15857\n",
      "15858\n",
      "15859\n",
      "15860\n",
      "15861\n",
      "15862\n",
      "15863\n",
      "15864\n",
      "15865\n",
      "15866\n",
      "15867\n",
      "15868\n",
      "15869\n",
      "15870\n",
      "15871\n",
      "15872\n",
      "15873\n",
      "15874\n",
      "15875\n",
      "15876\n",
      "15877\n",
      "15878\n",
      "15879\n",
      "15880\n",
      "15881\n",
      "15882\n",
      "15883\n",
      "15884\n",
      "15885\n",
      "15886\n",
      "15887\n",
      "15888\n",
      "15889\n",
      "15890\n",
      "15891\n",
      "15892\n",
      "15893\n",
      "15894\n",
      "15895\n",
      "15896\n",
      "15897\n",
      "15898\n",
      "15899\n",
      "15900\n",
      "15901\n",
      "15902\n",
      "15903\n",
      "15904\n",
      "15905\n",
      "15906\n",
      "15907\n",
      "15908\n",
      "15909\n",
      "15910\n",
      "15911\n",
      "15912\n",
      "15913\n",
      "15914\n",
      "15915\n",
      "15916\n",
      "15917\n",
      "15918\n",
      "15919\n",
      "15920\n",
      "15921\n",
      "15922\n",
      "15923\n",
      "15924\n",
      "15925\n",
      "15926\n",
      "15927\n",
      "15928\n",
      "15929\n",
      "15930\n",
      "15931\n",
      "15932\n",
      "15933\n",
      "15934\n",
      "15935\n",
      "15936\n",
      "15937\n",
      "15938\n",
      "15939\n",
      "15940\n",
      "15941\n",
      "15942\n",
      "15943\n",
      "15944\n",
      "15945\n",
      "15946\n",
      "15947\n",
      "15948\n",
      "15949\n",
      "15950\n",
      "15951\n",
      "15952\n",
      "15953\n",
      "15954\n",
      "15955\n",
      "15956\n",
      "15957\n",
      "15958\n",
      "15959\n",
      "15960\n",
      "15961\n",
      "15962\n",
      "15963\n",
      "15964\n",
      "15965\n",
      "15966\n",
      "15967\n",
      "15968\n",
      "15969\n",
      "15970\n",
      "15971\n",
      "15972\n",
      "15973\n",
      "15974\n",
      "15975\n",
      "15976\n",
      "15977\n",
      "15978\n",
      "15979\n",
      "15980\n",
      "15981\n",
      "15982\n",
      "15983\n",
      "15984\n",
      "15985\n",
      "15986\n",
      "15987\n",
      "15988\n",
      "15989\n",
      "15990\n",
      "15991\n",
      "15992\n",
      "15993\n",
      "15994\n",
      "15995\n",
      "15996\n",
      "15997\n",
      "15998\n",
      "15999\n",
      "16000\n",
      "16001\n",
      "16002\n",
      "16003\n",
      "16004\n",
      "16005\n",
      "16006\n",
      "16007\n",
      "16008\n",
      "16009\n",
      "16010\n",
      "16011\n",
      "16012\n",
      "16013\n",
      "16014\n",
      "16015\n",
      "16016\n",
      "16017\n",
      "16018\n",
      "16019\n",
      "16020\n",
      "16021\n",
      "16022\n",
      "16023\n",
      "16024\n",
      "16025\n",
      "16026\n",
      "16027\n",
      "16028\n",
      "16029\n",
      "16030\n",
      "16031\n",
      "16032\n",
      "16033\n",
      "16034\n",
      "16035\n",
      "16036\n",
      "16037\n",
      "16038\n",
      "16039\n",
      "16040\n",
      "16041\n",
      "16042\n",
      "16043\n",
      "16044\n",
      "16045\n",
      "16046\n",
      "16047\n",
      "16048\n",
      "16049\n",
      "16050\n",
      "16051\n",
      "16052\n",
      "16053\n",
      "16054\n",
      "16055\n",
      "16056\n",
      "16057\n",
      "16058\n",
      "16059\n",
      "16060\n",
      "16061\n",
      "16062\n",
      "16063\n",
      "16064\n",
      "16065\n",
      "16066\n",
      "16067\n",
      "16068\n",
      "16069\n",
      "16070\n",
      "16071\n",
      "16072\n",
      "16073\n",
      "16074\n",
      "16075\n",
      "16076\n",
      "16077\n",
      "16078\n",
      "16079\n",
      "16080\n",
      "16081\n",
      "16082\n",
      "16083\n",
      "16084\n",
      "16085\n",
      "16086\n",
      "16087\n",
      "16088\n",
      "16089\n",
      "16090\n",
      "16091\n",
      "16092\n",
      "16093\n",
      "16094\n",
      "16095\n",
      "16096\n",
      "16097\n",
      "16098\n",
      "16099\n",
      "16100\n",
      "16101\n",
      "16102\n",
      "16103\n",
      "16104\n",
      "16105\n",
      "16106\n",
      "16107\n",
      "16108\n",
      "16109\n",
      "16110\n",
      "16111\n",
      "16112\n",
      "16113\n",
      "16114\n",
      "16115\n",
      "16116\n",
      "16117\n",
      "16118\n",
      "16119\n",
      "16120\n",
      "16121\n",
      "16122\n",
      "16123\n",
      "16124\n",
      "16125\n",
      "16126\n",
      "16127\n",
      "16128\n",
      "16129\n",
      "16130\n",
      "16131\n",
      "16132\n",
      "16133\n",
      "16134\n",
      "16135\n",
      "16136\n",
      "16137\n",
      "16138\n",
      "16139\n",
      "16140\n",
      "16141\n",
      "16142\n",
      "16143\n",
      "16144\n",
      "16145\n",
      "16146\n",
      "16147\n",
      "16148\n",
      "16149\n",
      "16150\n",
      "16151\n",
      "16152\n",
      "16153\n",
      "16154\n",
      "16155\n",
      "16156\n",
      "16157\n",
      "16158\n",
      "16159\n",
      "16160\n",
      "16161\n",
      "16162\n",
      "16163\n",
      "16164\n",
      "16165\n",
      "16166\n",
      "16167\n",
      "16168\n",
      "16169\n",
      "16170\n",
      "16171\n",
      "16172\n",
      "16173\n",
      "16174\n",
      "16175\n",
      "16176\n",
      "16177\n",
      "16178\n",
      "16179\n",
      "16180\n",
      "16181\n",
      "16182\n",
      "16183\n",
      "16184\n",
      "16185\n",
      "16186\n",
      "16187\n",
      "16188\n",
      "16189\n",
      "16190\n",
      "16191\n",
      "16192\n",
      "16193\n",
      "16194\n",
      "16195\n",
      "16196\n",
      "16197\n",
      "16198\n",
      "16199\n",
      "16200\n",
      "16201\n",
      "16202\n",
      "16203\n",
      "16204\n",
      "16205\n",
      "16206\n",
      "16207\n",
      "16208\n",
      "16209\n",
      "16210\n",
      "16211\n",
      "16212\n",
      "16213\n",
      "16214\n",
      "16215\n",
      "16216\n",
      "16217\n",
      "16218\n",
      "16219\n",
      "16220\n",
      "16221\n",
      "16222\n",
      "16223\n",
      "16224\n",
      "16225\n",
      "16226\n",
      "16227\n",
      "16228\n",
      "16229\n",
      "16230\n",
      "16231\n",
      "16232\n",
      "16233\n",
      "16234\n",
      "16235\n",
      "16236\n",
      "16237\n",
      "16238\n",
      "16239\n",
      "16240\n",
      "16241\n",
      "16242\n",
      "16243\n",
      "16244\n",
      "16245\n",
      "16246\n",
      "16247\n",
      "16248\n",
      "16249\n",
      "16250\n",
      "16251\n",
      "16252\n",
      "16253\n",
      "16254\n",
      "16255\n",
      "16256\n",
      "16257\n",
      "16258\n",
      "16259\n",
      "16260\n",
      "16261\n",
      "16262\n",
      "16263\n",
      "16264\n",
      "16265\n",
      "16266\n",
      "16267\n",
      "16268\n",
      "16269\n",
      "16270\n",
      "16271\n",
      "16272\n",
      "16273\n",
      "16274\n",
      "16275\n",
      "16276\n",
      "16277\n",
      "16278\n",
      "16279\n",
      "16280\n",
      "16281\n",
      "16282\n",
      "16283\n",
      "16284\n",
      "16285\n",
      "16286\n",
      "16287\n",
      "16288\n",
      "16289\n",
      "16290\n",
      "16291\n",
      "16292\n",
      "16293\n",
      "16294\n",
      "16295\n",
      "16296\n",
      "16297\n",
      "16298\n",
      "16299\n",
      "16300\n",
      "16301\n",
      "16302\n",
      "16303\n",
      "16304\n",
      "16305\n",
      "16306\n",
      "16307\n",
      "16308\n",
      "16309\n",
      "16310\n",
      "16311\n",
      "16312\n",
      "16313\n",
      "16314\n",
      "16315\n",
      "16316\n",
      "16317\n",
      "16318\n",
      "16319\n",
      "16320\n",
      "16321\n",
      "16322\n",
      "16323\n",
      "16324\n",
      "16325\n",
      "16326\n",
      "16327\n",
      "16328\n",
      "16329\n",
      "16330\n",
      "16331\n",
      "16332\n",
      "16333\n",
      "16334\n",
      "16335\n",
      "16336\n",
      "16337\n",
      "16338\n",
      "16339\n",
      "16340\n",
      "16341\n",
      "16342\n",
      "16343\n",
      "16344\n",
      "16345\n",
      "16346\n",
      "16347\n",
      "16348\n",
      "16349\n",
      "16350\n",
      "16351\n",
      "16352\n",
      "16353\n",
      "16354\n",
      "16355\n",
      "16356\n",
      "16357\n",
      "16358\n",
      "16359\n",
      "16360\n",
      "16361\n",
      "16362\n",
      "16363\n",
      "16364\n",
      "16365\n",
      "16366\n",
      "16367\n",
      "16368\n",
      "16369\n",
      "16370\n",
      "16371\n",
      "16372\n",
      "16373\n",
      "16374\n",
      "16375\n",
      "16376\n",
      "16377\n",
      "16378\n",
      "16379\n",
      "16380\n",
      "16381\n",
      "16382\n",
      "16383\n",
      "16384\n",
      "16385\n",
      "16386\n",
      "16387\n",
      "16388\n",
      "16389\n",
      "16390\n",
      "16391\n",
      "16392\n",
      "16393\n",
      "16394\n",
      "16395\n",
      "16396\n",
      "16397\n",
      "16398\n",
      "16399\n",
      "16400\n",
      "16401\n",
      "16402\n",
      "16403\n",
      "16404\n",
      "16405\n",
      "16406\n",
      "16407\n",
      "16408\n",
      "16409\n",
      "16410\n",
      "16411\n",
      "16412\n",
      "16413\n",
      "16414\n",
      "16415\n",
      "16416\n",
      "16417\n",
      "16418\n",
      "16419\n",
      "16420\n",
      "16421\n",
      "16422\n",
      "16423\n",
      "16424\n",
      "16425\n",
      "16426\n",
      "16427\n",
      "16428\n",
      "16429\n",
      "16430\n",
      "16431\n",
      "16432\n",
      "16433\n",
      "16434\n",
      "16435\n",
      "16436\n",
      "16437\n",
      "16438\n",
      "16439\n",
      "16440\n",
      "16441\n",
      "16442\n",
      "16443\n",
      "16444\n",
      "16445\n",
      "16446\n",
      "16447\n",
      "16448\n",
      "16449\n",
      "16450\n",
      "16451\n",
      "16452\n",
      "16453\n",
      "16454\n",
      "16455\n",
      "16456\n",
      "16457\n",
      "16458\n",
      "16459\n",
      "16460\n",
      "16461\n",
      "16462\n",
      "16463\n",
      "16464\n",
      "16465\n",
      "16466\n",
      "16467\n",
      "16468\n",
      "16469\n",
      "16470\n",
      "16471\n",
      "16472\n",
      "16473\n",
      "16474\n",
      "16475\n",
      "16476\n",
      "16477\n",
      "16478\n",
      "16479\n",
      "16480\n",
      "16481\n",
      "16482\n",
      "16483\n",
      "16484\n",
      "16485\n",
      "16486\n",
      "16487\n",
      "16488\n",
      "16489\n",
      "16490\n",
      "16491\n",
      "16492\n",
      "16493\n",
      "16494\n",
      "16495\n",
      "16496\n",
      "16497\n",
      "16498\n",
      "16499\n",
      "16500\n",
      "16501\n",
      "16502\n",
      "16503\n",
      "16504\n",
      "16505\n",
      "16506\n",
      "16507\n",
      "16508\n",
      "16509\n",
      "16510\n",
      "16511\n",
      "16512\n",
      "16513\n",
      "16514\n",
      "16515\n",
      "16516\n",
      "16517\n",
      "16518\n",
      "16519\n",
      "16520\n",
      "16521\n",
      "16522\n",
      "16523\n",
      "16524\n",
      "16525\n",
      "16526\n",
      "16527\n",
      "16528\n",
      "16529\n",
      "16530\n",
      "16531\n",
      "16532\n",
      "16533\n",
      "16534\n",
      "16535\n",
      "16536\n",
      "16537\n",
      "16538\n",
      "16539\n",
      "16540\n",
      "16541\n",
      "16542\n",
      "16543\n",
      "16544\n",
      "16545\n",
      "16546\n",
      "16547\n",
      "16548\n",
      "16549\n",
      "16550\n",
      "16551\n",
      "16552\n",
      "16553\n",
      "16554\n",
      "16555\n",
      "16556\n",
      "16557\n",
      "16558\n",
      "16559\n",
      "16560\n",
      "16561\n",
      "16562\n",
      "16563\n",
      "16564\n",
      "16565\n",
      "16566\n",
      "16567\n",
      "16568\n",
      "16569\n",
      "16570\n",
      "16571\n",
      "16572\n",
      "16573\n",
      "16574\n",
      "16575\n",
      "16576\n",
      "16577\n",
      "16578\n",
      "16579\n",
      "16580\n",
      "16581\n",
      "16582\n",
      "16583\n",
      "16584\n",
      "16585\n",
      "16586\n",
      "16587\n",
      "16588\n",
      "16589\n",
      "16590\n",
      "16591\n",
      "16592\n",
      "16593\n",
      "16594\n",
      "16595\n",
      "16596\n",
      "16597\n",
      "16598\n",
      "16599\n",
      "16600\n",
      "16601\n",
      "16602\n",
      "16603\n",
      "16604\n",
      "16605\n",
      "16606\n",
      "16607\n",
      "16608\n",
      "16609\n",
      "16610\n",
      "16611\n",
      "16612\n",
      "16613\n",
      "16614\n",
      "16615\n",
      "16616\n",
      "16617\n",
      "16618\n",
      "16619\n",
      "16620\n",
      "16621\n",
      "16622\n",
      "16623\n",
      "16624\n",
      "16625\n",
      "16626\n",
      "16627\n",
      "16628\n",
      "16629\n",
      "16630\n",
      "16631\n",
      "16632\n",
      "16633\n",
      "16634\n",
      "16635\n",
      "16636\n",
      "16637\n",
      "16638\n",
      "16639\n",
      "16640\n",
      "16641\n",
      "16642\n",
      "16643\n",
      "16644\n",
      "16645\n",
      "16646\n",
      "16647\n",
      "16648\n",
      "16649\n",
      "16650\n",
      "16651\n",
      "16652\n",
      "16653\n",
      "16654\n",
      "16655\n",
      "16656\n",
      "16657\n",
      "16658\n",
      "16659\n",
      "16660\n",
      "16661\n",
      "16662\n",
      "16663\n",
      "16664\n",
      "16665\n",
      "16666\n",
      "16667\n",
      "16668\n",
      "16669\n",
      "16670\n",
      "16671\n",
      "16672\n",
      "16673\n",
      "16674\n",
      "16675\n",
      "16676\n",
      "16677\n",
      "16678\n",
      "16679\n",
      "16680\n",
      "16681\n",
      "16682\n",
      "16683\n",
      "16684\n",
      "16685\n",
      "16686\n",
      "16687\n",
      "16688\n",
      "16689\n",
      "16690\n",
      "16691\n",
      "16692\n",
      "16693\n",
      "16694\n",
      "16695\n",
      "16696\n",
      "16697\n",
      "16698\n",
      "16699\n",
      "16700\n",
      "16701\n",
      "16702\n",
      "16703\n",
      "16704\n",
      "16705\n",
      "16706\n",
      "16707\n",
      "16708\n",
      "16709\n",
      "16710\n",
      "16711\n",
      "16712\n",
      "16713\n",
      "16714\n",
      "16715\n",
      "16716\n",
      "16717\n",
      "16718\n",
      "16719\n",
      "16720\n",
      "16721\n",
      "16722\n",
      "16723\n",
      "16724\n",
      "16725\n",
      "16726\n",
      "16727\n",
      "16728\n",
      "16729\n",
      "16730\n",
      "16731\n",
      "16732\n",
      "16733\n",
      "16734\n",
      "16735\n",
      "16736\n",
      "16737\n",
      "16738\n",
      "16739\n",
      "16740\n",
      "16741\n",
      "16742\n",
      "16743\n",
      "16744\n",
      "16745\n",
      "16746\n",
      "16747\n",
      "16748\n",
      "16749\n",
      "16750\n",
      "16751\n",
      "16752\n",
      "16753\n",
      "16754\n",
      "16755\n",
      "16756\n",
      "16757\n",
      "16758\n",
      "16759\n",
      "16760\n",
      "16761\n",
      "16762\n",
      "16763\n",
      "16764\n",
      "16765\n",
      "16766\n",
      "16767\n",
      "16768\n",
      "16769\n",
      "16770\n",
      "16771\n",
      "16772\n",
      "16773\n",
      "16774\n",
      "16775\n",
      "16776\n",
      "16777\n",
      "16778\n",
      "16779\n",
      "16780\n",
      "16781\n",
      "16782\n",
      "16783\n",
      "16784\n",
      "16785\n",
      "16786\n",
      "16787\n",
      "16788\n",
      "16789\n",
      "16790\n",
      "16791\n",
      "16792\n",
      "16793\n",
      "16794\n",
      "16795\n",
      "16796\n",
      "16797\n",
      "16798\n",
      "16799\n",
      "16800\n",
      "16801\n",
      "16802\n",
      "16803\n",
      "16804\n",
      "16805\n",
      "16806\n",
      "16807\n",
      "16808\n",
      "16809\n",
      "16810\n",
      "16811\n",
      "16812\n",
      "16813\n",
      "16814\n",
      "16815\n",
      "16816\n",
      "16817\n",
      "16818\n",
      "16819\n",
      "16820\n",
      "16821\n",
      "16822\n",
      "16823\n",
      "16824\n",
      "16825\n",
      "16826\n",
      "16827\n",
      "16828\n",
      "16829\n",
      "16830\n",
      "16831\n",
      "16832\n",
      "16833\n",
      "16834\n",
      "16835\n",
      "16836\n",
      "16837\n",
      "16838\n",
      "16839\n",
      "16840\n",
      "16841\n",
      "16842\n",
      "16843\n",
      "16844\n",
      "16845\n",
      "16846\n",
      "16847\n",
      "16848\n",
      "16849\n",
      "16850\n",
      "16851\n",
      "16852\n",
      "16853\n",
      "16854\n",
      "16855\n",
      "16856\n",
      "16857\n",
      "16858\n",
      "16859\n",
      "16860\n",
      "16861\n",
      "16862\n",
      "16863\n",
      "16864\n",
      "16865\n",
      "16866\n",
      "16867\n",
      "16868\n",
      "16869\n",
      "16870\n",
      "16871\n",
      "16872\n",
      "16873\n",
      "16874\n",
      "16875\n",
      "16876\n",
      "16877\n",
      "16878\n",
      "16879\n",
      "16880\n",
      "16881\n",
      "16882\n",
      "16883\n",
      "16884\n",
      "16885\n",
      "16886\n",
      "16887\n",
      "16888\n",
      "16889\n",
      "16890\n",
      "16891\n",
      "16892\n",
      "16893\n",
      "16894\n",
      "16895\n",
      "16896\n",
      "16897\n",
      "16898\n",
      "16899\n",
      "16900\n",
      "16901\n",
      "16902\n",
      "16903\n",
      "16904\n",
      "16905\n",
      "16906\n",
      "16907\n",
      "16908\n",
      "16909\n",
      "16910\n",
      "16911\n",
      "16912\n",
      "16913\n",
      "16914\n",
      "16915\n",
      "16916\n",
      "16917\n",
      "16918\n",
      "16919\n",
      "16920\n",
      "16921\n",
      "16922\n",
      "16923\n",
      "16924\n",
      "16925\n",
      "16926\n",
      "16927\n",
      "16928\n",
      "16929\n",
      "16930\n",
      "16931\n",
      "16932\n",
      "16933\n",
      "16934\n",
      "16935\n",
      "16936\n",
      "16937\n",
      "16938\n",
      "16939\n",
      "16940\n",
      "16941\n",
      "16942\n",
      "16943\n",
      "16944\n",
      "16945\n",
      "16946\n",
      "16947\n",
      "16948\n",
      "16949\n",
      "16950\n",
      "16951\n",
      "16952\n",
      "16953\n",
      "16954\n",
      "16955\n",
      "16956\n",
      "16957\n",
      "16958\n",
      "16959\n",
      "16960\n",
      "16961\n",
      "16962\n",
      "16963\n",
      "16964\n",
      "16965\n",
      "16966\n",
      "16967\n",
      "16968\n",
      "16969\n",
      "16970\n",
      "16971\n",
      "16972\n",
      "16973\n",
      "16974\n",
      "16975\n",
      "16976\n",
      "16977\n",
      "16978\n",
      "16979\n",
      "16980\n",
      "16981\n",
      "16982\n",
      "16983\n",
      "16984\n",
      "16985\n",
      "16986\n",
      "16987\n",
      "16988\n",
      "16989\n",
      "16990\n",
      "16991\n",
      "16992\n",
      "16993\n",
      "16994\n",
      "16995\n",
      "16996\n",
      "16997\n",
      "16998\n",
      "16999\n",
      "17000\n",
      "17001\n",
      "17002\n",
      "17003\n",
      "17004\n",
      "17005\n",
      "17006\n",
      "17007\n",
      "17008\n",
      "17009\n",
      "17010\n",
      "17011\n",
      "17012\n",
      "17013\n",
      "17014\n",
      "17015\n",
      "17016\n",
      "17017\n",
      "17018\n",
      "17019\n",
      "17020\n",
      "17021\n",
      "17022\n",
      "17023\n",
      "17024\n",
      "17025\n",
      "17026\n",
      "17027\n",
      "17028\n",
      "17029\n",
      "17030\n",
      "17031\n",
      "17032\n",
      "17033\n",
      "17034\n",
      "17035\n",
      "17036\n",
      "17037\n",
      "17038\n",
      "17039\n",
      "17040\n",
      "17041\n",
      "17042\n",
      "17043\n",
      "17044\n",
      "17045\n",
      "17046\n",
      "17047\n",
      "17048\n",
      "17049\n",
      "17050\n",
      "17051\n",
      "17052\n",
      "17053\n",
      "17054\n",
      "17055\n",
      "17056\n",
      "17057\n",
      "17058\n",
      "17059\n",
      "17060\n",
      "17061\n",
      "17062\n",
      "17063\n",
      "17064\n",
      "17065\n",
      "17066\n",
      "17067\n",
      "17068\n",
      "17069\n",
      "17070\n",
      "17071\n",
      "17072\n",
      "17073\n",
      "17074\n",
      "17075\n",
      "17076\n",
      "17077\n",
      "17078\n",
      "17079\n",
      "17080\n",
      "17081\n",
      "17082\n",
      "17083\n",
      "17084\n",
      "17085\n",
      "17086\n",
      "17087\n",
      "17088\n",
      "17089\n",
      "17090\n",
      "17091\n",
      "17092\n",
      "17093\n",
      "17094\n",
      "17095\n",
      "17096\n",
      "17097\n",
      "17098\n",
      "17099\n",
      "17100\n",
      "17101\n",
      "17102\n",
      "17103\n",
      "17104\n",
      "17105\n",
      "17106\n",
      "17107\n",
      "17108\n",
      "17109\n",
      "17110\n",
      "17111\n",
      "17112\n",
      "17113\n",
      "17114\n",
      "17115\n",
      "17116\n",
      "17117\n",
      "17118\n",
      "17119\n",
      "17120\n",
      "17121\n",
      "17122\n",
      "17123\n",
      "17124\n",
      "17125\n",
      "17126\n",
      "17127\n",
      "17128\n",
      "17129\n",
      "17130\n",
      "17131\n",
      "17132\n",
      "17133\n",
      "17134\n",
      "17135\n",
      "17136\n",
      "17137\n",
      "17138\n",
      "17139\n",
      "17140\n",
      "17141\n",
      "17142\n",
      "17143\n",
      "17144\n",
      "17145\n",
      "17146\n",
      "17147\n",
      "17148\n",
      "17149\n",
      "17150\n",
      "17151\n",
      "17152\n",
      "17153\n",
      "17154\n",
      "17155\n",
      "17156\n",
      "17157\n",
      "17158\n",
      "17159\n",
      "17160\n",
      "17161\n",
      "17162\n",
      "17163\n",
      "17164\n",
      "17165\n",
      "17166\n",
      "17167\n",
      "17168\n",
      "17169\n",
      "17170\n",
      "17171\n",
      "17172\n",
      "17173\n",
      "17174\n",
      "17175\n",
      "17176\n",
      "17177\n",
      "17178\n",
      "17179\n",
      "17180\n",
      "17181\n",
      "17182\n",
      "17183\n",
      "17184\n",
      "17185\n",
      "17186\n",
      "17187\n",
      "17188\n",
      "17189\n",
      "17190\n",
      "17191\n",
      "17192\n",
      "17193\n",
      "17194\n",
      "17195\n",
      "17196\n",
      "17197\n",
      "17198\n",
      "17199\n",
      "17200\n",
      "17201\n",
      "17202\n",
      "17203\n",
      "17204\n",
      "17205\n",
      "17206\n",
      "17207\n",
      "17208\n",
      "17209\n",
      "17210\n",
      "17211\n",
      "17212\n",
      "17213\n",
      "17214\n",
      "17215\n",
      "17216\n",
      "17217\n",
      "17218\n",
      "17219\n",
      "17220\n",
      "17221\n",
      "17222\n",
      "17223\n",
      "17224\n",
      "17225\n",
      "17226\n",
      "17227\n",
      "17228\n",
      "17229\n",
      "17230\n",
      "17231\n",
      "17232\n",
      "17233\n",
      "17234\n",
      "17235\n",
      "17236\n",
      "17237\n",
      "17238\n",
      "17239\n",
      "17240\n",
      "17241\n",
      "17242\n",
      "17243\n",
      "17244\n",
      "17245\n",
      "17246\n",
      "17247\n",
      "17248\n",
      "17249\n",
      "17250\n",
      "17251\n",
      "17252\n",
      "17253\n",
      "17254\n",
      "17255\n",
      "17256\n",
      "17257\n",
      "17258\n",
      "17259\n",
      "17260\n",
      "17261\n",
      "17262\n",
      "17263\n",
      "17264\n",
      "17265\n",
      "17266\n",
      "17267\n",
      "17268\n",
      "17269\n",
      "17270\n",
      "17271\n",
      "17272\n",
      "17273\n",
      "17274\n",
      "17275\n",
      "17276\n",
      "17277\n",
      "17278\n",
      "17279\n",
      "17280\n",
      "17281\n",
      "17282\n",
      "17283\n",
      "17284\n",
      "17285\n",
      "17286\n",
      "17287\n",
      "17288\n",
      "17289\n",
      "17290\n",
      "17291\n",
      "17292\n",
      "17293\n",
      "17294\n",
      "17295\n",
      "17296\n",
      "17297\n",
      "17298\n",
      "17299\n",
      "17300\n",
      "17301\n",
      "17302\n",
      "17303\n",
      "17304\n",
      "17305\n",
      "17306\n",
      "17307\n",
      "17308\n",
      "17309\n",
      "17310\n",
      "17311\n",
      "17312\n",
      "17313\n",
      "17314\n",
      "17315\n",
      "17316\n",
      "17317\n",
      "17318\n",
      "17319\n",
      "17320\n",
      "17321\n",
      "17322\n",
      "17323\n",
      "17324\n",
      "17325\n",
      "17326\n",
      "17327\n",
      "17328\n",
      "17329\n",
      "17330\n",
      "17331\n",
      "17332\n",
      "17333\n",
      "17334\n",
      "17335\n",
      "17336\n",
      "17337\n",
      "17338\n",
      "17339\n",
      "17340\n",
      "17341\n",
      "17342\n",
      "17343\n",
      "17344\n",
      "17345\n",
      "17346\n",
      "17347\n",
      "17348\n",
      "17349\n",
      "17350\n",
      "17351\n",
      "17352\n",
      "17353\n",
      "17354\n",
      "17355\n",
      "17356\n",
      "17357\n",
      "17358\n",
      "17359\n",
      "17360\n",
      "17361\n",
      "17362\n",
      "17363\n",
      "17364\n",
      "17365\n",
      "17366\n",
      "17367\n",
      "17368\n",
      "17369\n",
      "17370\n",
      "17371\n",
      "17372\n",
      "17373\n",
      "17374\n",
      "17375\n",
      "17376\n",
      "17377\n",
      "17378\n",
      "17379\n",
      "17380\n",
      "17381\n",
      "17382\n",
      "17383\n",
      "17384\n",
      "17385\n",
      "17386\n",
      "17387\n",
      "17388\n",
      "17389\n",
      "17390\n",
      "17391\n",
      "17392\n",
      "17393\n",
      "17394\n",
      "17395\n",
      "17396\n",
      "17397\n",
      "17398\n",
      "17399\n",
      "17400\n",
      "17401\n",
      "17402\n",
      "17403\n",
      "17404\n",
      "17405\n",
      "17406\n",
      "17407\n",
      "17408\n",
      "17409\n",
      "17410\n",
      "17411\n",
      "17412\n",
      "17413\n",
      "17414\n",
      "17415\n",
      "17416\n",
      "17417\n",
      "17418\n",
      "17419\n",
      "17420\n",
      "17421\n",
      "17422\n",
      "17423\n",
      "17424\n",
      "17425\n",
      "17426\n",
      "17427\n",
      "17428\n",
      "17429\n",
      "17430\n",
      "17431\n",
      "17432\n",
      "17433\n",
      "17434\n",
      "17435\n",
      "17436\n",
      "17437\n",
      "17438\n",
      "17439\n",
      "17440\n",
      "17441\n",
      "17442\n",
      "17443\n",
      "17444\n",
      "17445\n",
      "17446\n",
      "17447\n",
      "17448\n",
      "17449\n",
      "17450\n",
      "17451\n",
      "17452\n",
      "17453\n",
      "17454\n",
      "17455\n",
      "17456\n",
      "17457\n",
      "17458\n",
      "17459\n",
      "17460\n",
      "17461\n",
      "17462\n",
      "17463\n",
      "17464\n",
      "17465\n",
      "17466\n",
      "17467\n",
      "17468\n",
      "17469\n",
      "17470\n",
      "17471\n",
      "17472\n",
      "17473\n",
      "17474\n",
      "17475\n",
      "17476\n",
      "17477\n",
      "17478\n",
      "17479\n",
      "17480\n",
      "17481\n",
      "17482\n",
      "17483\n",
      "17484\n",
      "17485\n",
      "17486\n",
      "17487\n",
      "17488\n",
      "17489\n",
      "17490\n",
      "17491\n",
      "17492\n",
      "17493\n",
      "17494\n",
      "17495\n",
      "17496\n",
      "17497\n",
      "17498\n",
      "17499\n",
      "17500\n",
      "17501\n",
      "17502\n",
      "17503\n",
      "17504\n",
      "17505\n",
      "17506\n",
      "17507\n",
      "17508\n",
      "17509\n",
      "17510\n",
      "17511\n",
      "17512\n",
      "17513\n",
      "17514\n",
      "17515\n",
      "17516\n",
      "17517\n",
      "17518\n",
      "17519\n",
      "17520\n",
      "17521\n",
      "17522\n",
      "17523\n",
      "17524\n",
      "17525\n",
      "17526\n",
      "17527\n",
      "17528\n",
      "17529\n",
      "17530\n",
      "17531\n",
      "17532\n",
      "17533\n",
      "17534\n",
      "17535\n",
      "17536\n",
      "17537\n",
      "17538\n",
      "17539\n",
      "17540\n",
      "17541\n",
      "17542\n",
      "17543\n",
      "17544\n",
      "17545\n",
      "17546\n",
      "17547\n",
      "17548\n",
      "17549\n",
      "17550\n",
      "17551\n",
      "17552\n",
      "17553\n",
      "17554\n",
      "17555\n",
      "17556\n",
      "17557\n",
      "17558\n",
      "17559\n",
      "17560\n",
      "17561\n",
      "17562\n",
      "17563\n",
      "17564\n",
      "17565\n",
      "17566\n",
      "17567\n",
      "17568\n",
      "17569\n",
      "17570\n",
      "17571\n",
      "17572\n",
      "17573\n",
      "17574\n",
      "17575\n",
      "17576\n",
      "17577\n",
      "17578\n",
      "17579\n",
      "17580\n",
      "17581\n",
      "17582\n",
      "17583\n",
      "17584\n",
      "17585\n",
      "17586\n",
      "17587\n",
      "17588\n",
      "17589\n",
      "17590\n",
      "17591\n",
      "17592\n",
      "17593\n",
      "17594\n",
      "17595\n",
      "17596\n",
      "17597\n",
      "17598\n",
      "17599\n",
      "17600\n",
      "17601\n",
      "17602\n",
      "17603\n",
      "17604\n",
      "17605\n",
      "17606\n",
      "17607\n",
      "17608\n",
      "17609\n",
      "17610\n",
      "17611\n",
      "17612\n",
      "17613\n",
      "17614\n",
      "17615\n",
      "17616\n",
      "17617\n",
      "17618\n",
      "17619\n",
      "17620\n",
      "17621\n",
      "17622\n",
      "17623\n",
      "17624\n",
      "17625\n",
      "17626\n",
      "17627\n",
      "17628\n",
      "17629\n",
      "17630\n",
      "17631\n",
      "17632\n",
      "17633\n",
      "17634\n",
      "17635\n",
      "17636\n",
      "17637\n",
      "17638\n",
      "17639\n",
      "17640\n",
      "17641\n",
      "17642\n",
      "17643\n",
      "17644\n",
      "17645\n",
      "17646\n",
      "17647\n",
      "17648\n",
      "17649\n",
      "17650\n",
      "17651\n",
      "17652\n",
      "17653\n",
      "17654\n",
      "17655\n",
      "17656\n",
      "17657\n",
      "17658\n",
      "17659\n",
      "17660\n",
      "17661\n",
      "17662\n",
      "17663\n",
      "17664\n",
      "17665\n",
      "17666\n",
      "17667\n",
      "17668\n",
      "17669\n",
      "17670\n",
      "17671\n",
      "17672\n",
      "17673\n",
      "17674\n",
      "17675\n",
      "17676\n",
      "17677\n",
      "17678\n",
      "17679\n",
      "17680\n",
      "17681\n",
      "17682\n",
      "17683\n",
      "17684\n",
      "17685\n",
      "17686\n",
      "17687\n",
      "17688\n",
      "17689\n",
      "17690\n",
      "17691\n",
      "17692\n",
      "17693\n",
      "17694\n",
      "17695\n",
      "17696\n",
      "17697\n",
      "17698\n",
      "17699\n",
      "17700\n",
      "17701\n",
      "17702\n",
      "17703\n",
      "17704\n",
      "17705\n",
      "17706\n",
      "17707\n",
      "17708\n",
      "17709\n",
      "17710\n",
      "17711\n",
      "17712\n",
      "17713\n",
      "17714\n",
      "17715\n",
      "17716\n",
      "17717\n",
      "17718\n",
      "17719\n",
      "17720\n",
      "17721\n",
      "17722\n",
      "17723\n",
      "17724\n",
      "17725\n",
      "17726\n",
      "17727\n",
      "17728\n",
      "17729\n",
      "17730\n",
      "17731\n",
      "17732\n",
      "17733\n",
      "17734\n",
      "17735\n",
      "17736\n",
      "17737\n",
      "17738\n",
      "17739\n",
      "17740\n",
      "17741\n",
      "17742\n",
      "17743\n",
      "17744\n",
      "17745\n",
      "17746\n",
      "17747\n",
      "17748\n",
      "17749\n",
      "17750\n",
      "17751\n",
      "17752\n",
      "17753\n",
      "17754\n",
      "17755\n",
      "17756\n",
      "17757\n",
      "17758\n",
      "17759\n",
      "17760\n",
      "17761\n",
      "17762\n",
      "17763\n",
      "17764\n",
      "17765\n",
      "17766\n",
      "17767\n",
      "17768\n",
      "17769\n",
      "17770\n",
      "17771\n",
      "17772\n",
      "17773\n",
      "17774\n",
      "17775\n",
      "17776\n",
      "17777\n",
      "17778\n",
      "17779\n",
      "17780\n",
      "17781\n",
      "17782\n",
      "17783\n",
      "17784\n",
      "17785\n",
      "17786\n",
      "17787\n",
      "17788\n",
      "17789\n",
      "17790\n",
      "17791\n",
      "17792\n",
      "17793\n",
      "17794\n",
      "17795\n",
      "17796\n",
      "17797\n",
      "17798\n",
      "17799\n",
      "17800\n",
      "17801\n",
      "17802\n",
      "17803\n",
      "17804\n",
      "17805\n",
      "17806\n",
      "17807\n",
      "17808\n",
      "17809\n",
      "17810\n",
      "17811\n",
      "17812\n",
      "17813\n",
      "17814\n",
      "17815\n",
      "17816\n",
      "17817\n",
      "17818\n",
      "17819\n",
      "17820\n",
      "17821\n",
      "17822\n",
      "17823\n",
      "17824\n",
      "17825\n",
      "17826\n",
      "17827\n",
      "17828\n",
      "17829\n",
      "17830\n",
      "17831\n",
      "17832\n",
      "17833\n",
      "17834\n",
      "17835\n",
      "17836\n",
      "17837\n",
      "17838\n",
      "17839\n",
      "17840\n",
      "17841\n",
      "17842\n",
      "17843\n",
      "17844\n",
      "17845\n",
      "17846\n",
      "17847\n",
      "17848\n",
      "17849\n",
      "17850\n",
      "17851\n",
      "17852\n",
      "17853\n",
      "17854\n",
      "17855\n",
      "17856\n",
      "17857\n",
      "17858\n",
      "17859\n",
      "17860\n",
      "17861\n",
      "17862\n",
      "17863\n",
      "17864\n",
      "17865\n",
      "17866\n",
      "17867\n",
      "17868\n",
      "17869\n",
      "17870\n",
      "17871\n",
      "17872\n",
      "17873\n",
      "17874\n",
      "17875\n",
      "17876\n",
      "17877\n",
      "17878\n",
      "17879\n",
      "17880\n",
      "17881\n",
      "17882\n",
      "17883\n",
      "17884\n",
      "17885\n",
      "17886\n",
      "17887\n",
      "17888\n",
      "17889\n",
      "17890\n",
      "17891\n",
      "17892\n",
      "17893\n",
      "17894\n",
      "17895\n",
      "17896\n",
      "17897\n",
      "17898\n",
      "17899\n",
      "17900\n",
      "17901\n",
      "17902\n",
      "17903\n",
      "17904\n",
      "17905\n",
      "17906\n",
      "17907\n",
      "17908\n",
      "17909\n",
      "17910\n",
      "17911\n",
      "17912\n",
      "17913\n",
      "17914\n",
      "17915\n",
      "17916\n",
      "17917\n",
      "17918\n",
      "17919\n",
      "17920\n",
      "17921\n",
      "17922\n",
      "17923\n",
      "17924\n",
      "17925\n",
      "17926\n",
      "17927\n",
      "17928\n",
      "17929\n",
      "17930\n",
      "17931\n",
      "17932\n",
      "17933\n",
      "17934\n",
      "17935\n",
      "17936\n",
      "17937\n",
      "17938\n",
      "17939\n",
      "17940\n",
      "17941\n",
      "17942\n",
      "17943\n",
      "17944\n",
      "17945\n",
      "17946\n",
      "17947\n",
      "17948\n",
      "17949\n",
      "17950\n",
      "17951\n",
      "17952\n",
      "17953\n",
      "17954\n",
      "17955\n",
      "17956\n",
      "17957\n",
      "17958\n",
      "17959\n",
      "17960\n",
      "17961\n",
      "17962\n",
      "17963\n",
      "17964\n",
      "17965\n",
      "17966\n",
      "17967\n",
      "17968\n",
      "17969\n",
      "17970\n",
      "17971\n",
      "17972\n",
      "17973\n",
      "17974\n",
      "17975\n",
      "17976\n",
      "17977\n",
      "17978\n",
      "17979\n",
      "17980\n",
      "17981\n",
      "17982\n",
      "17983\n",
      "17984\n",
      "17985\n",
      "17986\n",
      "17987\n",
      "17988\n",
      "17989\n",
      "17990\n",
      "17991\n",
      "17992\n",
      "17993\n",
      "17994\n",
      "17995\n",
      "17996\n",
      "17997\n",
      "17998\n",
      "17999\n",
      "18000\n",
      "18001\n",
      "18002\n",
      "18003\n",
      "18004\n",
      "18005\n",
      "18006\n",
      "18007\n",
      "18008\n",
      "18009\n",
      "18010\n",
      "18011\n",
      "18012\n",
      "18013\n",
      "18014\n",
      "18015\n",
      "18016\n",
      "18017\n",
      "18018\n",
      "18019\n",
      "18020\n",
      "18021\n",
      "18022\n",
      "18023\n",
      "18024\n",
      "18025\n",
      "18026\n",
      "18027\n",
      "18028\n",
      "18029\n",
      "18030\n",
      "18031\n",
      "18032\n",
      "18033\n",
      "18034\n",
      "18035\n",
      "18036\n",
      "18037\n",
      "18038\n",
      "18039\n",
      "18040\n",
      "18041\n",
      "18042\n",
      "18043\n",
      "18044\n",
      "18045\n",
      "18046\n",
      "18047\n",
      "18048\n",
      "18049\n",
      "18050\n",
      "18051\n",
      "18052\n",
      "18053\n",
      "18054\n",
      "18055\n",
      "18056\n",
      "18057\n",
      "18058\n",
      "18059\n",
      "18060\n",
      "18061\n",
      "18062\n",
      "18063\n",
      "18064\n",
      "18065\n",
      "18066\n",
      "18067\n",
      "18068\n",
      "18069\n",
      "18070\n",
      "18071\n",
      "18072\n",
      "18073\n",
      "18074\n",
      "18075\n",
      "18076\n",
      "18077\n",
      "18078\n",
      "18079\n",
      "18080\n",
      "18081\n",
      "18082\n",
      "18083\n",
      "18084\n",
      "18085\n",
      "18086\n",
      "18087\n",
      "18088\n",
      "18089\n",
      "18090\n",
      "18091\n",
      "18092\n",
      "18093\n",
      "18094\n",
      "18095\n",
      "18096\n",
      "18097\n",
      "18098\n",
      "18099\n",
      "18100\n",
      "18101\n",
      "18102\n",
      "18103\n",
      "18104\n",
      "18105\n",
      "18106\n",
      "18107\n",
      "18108\n",
      "18109\n",
      "18110\n",
      "18111\n",
      "18112\n",
      "18113\n",
      "18114\n",
      "18115\n",
      "18116\n",
      "18117\n",
      "18118\n",
      "18119\n",
      "18120\n",
      "18121\n",
      "18122\n",
      "18123\n",
      "18124\n",
      "18125\n",
      "18126\n",
      "18127\n",
      "18128\n",
      "18129\n",
      "18130\n",
      "18131\n",
      "18132\n",
      "18133\n",
      "18134\n",
      "18135\n",
      "18136\n",
      "18137\n",
      "18138\n",
      "18139\n",
      "18140\n",
      "18141\n",
      "18142\n",
      "18143\n",
      "18144\n",
      "18145\n",
      "18146\n",
      "18147\n",
      "18148\n",
      "18149\n",
      "18150\n",
      "18151\n",
      "18152\n",
      "18153\n",
      "18154\n",
      "18155\n",
      "18156\n",
      "18157\n",
      "18158\n",
      "18159\n",
      "18160\n",
      "18161\n",
      "18162\n",
      "18163\n",
      "18164\n",
      "18165\n",
      "18166\n",
      "18167\n",
      "18168\n",
      "18169\n",
      "18170\n",
      "18171\n",
      "18172\n",
      "18173\n",
      "18174\n",
      "18175\n",
      "18176\n",
      "18177\n",
      "18178\n",
      "18179\n",
      "18180\n",
      "18181\n",
      "18182\n",
      "18183\n",
      "18184\n",
      "18185\n",
      "18186\n",
      "18187\n",
      "18188\n",
      "18189\n",
      "18190\n",
      "18191\n",
      "18192\n",
      "18193\n",
      "18194\n",
      "18195\n",
      "18196\n",
      "18197\n",
      "18198\n",
      "18199\n",
      "18200\n",
      "18201\n",
      "18202\n",
      "18203\n",
      "18204\n",
      "18205\n",
      "18206\n",
      "18207\n",
      "18208\n",
      "18209\n",
      "18210\n",
      "18211\n",
      "18212\n",
      "18213\n",
      "18214\n",
      "18215\n",
      "18216\n",
      "18217\n",
      "18218\n",
      "18219\n",
      "18220\n",
      "18221\n",
      "18222\n",
      "18223\n",
      "18224\n",
      "18225\n",
      "18226\n",
      "18227\n",
      "18228\n",
      "18229\n",
      "18230\n",
      "18231\n",
      "18232\n",
      "18233\n",
      "18234\n",
      "18235\n",
      "18236\n",
      "18237\n",
      "18238\n",
      "18239\n",
      "18240\n",
      "18241\n",
      "18242\n",
      "18243\n",
      "18244\n",
      "18245\n",
      "18246\n",
      "18247\n",
      "18248\n",
      "18249\n",
      "18250\n",
      "18251\n",
      "18252\n",
      "18253\n",
      "18254\n",
      "18255\n",
      "18256\n",
      "18257\n",
      "18258\n",
      "18259\n",
      "18260\n",
      "18261\n",
      "18262\n",
      "18263\n",
      "18264\n",
      "18265\n",
      "18266\n",
      "18267\n",
      "18268\n",
      "18269\n",
      "18270\n",
      "18271\n",
      "18272\n",
      "18273\n",
      "18274\n",
      "18275\n",
      "18276\n",
      "18277\n",
      "18278\n",
      "18279\n",
      "18280\n",
      "18281\n",
      "18282\n",
      "18283\n",
      "18284\n",
      "18285\n",
      "18286\n",
      "18287\n",
      "18288\n",
      "18289\n",
      "18290\n",
      "18291\n",
      "18292\n",
      "18293\n",
      "18294\n",
      "18295\n",
      "18296\n",
      "18297\n",
      "18298\n",
      "18299\n",
      "18300\n",
      "18301\n",
      "18302\n",
      "18303\n",
      "18304\n",
      "18305\n",
      "18306\n",
      "18307\n",
      "18308\n",
      "18309\n",
      "18310\n",
      "18311\n",
      "18312\n",
      "18313\n",
      "18314\n",
      "18315\n",
      "18316\n",
      "18317\n",
      "18318\n",
      "18319\n",
      "18320\n",
      "18321\n",
      "18322\n",
      "18323\n",
      "18324\n",
      "18325\n",
      "18326\n",
      "18327\n",
      "18328\n",
      "18329\n",
      "18330\n",
      "18331\n",
      "18332\n",
      "18333\n",
      "18334\n",
      "18335\n",
      "18336\n",
      "18337\n",
      "18338\n",
      "18339\n",
      "18340\n",
      "18341\n",
      "18342\n",
      "18343\n",
      "18344\n",
      "18345\n",
      "18346\n",
      "18347\n",
      "18348\n",
      "18349\n",
      "18350\n",
      "18351\n",
      "18352\n",
      "18353\n",
      "18354\n",
      "18355\n",
      "18356\n",
      "18357\n",
      "18358\n",
      "18359\n",
      "18360\n",
      "18361\n",
      "18362\n",
      "18363\n",
      "18364\n",
      "18365\n",
      "18366\n",
      "18367\n",
      "18368\n",
      "18369\n",
      "18370\n",
      "18371\n",
      "18372\n",
      "18373\n",
      "18374\n",
      "18375\n",
      "18376\n",
      "18377\n",
      "18378\n",
      "18379\n",
      "18380\n",
      "18381\n",
      "18382\n",
      "18383\n",
      "18384\n",
      "18385\n",
      "18386\n",
      "18387\n",
      "18388\n",
      "18389\n",
      "18390\n",
      "18391\n",
      "18392\n",
      "18393\n",
      "18394\n",
      "18395\n",
      "18396\n",
      "18397\n",
      "18398\n",
      "18399\n",
      "18400\n",
      "18401\n",
      "18402\n",
      "18403\n",
      "18404\n",
      "18405\n",
      "18406\n",
      "18407\n",
      "18408\n",
      "18409\n",
      "18410\n",
      "18411\n",
      "18412\n",
      "18413\n",
      "18414\n",
      "18415\n",
      "18416\n",
      "18417\n",
      "18418\n",
      "18419\n",
      "18420\n",
      "18421\n",
      "18422\n",
      "18423\n",
      "18424\n",
      "18425\n",
      "18426\n",
      "18427\n",
      "18428\n",
      "18429\n",
      "18430\n",
      "18431\n",
      "18432\n",
      "18433\n",
      "18434\n",
      "18435\n",
      "18436\n",
      "18437\n",
      "18438\n",
      "18439\n",
      "18440\n",
      "18441\n",
      "18442\n",
      "18443\n",
      "18444\n",
      "18445\n",
      "18446\n",
      "18447\n",
      "18448\n",
      "18449\n",
      "18450\n",
      "18451\n",
      "18452\n",
      "18453\n",
      "18454\n",
      "18455\n",
      "18456\n",
      "18457\n",
      "18458\n",
      "18459\n",
      "18460\n",
      "18461\n",
      "18462\n",
      "18463\n",
      "18464\n",
      "18465\n",
      "18466\n",
      "18467\n",
      "18468\n",
      "18469\n",
      "18470\n",
      "18471\n",
      "18472\n",
      "18473\n",
      "18474\n",
      "18475\n",
      "18476\n",
      "18477\n",
      "18478\n",
      "18479\n",
      "18480\n",
      "18481\n",
      "18482\n",
      "18483\n",
      "18484\n",
      "18485\n",
      "18486\n",
      "18487\n",
      "18488\n",
      "18489\n",
      "18490\n",
      "18491\n",
      "18492\n",
      "18493\n",
      "18494\n",
      "18495\n",
      "18496\n",
      "18497\n",
      "18498\n",
      "18499\n",
      "18500\n",
      "18501\n",
      "18502\n",
      "18503\n",
      "18504\n",
      "18505\n",
      "18506\n",
      "18507\n",
      "18508\n",
      "18509\n",
      "18510\n",
      "18511\n",
      "18512\n",
      "18513\n",
      "18514\n",
      "18515\n",
      "18516\n",
      "18517\n",
      "18518\n",
      "18519\n",
      "18520\n",
      "18521\n",
      "18522\n",
      "18523\n",
      "18524\n",
      "18525\n",
      "18526\n",
      "18527\n",
      "18528\n",
      "18529\n",
      "18530\n",
      "18531\n",
      "18532\n",
      "18533\n",
      "18534\n",
      "18535\n",
      "18536\n",
      "18537\n",
      "18538\n",
      "18539\n",
      "18540\n",
      "18541\n",
      "18542\n",
      "18543\n",
      "18544\n",
      "18545\n",
      "18546\n",
      "18547\n",
      "18548\n",
      "18549\n",
      "18550\n",
      "18551\n",
      "18552\n",
      "18553\n",
      "18554\n",
      "18555\n",
      "18556\n",
      "18557\n",
      "18558\n",
      "18559\n",
      "18560\n",
      "18561\n",
      "18562\n",
      "18563\n",
      "18564\n",
      "18565\n",
      "18566\n",
      "18567\n",
      "18568\n",
      "18569\n",
      "18570\n",
      "18571\n",
      "18572\n",
      "18573\n",
      "18574\n",
      "18575\n",
      "18576\n",
      "18577\n",
      "18578\n",
      "18579\n",
      "18580\n",
      "18581\n",
      "18582\n",
      "18583\n",
      "18584\n",
      "18585\n",
      "18586\n",
      "18587\n",
      "18588\n",
      "18589\n",
      "18590\n",
      "18591\n",
      "18592\n",
      "18593\n",
      "18594\n",
      "18595\n",
      "18596\n",
      "18597\n",
      "18598\n",
      "18599\n",
      "18600\n",
      "18601\n",
      "18602\n",
      "18603\n",
      "18604\n",
      "18605\n",
      "18606\n",
      "18607\n",
      "18608\n",
      "18609\n",
      "18610\n",
      "18611\n",
      "18612\n",
      "18613\n",
      "18614\n",
      "18615\n",
      "18616\n",
      "18617\n",
      "18618\n",
      "18619\n",
      "18620\n",
      "18621\n",
      "18622\n",
      "18623\n",
      "18624\n",
      "18625\n",
      "18626\n",
      "18627\n",
      "18628\n",
      "18629\n",
      "18630\n",
      "18631\n",
      "18632\n",
      "18633\n",
      "18634\n",
      "18635\n",
      "18636\n",
      "18637\n",
      "18638\n",
      "18639\n",
      "18640\n",
      "18641\n",
      "18642\n",
      "18643\n",
      "18644\n",
      "18645\n",
      "18646\n",
      "18647\n",
      "18648\n",
      "18649\n",
      "18650\n",
      "18651\n",
      "18652\n",
      "18653\n",
      "18654\n",
      "18655\n",
      "18656\n",
      "18657\n",
      "18658\n",
      "18659\n",
      "18660\n",
      "18661\n",
      "18662\n",
      "18663\n",
      "18664\n",
      "18665\n",
      "18666\n",
      "18667\n",
      "18668\n",
      "18669\n",
      "18670\n",
      "18671\n",
      "18672\n",
      "18673\n",
      "18674\n",
      "18675\n",
      "18676\n",
      "18677\n",
      "18678\n",
      "18679\n",
      "18680\n",
      "18681\n",
      "18682\n",
      "18683\n",
      "18684\n",
      "18685\n",
      "18686\n",
      "18687\n",
      "18688\n",
      "18689\n",
      "18690\n",
      "18691\n",
      "18692\n",
      "18693\n",
      "18694\n",
      "18695\n",
      "18696\n",
      "18697\n",
      "18698\n",
      "18699\n",
      "18700\n",
      "18701\n",
      "18702\n",
      "18703\n",
      "18704\n",
      "18705\n",
      "18706\n",
      "18707\n",
      "18708\n",
      "18709\n",
      "18710\n",
      "18711\n",
      "18712\n",
      "18713\n",
      "18714\n",
      "18715\n",
      "18716\n",
      "18717\n",
      "18718\n",
      "18719\n",
      "18720\n",
      "18721\n",
      "18722\n",
      "18723\n",
      "18724\n",
      "18725\n",
      "18726\n",
      "18727\n",
      "18728\n",
      "18729\n",
      "18730\n",
      "18731\n",
      "18732\n",
      "18733\n",
      "18734\n",
      "18735\n",
      "18736\n",
      "18737\n",
      "18738\n",
      "18739\n",
      "18740\n",
      "18741\n",
      "18742\n",
      "18743\n",
      "18744\n",
      "18745\n",
      "18746\n",
      "18747\n",
      "18748\n",
      "18749\n",
      "18750\n",
      "18751\n",
      "18752\n",
      "18753\n",
      "18754\n",
      "18755\n",
      "18756\n",
      "18757\n",
      "18758\n",
      "18759\n",
      "18760\n",
      "18761\n",
      "18762\n",
      "18763\n",
      "18764\n",
      "18765\n",
      "18766\n",
      "18767\n",
      "18768\n",
      "18769\n",
      "18770\n",
      "18771\n",
      "18772\n",
      "18773\n",
      "18774\n",
      "18775\n",
      "18776\n",
      "18777\n",
      "18778\n",
      "18779\n",
      "18780\n",
      "18781\n",
      "18782\n",
      "18783\n",
      "18784\n",
      "18785\n",
      "18786\n",
      "18787\n",
      "18788\n",
      "18789\n",
      "18790\n",
      "18791\n",
      "18792\n",
      "18793\n",
      "18794\n",
      "18795\n",
      "18796\n",
      "18797\n",
      "18798\n",
      "18799\n",
      "18800\n",
      "18801\n",
      "18802\n",
      "18803\n",
      "18804\n",
      "18805\n",
      "18806\n",
      "18807\n",
      "18808\n",
      "18809\n",
      "18810\n",
      "18811\n",
      "18812\n",
      "18813\n",
      "18814\n",
      "18815\n",
      "18816\n",
      "18817\n",
      "18818\n",
      "18819\n",
      "18820\n",
      "18821\n",
      "18822\n",
      "18823\n",
      "18824\n",
      "18825\n",
      "18826\n",
      "18827\n",
      "18828\n",
      "18829\n",
      "18830\n",
      "18831\n",
      "18832\n",
      "18833\n",
      "18834\n",
      "18835\n",
      "18836\n",
      "18837\n",
      "18838\n",
      "18839\n",
      "18840\n",
      "18841\n",
      "18842\n",
      "18843\n",
      "18844\n",
      "18845\n",
      "18846\n",
      "18847\n",
      "18848\n",
      "18849\n",
      "18850\n",
      "18851\n",
      "18852\n",
      "18853\n",
      "18854\n",
      "18855\n",
      "18856\n",
      "18857\n",
      "18858\n",
      "18859\n",
      "18860\n",
      "18861\n",
      "18862\n",
      "18863\n",
      "18864\n",
      "18865\n",
      "18866\n",
      "18867\n",
      "18868\n",
      "18869\n",
      "18870\n",
      "18871\n",
      "18872\n",
      "18873\n",
      "18874\n",
      "18875\n",
      "18876\n",
      "18877\n",
      "18878\n",
      "18879\n",
      "18880\n",
      "18881\n",
      "18882\n",
      "18883\n",
      "18884\n",
      "18885\n",
      "18886\n",
      "18887\n",
      "18888\n",
      "18889\n",
      "18890\n",
      "18891\n",
      "18892\n",
      "18893\n",
      "18894\n",
      "18895\n",
      "18896\n",
      "18897\n",
      "18898\n",
      "18899\n",
      "18900\n",
      "18901\n",
      "18902\n",
      "18903\n",
      "18904\n",
      "18905\n",
      "18906\n",
      "18907\n",
      "18908\n",
      "18909\n",
      "18910\n",
      "18911\n",
      "18912\n",
      "18913\n",
      "18914\n",
      "18915\n",
      "18916\n",
      "18917\n",
      "18918\n",
      "18919\n",
      "18920\n",
      "18921\n",
      "18922\n",
      "18923\n",
      "18924\n",
      "18925\n",
      "18926\n",
      "18927\n",
      "18928\n",
      "18929\n",
      "18930\n",
      "18931\n",
      "18932\n",
      "18933\n",
      "18934\n",
      "18935\n",
      "18936\n",
      "18937\n",
      "18938\n",
      "18939\n",
      "18940\n",
      "18941\n",
      "18942\n",
      "18943\n",
      "18944\n",
      "18945\n",
      "18946\n",
      "18947\n",
      "18948\n",
      "18949\n",
      "18950\n",
      "18951\n",
      "18952\n",
      "18953\n",
      "18954\n",
      "18955\n",
      "18956\n",
      "18957\n",
      "18958\n",
      "18959\n",
      "18960\n",
      "18961\n",
      "18962\n",
      "18963\n",
      "18964\n",
      "18965\n",
      "18966\n",
      "18967\n",
      "18968\n",
      "18969\n",
      "18970\n",
      "18971\n",
      "18972\n",
      "18973\n",
      "18974\n",
      "18975\n",
      "18976\n",
      "18977\n",
      "18978\n",
      "18979\n",
      "18980\n",
      "18981\n",
      "18982\n",
      "18983\n",
      "18984\n",
      "18985\n",
      "18986\n",
      "18987\n",
      "18988\n",
      "18989\n",
      "18990\n",
      "18991\n",
      "18992\n",
      "18993\n",
      "18994\n",
      "18995\n",
      "18996\n",
      "18997\n",
      "18998\n",
      "18999\n",
      "19000\n",
      "19001\n",
      "19002\n",
      "19003\n",
      "19004\n",
      "19005\n",
      "19006\n",
      "19007\n",
      "19008\n",
      "19009\n",
      "19010\n",
      "19011\n",
      "19012\n",
      "19013\n",
      "19014\n",
      "19015\n",
      "19016\n",
      "19017\n",
      "19018\n",
      "19019\n",
      "19020\n",
      "19021\n",
      "19022\n",
      "19023\n",
      "19024\n",
      "19025\n",
      "19026\n",
      "19027\n",
      "19028\n",
      "19029\n",
      "19030\n",
      "19031\n",
      "19032\n",
      "19033\n",
      "19034\n",
      "19035\n",
      "19036\n",
      "19037\n",
      "19038\n",
      "19039\n",
      "19040\n",
      "19041\n",
      "19042\n",
      "19043\n",
      "19044\n",
      "19045\n",
      "19046\n",
      "19047\n",
      "19048\n",
      "19049\n",
      "19050\n",
      "19051\n",
      "19052\n",
      "19053\n",
      "19054\n",
      "19055\n",
      "19056\n",
      "19057\n",
      "19058\n",
      "19059\n",
      "19060\n",
      "19061\n",
      "19062\n",
      "19063\n",
      "19064\n",
      "19065\n",
      "19066\n",
      "19067\n",
      "19068\n",
      "19069\n",
      "19070\n",
      "19071\n",
      "19072\n",
      "19073\n",
      "19074\n",
      "19075\n",
      "19076\n",
      "19077\n",
      "19078\n",
      "19079\n",
      "19080\n",
      "19081\n",
      "19082\n",
      "19083\n",
      "19084\n",
      "19085\n",
      "19086\n",
      "19087\n",
      "19088\n",
      "19089\n",
      "19090\n",
      "19091\n",
      "19092\n",
      "19093\n",
      "19094\n",
      "19095\n",
      "19096\n",
      "19097\n",
      "19098\n",
      "19099\n",
      "19100\n",
      "19101\n",
      "19102\n",
      "19103\n",
      "19104\n",
      "19105\n",
      "19106\n",
      "19107\n",
      "19108\n",
      "19109\n",
      "19110\n",
      "19111\n",
      "19112\n",
      "19113\n",
      "19114\n",
      "19115\n",
      "19116\n",
      "19117\n",
      "19118\n",
      "19119\n",
      "19120\n",
      "19121\n",
      "19122\n",
      "19123\n",
      "19124\n",
      "19125\n",
      "19126\n",
      "19127\n",
      "19128\n",
      "19129\n",
      "19130\n",
      "19131\n",
      "19132\n",
      "19133\n",
      "19134\n",
      "19135\n",
      "19136\n",
      "19137\n",
      "19138\n",
      "19139\n",
      "19140\n",
      "19141\n",
      "19142\n",
      "19143\n",
      "19144\n",
      "19145\n",
      "19146\n",
      "19147\n",
      "19148\n",
      "19149\n",
      "19150\n",
      "19151\n",
      "19152\n",
      "19153\n",
      "19154\n",
      "19155\n",
      "19156\n",
      "19157\n",
      "19158\n",
      "19159\n",
      "19160\n",
      "19161\n",
      "19162\n",
      "19163\n",
      "19164\n",
      "19165\n",
      "19166\n",
      "19167\n",
      "19168\n",
      "19169\n",
      "19170\n",
      "19171\n",
      "19172\n",
      "19173\n",
      "19174\n",
      "19175\n",
      "19176\n",
      "19177\n",
      "19178\n",
      "19179\n",
      "19180\n",
      "19181\n",
      "19182\n",
      "19183\n",
      "19184\n",
      "19185\n",
      "19186\n",
      "19187\n",
      "19188\n",
      "19189\n",
      "19190\n",
      "19191\n",
      "19192\n",
      "19193\n",
      "19194\n",
      "19195\n",
      "19196\n",
      "19197\n",
      "19198\n",
      "19199\n",
      "19200\n",
      "19201\n",
      "19202\n",
      "19203\n",
      "19204\n",
      "19205\n",
      "19206\n",
      "19207\n",
      "19208\n",
      "19209\n",
      "19210\n",
      "19211\n",
      "19212\n",
      "19213\n",
      "19214\n",
      "19215\n",
      "19216\n",
      "19217\n",
      "19218\n",
      "19219\n",
      "19220\n",
      "19221\n",
      "19222\n",
      "19223\n",
      "19224\n",
      "19225\n",
      "19226\n",
      "19227\n",
      "19228\n",
      "19229\n",
      "19230\n",
      "19231\n",
      "19232\n",
      "19233\n",
      "19234\n",
      "19235\n",
      "19236\n",
      "19237\n",
      "19238\n",
      "19239\n",
      "19240\n",
      "19241\n",
      "19242\n",
      "19243\n",
      "19244\n",
      "19245\n",
      "19246\n",
      "19247\n",
      "19248\n",
      "19249\n",
      "19250\n",
      "19251\n",
      "19252\n",
      "19253\n",
      "19254\n",
      "19255\n",
      "19256\n",
      "19257\n",
      "19258\n",
      "19259\n",
      "19260\n",
      "19261\n",
      "19262\n",
      "19263\n",
      "19264\n",
      "19265\n",
      "19266\n",
      "19267\n",
      "19268\n",
      "19269\n",
      "19270\n",
      "19271\n",
      "19272\n",
      "19273\n",
      "19274\n",
      "19275\n",
      "19276\n",
      "19277\n",
      "19278\n",
      "19279\n",
      "19280\n",
      "19281\n",
      "19282\n",
      "19283\n",
      "19284\n",
      "19285\n",
      "19286\n",
      "19287\n",
      "19288\n",
      "19289\n",
      "19290\n",
      "19291\n",
      "19292\n",
      "19293\n",
      "19294\n",
      "19295\n",
      "19296\n",
      "19297\n",
      "19298\n",
      "19299\n",
      "19300\n",
      "19301\n",
      "19302\n",
      "19303\n",
      "19304\n",
      "19305\n",
      "19306\n",
      "19307\n",
      "19308\n",
      "19309\n",
      "19310\n",
      "19311\n",
      "19312\n",
      "19313\n",
      "19314\n",
      "19315\n",
      "19316\n",
      "19317\n",
      "19318\n",
      "19319\n",
      "19320\n",
      "19321\n",
      "19322\n",
      "19323\n",
      "19324\n",
      "19325\n",
      "19326\n",
      "19327\n",
      "19328\n",
      "19329\n",
      "19330\n",
      "19331\n",
      "19332\n",
      "19333\n",
      "19334\n",
      "19335\n",
      "19336\n",
      "19337\n",
      "19338\n",
      "19339\n",
      "19340\n",
      "19341\n",
      "19342\n",
      "19343\n",
      "19344\n",
      "19345\n",
      "19346\n",
      "19347\n",
      "19348\n",
      "19349\n",
      "19350\n",
      "19351\n",
      "19352\n",
      "19353\n",
      "19354\n",
      "19355\n",
      "19356\n",
      "19357\n",
      "19358\n",
      "19359\n",
      "19360\n",
      "19361\n",
      "19362\n",
      "19363\n",
      "19364\n",
      "19365\n",
      "19366\n",
      "19367\n",
      "19368\n",
      "19369\n",
      "19370\n",
      "19371\n",
      "19372\n",
      "19373\n",
      "19374\n",
      "19375\n",
      "19376\n",
      "19377\n",
      "19378\n",
      "19379\n",
      "19380\n",
      "19381\n",
      "19382\n",
      "19383\n",
      "19384\n",
      "19385\n",
      "19386\n",
      "19387\n",
      "19388\n",
      "19389\n",
      "19390\n",
      "19391\n",
      "19392\n",
      "19393\n",
      "19394\n",
      "19395\n",
      "19396\n",
      "19397\n",
      "19398\n",
      "19399\n",
      "19400\n",
      "19401\n",
      "19402\n",
      "19403\n",
      "19404\n",
      "19405\n",
      "19406\n",
      "19407\n",
      "19408\n",
      "19409\n",
      "19410\n",
      "19411\n",
      "19412\n",
      "19413\n",
      "19414\n",
      "19415\n",
      "19416\n",
      "19417\n",
      "19418\n",
      "19419\n",
      "19420\n",
      "19421\n",
      "19422\n",
      "19423\n",
      "19424\n",
      "19425\n",
      "19426\n",
      "19427\n",
      "19428\n",
      "19429\n",
      "19430\n",
      "19431\n",
      "19432\n",
      "19433\n",
      "19434\n",
      "19435\n",
      "19436\n",
      "19437\n",
      "19438\n",
      "19439\n",
      "19440\n",
      "19441\n",
      "19442\n",
      "19443\n",
      "19444\n",
      "19445\n",
      "19446\n",
      "19447\n",
      "19448\n",
      "19449\n",
      "19450\n",
      "19451\n",
      "19452\n",
      "19453\n",
      "19454\n",
      "19455\n",
      "19456\n",
      "19457\n",
      "19458\n",
      "19459\n",
      "19460\n",
      "19461\n",
      "19462\n",
      "19463\n",
      "19464\n",
      "19465\n",
      "19466\n",
      "19467\n",
      "19468\n",
      "19469\n",
      "19470\n",
      "19471\n",
      "19472\n",
      "19473\n",
      "19474\n",
      "19475\n",
      "19476\n",
      "19477\n",
      "19478\n",
      "19479\n",
      "19480\n",
      "19481\n",
      "19482\n",
      "19483\n",
      "19484\n",
      "19485\n",
      "19486\n",
      "19487\n",
      "19488\n",
      "19489\n",
      "19490\n",
      "19491\n",
      "19492\n",
      "19493\n",
      "19494\n",
      "19495\n",
      "19496\n",
      "19497\n",
      "19498\n",
      "19499\n",
      "19500\n",
      "19501\n",
      "19502\n",
      "19503\n",
      "19504\n",
      "19505\n",
      "19506\n",
      "19507\n",
      "19508\n",
      "19509\n",
      "19510\n",
      "19511\n",
      "19512\n",
      "19513\n",
      "19514\n",
      "19515\n",
      "19516\n",
      "19517\n",
      "19518\n",
      "19519\n",
      "19520\n",
      "19521\n",
      "19522\n",
      "19523\n",
      "19524\n",
      "19525\n",
      "19526\n",
      "19527\n",
      "19528\n",
      "19529\n",
      "19530\n",
      "19531\n",
      "19532\n",
      "19533\n",
      "19534\n",
      "19535\n",
      "19536\n",
      "19537\n",
      "19538\n",
      "19539\n",
      "19540\n",
      "19541\n",
      "19542\n",
      "19543\n",
      "19544\n",
      "19545\n",
      "19546\n",
      "19547\n",
      "19548\n",
      "19549\n",
      "19550\n",
      "19551\n",
      "19552\n",
      "19553\n",
      "19554\n",
      "19555\n",
      "19556\n",
      "19557\n",
      "19558\n",
      "19559\n",
      "19560\n",
      "19561\n",
      "19562\n",
      "19563\n",
      "19564\n",
      "19565\n",
      "19566\n",
      "19567\n",
      "19568\n",
      "19569\n",
      "19570\n",
      "19571\n",
      "19572\n",
      "19573\n",
      "19574\n",
      "19575\n",
      "19576\n",
      "19577\n",
      "19578\n",
      "19579\n",
      "19580\n",
      "19581\n",
      "19582\n",
      "19583\n",
      "19584\n",
      "19585\n",
      "19586\n",
      "19587\n",
      "19588\n",
      "19589\n",
      "19590\n",
      "19591\n",
      "19592\n",
      "19593\n",
      "19594\n",
      "19595\n",
      "19596\n",
      "19597\n",
      "19598\n",
      "19599\n",
      "19600\n",
      "19601\n",
      "19602\n",
      "19603\n",
      "19604\n",
      "19605\n",
      "19606\n",
      "19607\n",
      "19608\n",
      "19609\n",
      "19610\n",
      "19611\n",
      "19612\n",
      "19613\n",
      "19614\n",
      "19615\n",
      "19616\n",
      "19617\n",
      "19618\n",
      "19619\n",
      "19620\n",
      "19621\n",
      "19622\n",
      "19623\n",
      "19624\n",
      "19625\n",
      "19626\n",
      "19627\n",
      "19628\n",
      "19629\n",
      "19630\n",
      "19631\n",
      "19632\n",
      "19633\n",
      "19634\n",
      "19635\n",
      "19636\n",
      "19637\n",
      "19638\n",
      "19639\n",
      "19640\n",
      "19641\n",
      "19642\n",
      "19643\n",
      "19644\n",
      "19645\n",
      "19646\n",
      "19647\n",
      "19648\n",
      "19649\n",
      "19650\n",
      "19651\n",
      "19652\n",
      "19653\n",
      "19654\n",
      "19655\n",
      "19656\n",
      "19657\n",
      "19658\n",
      "19659\n",
      "19660\n",
      "19661\n",
      "19662\n",
      "19663\n",
      "19664\n",
      "19665\n",
      "19666\n",
      "19667\n",
      "19668\n",
      "19669\n",
      "19670\n",
      "19671\n",
      "19672\n",
      "19673\n",
      "19674\n",
      "19675\n",
      "19676\n",
      "19677\n",
      "19678\n",
      "19679\n",
      "19680\n",
      "19681\n",
      "19682\n",
      "19683\n",
      "19684\n",
      "19685\n",
      "19686\n",
      "19687\n",
      "19688\n",
      "19689\n",
      "19690\n",
      "19691\n",
      "19692\n",
      "19693\n",
      "19694\n",
      "19695\n",
      "19696\n",
      "19697\n",
      "19698\n",
      "19699\n",
      "19700\n",
      "19701\n",
      "19702\n",
      "19703\n",
      "19704\n",
      "19705\n",
      "19706\n",
      "19707\n",
      "19708\n",
      "19709\n",
      "19710\n",
      "19711\n",
      "19712\n",
      "19713\n",
      "19714\n",
      "19715\n",
      "19716\n",
      "19717\n",
      "19718\n",
      "19719\n",
      "19720\n",
      "19721\n",
      "19722\n",
      "19723\n",
      "19724\n",
      "19725\n",
      "19726\n",
      "19727\n",
      "19728\n",
      "19729\n",
      "19730\n",
      "19731\n",
      "19732\n",
      "19733\n",
      "19734\n",
      "19735\n",
      "19736\n",
      "19737\n",
      "19738\n",
      "19739\n",
      "19740\n",
      "19741\n",
      "19742\n",
      "19743\n",
      "19744\n",
      "19745\n",
      "19746\n",
      "19747\n",
      "19748\n",
      "19749\n",
      "19750\n",
      "19751\n",
      "19752\n",
      "19753\n",
      "19754\n",
      "19755\n",
      "19756\n",
      "19757\n",
      "19758\n",
      "19759\n",
      "19760\n",
      "19761\n",
      "19762\n",
      "19763\n",
      "19764\n",
      "19765\n",
      "19766\n",
      "19767\n",
      "19768\n",
      "19769\n",
      "19770\n",
      "19771\n",
      "19772\n",
      "19773\n",
      "19774\n",
      "19775\n",
      "19776\n",
      "19777\n",
      "19778\n",
      "19779\n",
      "19780\n",
      "19781\n",
      "19782\n",
      "19783\n",
      "19784\n",
      "19785\n",
      "19786\n",
      "19787\n",
      "19788\n",
      "19789\n",
      "19790\n",
      "19791\n",
      "19792\n",
      "19793\n",
      "19794\n",
      "19795\n",
      "19796\n",
      "19797\n",
      "19798\n",
      "19799\n",
      "19800\n",
      "19801\n",
      "19802\n",
      "19803\n",
      "19804\n",
      "19805\n",
      "19806\n",
      "19807\n",
      "19808\n",
      "19809\n",
      "19810\n",
      "19811\n",
      "19812\n",
      "19813\n",
      "19814\n",
      "19815\n",
      "19816\n",
      "19817\n",
      "19818\n",
      "19819\n",
      "19820\n",
      "19821\n",
      "19822\n",
      "19823\n",
      "19824\n",
      "19825\n",
      "19826\n",
      "19827\n",
      "19828\n",
      "19829\n",
      "19830\n",
      "19831\n",
      "19832\n",
      "19833\n",
      "19834\n",
      "19835\n",
      "19836\n",
      "19837\n",
      "19838\n",
      "19839\n",
      "19840\n",
      "19841\n",
      "19842\n",
      "19843\n",
      "19844\n",
      "19845\n",
      "19846\n",
      "19847\n",
      "19848\n",
      "19849\n",
      "19850\n",
      "19851\n",
      "19852\n",
      "19853\n",
      "19854\n",
      "19855\n",
      "19856\n",
      "19857\n",
      "19858\n",
      "19859\n",
      "19860\n",
      "19861\n",
      "19862\n",
      "19863\n",
      "19864\n",
      "19865\n",
      "19866\n",
      "19867\n",
      "19868\n",
      "19869\n",
      "19870\n",
      "19871\n",
      "19872\n",
      "19873\n",
      "19874\n",
      "19875\n",
      "19876\n",
      "19877\n",
      "19878\n",
      "19879\n",
      "19880\n",
      "19881\n",
      "19882\n",
      "19883\n",
      "19884\n",
      "19885\n",
      "19886\n",
      "19887\n",
      "19888\n",
      "19889\n",
      "19890\n",
      "19891\n",
      "19892\n",
      "19893\n",
      "19894\n",
      "19895\n",
      "19896\n",
      "19897\n",
      "19898\n",
      "19899\n",
      "19900\n",
      "19901\n",
      "19902\n",
      "19903\n",
      "19904\n",
      "19905\n",
      "19906\n",
      "19907\n",
      "19908\n",
      "19909\n",
      "19910\n",
      "19911\n",
      "19912\n",
      "19913\n",
      "19914\n",
      "19915\n",
      "19916\n",
      "19917\n",
      "19918\n",
      "19919\n",
      "19920\n",
      "19921\n",
      "19922\n",
      "19923\n",
      "19924\n",
      "19925\n",
      "19926\n",
      "19927\n",
      "19928\n",
      "19929\n",
      "19930\n",
      "19931\n",
      "19932\n",
      "19933\n",
      "19934\n",
      "19935\n",
      "19936\n",
      "19937\n",
      "19938\n",
      "19939\n",
      "19940\n",
      "19941\n",
      "19942\n",
      "19943\n",
      "19944\n",
      "19945\n",
      "19946\n",
      "19947\n",
      "19948\n",
      "19949\n",
      "19950\n",
      "19951\n",
      "19952\n",
      "19953\n",
      "19954\n",
      "19955\n",
      "19956\n",
      "19957\n",
      "19958\n",
      "19959\n",
      "19960\n",
      "19961\n",
      "19962\n",
      "19963\n",
      "19964\n",
      "19965\n",
      "19966\n",
      "19967\n",
      "19968\n",
      "19969\n",
      "19970\n",
      "19971\n",
      "19972\n",
      "19973\n",
      "19974\n",
      "19975\n",
      "19976\n",
      "19977\n",
      "19978\n",
      "19979\n",
      "19980\n",
      "19981\n",
      "19982\n",
      "19983\n",
      "19984\n",
      "19985\n",
      "19986\n",
      "19987\n",
      "19988\n",
      "19989\n",
      "19990\n",
      "19991\n",
      "19992\n",
      "19993\n",
      "19994\n",
      "19995\n",
      "19996\n",
      "19997\n",
      "19998\n",
      "19999\n",
      "Max abs error is:  0.327242910861969\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Domain and Sampling\n",
    "def interior(n=1000):\n",
    "    x = torch.rand(n, 1).to(device)\n",
    "    y = torch.rand(n, 1).to(device)\n",
    "    cond = (2 - x ** 2) * torch.exp(-y).to(device)\n",
    "    return x.requires_grad_(True), y.requires_grad_(True), cond\n",
    "\n",
    "\n",
    "def down_yy(n=100):\n",
    "    x = torch.rand(n, 1).to(device)\n",
    "    y = torch.zeros_like(x).to(device)\n",
    "    cond = (x ** 2).to(device)\n",
    "    return x.requires_grad_(True), y.requires_grad_(True), cond\n",
    "\n",
    "\n",
    "def up_yy(n=100):\n",
    "    x = torch.rand(n, 1).to(device)\n",
    "    y = torch.ones_like(x).to(device)\n",
    "    cond = (x ** 2 / torch.e).to(device)\n",
    "    return x.requires_grad_(True), y.requires_grad_(True), cond\n",
    "\n",
    "\n",
    "def down(n=100):\n",
    "    x = torch.rand(n, 1).to(device)\n",
    "    y = torch.zeros_like(x).to(device)\n",
    "    cond = (x ** 2).to(device)\n",
    "    return x.requires_grad_(True), y.requires_grad_(True), cond\n",
    "\n",
    "\n",
    "def up(n=100):\n",
    "    x = torch.rand(n, 1).to(device)\n",
    "    y = torch.ones_like(x).to(device)\n",
    "    cond = (x ** 2 / torch.e).to(device)\n",
    "    return x.requires_grad_(True), y.requires_grad_(True), cond\n",
    "\n",
    "\n",
    "def left(n=100):\n",
    "    y = torch.rand(n, 1).to(device)\n",
    "    x = torch.zeros_like(y).to(device)\n",
    "    cond = torch.zeros_like(x).to(device)\n",
    "    return x.requires_grad_(True), y.requires_grad_(True), cond\n",
    "\n",
    "\n",
    "def right(n=100):\n",
    "    y = torch.rand(n, 1).to(device)\n",
    "    x = torch.ones_like(y).to(device)\n",
    "    cond = torch.exp(-y).to(device)\n",
    "    return x.requires_grad_(True), y.requires_grad_(True), cond\n",
    "\n",
    "\n",
    "# Neural Network\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2, 32),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(32, 32),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(32, 32),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(32, 32),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# Loss\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "def gradients(u, x, order=1):\n",
    "    if order == 1:\n",
    "        return torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u),\n",
    "                                   create_graph=True,\n",
    "                                   only_inputs=True, )[0]\n",
    "    else:\n",
    "        return gradients(gradients(u, x), x, order=order - 1)\n",
    "\n",
    "\n",
    "def l_interior(u):\n",
    "    x, y, cond = interior()\n",
    "    uxy = u(torch.cat([x, y], dim=1))\n",
    "    return loss(gradients(uxy, x, 2) - gradients(uxy, y, 4), cond)\n",
    "\n",
    "\n",
    "def l_down_yy(u):\n",
    "    x, y, cond = down_yy()\n",
    "    uxy = u(torch.cat([x, y], dim=1))\n",
    "    return loss(gradients(uxy, y, 2), cond)\n",
    "\n",
    "\n",
    "def l_up_yy(u):\n",
    "    x, y, cond = up_yy()\n",
    "    uxy = u(torch.cat([x, y], dim=1))\n",
    "    return loss(gradients(uxy, y, 2), cond)\n",
    "\n",
    "\n",
    "def l_down(u):\n",
    "    x, y, cond = down()\n",
    "    uxy = u(torch.cat([x, y], dim=1))\n",
    "    return loss(uxy, cond)\n",
    "\n",
    "\n",
    "def l_up(u):\n",
    "    x, y, cond = up()\n",
    "    uxy = u(torch.cat([x, y], dim=1))\n",
    "    return loss(uxy, cond)\n",
    "\n",
    "\n",
    "def l_left(u):\n",
    "    x, y, cond = left()\n",
    "    uxy = u(torch.cat([x, y], dim=1))\n",
    "    return loss(uxy, cond)\n",
    "\n",
    "\n",
    "def l_right(u):\n",
    "    x, y, cond = right()\n",
    "    uxy = u(torch.cat([x, y], dim=1))\n",
    "    return loss(uxy, cond)\n",
    "\n",
    "\n",
    "# Training\n",
    "# device = 'cpu'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "u = MLP().to(device)\n",
    "opt = torch.optim.Adam(params=u.parameters())\n",
    "for i in range(20000):\n",
    "    opt.zero_grad()\n",
    "    l = l_interior(u) \\\n",
    "        + l_up_yy(u) \\\n",
    "        + l_down_yy(u) \\\n",
    "        + l_up(u) \\\n",
    "        + l_down(u) \\\n",
    "        + l_left(u) \\\n",
    "        + l_right(u)\n",
    "    l.backward()\n",
    "    opt.step()\n",
    "    print(i)\n",
    "\n",
    "# Inference\n",
    "xc = torch.linspace(2, 3, 100).to(device)\n",
    "xx, yy = torch.meshgrid(xc, xc,indexing='xy')\n",
    "xx = xx.reshape(-1, 1).to(device)\n",
    "yy = yy.reshape(-1, 1) .to(device)\n",
    "xy = torch.cat([xx, yy], dim=1).to(device)\n",
    "u_pred = u(xy)\n",
    "u_true = xx * xx * torch.exp(-yy).to(device) \n",
    "print(\"Max abs error is: \", float(torch.max(torch.abs(u_pred - u_true))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
